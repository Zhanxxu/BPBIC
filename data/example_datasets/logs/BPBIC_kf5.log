2022-10-29 12:24:28
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY++++++++++++++++++++++++++++++++++++++++
 Status:
     mode                 : train
 ++++++++++++++++++++++++++++++++++++++++
 Datasets:
     datasets         fold: data/example_datasets
     train            file: train_1920.csv
     validation       file: None
     vocab             dir: data/example_datasets/vocab/BPBIC_kf5
     delimiter            : b
     use  pretrained model: True
     pretrained      model: Bert
     finetune             : False
     use    middle   model: True
     middle          model: bilstm+idcnn
     checkpoints       dir: checkpoints/BPBIC_kf5
     log               dir: data/example_datasets/logs
 ++++++++++++++++++++++++++++++++++++++++
Labeling Scheme:
     label          scheme: BIO
     label           level: 2
     suffixes             : ['Dsa', 'Chk', 'Ins', 'Sur', 'Med', 'Ana']
     measuring     metrics: ['precision', 'recall', 'f1', 'accuracy']
 ++++++++++++++++++++++++++++++++++++++++
Model Configuration:
     embedding         dim: 100
     max  sequence  length: 100
     hidden            dim: 128
     filter           nums: 64
     idcnn            nums: 3
     CUDA  VISIBLE  DEVICE: 0
     seed                 : 23
 ++++++++++++++++++++++++++++++++++++++++
 Training Settings:
     epoch                : 100
     batch            size: 8
     dropout              : 0.3
     learning         rate: 0.001
     optimizer            : Adam
     use               gan: True
     gan            method: pgd
     checkpoint       name: model_our
     max       checkpoints: 3
     print       per_batch: 20
     is     early     stop: True
     patient              : 5
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY END++++++++++++++++++++++++++++++++++++++++
label vocab files not exist, building label vocab...
dataManager initialed...
mode: train
loading data...
validating set is not exist, built...
training set size: 11060, validating set size: 2765
++++++++++++++++++++training starting++++++++++++++++++++
epoch:1/100
training batch:    20, loss: 118.77795, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.745 
training batch:    40, loss: 81.34139, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.762 
training batch:    60, loss: 64.06211, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.819 
training batch:    80, loss: 39.95237, precision: 0.500 recall: 0.056 f1: 0.100 accuracy: 0.868 
training batch:   100, loss: 35.41949, precision: 0.267 recall: 0.108 f1: 0.154 accuracy: 0.871 
training batch:   120, loss: 20.01528, precision: 0.593 recall: 0.485 f1: 0.533 accuracy: 0.948 
training batch:   140, loss: 15.54577, precision: 0.409 recall: 0.360 f1: 0.383 accuracy: 0.935 
training batch:   160, loss: 30.70980, precision: 0.444 recall: 0.429 f1: 0.436 accuracy: 0.905 
training batch:   180, loss: 15.68433, precision: 0.588 recall: 0.541 f1: 0.563 accuracy: 0.953 
training batch:   200, loss: 12.62434, precision: 0.765 recall: 0.406 f1: 0.531 accuracy: 0.963 
training batch:   220, loss: 26.46538, precision: 0.649 recall: 0.667 f1: 0.658 accuracy: 0.916 
training batch:   240, loss: 23.62700, precision: 0.696 recall: 0.533 f1: 0.604 accuracy: 0.939 
training batch:   260, loss: 20.09791, precision: 0.583 recall: 0.583 f1: 0.583 accuracy: 0.936 
training batch:   280, loss: 14.11818, precision: 0.679 recall: 0.613 f1: 0.644 accuracy: 0.948 
training batch:   300, loss: 18.78609, precision: 0.735 recall: 0.595 f1: 0.658 accuracy: 0.930 
training batch:   320, loss: 18.15104, precision: 0.840 recall: 0.677 f1: 0.750 accuracy: 0.954 
training batch:   340, loss: 17.49773, precision: 0.875 recall: 0.724 f1: 0.792 accuracy: 0.959 
training batch:   360, loss: 16.10085, precision: 0.793 recall: 0.767 f1: 0.780 accuracy: 0.958 
training batch:   380, loss: 7.07809, precision: 0.828 recall: 0.828 f1: 0.828 accuracy: 0.974 
training batch:   400, loss: 13.35487, precision: 0.811 recall: 0.882 f1: 0.845 accuracy: 0.950 
training batch:   420, loss: 11.89120, precision: 0.692 recall: 0.750 f1: 0.720 accuracy: 0.946 
training batch:   440, loss: 6.92970, precision: 0.816 recall: 0.838 f1: 0.827 accuracy: 0.984 
training batch:   460, loss: 23.94820, precision: 0.568 recall: 0.583 f1: 0.575 accuracy: 0.896 
training batch:   480, loss: 10.26830, precision: 0.765 recall: 0.765 f1: 0.765 accuracy: 0.966 
training batch:   500, loss: 4.76855, precision: 0.771 recall: 0.794 f1: 0.783 accuracy: 0.979 
training batch:   520, loss: 9.27666, precision: 0.724 recall: 0.700 f1: 0.712 accuracy: 0.961 
training batch:   540, loss: 13.76180, precision: 0.862 recall: 0.625 f1: 0.725 accuracy: 0.953 
training batch:   560, loss: 8.78555, precision: 0.917 recall: 0.786 f1: 0.846 accuracy: 0.990 
training batch:   580, loss: 13.95930, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.981 
training batch:   600, loss: 5.79439, precision: 0.871 recall: 0.818 f1: 0.844 accuracy: 0.973 
training batch:   620, loss: 15.69514, precision: 0.667 recall: 0.688 f1: 0.677 accuracy: 0.953 
training batch:   640, loss: 10.57323, precision: 0.800 recall: 0.780 f1: 0.790 accuracy: 0.935 
training batch:   660, loss: 7.66794, precision: 0.721 recall: 0.689 f1: 0.705 accuracy: 0.966 
training batch:   680, loss: 6.85555, precision: 0.757 recall: 0.875 f1: 0.812 accuracy: 0.969 
training batch:   700, loss: 5.92986, precision: 0.750 recall: 0.875 f1: 0.808 accuracy: 0.975 
training batch:   720, loss: 15.48538, precision: 0.769 recall: 0.732 f1: 0.750 accuracy: 0.959 
training batch:   740, loss: 8.30657, precision: 0.867 recall: 0.812 f1: 0.839 accuracy: 0.980 
training batch:   760, loss: 5.27247, precision: 0.758 recall: 0.781 f1: 0.769 accuracy: 0.973 
training batch:   780, loss: 7.61674, precision: 0.800 recall: 0.737 f1: 0.767 accuracy: 0.971 
training batch:   800, loss: 4.25406, precision: 0.862 recall: 0.781 f1: 0.820 accuracy: 0.983 
training batch:   820, loss: 9.47493, precision: 0.821 recall: 0.780 f1: 0.800 accuracy: 0.971 
training batch:   840, loss: 4.72947, precision: 0.842 recall: 0.865 f1: 0.853 accuracy: 0.973 
training batch:   860, loss: 3.09769, precision: 0.912 recall: 0.969 f1: 0.939 accuracy: 0.988 
training batch:   880, loss: 4.93639, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.990 
training batch:   900, loss: 7.07330, precision: 0.769 recall: 0.732 f1: 0.750 accuracy: 0.974 
training batch:   920, loss: 6.28205, precision: 0.840 recall: 0.840 f1: 0.840 accuracy: 0.979 
training batch:   940, loss: 7.12179, precision: 0.800 recall: 0.750 f1: 0.774 accuracy: 0.978 
training batch:   960, loss: 4.09634, precision: 0.875 recall: 0.757 f1: 0.812 accuracy: 0.986 
training batch:   980, loss: 7.26387, precision: 0.947 recall: 0.783 f1: 0.857 accuracy: 0.979 
training batch:  1000, loss: 8.33041, precision: 0.938 recall: 0.882 f1: 0.909 accuracy: 0.973 
training batch:  1020, loss: 6.36655, precision: 0.795 recall: 0.854 f1: 0.824 accuracy: 0.981 
training batch:  1040, loss: 10.09177, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.956 
training batch:  1060, loss: 6.63651, precision: 0.789 recall: 0.769 f1: 0.779 accuracy: 0.978 
training batch:  1080, loss: 3.97148, precision: 0.882 recall: 0.811 f1: 0.845 accuracy: 0.988 
training batch:  1100, loss: 7.49087, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.975 
training batch:  1120, loss: 7.70705, precision: 0.844 recall: 0.844 f1: 0.844 accuracy: 0.958 
training batch:  1140, loss: 2.46194, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.995 
training batch:  1160, loss: 7.85419, precision: 0.795 recall: 0.816 f1: 0.805 accuracy: 0.974 
training batch:  1180, loss: 4.54401, precision: 0.833 recall: 0.882 f1: 0.857 accuracy: 0.981 
training batch:  1200, loss: 5.73825, precision: 0.857 recall: 0.889 f1: 0.873 accuracy: 0.986 
training batch:  1220, loss: 7.66593, precision: 0.950 recall: 0.905 f1: 0.927 accuracy: 0.970 
training batch:  1240, loss: 2.59106, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.995 
training batch:  1260, loss: 4.30682, precision: 0.867 recall: 0.839 f1: 0.852 accuracy: 0.983 
training batch:  1280, loss: 2.24548, precision: 0.897 recall: 0.946 f1: 0.921 accuracy: 0.994 
training batch:  1300, loss: 5.83836, precision: 0.926 recall: 0.833 f1: 0.877 accuracy: 0.980 
training batch:  1320, loss: 3.64865, precision: 0.878 recall: 0.947 f1: 0.911 accuracy: 0.991 
training batch:  1340, loss: 10.19670, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.990 
training batch:  1360, loss: 4.51308, precision: 0.848 recall: 0.824 f1: 0.836 accuracy: 0.973 
training batch:  1380, loss: 2.16472, precision: 0.962 recall: 0.926 f1: 0.943 accuracy: 0.994 
start evaluate engines...
label: Dsa, precision: 0.928 recall: 0.920 f1: 0.922 
label: Chk, precision: 0.642 recall: 0.665 f1: 0.649 
label: Ins, precision: 0.389 recall: 0.401 f1: 0.392 
label: Sur, precision: 0.824 recall: 0.818 f1: 0.819 
label: Med, precision: 0.434 recall: 0.432 f1: 0.431 
label: Ana, precision: 0.926 recall: 0.936 f1: 0.930 
time consumption:17.10(min), precision: 0.934 recall: 0.938 f1: 0.936 accuracy: 0.991 
saved the new best model with f1: 0.936
epoch:2/100
training batch:    20, loss: 4.90123, precision: 0.846 recall: 0.892 f1: 0.868 accuracy: 0.975 
training batch:    40, loss: 6.96995, precision: 0.750 recall: 0.818 f1: 0.783 accuracy: 0.974 
training batch:    60, loss: 2.87220, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.984 
training batch:    80, loss: 4.81412, precision: 0.892 recall: 0.892 f1: 0.892 accuracy: 0.990 
training batch:   100, loss: 3.00566, precision: 0.886 recall: 1.000 f1: 0.940 accuracy: 0.991 
training batch:   120, loss: 12.06842, precision: 0.842 recall: 0.780 f1: 0.810 accuracy: 0.950 
training batch:   140, loss: 3.23689, precision: 0.865 recall: 0.914 f1: 0.889 accuracy: 0.991 
training batch:   160, loss: 1.02341, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.996 
training batch:   180, loss: 7.70271, precision: 0.829 recall: 0.723 f1: 0.773 accuracy: 0.970 
training batch:   200, loss: 1.52981, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.994 
training batch:   220, loss: 3.18816, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.985 
training batch:   240, loss: 6.21803, precision: 0.903 recall: 0.933 f1: 0.918 accuracy: 0.970 
training batch:   260, loss: 3.79689, precision: 0.833 recall: 0.862 f1: 0.847 accuracy: 0.975 
training batch:   280, loss: 4.73425, precision: 0.898 recall: 0.936 f1: 0.917 accuracy: 0.984 
training batch:   300, loss: 4.03085, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.991 
training batch:   320, loss: 1.75455, precision: 0.923 recall: 0.889 f1: 0.906 accuracy: 0.995 
training batch:   340, loss: 1.09036, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:   360, loss: 3.87442, precision: 0.786 recall: 0.759 f1: 0.772 accuracy: 0.979 
training batch:   380, loss: 2.67375, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.994 
training batch:   400, loss: 4.32211, precision: 0.865 recall: 0.914 f1: 0.889 accuracy: 0.985 
training batch:   420, loss: 2.06751, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.994 
training batch:   440, loss: 5.39124, precision: 0.853 recall: 0.853 f1: 0.853 accuracy: 0.986 
training batch:   460, loss: 4.24294, precision: 0.867 recall: 0.788 f1: 0.825 accuracy: 0.980 
training batch:   480, loss: 4.35527, precision: 0.800 recall: 0.800 f1: 0.800 accuracy: 0.975 
training batch:   500, loss: 3.14398, precision: 0.842 recall: 0.889 f1: 0.865 accuracy: 0.989 
training batch:   520, loss: 2.45578, precision: 0.868 recall: 0.917 f1: 0.892 accuracy: 0.993 
training batch:   540, loss: 4.47388, precision: 0.875 recall: 0.921 f1: 0.897 accuracy: 0.988 
training batch:   560, loss: 1.10172, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   580, loss: 4.45993, precision: 0.881 recall: 0.860 f1: 0.871 accuracy: 0.986 
training batch:   600, loss: 3.59113, precision: 0.927 recall: 0.950 f1: 0.938 accuracy: 0.990 
training batch:   620, loss: 4.43540, precision: 0.833 recall: 0.857 f1: 0.845 accuracy: 0.981 
training batch:   640, loss: 5.14279, precision: 0.860 recall: 0.841 f1: 0.851 accuracy: 0.979 
training batch:   660, loss: 3.96843, precision: 0.860 recall: 0.881 f1: 0.871 accuracy: 0.986 
training batch:   680, loss: 2.66899, precision: 0.895 recall: 0.919 f1: 0.907 accuracy: 0.983 
training batch:   700, loss: 2.05737, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.998 
training batch:   720, loss: 4.47713, precision: 0.833 recall: 0.862 f1: 0.847 accuracy: 0.985 
training batch:   740, loss: 1.40977, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.999 
training batch:   760, loss: 1.51822, precision: 0.932 recall: 0.976 f1: 0.953 accuracy: 0.994 
training batch:   780, loss: 6.76936, precision: 0.893 recall: 0.893 f1: 0.893 accuracy: 0.986 
training batch:   800, loss: 3.83531, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.986 
training batch:   820, loss: 3.87642, precision: 0.844 recall: 0.844 f1: 0.844 accuracy: 0.984 
training batch:   840, loss: 1.94329, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.990 
training batch:   860, loss: 1.56953, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.996 
training batch:   880, loss: 2.46227, precision: 0.903 recall: 0.848 f1: 0.875 accuracy: 0.989 
training batch:   900, loss: 2.30592, precision: 0.875 recall: 0.913 f1: 0.894 accuracy: 0.994 
training batch:   920, loss: 1.22228, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.996 
training batch:   940, loss: 1.99478, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.980 
training batch:   960, loss: 1.58986, precision: 0.913 recall: 0.955 f1: 0.933 accuracy: 0.995 
training batch:   980, loss: 4.11083, precision: 0.964 recall: 0.871 f1: 0.915 accuracy: 0.988 
training batch:  1000, loss: 2.88843, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.990 
training batch:  1020, loss: 2.00282, precision: 0.944 recall: 0.850 f1: 0.895 accuracy: 0.993 
training batch:  1040, loss: 1.94504, precision: 0.778 recall: 0.840 f1: 0.808 accuracy: 0.988 
training batch:  1060, loss: 1.29790, precision: 0.955 recall: 1.000 f1: 0.977 accuracy: 0.996 
training batch:  1080, loss: 2.54358, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.986 
training batch:  1100, loss: 5.68919, precision: 0.885 recall: 0.920 f1: 0.902 accuracy: 0.984 
training batch:  1120, loss: 1.31612, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.994 
training batch:  1140, loss: 6.01220, precision: 0.879 recall: 0.853 f1: 0.866 accuracy: 0.976 
training batch:  1160, loss: 4.35069, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.980 
training batch:  1180, loss: 1.73528, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.988 
training batch:  1200, loss: 2.96402, precision: 0.925 recall: 0.902 f1: 0.914 accuracy: 0.991 
training batch:  1220, loss: 4.13749, precision: 0.944 recall: 0.895 f1: 0.919 accuracy: 0.986 
training batch:  1240, loss: 11.35616, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.978 
training batch:  1260, loss: 4.26460, precision: 0.842 recall: 0.800 f1: 0.821 accuracy: 0.979 
training batch:  1280, loss: 1.71805, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.991 
training batch:  1300, loss: 0.86234, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:  1320, loss: 1.08435, precision: 0.930 recall: 0.952 f1: 0.941 accuracy: 0.995 
training batch:  1340, loss: 0.96994, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.998 
training batch:  1360, loss: 3.48672, precision: 0.810 recall: 0.773 f1: 0.791 accuracy: 0.984 
training batch:  1380, loss: 2.10480, precision: 0.950 recall: 0.927 f1: 0.938 accuracy: 0.988 
start evaluate engines...
label: Dsa, precision: 0.961 recall: 0.962 f1: 0.960 
label: Chk, precision: 0.680 recall: 0.685 f1: 0.682 
label: Ins, precision: 0.411 recall: 0.418 f1: 0.412 
label: Sur, precision: 0.838 recall: 0.839 f1: 0.838 
label: Med, precision: 0.447 recall: 0.446 f1: 0.446 
label: Ana, precision: 0.953 recall: 0.972 f1: 0.962 
time consumption:20.63(min), precision: 0.962 recall: 0.972 f1: 0.967 accuracy: 0.996 
saved the new best model with f1: 0.967
epoch:3/100
training batch:    20, loss: 1.41186, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.994 
training batch:    40, loss: 0.64519, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:    60, loss: 1.41542, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.994 
training batch:    80, loss: 1.67172, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.993 
training batch:   100, loss: 2.58194, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.990 
training batch:   120, loss: 5.34389, precision: 0.857 recall: 0.878 f1: 0.867 accuracy: 0.975 
training batch:   140, loss: 3.22208, precision: 0.850 recall: 0.872 f1: 0.861 accuracy: 0.989 
training batch:   160, loss: 1.13651, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.996 
training batch:   180, loss: 0.55531, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:   200, loss: 1.89001, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.991 
training batch:   220, loss: 2.07410, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.995 
training batch:   240, loss: 3.16119, precision: 0.905 recall: 0.905 f1: 0.905 accuracy: 0.988 
training batch:   260, loss: 2.72169, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.993 
training batch:   280, loss: 7.52847, precision: 0.821 recall: 0.914 f1: 0.865 accuracy: 0.970 
training batch:   300, loss: 0.95107, precision: 0.964 recall: 0.900 f1: 0.931 accuracy: 0.996 
training batch:   320, loss: 1.92534, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.989 
training batch:   340, loss: 1.25824, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.989 
training batch:   360, loss: 2.62096, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.989 
training batch:   380, loss: 1.44902, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.996 
training batch:   400, loss: 1.68248, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.995 
training batch:   420, loss: 1.38757, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.994 
training batch:   440, loss: 0.58327, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   460, loss: 1.48694, precision: 0.929 recall: 0.951 f1: 0.940 accuracy: 0.993 
training batch:   480, loss: 1.50723, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.996 
training batch:   500, loss: 1.34306, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.998 
training batch:   520, loss: 2.25488, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.993 
training batch:   540, loss: 2.24403, precision: 0.913 recall: 0.977 f1: 0.944 accuracy: 0.995 
training batch:   560, loss: 0.26775, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.999 
training batch:   580, loss: 0.71320, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.998 
training batch:   600, loss: 3.08366, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.986 
training batch:   620, loss: 2.36653, precision: 1.000 recall: 0.933 f1: 0.966 accuracy: 0.991 
training batch:   640, loss: 1.04869, precision: 0.875 recall: 0.913 f1: 0.894 accuracy: 0.995 
training batch:   660, loss: 1.93471, precision: 0.875 recall: 0.933 f1: 0.903 accuracy: 0.994 
training batch:   680, loss: 0.68358, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:   700, loss: 0.45576, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 1.20282, precision: 0.935 recall: 0.977 f1: 0.956 accuracy: 0.995 
training batch:   740, loss: 3.67810, precision: 0.879 recall: 0.906 f1: 0.892 accuracy: 0.988 
training batch:   760, loss: 2.96336, precision: 0.848 recall: 0.875 f1: 0.862 accuracy: 0.986 
training batch:   780, loss: 2.26921, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.993 
training batch:   800, loss: 2.35410, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.990 
training batch:   820, loss: 2.31015, precision: 0.853 recall: 0.906 f1: 0.879 accuracy: 0.990 
training batch:   840, loss: 2.15518, precision: 0.951 recall: 1.000 f1: 0.975 accuracy: 0.994 
training batch:   860, loss: 1.50069, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   880, loss: 2.40256, precision: 1.000 recall: 0.828 f1: 0.906 accuracy: 0.989 
training batch:   900, loss: 2.36203, precision: 0.921 recall: 0.897 f1: 0.909 accuracy: 0.979 
training batch:   920, loss: 1.41213, precision: 0.911 recall: 0.953 f1: 0.932 accuracy: 0.994 
training batch:   940, loss: 0.59309, precision: 0.867 recall: 0.897 f1: 0.881 accuracy: 0.996 
training batch:   960, loss: 1.17019, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:   980, loss: 1.14090, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:  1000, loss: 2.29683, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.988 
training batch:  1020, loss: 2.48712, precision: 0.833 recall: 0.909 f1: 0.870 accuracy: 0.985 
training batch:  1040, loss: 1.27080, precision: 0.875 recall: 1.000 f1: 0.933 accuracy: 0.995 
training batch:  1060, loss: 0.84027, precision: 1.000 recall: 0.975 f1: 0.987 accuracy: 0.999 
training batch:  1080, loss: 0.63477, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.996 
training batch:  1100, loss: 1.66641, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.991 
training batch:  1120, loss: 0.53505, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.998 
training batch:  1140, loss: 2.82697, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.990 
training batch:  1160, loss: 4.60779, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.989 
training batch:  1180, loss: 2.32013, precision: 0.972 recall: 0.921 f1: 0.946 accuracy: 0.986 
training batch:  1200, loss: 0.40298, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 2.16833, precision: 0.919 recall: 0.895 f1: 0.907 accuracy: 0.991 
training batch:  1240, loss: 0.97911, precision: 1.000 recall: 0.979 f1: 0.989 accuracy: 0.998 
training batch:  1260, loss: 1.18106, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.995 
training batch:  1280, loss: 2.17474, precision: 0.824 recall: 0.875 f1: 0.848 accuracy: 0.990 
training batch:  1300, loss: 0.22592, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.56333, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1340, loss: 0.46007, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 1.57350, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.995 
training batch:  1380, loss: 1.44302, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.995 
start evaluate engines...
label: Dsa, precision: 0.980 recall: 0.978 f1: 0.978 
label: Chk, precision: 0.680 recall: 0.684 f1: 0.681 
label: Ins, precision: 0.438 recall: 0.435 f1: 0.436 
label: Sur, precision: 0.863 recall: 0.858 f1: 0.860 
label: Med, precision: 0.449 recall: 0.449 f1: 0.449 
label: Ana, precision: 0.981 recall: 0.984 f1: 0.982 
time consumption:20.39(min), precision: 0.986 recall: 0.986 f1: 0.986 accuracy: 0.998 
saved the new best model with f1: 0.986
epoch:4/100
training batch:    20, loss: 2.24672, precision: 0.964 recall: 0.931 f1: 0.947 accuracy: 0.989 
training batch:    40, loss: 1.04835, precision: 0.941 recall: 0.865 f1: 0.901 accuracy: 0.994 
training batch:    60, loss: 1.71251, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.989 
training batch:    80, loss: 1.70442, precision: 0.907 recall: 0.951 f1: 0.929 accuracy: 0.981 
training batch:   100, loss: 1.03102, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.998 
training batch:   120, loss: 1.09111, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:   140, loss: 1.32497, precision: 0.884 recall: 0.950 f1: 0.916 accuracy: 0.994 
training batch:   160, loss: 0.63998, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   180, loss: 1.19707, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:   200, loss: 0.85826, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.998 
training batch:   220, loss: 1.08519, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.999 
training batch:   240, loss: 0.57179, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   260, loss: 1.64199, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.993 
training batch:   280, loss: 0.86717, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.998 
training batch:   300, loss: 1.08345, precision: 0.976 recall: 0.952 f1: 0.964 accuracy: 0.996 
training batch:   320, loss: 0.94656, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.995 
training batch:   340, loss: 0.82281, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.998 
training batch:   360, loss: 0.23145, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 2.02473, precision: 0.897 recall: 0.946 f1: 0.921 accuracy: 0.989 
training batch:   400, loss: 0.87057, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   420, loss: 1.31359, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.998 
training batch:   440, loss: 2.23793, precision: 0.935 recall: 1.000 f1: 0.967 accuracy: 0.995 
training batch:   460, loss: 4.17712, precision: 0.875 recall: 0.966 f1: 0.918 accuracy: 0.981 
training batch:   480, loss: 1.90265, precision: 0.926 recall: 0.833 f1: 0.877 accuracy: 0.993 
training batch:   500, loss: 3.12270, precision: 0.892 recall: 0.868 f1: 0.880 accuracy: 0.979 
training batch:   520, loss: 0.80673, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.996 
training batch:   540, loss: 0.63939, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   560, loss: 0.28065, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:   580, loss: 0.83586, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   600, loss: 0.72644, precision: 0.977 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:   620, loss: 0.79587, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.998 
training batch:   640, loss: 0.94485, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.998 
training batch:   660, loss: 0.18243, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.19845, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.57180, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.998 
training batch:   720, loss: 2.79303, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.994 
training batch:   740, loss: 0.71744, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   760, loss: 0.72583, precision: 0.979 recall: 0.958 f1: 0.968 accuracy: 0.994 
training batch:   780, loss: 2.20918, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.993 
training batch:   800, loss: 0.42797, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:   820, loss: 1.06110, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.998 
training batch:   840, loss: 1.32864, precision: 0.893 recall: 0.893 f1: 0.893 accuracy: 0.991 
training batch:   860, loss: 0.59149, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.996 
training batch:   880, loss: 0.61281, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.998 
training batch:   900, loss: 0.45525, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   920, loss: 0.19228, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   940, loss: 1.74709, precision: 1.000 recall: 0.850 f1: 0.919 accuracy: 0.991 
training batch:   960, loss: 1.68750, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.991 
training batch:   980, loss: 0.67693, precision: 0.935 recall: 1.000 f1: 0.967 accuracy: 0.998 
training batch:  1000, loss: 0.62897, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.996 
training batch:  1020, loss: 1.33672, precision: 0.947 recall: 1.000 f1: 0.973 accuracy: 0.998 
training batch:  1040, loss: 2.14398, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.988 
training batch:  1060, loss: 0.41360, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:  1080, loss: 0.21109, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 2.45208, precision: 0.933 recall: 0.977 f1: 0.955 accuracy: 0.985 
training batch:  1120, loss: 1.20885, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.994 
training batch:  1140, loss: 1.37167, precision: 0.925 recall: 0.925 f1: 0.925 accuracy: 0.995 
training batch:  1160, loss: 0.22905, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.45386, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:  1200, loss: 0.81373, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:  1220, loss: 0.61462, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.998 
training batch:  1240, loss: 1.35745, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:  1260, loss: 0.24052, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 1.43211, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.995 
training batch:  1300, loss: 0.70320, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.995 
training batch:  1320, loss: 1.74733, precision: 0.848 recall: 0.903 f1: 0.875 accuracy: 0.984 
training batch:  1340, loss: 0.36461, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:  1360, loss: 0.97593, precision: 0.961 recall: 0.980 f1: 0.970 accuracy: 0.995 
training batch:  1380, loss: 1.05609, precision: 1.000 recall: 0.951 f1: 0.975 accuracy: 0.993 
start evaluate engines...
label: Dsa, precision: 0.982 recall: 0.982 f1: 0.982 
label: Chk, precision: 0.687 recall: 0.685 f1: 0.686 
label: Ins, precision: 0.428 recall: 0.428 f1: 0.427 
label: Sur, precision: 0.866 recall: 0.866 f1: 0.866 
label: Med, precision: 0.449 recall: 0.450 f1: 0.450 
label: Ana, precision: 0.987 recall: 0.982 f1: 0.984 
time consumption:19.81(min), precision: 0.989 recall: 0.987 f1: 0.988 accuracy: 0.999 
saved the new best model with f1: 0.988
epoch:5/100
training batch:    20, loss: 1.22014, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:    40, loss: 0.48195, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.996 
training batch:    60, loss: 1.07857, precision: 0.909 recall: 1.000 f1: 0.952 accuracy: 0.993 
training batch:    80, loss: 0.80531, precision: 1.000 recall: 0.938 f1: 0.968 accuracy: 0.996 
training batch:   100, loss: 0.84543, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.994 
training batch:   120, loss: 2.60603, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.993 
training batch:   140, loss: 0.72321, precision: 0.977 recall: 0.955 f1: 0.966 accuracy: 0.995 
training batch:   160, loss: 0.36104, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.994 
training batch:   180, loss: 1.21898, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.993 
training batch:   200, loss: 0.17570, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.65569, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:   240, loss: 0.25923, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   260, loss: 2.50179, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.995 
training batch:   280, loss: 3.32129, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.986 
training batch:   300, loss: 0.29976, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.999 
training batch:   320, loss: 0.38393, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.998 
training batch:   340, loss: 0.97115, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.990 
training batch:   360, loss: 0.20624, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.999 
training batch:   380, loss: 1.08316, precision: 0.953 recall: 0.976 f1: 0.965 accuracy: 0.996 
training batch:   400, loss: 0.40237, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.85089, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.998 
training batch:   440, loss: 1.73561, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.990 
training batch:   460, loss: 3.01067, precision: 0.824 recall: 0.875 f1: 0.848 accuracy: 0.981 
training batch:   480, loss: 0.38834, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   500, loss: 0.32753, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.999 
training batch:   520, loss: 0.63133, precision: 0.970 recall: 0.914 f1: 0.941 accuracy: 0.993 
training batch:   540, loss: 1.44125, precision: 0.974 recall: 0.905 f1: 0.938 accuracy: 0.989 
training batch:   560, loss: 0.15327, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 1.94173, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.989 
training batch:   600, loss: 0.08562, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.25623, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 0.21718, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.72070, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.999 
training batch:   680, loss: 0.70891, precision: 0.974 recall: 0.950 f1: 0.962 accuracy: 0.998 
training batch:   700, loss: 0.30748, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:   720, loss: 1.06924, precision: 0.903 recall: 1.000 f1: 0.949 accuracy: 0.995 
training batch:   740, loss: 0.36110, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.998 
training batch:   760, loss: 0.54794, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.996 
training batch:   780, loss: 0.18948, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   800, loss: 0.65601, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.995 
training batch:   820, loss: 0.19968, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 1.17867, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.995 
training batch:   860, loss: 1.08597, precision: 0.973 recall: 0.923 f1: 0.947 accuracy: 0.996 
training batch:   880, loss: 0.73946, precision: 0.932 recall: 0.953 f1: 0.943 accuracy: 0.998 
training batch:   900, loss: 0.31631, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 1.17702, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.995 
training batch:   940, loss: 1.49483, precision: 0.921 recall: 1.000 f1: 0.959 accuracy: 0.990 
training batch:   960, loss: 0.30743, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   980, loss: 1.14993, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.993 
training batch:  1000, loss: 0.86597, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.998 
training batch:  1020, loss: 0.47287, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:  1040, loss: 0.86870, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.998 
training batch:  1060, loss: 0.34799, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.995 
training batch:  1080, loss: 6.17825, precision: 0.944 recall: 0.829 f1: 0.883 accuracy: 0.989 
training batch:  1100, loss: 0.84360, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:  1120, loss: 0.75777, precision: 0.972 recall: 0.921 f1: 0.946 accuracy: 0.996 
training batch:  1140, loss: 0.29930, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:  1160, loss: 1.32886, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.996 
training batch:  1180, loss: 0.46830, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 3.01579, precision: 0.857 recall: 0.882 f1: 0.870 accuracy: 0.976 
training batch:  1220, loss: 2.00043, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.985 
training batch:  1240, loss: 0.62965, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.996 
training batch:  1260, loss: 0.65022, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:  1280, loss: 0.51428, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:  1300, loss: 2.65706, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.994 
training batch:  1320, loss: 1.42262, precision: 0.953 recall: 0.976 f1: 0.965 accuracy: 0.988 
training batch:  1340, loss: 0.23722, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 0.64622, precision: 0.955 recall: 0.977 f1: 0.966 accuracy: 0.996 
training batch:  1380, loss: 0.35326, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
start evaluate engines...
label: Dsa, precision: 0.982 recall: 0.981 f1: 0.981 
label: Chk, precision: 0.685 recall: 0.685 f1: 0.685 
label: Ins, precision: 0.430 recall: 0.435 f1: 0.431 
label: Sur, precision: 0.862 recall: 0.863 f1: 0.862 
label: Med, precision: 0.450 recall: 0.451 f1: 0.450 
label: Ana, precision: 0.989 recall: 0.992 f1: 0.990 
time consumption:19.68(min), precision: 0.990 recall: 0.993 f1: 0.991 accuracy: 0.999 
saved the new best model with f1: 0.991
epoch:6/100
training batch:    20, loss: 0.23759, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 2.96863, precision: 0.851 recall: 0.909 f1: 0.879 accuracy: 0.989 
training batch:    60, loss: 0.44373, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.998 
training batch:    80, loss: 0.95039, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.996 
training batch:   100, loss: 0.91837, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:   120, loss: 0.38786, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   140, loss: 1.18056, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.994 
training batch:   160, loss: 0.66123, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.996 
training batch:   180, loss: 0.57391, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.995 
training batch:   200, loss: 0.09401, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.57489, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.996 
training batch:   240, loss: 0.06084, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   260, loss: 0.13838, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 1.25673, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.998 
training batch:   300, loss: 0.32454, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.995 
training batch:   320, loss: 1.22476, precision: 1.000 recall: 0.964 f1: 0.982 accuracy: 0.995 
training batch:   340, loss: 1.19304, precision: 1.000 recall: 0.864 f1: 0.927 accuracy: 0.996 
training batch:   360, loss: 0.28355, precision: 0.977 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:   380, loss: 1.49550, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.998 
training batch:   400, loss: 0.04900, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 1.79237, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.984 
training batch:   440, loss: 2.79451, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.991 
training batch:   460, loss: 0.09485, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.76619, precision: 1.000 recall: 0.941 f1: 0.970 accuracy: 0.995 
training batch:   500, loss: 0.14521, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.35169, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:   540, loss: 0.71395, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.994 
training batch:   560, loss: 0.13751, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.87389, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:   600, loss: 0.05078, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.38229, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:   640, loss: 1.38280, precision: 0.926 recall: 1.000 f1: 0.962 accuracy: 0.998 
training batch:   660, loss: 0.22328, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.26643, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 1.47101, precision: 0.939 recall: 0.886 f1: 0.912 accuracy: 0.990 
training batch:   720, loss: 0.30302, precision: 1.000 recall: 0.917 f1: 0.957 accuracy: 0.998 
training batch:   740, loss: 0.12093, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   760, loss: 1.19189, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:   780, loss: 1.14874, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.993 
training batch:   800, loss: 0.72713, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.996 
training batch:   820, loss: 0.98517, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.999 
training batch:   840, loss: 0.20232, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 0.06120, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   880, loss: 0.35789, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   900, loss: 0.56476, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.994 
training batch:   920, loss: 0.43007, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:   940, loss: 0.09090, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 0.07161, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   980, loss: 0.05066, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 0.66293, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:  1020, loss: 1.26370, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.993 
training batch:  1040, loss: 0.11855, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1060, loss: 0.11613, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 0.57953, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:  1100, loss: 0.69428, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:  1120, loss: 0.87777, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.993 
training batch:  1140, loss: 4.97192, precision: 0.946 recall: 0.921 f1: 0.933 accuracy: 0.984 
training batch:  1160, loss: 1.84553, precision: 0.935 recall: 0.906 f1: 0.921 accuracy: 0.984 
training batch:  1180, loss: 0.06802, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.57006, precision: 0.978 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:  1220, loss: 0.26865, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.84206, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.993 
training batch:  1260, loss: 0.29985, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:  1280, loss: 0.10062, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.59109, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:  1320, loss: 0.29842, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.998 
training batch:  1340, loss: 0.64366, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.994 
training batch:  1360, loss: 0.59125, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.996 
training batch:  1380, loss: 0.13808, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.984 recall: 0.982 f1: 0.983 
label: Chk, precision: 0.686 recall: 0.687 f1: 0.687 
label: Ins, precision: 0.438 recall: 0.435 f1: 0.436 
label: Sur, precision: 0.868 recall: 0.867 f1: 0.868 
label: Med, precision: 0.449 recall: 0.451 f1: 0.450 
label: Ana, precision: 0.990 recall: 0.995 f1: 0.993 
time consumption:20.33(min), precision: 0.992 recall: 0.994 f1: 0.993 accuracy: 0.999 
saved the new best model with f1: 0.993
epoch:7/100
training batch:    20, loss: 0.31174, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.999 
training batch:    40, loss: 0.06784, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.11098, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.30183, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.14455, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 2.00134, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.989 
training batch:   140, loss: 0.27074, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   160, loss: 0.18897, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   180, loss: 0.15965, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.02390, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.70914, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.996 
training batch:   240, loss: 0.34263, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.998 
training batch:   260, loss: 0.49533, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   280, loss: 0.38976, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:   300, loss: 0.37090, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.999 
training batch:   320, loss: 0.52697, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.998 
training batch:   340, loss: 0.56592, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   360, loss: 0.12271, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 1.52603, precision: 1.000 recall: 0.923 f1: 0.960 accuracy: 0.994 
training batch:   400, loss: 0.02032, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.01925, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   440, loss: 0.13828, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.28348, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.999 
training batch:   480, loss: 2.65337, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.988 
training batch:   500, loss: 0.18388, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:   520, loss: 0.14134, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 2.31338, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.991 
training batch:   560, loss: 0.17458, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.13620, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.18915, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.996 
training batch:   620, loss: 1.92299, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.996 
training batch:   640, loss: 0.05341, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.35081, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.999 
training batch:   680, loss: 0.16310, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.33336, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.998 
training batch:   720, loss: 1.51900, precision: 0.974 recall: 0.950 f1: 0.962 accuracy: 0.989 
training batch:   740, loss: 2.04127, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.985 
training batch:   760, loss: 0.51302, precision: 0.929 recall: 1.000 f1: 0.963 accuracy: 0.996 
training batch:   780, loss: 0.12608, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   800, loss: 0.19111, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   820, loss: 0.10284, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.21125, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.998 
training batch:   860, loss: 0.35875, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.995 
training batch:   880, loss: 0.12103, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.14156, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 0.46830, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:   940, loss: 1.88693, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.995 
training batch:   960, loss: 3.10777, precision: 0.906 recall: 1.000 f1: 0.951 accuracy: 0.989 
training batch:   980, loss: 0.34997, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.998 
training batch:  1000, loss: 0.29471, precision: 0.960 recall: 1.000 f1: 0.980 accuracy: 0.999 
training batch:  1020, loss: 0.49609, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:  1040, loss: 0.27460, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:  1060, loss: 1.66339, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.991 
training batch:  1080, loss: 0.05597, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.68301, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:  1120, loss: 0.11269, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1140, loss: 0.28760, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.999 
training batch:  1160, loss: 0.62534, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:  1180, loss: 1.94213, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.983 
training batch:  1200, loss: 0.24062, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 0.73573, precision: 0.976 recall: 0.930 f1: 0.952 accuracy: 0.994 
training batch:  1240, loss: 0.27412, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.999 
training batch:  1260, loss: 0.08095, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.25947, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 1.39833, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.993 
training batch:  1320, loss: 0.70657, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.989 
training batch:  1340, loss: 0.07336, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 0.05682, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 0.46995, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
start evaluate engines...
label: Dsa, precision: 0.981 recall: 0.983 f1: 0.981 
label: Chk, precision: 0.686 recall: 0.687 f1: 0.687 
label: Ins, precision: 0.433 recall: 0.439 f1: 0.435 
label: Sur, precision: 0.867 recall: 0.868 f1: 0.868 
label: Med, precision: 0.445 recall: 0.441 f1: 0.443 
label: Ana, precision: 0.994 recall: 0.990 f1: 0.992 
time consumption:22.11(min), precision: 0.994 recall: 0.993 f1: 0.993 accuracy: 0.999 
epoch:8/100
training batch:    20, loss: 0.25218, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    40, loss: 0.36362, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.996 
training batch:    60, loss: 0.58265, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.998 
training batch:    80, loss: 0.01427, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.15620, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.06781, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.16263, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   160, loss: 0.96951, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.994 
training batch:   180, loss: 0.11533, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.31342, precision: 1.000 recall: 0.929 f1: 0.963 accuracy: 0.996 
training batch:   220, loss: 0.03101, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   240, loss: 0.06929, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   260, loss: 0.65869, precision: 0.955 recall: 1.000 f1: 0.977 accuracy: 0.999 
training batch:   280, loss: 0.25565, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   300, loss: 0.65866, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   320, loss: 0.23991, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:   340, loss: 0.52139, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.993 
training batch:   360, loss: 0.09779, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 0.63025, precision: 0.931 recall: 0.900 f1: 0.915 accuracy: 0.991 
training batch:   400, loss: 0.45305, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.993 
training batch:   420, loss: 0.13269, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   440, loss: 1.28532, precision: 0.927 recall: 0.974 f1: 0.950 accuracy: 0.994 
training batch:   460, loss: 0.13331, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.63003, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   500, loss: 0.77213, precision: 0.920 recall: 0.920 f1: 0.920 accuracy: 0.988 
training batch:   520, loss: 0.12394, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.39774, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.996 
training batch:   560, loss: 1.08778, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.990 
training batch:   580, loss: 0.10666, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.98250, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.995 
training batch:   620, loss: 0.09664, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 1.55427, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.991 
training batch:   660, loss: 0.93816, precision: 1.000 recall: 0.953 f1: 0.976 accuracy: 0.995 
training batch:   680, loss: 0.77386, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:   700, loss: 0.17168, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.41519, precision: 0.979 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:   740, loss: 0.10342, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   760, loss: 0.39683, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.993 
training batch:   780, loss: 0.39279, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:   800, loss: 0.93355, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:   820, loss: 0.18301, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.01047, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 0.32095, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.998 
training batch:   880, loss: 0.11822, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.22110, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:   920, loss: 1.60645, precision: 0.848 recall: 0.875 f1: 0.862 accuracy: 0.974 
training batch:   940, loss: 0.33440, precision: 0.978 recall: 0.978 f1: 0.978 accuracy: 0.999 
training batch:   960, loss: 0.28174, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   980, loss: 0.30018, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.998 
training batch:  1000, loss: 0.75042, precision: 0.956 recall: 0.915 f1: 0.935 accuracy: 0.995 
training batch:  1020, loss: 1.51001, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.996 
training batch:  1040, loss: 0.09071, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1060, loss: 0.11620, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 0.67412, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.993 
training batch:  1100, loss: 0.76538, precision: 0.953 recall: 0.976 f1: 0.965 accuracy: 0.999 
training batch:  1120, loss: 0.08723, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1140, loss: 0.27277, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.998 
training batch:  1160, loss: 0.09075, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.35490, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.998 
training batch:  1200, loss: 0.06310, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 0.22701, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:  1240, loss: 0.23347, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:  1260, loss: 0.03064, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.10623, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.11523, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.15255, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1340, loss: 0.11529, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 0.03989, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 0.16844, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.987 recall: 0.982 f1: 0.984 
label: Chk, precision: 0.684 recall: 0.684 f1: 0.684 
label: Ins, precision: 0.436 recall: 0.430 f1: 0.432 
label: Sur, precision: 0.869 recall: 0.868 f1: 0.869 
label: Med, precision: 0.450 recall: 0.450 f1: 0.450 
label: Ana, precision: 0.991 recall: 0.994 f1: 0.992 
time consumption:23.47(min), precision: 0.994 recall: 0.993 f1: 0.993 accuracy: 0.999 
saved the new best model with f1: 0.993
epoch:9/100
training batch:    20, loss: 0.57668, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.996 
training batch:    40, loss: 0.04466, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.07967, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.04968, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.20408, precision: 1.000 recall: 0.977 f1: 0.988 accuracy: 0.999 
training batch:   120, loss: 0.06994, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.21075, precision: 1.000 recall: 0.958 f1: 0.979 accuracy: 0.999 
training batch:   160, loss: 0.04558, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   180, loss: 0.14548, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 1.00214, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.998 
training batch:   220, loss: 0.06591, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   240, loss: 0.90903, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.996 
training batch:   260, loss: 0.08266, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.43814, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.999 
training batch:   300, loss: 0.02770, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 0.27976, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.24198, precision: 0.923 recall: 0.960 f1: 0.941 accuracy: 0.995 
training batch:   360, loss: 0.03245, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 0.44811, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.993 
training batch:   400, loss: 0.03264, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.34912, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.998 
training batch:   440, loss: 0.26796, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.999 
training batch:   460, loss: 1.19178, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.993 
training batch:   480, loss: 0.49653, precision: 0.920 recall: 0.885 f1: 0.902 accuracy: 0.994 
training batch:   500, loss: 0.94057, precision: 0.914 recall: 0.970 f1: 0.941 accuracy: 0.995 
training batch:   520, loss: 0.06320, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.45508, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.995 
training batch:   560, loss: 0.13353, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.22492, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.71237, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.998 
training batch:   620, loss: 1.22940, precision: 0.979 recall: 1.000 f1: 0.989 accuracy: 0.988 
training batch:   640, loss: 0.41291, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   660, loss: 0.71842, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.996 
training batch:   680, loss: 0.92263, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   700, loss: 0.20461, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.998 
training batch:   720, loss: 0.17062, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 0.11722, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   760, loss: 0.48569, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   780, loss: 1.71483, precision: 0.951 recall: 0.907 f1: 0.929 accuracy: 0.995 
training batch:   800, loss: 0.25105, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   820, loss: 0.27234, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.999 
training batch:   840, loss: 0.13891, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   860, loss: 0.04528, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   880, loss: 0.04351, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.27888, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:   920, loss: 0.01490, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   940, loss: 0.03378, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 0.25834, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   980, loss: 0.21185, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.998 
training batch:  1000, loss: 0.45148, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.999 
training batch:  1020, loss: 0.06896, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1040, loss: 0.34531, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.995 
training batch:  1060, loss: 0.09832, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 0.80032, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.996 
training batch:  1100, loss: 0.06717, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1120, loss: 0.65552, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:  1140, loss: 0.43786, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.998 
training batch:  1160, loss: 0.33421, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:  1180, loss: 1.15972, precision: 0.950 recall: 1.000 f1: 0.974 accuracy: 0.998 
training batch:  1200, loss: 0.06828, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 0.87239, precision: 0.958 recall: 0.958 f1: 0.958 accuracy: 0.991 
training batch:  1240, loss: 0.13467, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:  1260, loss: 1.98715, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.993 
training batch:  1280, loss: 0.72153, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.998 
training batch:  1300, loss: 0.20718, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.18713, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1340, loss: 0.06638, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 0.12066, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 0.65694, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
start evaluate engines...
label: Dsa, precision: 0.979 recall: 0.983 f1: 0.981 
label: Chk, precision: 0.687 recall: 0.687 f1: 0.687 
label: Ins, precision: 0.436 recall: 0.434 f1: 0.434 
label: Sur, precision: 0.869 recall: 0.865 f1: 0.867 
label: Med, precision: 0.450 recall: 0.451 f1: 0.450 
label: Ana, precision: 0.992 recall: 0.996 f1: 0.994 
time consumption:24.25(min), precision: 0.993 recall: 0.996 f1: 0.995 accuracy: 0.999 
saved the new best model with f1: 0.995
epoch:10/100
training batch:    20, loss: 0.79330, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.996 
training batch:    40, loss: 0.29345, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.996 
training batch:    60, loss: 1.08067, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.994 
training batch:    80, loss: 1.11682, precision: 1.000 recall: 0.903 f1: 0.949 accuracy: 0.996 
training batch:   100, loss: 0.02315, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.29915, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.999 
training batch:   140, loss: 0.07224, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   160, loss: 0.32799, precision: 0.933 recall: 1.000 f1: 0.966 accuracy: 0.998 
training batch:   180, loss: 0.30733, precision: 1.000 recall: 0.946 f1: 0.972 accuracy: 0.998 
training batch:   200, loss: 0.36301, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.996 
training batch:   220, loss: 0.72633, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.995 
training batch:   240, loss: 0.06713, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   260, loss: 0.11325, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.48048, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.998 
training batch:   300, loss: 0.10799, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 0.02783, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.16042, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   360, loss: 0.04594, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 0.04534, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.03518, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.39687, precision: 0.932 recall: 0.953 f1: 0.943 accuracy: 0.996 
training batch:   440, loss: 0.38457, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.988 
training batch:   460, loss: 0.13998, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:   480, loss: 0.02615, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.18540, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.999 
training batch:   520, loss: 0.44308, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:   540, loss: 0.81916, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   560, loss: 0.82727, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.996 
training batch:   580, loss: 0.09139, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 1.34306, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.996 
training batch:   620, loss: 0.22847, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 0.70647, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   660, loss: 0.22236, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   680, loss: 0.79739, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:   700, loss: 0.63348, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.990 
training batch:   720, loss: 0.61286, precision: 0.950 recall: 0.905 f1: 0.927 accuracy: 0.994 
training batch:   740, loss: 0.82549, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.991 
training batch:   760, loss: 0.06418, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   780, loss: 0.24857, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   800, loss: 0.03632, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   820, loss: 0.02897, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.07985, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 0.13919, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   880, loss: 0.12703, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.11945, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:   920, loss: 0.35387, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.998 
training batch:   940, loss: 0.43637, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.998 
training batch:   960, loss: 0.10870, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   980, loss: 0.46941, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:  1000, loss: 0.04714, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1020, loss: 0.00988, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1040, loss: 0.46908, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:  1060, loss: 0.72861, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.996 
training batch:  1080, loss: 0.59938, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.998 
training batch:  1100, loss: 0.04493, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1120, loss: 0.22023, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.998 
training batch:  1140, loss: 0.09026, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1160, loss: 1.38200, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.990 
training batch:  1180, loss: 0.01726, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.46895, precision: 0.946 recall: 1.000 f1: 0.972 accuracy: 0.993 
training batch:  1220, loss: 0.13767, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.32900, precision: 0.977 recall: 1.000 f1: 0.988 accuracy: 0.998 
training batch:  1260, loss: 0.01586, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.24015, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:  1300, loss: 0.44523, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:  1320, loss: 1.09187, precision: 0.953 recall: 0.911 f1: 0.932 accuracy: 0.994 
training batch:  1340, loss: 1.75942, precision: 0.923 recall: 0.960 f1: 0.941 accuracy: 0.994 
training batch:  1360, loss: 0.10377, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 0.55464, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
start evaluate engines...
label: Dsa, precision: 0.977 recall: 0.979 f1: 0.978 
label: Chk, precision: 0.687 recall: 0.687 f1: 0.687 
label: Ins, precision: 0.436 recall: 0.436 f1: 0.435 
label: Sur, precision: 0.869 recall: 0.868 f1: 0.869 
label: Med, precision: 0.447 recall: 0.446 f1: 0.446 
label: Ana, precision: 0.994 recall: 0.992 f1: 0.993 
time consumption:22.72(min), precision: 0.994 recall: 0.993 f1: 0.993 accuracy: 0.999 
epoch:11/100
training batch:    20, loss: 0.25528, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:    40, loss: 0.06197, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.17604, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.999 
training batch:    80, loss: 0.07278, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.20619, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.34634, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.998 
training batch:   140, loss: 0.57369, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.998 
training batch:   160, loss: 0.19628, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:   180, loss: 0.16253, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:   200, loss: 0.19037, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.994 
training batch:   220, loss: 0.52657, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.996 
training batch:   240, loss: 0.05742, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   260, loss: 0.26167, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.49784, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.988 
training batch:   300, loss: 0.24490, precision: 1.000 recall: 0.964 f1: 0.982 accuracy: 0.999 
training batch:   320, loss: 0.01304, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.21287, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.999 
training batch:   360, loss: 0.32150, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:   380, loss: 0.03838, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.00034, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.09233, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   440, loss: 0.05646, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.08052, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.30627, precision: 0.982 recall: 0.982 f1: 0.982 accuracy: 0.999 
training batch:   500, loss: 0.01167, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.19516, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.97319, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.993 
training batch:   560, loss: 0.10297, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.06233, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.00654, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 1.41273, precision: 1.000 recall: 0.912 f1: 0.954 accuracy: 0.996 
training batch:   640, loss: 0.21751, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:   660, loss: 0.26546, precision: 1.000 recall: 0.947 f1: 0.973 accuracy: 0.998 
training batch:   680, loss: 0.03362, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.00646, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.02908, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 0.69421, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.996 
training batch:   760, loss: 0.16784, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:   780, loss: 0.54934, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.996 
training batch:   800, loss: 0.95540, precision: 1.000 recall: 0.930 f1: 0.964 accuracy: 0.988 
training batch:   820, loss: 0.76663, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.996 
training batch:   840, loss: 0.43494, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:   860, loss: 0.37837, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   880, loss: 0.04285, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.05180, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 0.05769, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   940, loss: 0.29672, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:   960, loss: 0.12350, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   980, loss: 0.32852, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:  1000, loss: 0.06493, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1020, loss: 0.13247, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1040, loss: 0.07169, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1060, loss: 0.12929, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 0.21017, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.89762, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.998 
training batch:  1120, loss: 0.21765, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:  1140, loss: 0.25677, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.994 
training batch:  1160, loss: 0.29332, precision: 0.958 recall: 0.958 f1: 0.958 accuracy: 0.999 
training batch:  1180, loss: 0.04535, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.21816, precision: 1.000 recall: 0.962 f1: 0.980 accuracy: 0.995 
training batch:  1220, loss: 0.17782, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.36311, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:  1260, loss: 0.02130, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.02515, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.01013, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.15150, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:  1340, loss: 0.26612, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.999 
training batch:  1360, loss: 0.06792, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 0.71162, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
start evaluate engines...
label: Dsa, precision: 0.985 recall: 0.983 f1: 0.984 
label: Chk, precision: 0.687 recall: 0.687 f1: 0.687 
label: Ins, precision: 0.434 recall: 0.432 f1: 0.432 
label: Sur, precision: 0.867 recall: 0.868 f1: 0.867 
label: Med, precision: 0.449 recall: 0.451 f1: 0.450 
label: Ana, precision: 0.993 recall: 0.995 f1: 0.994 
time consumption:22.88(min), precision: 0.994 recall: 0.995 f1: 0.994 accuracy: 0.999 
epoch:12/100
training batch:    20, loss: 0.01752, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.19067, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.998 
training batch:    60, loss: 0.27421, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:    80, loss: 0.01809, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.43144, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   120, loss: 0.34580, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.991 
training batch:   140, loss: 0.01113, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   160, loss: 1.42380, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.990 
training batch:   180, loss: 0.01191, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.20457, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.93863, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.990 
training batch:   240, loss: 0.15235, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:   260, loss: 0.36830, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   280, loss: 0.01532, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   300, loss: 0.04230, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 0.06701, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.11597, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   360, loss: 0.13994, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:   380, loss: 0.06844, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.27489, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.999 
training batch:   420, loss: 0.13256, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   440, loss: 0.30006, precision: 0.952 recall: 0.976 f1: 0.964 accuracy: 0.998 
training batch:   460, loss: 0.09933, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 1.72195, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.996 
training batch:   500, loss: 0.01850, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.13089, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.16099, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   560, loss: 0.12624, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:   580, loss: 0.02798, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.75953, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:   620, loss: 0.20263, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.998 
training batch:   640, loss: 0.03123, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.01541, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.04519, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.37479, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.998 
training batch:   720, loss: 2.26784, precision: 0.950 recall: 0.927 f1: 0.938 accuracy: 0.981 
training batch:   740, loss: 0.03893, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   760, loss: 0.03463, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   780, loss: 1.63569, precision: 0.936 recall: 0.978 f1: 0.957 accuracy: 0.990 
training batch:   800, loss: 0.70613, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.993 
training batch:   820, loss: 0.06771, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.47150, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.991 
training batch:   860, loss: 0.16364, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:   880, loss: 0.12054, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.02963, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 0.70991, precision: 1.000 recall: 0.938 f1: 0.968 accuracy: 0.995 
training batch:   940, loss: 0.03506, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 0.61089, precision: 0.980 recall: 0.980 f1: 0.980 accuracy: 0.999 
training batch:   980, loss: 0.00713, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 0.02617, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1020, loss: 0.11491, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1040, loss: 0.22141, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.999 
training batch:  1060, loss: 0.14636, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 0.13023, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.31342, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:  1120, loss: 0.34772, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.998 
training batch:  1140, loss: 0.10767, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1160, loss: 0.92921, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.994 
training batch:  1180, loss: 0.01250, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.02696, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 0.02364, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.43989, precision: 0.962 recall: 1.000 f1: 0.980 accuracy: 0.999 
training batch:  1260, loss: 1.82416, precision: 0.892 recall: 0.825 f1: 0.857 accuracy: 0.979 
training batch:  1280, loss: 0.06036, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.56360, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.994 
training batch:  1320, loss: 0.28603, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:  1340, loss: 0.04832, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 0.48112, precision: 0.956 recall: 0.956 f1: 0.956 accuracy: 0.993 
training batch:  1380, loss: 0.02288, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.978 recall: 0.983 f1: 0.980 
label: Chk, precision: 0.687 recall: 0.687 f1: 0.687 
label: Ins, precision: 0.436 recall: 0.438 f1: 0.436 
label: Sur, precision: 0.866 recall: 0.864 f1: 0.865 
label: Med, precision: 0.450 recall: 0.451 f1: 0.450 
label: Ana, precision: 0.995 recall: 0.995 f1: 0.995 
time consumption:19.00(min), precision: 0.994 recall: 0.996 f1: 0.995 accuracy: 0.999 
epoch:13/100
training batch:    20, loss: 0.93348, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.996 
training batch:    40, loss: 0.01469, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.02654, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.60867, precision: 0.846 recall: 0.957 f1: 0.898 accuracy: 0.996 
training batch:   100, loss: 0.12099, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.69274, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.995 
training batch:   140, loss: 0.09855, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:   160, loss: 0.12740, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:   180, loss: 0.06506, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.18132, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.01512, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   240, loss: 0.21925, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   260, loss: 0.00681, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.41437, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.995 
training batch:   300, loss: 0.11653, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 0.18655, precision: 0.957 recall: 1.000 f1: 0.978 accuracy: 0.999 
training batch:   340, loss: 0.98324, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.988 
training batch:   360, loss: 0.02303, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 0.11656, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.01994, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.14114, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:   440, loss: 0.47829, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.995 
training batch:   460, loss: 0.04194, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.03679, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.11395, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.998 
training batch:   520, loss: 0.02084, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.04371, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   560, loss: 0.00377, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.00800, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.05649, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.00702, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 0.04593, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.03487, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.07521, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.22943, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:   720, loss: 0.05518, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 0.00565, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   760, loss: 0.05364, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   780, loss: 0.16295, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:   800, loss: 0.07777, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   820, loss: 0.08941, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.00784, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 0.15167, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   880, loss: 0.21535, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   900, loss: 0.29342, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.998 
training batch:   920, loss: 0.35165, precision: 1.000 recall: 0.929 f1: 0.963 accuracy: 0.998 
training batch:   940, loss: 0.02654, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 0.53062, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   980, loss: 0.01709, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 1.21424, precision: 0.923 recall: 0.857 f1: 0.889 accuracy: 0.991 
training batch:  1020, loss: 0.35250, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.995 
training batch:  1040, loss: 0.03528, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1060, loss: 0.33698, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.993 
training batch:  1080, loss: 0.03896, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 1.05713, precision: 1.000 recall: 0.946 f1: 0.972 accuracy: 0.996 
training batch:  1120, loss: 0.11214, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1140, loss: 0.35700, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.998 
training batch:  1160, loss: 0.03079, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.11108, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.46091, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.998 
training batch:  1220, loss: 0.06858, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 1.35867, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:  1260, loss: 0.51876, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.989 
training batch:  1280, loss: 0.44662, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.996 
training batch:  1300, loss: 0.27705, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.998 
training batch:  1320, loss: 0.20525, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.994 
training batch:  1340, loss: 0.24017, precision: 0.955 recall: 1.000 f1: 0.977 accuracy: 0.999 
training batch:  1360, loss: 1.10386, precision: 0.973 recall: 0.923 f1: 0.947 accuracy: 0.993 
training batch:  1380, loss: 0.32353, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.986 recall: 0.984 f1: 0.985 
label: Chk, precision: 0.685 recall: 0.685 f1: 0.685 
label: Ins, precision: 0.430 recall: 0.435 f1: 0.432 
label: Sur, precision: 0.868 recall: 0.868 f1: 0.868 
label: Med, precision: 0.450 recall: 0.451 f1: 0.450 
label: Ana, precision: 0.996 recall: 0.994 f1: 0.995 
time consumption:16.62(min), precision: 0.996 recall: 0.994 f1: 0.995 accuracy: 0.999 
saved the new best model with f1: 0.995
epoch:14/100
training batch:    20, loss: 0.03210, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.11482, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    60, loss: 0.02472, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.00670, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.02422, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.08984, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.14128, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.995 
training batch:   160, loss: 0.03056, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   180, loss: 0.27854, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   200, loss: 0.60886, precision: 0.979 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:   220, loss: 0.03134, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   240, loss: 0.31550, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:   260, loss: 0.28845, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 2.01697, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.988 
training batch:   300, loss: 0.17953, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:   320, loss: 0.01778, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.05761, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   360, loss: 0.04001, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 0.14106, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   400, loss: 0.01652, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.03584, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   440, loss: 0.00630, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.02740, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.21701, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   500, loss: 0.21416, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:   520, loss: 0.02039, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.19204, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:   560, loss: 0.27946, precision: 1.000 recall: 0.977 f1: 0.989 accuracy: 0.998 
training batch:   580, loss: 1.49393, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.998 
training batch:   600, loss: 0.11730, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:   620, loss: 0.75776, precision: 0.963 recall: 0.812 f1: 0.881 accuracy: 0.994 
training batch:   640, loss: 0.10668, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.34726, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.999 
training batch:   680, loss: 0.94778, precision: 1.000 recall: 0.927 f1: 0.962 accuracy: 0.994 
training batch:   700, loss: 0.51593, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.995 
training batch:   720, loss: 0.51979, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:   740, loss: 0.64278, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:   760, loss: 0.01646, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   780, loss: 0.03520, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   800, loss: 0.51164, precision: 1.000 recall: 0.950 f1: 0.974 accuracy: 0.998 
training batch:   820, loss: 0.49674, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.998 
training batch:   840, loss: 0.03852, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 0.13031, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   880, loss: 0.02669, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.28152, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.996 
training batch:   920, loss: 0.06433, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   940, loss: 0.06965, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 0.26308, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:   980, loss: 0.13480, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 0.04783, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1020, loss: 0.01563, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1040, loss: 0.57332, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.994 
training batch:  1060, loss: 0.01285, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 0.08655, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.54205, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.993 
training batch:  1120, loss: 0.05564, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1140, loss: 0.16814, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.999 
training batch:  1160, loss: 0.56601, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:  1180, loss: 0.21384, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.08485, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 0.00165, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.01775, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.03668, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.23445, precision: 0.977 recall: 1.000 f1: 0.989 accuracy: 0.998 
training batch:  1300, loss: 0.13699, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.994 
training batch:  1320, loss: 0.21468, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:  1340, loss: 0.05483, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 0.02080, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 0.00201, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.986 recall: 0.984 f1: 0.985 
label: Chk, precision: 0.685 recall: 0.685 f1: 0.685 
label: Ins, precision: 0.429 recall: 0.436 f1: 0.432 
label: Sur, precision: 0.869 recall: 0.869 f1: 0.869 
label: Med, precision: 0.450 recall: 0.451 f1: 0.450 
label: Ana, precision: 0.996 recall: 0.995 f1: 0.995 
time consumption:17.68(min), precision: 0.996 recall: 0.995 f1: 0.995 accuracy: 0.999 
saved the new best model with f1: 0.995
epoch:15/100
training batch:    20, loss: 0.27028, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    40, loss: 0.01112, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.08046, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.02345, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.01984, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.00990, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.37710, precision: 1.000 recall: 0.964 f1: 0.982 accuracy: 0.998 
training batch:   160, loss: 0.05936, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   180, loss: 0.20489, precision: 1.000 recall: 0.979 f1: 0.989 accuracy: 0.999 
training batch:   200, loss: 0.26443, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:   220, loss: 0.46330, precision: 1.000 recall: 0.939 f1: 0.969 accuracy: 0.993 
training batch:   240, loss: 0.20296, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   260, loss: 0.15515, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   280, loss: 0.31811, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.998 
training batch:   300, loss: 1.78701, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.981 
training batch:   320, loss: 0.16806, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.04180, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   360, loss: 0.28640, precision: 1.000 recall: 0.978 f1: 0.989 accuracy: 0.999 
training batch:   380, loss: 0.01926, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.06054, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.26838, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.998 
training batch:   440, loss: 0.11445, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.999 
training batch:   460, loss: 0.59151, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.998 
training batch:   480, loss: 0.06348, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.83007, precision: 0.930 recall: 0.909 f1: 0.920 accuracy: 0.980 
training batch:   520, loss: 0.09711, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.00600, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   560, loss: 0.49977, precision: 0.978 recall: 0.978 f1: 0.978 accuracy: 0.998 
training batch:   580, loss: 0.08627, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.20926, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.998 
training batch:   620, loss: 0.19102, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.994 
training batch:   640, loss: 0.05041, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.00329, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.01569, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.22343, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   720, loss: 0.05576, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 0.27084, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:   760, loss: 0.05643, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   780, loss: 0.85571, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.995 
training batch:   800, loss: 0.01022, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   820, loss: 0.19865, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.999 
training batch:   840, loss: 0.23712, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   860, loss: 0.05303, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   880, loss: 0.02156, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.04061, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 0.10084, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   940, loss: 0.02494, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 0.51929, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   980, loss: 1.29945, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.994 
training batch:  1000, loss: 1.51427, precision: 0.957 recall: 1.000 f1: 0.978 accuracy: 0.994 
training batch:  1020, loss: 0.53522, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.995 
training batch:  1040, loss: 1.40108, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.995 
training batch:  1060, loss: 0.15798, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.998 
training batch:  1080, loss: 0.23464, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.18211, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.999 
training batch:  1120, loss: 0.29137, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.996 
training batch:  1140, loss: 0.06460, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1160, loss: 0.04829, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.00827, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.00600, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 0.17551, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:  1240, loss: 0.19748, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:  1260, loss: 0.01468, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.20670, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.999 
training batch:  1300, loss: 1.35374, precision: 0.921 recall: 0.972 f1: 0.946 accuracy: 0.993 
training batch:  1320, loss: 0.03581, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1340, loss: 0.06715, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 0.05357, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 0.03999, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.986 recall: 0.981 f1: 0.983 
label: Chk, precision: 0.685 recall: 0.685 f1: 0.685 
label: Ins, precision: 0.436 recall: 0.438 f1: 0.436 
label: Sur, precision: 0.869 recall: 0.868 f1: 0.869 
label: Med, precision: 0.448 recall: 0.444 f1: 0.446 
label: Ana, precision: 0.994 recall: 0.996 f1: 0.995 
time consumption:23.09(min), precision: 0.995 recall: 0.994 f1: 0.995 accuracy: 0.999 
epoch:16/100
training batch:    20, loss: 0.82919, precision: 0.914 recall: 0.889 f1: 0.901 accuracy: 0.991 
training batch:    40, loss: 0.03761, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.28313, precision: 1.000 recall: 0.949 f1: 0.974 accuracy: 0.993 
training batch:    80, loss: 0.33556, precision: 0.920 recall: 0.958 f1: 0.939 accuracy: 0.995 
training batch:   100, loss: 0.67477, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.978 
training batch:   120, loss: 0.00239, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.20506, precision: 0.977 recall: 0.955 f1: 0.966 accuracy: 0.996 
training batch:   160, loss: 0.58475, precision: 0.958 recall: 1.000 f1: 0.979 accuracy: 0.996 
training batch:   180, loss: 0.01121, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.58566, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.998 
training batch:   220, loss: 0.19978, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:   240, loss: 0.09691, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   260, loss: 0.03546, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.42965, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.991 
training batch:   300, loss: 0.00430, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 1.42016, precision: 0.938 recall: 1.000 f1: 0.968 accuracy: 0.995 
training batch:   340, loss: 0.05955, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   360, loss: 0.18197, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   380, loss: 0.60181, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   400, loss: 0.84839, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.994 
training batch:   420, loss: 0.73832, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:   440, loss: 0.04510, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.00637, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.22923, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.07371, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.05187, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.57359, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.990 
training batch:   560, loss: 0.02925, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.06285, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.02491, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.10725, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 0.19166, precision: 1.000 recall: 0.979 f1: 0.989 accuracy: 0.998 
training batch:   660, loss: 0.01299, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.04062, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.05525, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.00668, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 0.03767, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   760, loss: 0.00166, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   780, loss: 0.09159, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   800, loss: 0.24256, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.996 
training batch:   820, loss: 2.04549, precision: 0.968 recall: 0.833 f1: 0.896 accuracy: 0.994 
training batch:   840, loss: 0.02174, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 0.26764, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.996 
training batch:   880, loss: 0.06556, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.03507, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 0.23429, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:   940, loss: 0.02467, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 0.18920, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   980, loss: 0.05441, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 0.01582, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1020, loss: 0.01737, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1040, loss: 0.18582, precision: 1.000 recall: 0.960 f1: 0.980 accuracy: 0.999 
training batch:  1060, loss: 0.65991, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:  1080, loss: 0.89034, precision: 0.929 recall: 1.000 f1: 0.963 accuracy: 0.990 
training batch:  1100, loss: 0.02560, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1120, loss: 0.01862, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1140, loss: 0.42017, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:  1160, loss: 0.00446, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.00211, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.15785, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:  1220, loss: 0.01692, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.04997, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.02534, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 1.07758, precision: 0.927 recall: 1.000 f1: 0.962 accuracy: 0.991 
training batch:  1300, loss: 0.29448, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:  1320, loss: 0.03702, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1340, loss: 0.13427, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 0.02122, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 0.17303, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
start evaluate engines...
label: Dsa, precision: 0.982 recall: 0.984 f1: 0.983 
label: Chk, precision: 0.687 recall: 0.687 f1: 0.687 
label: Ins, precision: 0.436 recall: 0.438 f1: 0.436 
label: Sur, precision: 0.868 recall: 0.869 f1: 0.869 
label: Med, precision: 0.450 recall: 0.451 f1: 0.450 
label: Ana, precision: 0.995 recall: 0.996 f1: 0.995 
time consumption:23.45(min), precision: 0.995 recall: 0.996 f1: 0.996 accuracy: 0.999 
saved the new best model with f1: 0.996
epoch:17/100
training batch:    20, loss: 0.34912, precision: 0.958 recall: 1.000 f1: 0.979 accuracy: 0.999 
training batch:    40, loss: 0.00729, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.22901, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.998 
training batch:    80, loss: 0.09563, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.46312, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:   120, loss: 0.54070, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.998 
training batch:   140, loss: 1.16904, precision: 0.952 recall: 0.930 f1: 0.941 accuracy: 0.994 
training batch:   160, loss: 0.46925, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.991 
training batch:   180, loss: 0.34917, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.994 
training batch:   200, loss: 0.40487, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   220, loss: 0.17876, precision: 1.000 recall: 0.960 f1: 0.980 accuracy: 0.999 
training batch:   240, loss: 0.24122, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   260, loss: 1.18953, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.988 
training batch:   280, loss: 0.08488, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   300, loss: 0.02134, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 1.24208, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.993 
training batch:   340, loss: 0.09409, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   360, loss: 0.01603, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 0.35474, precision: 0.953 recall: 1.000 f1: 0.976 accuracy: 0.995 
training batch:   400, loss: 1.33266, precision: 0.971 recall: 0.846 f1: 0.904 accuracy: 0.980 
training batch:   420, loss: 0.46259, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   440, loss: 0.04472, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.03217, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.10278, precision: 1.000 recall: 0.980 f1: 0.990 accuracy: 0.998 
training batch:   500, loss: 0.85252, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.998 
training batch:   520, loss: 0.29442, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.998 
training batch:   540, loss: 0.86163, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.993 
training batch:   560, loss: 0.01020, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.12396, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   600, loss: 0.00968, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.00346, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 0.04917, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.00876, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.03796, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.17467, precision: 1.000 recall: 0.977 f1: 0.988 accuracy: 0.999 
training batch:   720, loss: 0.24697, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:   740, loss: 0.82510, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.990 
training batch:   760, loss: 0.59074, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   780, loss: 0.48901, precision: 1.000 recall: 0.943 f1: 0.971 accuracy: 0.993 
training batch:   800, loss: 0.65679, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:   820, loss: 0.11069, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.14169, precision: 1.000 recall: 0.958 f1: 0.979 accuracy: 0.999 
training batch:   860, loss: 2.20058, precision: 1.000 recall: 0.946 f1: 0.972 accuracy: 0.988 
training batch:   880, loss: 0.19978, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   900, loss: 0.12637, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.998 
training batch:   920, loss: 0.10165, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   940, loss: 0.17416, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:   960, loss: 0.34665, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:   980, loss: 0.20074, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:  1000, loss: 0.10493, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:  1020, loss: 0.60485, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.996 
training batch:  1040, loss: 0.44456, precision: 0.956 recall: 1.000 f1: 0.977 accuracy: 0.998 
training batch:  1060, loss: 0.43396, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.998 
training batch:  1080, loss: 0.04028, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.09702, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1120, loss: 0.29207, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:  1140, loss: 0.00727, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1160, loss: 0.01788, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.01176, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.04508, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 0.00533, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.00467, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.56328, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.998 
training batch:  1280, loss: 0.55223, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.996 
training batch:  1300, loss: 0.01175, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.74241, precision: 0.977 recall: 1.000 f1: 0.988 accuracy: 0.993 
training batch:  1340, loss: 0.10334, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.999 
training batch:  1360, loss: 0.26270, precision: 1.000 recall: 0.975 f1: 0.987 accuracy: 0.998 
training batch:  1380, loss: 0.07742, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.978 recall: 0.985 f1: 0.981 
label: Chk, precision: 0.687 recall: 0.687 f1: 0.687 
label: Ins, precision: 0.431 recall: 0.430 f1: 0.429 
label: Sur, precision: 0.869 recall: 0.869 f1: 0.869 
label: Med, precision: 0.445 recall: 0.441 f1: 0.443 
label: Ana, precision: 0.998 recall: 0.993 f1: 0.995 
time consumption:23.43(min), precision: 0.995 recall: 0.994 f1: 0.995 accuracy: 0.999 
epoch:18/100
training batch:    20, loss: 0.05038, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.17659, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.998 
training batch:    60, loss: 0.01877, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.26732, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.998 
training batch:   100, loss: 0.00610, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.01241, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.40057, precision: 1.000 recall: 0.952 f1: 0.976 accuracy: 0.998 
training batch:   160, loss: 0.26620, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.996 
training batch:   180, loss: 0.85410, precision: 1.000 recall: 0.930 f1: 0.964 accuracy: 0.996 
training batch:   200, loss: 0.02071, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.36329, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.999 
training batch:   240, loss: 0.01413, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   260, loss: 0.13928, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:   280, loss: 0.99578, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.993 
training batch:   300, loss: 0.20002, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:   320, loss: 0.14170, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.13013, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   360, loss: 0.36934, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.989 
training batch:   380, loss: 0.26834, precision: 0.977 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:   400, loss: 0.20552, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:   420, loss: 0.13346, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:   440, loss: 0.09438, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.22787, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.995 
training batch:   480, loss: 0.00127, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.03870, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.12408, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:   540, loss: 0.21190, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.999 
training batch:   560, loss: 0.30157, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:   580, loss: 0.01528, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.03857, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.02132, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 0.02618, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.53065, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.994 
training batch:   680, loss: 0.19266, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:   700, loss: 0.09294, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.11546, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 0.84734, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.998 
training batch:   760, loss: 0.25780, precision: 0.977 recall: 1.000 f1: 0.989 accuracy: 0.998 
training batch:   780, loss: 0.16489, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.994 
training batch:   800, loss: 0.01505, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   820, loss: 0.32301, precision: 1.000 recall: 0.977 f1: 0.989 accuracy: 0.994 
training batch:   840, loss: 0.16096, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   860, loss: 0.19740, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:   880, loss: 0.02781, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.01585, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 0.04504, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   940, loss: 0.22888, precision: 0.977 recall: 0.956 f1: 0.966 accuracy: 0.998 
training batch:   960, loss: 0.03517, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   980, loss: 0.02218, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 0.08575, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1020, loss: 0.93345, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.995 
training batch:  1040, loss: 0.08620, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1060, loss: 0.58777, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.998 
training batch:  1080, loss: 0.10450, precision: 0.962 recall: 0.926 f1: 0.943 accuracy: 0.999 
training batch:  1100, loss: 0.51935, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:  1120, loss: 0.01074, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1140, loss: 0.79746, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.988 
training batch:  1160, loss: 0.50192, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:  1180, loss: 0.04394, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.76878, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.996 
training batch:  1220, loss: 0.00348, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.00807, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.14997, precision: 1.000 recall: 0.978 f1: 0.989 accuracy: 0.999 
training batch:  1280, loss: 0.07796, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.04636, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.17146, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:  1340, loss: 0.05352, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 0.00457, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 1.41161, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.986 
start evaluate engines...
label: Dsa, precision: 0.986 recall: 0.986 f1: 0.986 
label: Chk, precision: 0.674 recall: 0.671 f1: 0.672 
label: Ins, precision: 0.433 recall: 0.434 f1: 0.432 
label: Sur, precision: 0.869 recall: 0.869 f1: 0.869 
label: Med, precision: 0.445 recall: 0.441 f1: 0.443 
label: Ana, precision: 0.995 recall: 0.996 f1: 0.996 
time consumption:23.77(min), precision: 0.994 recall: 0.994 f1: 0.994 accuracy: 0.999 
epoch:19/100
training batch:    20, loss: 0.00748, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.03021, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.02958, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.25228, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.06316, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.04774, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.00038, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   160, loss: 0.06773, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   180, loss: 0.03175, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.00502, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.02356, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   240, loss: 0.54807, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.996 
training batch:   260, loss: 0.05152, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.53378, precision: 0.980 recall: 0.960 f1: 0.970 accuracy: 0.998 
training batch:   300, loss: 0.58776, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   320, loss: 0.00420, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.34227, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:   360, loss: 0.00907, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 0.08503, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.00905, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.13396, precision: 1.000 recall: 0.964 f1: 0.982 accuracy: 0.999 
training batch:   440, loss: 0.10896, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.00558, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.01483, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.06720, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.12884, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.45983, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   560, loss: 0.00727, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.09100, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.11933, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.09283, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 0.02209, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.00796, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.01398, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.01094, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.27098, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.999 
training batch:   740, loss: 0.06644, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   760, loss: 0.20956, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:   780, loss: 0.05008, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   800, loss: 0.08092, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   820, loss: 0.14422, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.07627, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 0.01636, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   880, loss: 1.30129, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:   900, loss: 0.04329, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 0.02210, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   940, loss: 0.00517, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 0.43450, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   980, loss: 0.31891, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:  1000, loss: 0.61761, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.990 
training batch:  1020, loss: 0.00299, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1040, loss: 0.04882, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1060, loss: 0.06461, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 1.22005, precision: 0.949 recall: 0.902 f1: 0.925 accuracy: 0.988 
training batch:  1100, loss: 2.29590, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.978 
training batch:  1120, loss: 0.17252, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:  1140, loss: 0.19694, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:  1160, loss: 0.31421, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.998 
training batch:  1180, loss: 0.11364, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.00180, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 2.36061, precision: 0.972 recall: 0.854 f1: 0.909 accuracy: 0.990 
training batch:  1240, loss: 0.74346, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.994 
training batch:  1260, loss: 0.00954, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.00600, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.03899, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.23498, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.999 
training batch:  1340, loss: 0.13406, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:  1360, loss: 0.29313, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.995 
training batch:  1380, loss: 0.00848, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.983 recall: 0.984 f1: 0.983 
label: Chk, precision: 0.685 recall: 0.684 f1: 0.684 
label: Ins, precision: 0.439 recall: 0.432 f1: 0.435 
label: Sur, precision: 0.868 recall: 0.869 f1: 0.868 
label: Med, precision: 0.450 recall: 0.451 f1: 0.450 
label: Ana, precision: 0.997 recall: 0.993 f1: 0.995 
time consumption:23.10(min), precision: 0.997 recall: 0.994 f1: 0.995 accuracy: 0.999 
epoch:20/100
training batch:    20, loss: 0.00296, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.62807, precision: 0.951 recall: 0.886 f1: 0.918 accuracy: 0.995 
training batch:    60, loss: 0.00294, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.01181, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.40250, precision: 0.951 recall: 0.929 f1: 0.940 accuracy: 0.993 
training batch:   120, loss: 0.40491, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.993 
training batch:   140, loss: 0.11575, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   160, loss: 1.28934, precision: 0.923 recall: 0.973 f1: 0.947 accuracy: 0.991 
training batch:   180, loss: 1.41630, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   200, loss: 0.01434, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.24052, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:   240, loss: 0.32475, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.998 
training batch:   260, loss: 0.00705, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.96330, precision: 0.970 recall: 0.889 f1: 0.928 accuracy: 0.989 
training batch:   300, loss: 0.03696, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 0.05868, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.08524, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   360, loss: 0.23305, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.996 
training batch:   380, loss: 0.03288, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.01699, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.59210, precision: 0.952 recall: 1.000 f1: 0.976 accuracy: 0.993 
training batch:   440, loss: 0.00446, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.24403, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:   480, loss: 0.05345, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.02058, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.56768, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.995 
training batch:   540, loss: 1.39022, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.995 
training batch:   560, loss: 0.00762, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.29449, precision: 0.974 recall: 0.950 f1: 0.962 accuracy: 0.996 
training batch:   600, loss: 0.04113, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.01280, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 0.12924, precision: 1.000 recall: 0.975 f1: 0.987 accuracy: 0.995 
training batch:   660, loss: 0.06155, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.02995, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.01735, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.21245, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:   740, loss: 0.06151, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   760, loss: 0.03516, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   780, loss: 0.00365, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   800, loss: 0.05110, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   820, loss: 0.07389, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 1.38293, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.996 
training batch:   860, loss: 0.26778, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.993 
training batch:   880, loss: 0.00240, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.01367, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 0.01466, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   940, loss: 0.04807, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 0.00369, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   980, loss: 0.09044, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 0.12703, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.999 
training batch:  1020, loss: 0.03107, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1040, loss: 0.02409, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1060, loss: 0.02425, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 0.03816, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 1.57375, precision: 0.875 recall: 0.848 f1: 0.862 accuracy: 0.969 
training batch:  1120, loss: 0.00426, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1140, loss: 0.01054, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1160, loss: 1.64990, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.993 
training batch:  1180, loss: 0.07010, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.17755, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:  1220, loss: 0.54252, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.994 
training batch:  1240, loss: 0.00497, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.00667, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.10926, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.10231, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.08946, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1340, loss: 0.22870, precision: 1.000 recall: 0.946 f1: 0.972 accuracy: 0.996 
training batch:  1360, loss: 0.00138, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 1.26681, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.998 
start evaluate engines...
label: Dsa, precision: 0.986 recall: 0.987 f1: 0.986 
label: Chk, precision: 0.687 recall: 0.686 f1: 0.686 
label: Ins, precision: 0.434 recall: 0.427 f1: 0.429 
label: Sur, precision: 0.869 recall: 0.868 f1: 0.868 
label: Med, precision: 0.448 recall: 0.446 f1: 0.447 
label: Ana, precision: 0.996 recall: 0.995 f1: 0.995 
time consumption:19.87(min), precision: 0.996 recall: 0.995 f1: 0.996 accuracy: 0.999 
epoch:21/100
training batch:    20, loss: 0.04445, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 1.53629, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.996 
training batch:    60, loss: 0.21230, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.994 
training batch:    80, loss: 0.00128, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.06536, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.00258, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.06266, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   160, loss: 0.16759, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.998 
training batch:   180, loss: 0.00136, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.02693, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 1.09929, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   240, loss: 0.91411, precision: 0.938 recall: 1.000 f1: 0.968 accuracy: 0.995 
training batch:   260, loss: 0.00298, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.07937, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   300, loss: 0.02878, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 0.00614, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.00701, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   360, loss: 0.00985, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 0.00497, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.00751, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 1.34406, precision: 0.900 recall: 0.964 f1: 0.931 accuracy: 0.986 
training batch:   440, loss: 0.29527, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.998 
training batch:   460, loss: 0.01755, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.00440, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.00510, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.02378, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.03600, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   560, loss: 0.06200, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.01249, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.02026, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.40442, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:   640, loss: 0.87713, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:   660, loss: 0.77807, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.993 
training batch:   680, loss: 0.21181, precision: 1.000 recall: 0.977 f1: 0.988 accuracy: 0.998 
training batch:   700, loss: 0.40234, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:   720, loss: 0.00974, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 0.36749, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:   760, loss: 0.04429, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   780, loss: 0.14915, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   800, loss: 0.37212, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   820, loss: 0.01710, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.35007, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.991 
training batch:   860, loss: 0.43834, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.993 
training batch:   880, loss: 0.00294, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.08743, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 0.02856, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   940, loss: 0.51852, precision: 0.889 recall: 0.923 f1: 0.906 accuracy: 0.996 
training batch:   960, loss: 0.89178, precision: 0.978 recall: 0.957 f1: 0.967 accuracy: 0.999 
training batch:   980, loss: 0.04070, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 0.02906, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1020, loss: 0.02855, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1040, loss: 0.07555, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1060, loss: 0.00995, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 0.05602, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.36721, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.993 
training batch:  1120, loss: 0.51228, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.996 
training batch:  1140, loss: 0.41544, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.994 
training batch:  1160, loss: 0.27742, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.07169, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 1.39799, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.995 
training batch:  1220, loss: 0.21538, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.998 
training batch:  1240, loss: 0.06245, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.00523, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.00684, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.38847, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.989 
training batch:  1320, loss: 0.52349, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.996 
training batch:  1340, loss: 0.05924, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 0.40433, precision: 1.000 recall: 0.943 f1: 0.971 accuracy: 0.998 
training batch:  1380, loss: 0.26476, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.998 
start evaluate engines...
label: Dsa, precision: 0.981 recall: 0.984 f1: 0.982 
label: Chk, precision: 0.685 recall: 0.685 f1: 0.685 
label: Ins, precision: 0.436 recall: 0.429 f1: 0.432 
label: Sur, precision: 0.869 recall: 0.869 f1: 0.869 
label: Med, precision: 0.450 recall: 0.451 f1: 0.450 
label: Ana, precision: 0.995 recall: 0.997 f1: 0.996 
time consumption:27.77(min), precision: 0.994 recall: 0.996 f1: 0.995 accuracy: 0.999 
early stopped, no progress obtained within 5 epochs
overall best f1 is 0.9956466654580051 at 16 epoch
total training time consumption: 451.175(min)
