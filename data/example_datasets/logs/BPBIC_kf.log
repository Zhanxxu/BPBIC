2022-10-28 12:33:51
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY++++++++++++++++++++++++++++++++++++++++
 Status:
     mode                 : train
 ++++++++++++++++++++++++++++++++++++++++
 Datasets:
     datasets         fold: data/example_datasets
     train            file: train_all.csv
     validation       file: None
     vocab             dir: data/example_datasets/vocab/BPBIC_kf
     delimiter            : b
     use  pretrained model: True
     pretrained      model: Bert
     finetune             : False
     use    middle   model: True
     middle          model: bilstm+idcnn
     checkpoints       dir: checkpoints/BPBIC_kf
     log               dir: data/example_datasets/logs
 ++++++++++++++++++++++++++++++++++++++++
Labeling Scheme:
     label          scheme: BIO
     label           level: 2
     suffixes             : ['Dsa', 'Chk', 'Ins', 'Sur', 'Med', 'Ana']
     measuring     metrics: ['precision', 'recall', 'f1', 'accuracy']
 ++++++++++++++++++++++++++++++++++++++++
Model Configuration:
     embedding         dim: 100
     max  sequence  length: 100
     hidden            dim: 128
     filter           nums: 64
     idcnn            nums: 3
     CUDA  VISIBLE  DEVICE: 0
     seed                 : 23
 ++++++++++++++++++++++++++++++++++++++++
 Training Settings:
     epoch                : 100
     batch            size: 8
     dropout              : 0.3
     learning         rate: 0.001
     optimizer            : Adam
     use               gan: True
     gan            method: pgd
     checkpoint       name: model_our
     max       checkpoints: 3
     print       per_batch: 20
     is     early     stop: True
     patient              : 5
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY END++++++++++++++++++++++++++++++++++++++++
label vocab files not exist, building label vocab...
dataManager initialed...
mode: train
loading data...
validating set is not exist, built...
training set size: 15260, validating set size: 3815
++++++++++++++++++++training starting++++++++++++++++++++
epoch:1/100
training batch:    20, loss: 132.74155, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.756 
training batch:    40, loss: 45.67373, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.856 
training batch:    60, loss: 73.32249, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.810 
training batch:    80, loss: 51.58382, precision: 0.250 recall: 0.075 f1: 0.115 accuracy: 0.874 
training batch:   100, loss: 34.44952, precision: 0.429 recall: 0.265 f1: 0.327 accuracy: 0.894 
training batch:   120, loss: 39.35700, precision: 0.250 recall: 0.188 f1: 0.214 accuracy: 0.875 
training batch:   140, loss: 24.10114, precision: 0.607 recall: 0.567 f1: 0.586 accuracy: 0.931 
training batch:   160, loss: 17.04303, precision: 0.621 recall: 0.621 f1: 0.621 accuracy: 0.951 
training batch:   180, loss: 25.98324, precision: 0.571 recall: 0.457 f1: 0.508 accuracy: 0.924 
training batch:   200, loss: 44.34745, precision: 0.412 recall: 0.424 f1: 0.418 accuracy: 0.865 
training batch:   220, loss: 17.65234, precision: 0.531 recall: 0.531 f1: 0.531 accuracy: 0.934 
training batch:   240, loss: 21.23829, precision: 0.667 recall: 0.643 f1: 0.655 accuracy: 0.934 
training batch:   260, loss: 11.67766, precision: 0.761 recall: 0.875 f1: 0.814 accuracy: 0.978 
training batch:   280, loss: 20.85104, precision: 0.528 recall: 0.514 f1: 0.521 accuracy: 0.931 
training batch:   300, loss: 25.88194, precision: 0.714 recall: 0.556 f1: 0.625 accuracy: 0.925 
training batch:   320, loss: 10.76339, precision: 0.643 recall: 0.529 f1: 0.581 accuracy: 0.964 
training batch:   340, loss: 13.60909, precision: 0.657 recall: 0.605 f1: 0.630 accuracy: 0.959 
training batch:   360, loss: 13.74917, precision: 0.690 recall: 0.714 f1: 0.702 accuracy: 0.960 
training batch:   380, loss: 30.05230, precision: 0.750 recall: 0.767 f1: 0.759 accuracy: 0.930 
training batch:   400, loss: 13.52040, precision: 0.647 recall: 0.710 f1: 0.677 accuracy: 0.955 
training batch:   420, loss: 5.43694, precision: 0.857 recall: 0.828 f1: 0.842 accuracy: 0.986 
training batch:   440, loss: 17.54258, precision: 0.590 recall: 0.697 f1: 0.639 accuracy: 0.944 
training batch:   460, loss: 17.14259, precision: 0.714 recall: 0.732 f1: 0.723 accuracy: 0.940 
training batch:   480, loss: 8.36784, precision: 0.852 recall: 0.885 f1: 0.868 accuracy: 0.978 
training batch:   500, loss: 14.29493, precision: 0.808 recall: 0.700 f1: 0.750 accuracy: 0.966 
training batch:   520, loss: 6.88091, precision: 0.905 recall: 0.679 f1: 0.776 accuracy: 0.976 
training batch:   540, loss: 35.11884, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.940 
training batch:   560, loss: 12.85642, precision: 0.658 recall: 0.610 f1: 0.633 accuracy: 0.960 
training batch:   580, loss: 20.51927, precision: 0.778 recall: 0.778 f1: 0.778 accuracy: 0.943 
training batch:   600, loss: 16.32720, precision: 0.676 recall: 0.781 f1: 0.725 accuracy: 0.936 
training batch:   620, loss: 9.06970, precision: 0.743 recall: 0.765 f1: 0.754 accuracy: 0.965 
training batch:   640, loss: 8.17387, precision: 0.789 recall: 0.789 f1: 0.789 accuracy: 0.978 
training batch:   660, loss: 10.02721, precision: 0.825 recall: 0.767 f1: 0.795 accuracy: 0.966 
training batch:   680, loss: 8.09219, precision: 0.811 recall: 0.882 f1: 0.845 accuracy: 0.980 
training batch:   700, loss: 5.16103, precision: 0.839 recall: 0.867 f1: 0.852 accuracy: 0.989 
training batch:   720, loss: 5.97423, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.986 
training batch:   740, loss: 7.00388, precision: 0.800 recall: 0.727 f1: 0.762 accuracy: 0.979 
training batch:   760, loss: 6.18207, precision: 0.789 recall: 0.857 f1: 0.822 accuracy: 0.974 
training batch:   780, loss: 3.98640, precision: 0.808 recall: 0.808 f1: 0.808 accuracy: 0.988 
training batch:   800, loss: 9.81560, precision: 0.891 recall: 0.837 f1: 0.863 accuracy: 0.968 
training batch:   820, loss: 3.84463, precision: 0.882 recall: 0.857 f1: 0.870 accuracy: 0.988 
training batch:   840, loss: 5.26762, precision: 0.872 recall: 0.919 f1: 0.895 accuracy: 0.979 
training batch:   860, loss: 7.71432, precision: 0.905 recall: 0.809 f1: 0.854 accuracy: 0.975 
training batch:   880, loss: 4.76756, precision: 0.875 recall: 0.933 f1: 0.903 accuracy: 0.984 
training batch:   900, loss: 10.00929, precision: 0.730 recall: 0.750 f1: 0.740 accuracy: 0.969 
training batch:   920, loss: 7.79646, precision: 0.833 recall: 0.811 f1: 0.822 accuracy: 0.979 
training batch:   940, loss: 11.58629, precision: 0.848 recall: 0.848 f1: 0.848 accuracy: 0.956 
training batch:   960, loss: 8.92202, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.954 
training batch:   980, loss: 5.07681, precision: 0.806 recall: 0.862 f1: 0.833 accuracy: 0.983 
training batch:  1000, loss: 8.37620, precision: 0.938 recall: 0.957 f1: 0.947 accuracy: 0.984 
training batch:  1020, loss: 11.11152, precision: 0.667 recall: 0.690 f1: 0.678 accuracy: 0.958 
training batch:  1040, loss: 4.85659, precision: 0.793 recall: 0.852 f1: 0.821 accuracy: 0.983 
training batch:  1060, loss: 5.25703, precision: 0.868 recall: 0.892 f1: 0.880 accuracy: 0.981 
training batch:  1080, loss: 4.18870, precision: 0.732 recall: 0.857 f1: 0.789 accuracy: 0.985 
training batch:  1100, loss: 6.14626, precision: 0.727 recall: 0.857 f1: 0.787 accuracy: 0.978 
training batch:  1120, loss: 9.94740, precision: 0.634 recall: 0.743 f1: 0.684 accuracy: 0.954 
training batch:  1140, loss: 11.11292, precision: 0.792 recall: 0.792 f1: 0.792 accuracy: 0.949 
training batch:  1160, loss: 4.68045, precision: 0.875 recall: 0.824 f1: 0.848 accuracy: 0.989 
training batch:  1180, loss: 10.53694, precision: 0.774 recall: 0.750 f1: 0.762 accuracy: 0.973 
training batch:  1200, loss: 4.96272, precision: 0.939 recall: 0.816 f1: 0.873 accuracy: 0.975 
training batch:  1220, loss: 8.12696, precision: 0.789 recall: 0.857 f1: 0.822 accuracy: 0.965 
training batch:  1240, loss: 8.74084, precision: 0.885 recall: 0.939 f1: 0.911 accuracy: 0.971 
training batch:  1260, loss: 6.53382, precision: 0.867 recall: 0.812 f1: 0.839 accuracy: 0.985 
training batch:  1280, loss: 3.87612, precision: 0.927 recall: 0.905 f1: 0.916 accuracy: 0.988 
training batch:  1300, loss: 8.01607, precision: 0.811 recall: 0.789 f1: 0.800 accuracy: 0.973 
training batch:  1320, loss: 3.20679, precision: 0.857 recall: 0.818 f1: 0.837 accuracy: 0.988 
training batch:  1340, loss: 5.28762, precision: 0.875 recall: 0.854 f1: 0.864 accuracy: 0.989 
training batch:  1360, loss: 4.37927, precision: 0.788 recall: 0.765 f1: 0.776 accuracy: 0.985 
training batch:  1380, loss: 3.55779, precision: 0.800 recall: 0.800 f1: 0.800 accuracy: 0.983 
training batch:  1400, loss: 2.63267, precision: 0.897 recall: 0.867 f1: 0.881 accuracy: 0.988 
training batch:  1420, loss: 10.69090, precision: 0.951 recall: 0.929 f1: 0.940 accuracy: 0.975 
training batch:  1440, loss: 6.36412, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.969 
training batch:  1460, loss: 5.88066, precision: 0.879 recall: 0.829 f1: 0.853 accuracy: 0.988 
training batch:  1480, loss: 4.40737, precision: 0.868 recall: 0.868 f1: 0.868 accuracy: 0.979 
training batch:  1500, loss: 2.61447, precision: 0.895 recall: 0.919 f1: 0.907 accuracy: 0.993 
training batch:  1520, loss: 3.42338, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.988 
training batch:  1540, loss: 5.62711, precision: 0.818 recall: 0.844 f1: 0.831 accuracy: 0.980 
training batch:  1560, loss: 3.28601, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.994 
training batch:  1580, loss: 1.57519, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.996 
training batch:  1600, loss: 10.15292, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.983 
training batch:  1620, loss: 5.17231, precision: 0.833 recall: 0.857 f1: 0.845 accuracy: 0.985 
training batch:  1640, loss: 5.15070, precision: 0.783 recall: 0.878 f1: 0.828 accuracy: 0.978 
training batch:  1660, loss: 3.67644, precision: 0.969 recall: 0.886 f1: 0.925 accuracy: 0.985 
training batch:  1680, loss: 11.35271, precision: 0.833 recall: 0.750 f1: 0.789 accuracy: 0.960 
training batch:  1700, loss: 6.12714, precision: 0.846 recall: 0.805 f1: 0.825 accuracy: 0.969 
training batch:  1720, loss: 2.96339, precision: 0.912 recall: 0.861 f1: 0.886 accuracy: 0.989 
training batch:  1740, loss: 5.49660, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.985 
training batch:  1760, loss: 1.61594, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.995 
training batch:  1780, loss: 4.06953, precision: 0.897 recall: 0.867 f1: 0.881 accuracy: 0.993 
training batch:  1800, loss: 2.15709, precision: 0.949 recall: 0.925 f1: 0.937 accuracy: 0.988 
training batch:  1820, loss: 1.80626, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.996 
training batch:  1840, loss: 2.86211, precision: 0.853 recall: 0.906 f1: 0.879 accuracy: 0.986 
training batch:  1860, loss: 2.87459, precision: 0.897 recall: 0.946 f1: 0.921 accuracy: 0.981 
training batch:  1880, loss: 2.36729, precision: 0.889 recall: 0.960 f1: 0.923 accuracy: 0.993 
training batch:  1900, loss: 3.15041, precision: 0.971 recall: 0.917 f1: 0.943 accuracy: 0.989 
start evaluate engines...
label: Dsa, precision: 0.952 recall: 0.949 f1: 0.949 
label: Chk, precision: 0.696 recall: 0.694 f1: 0.693 
label: Ins, precision: 0.411 recall: 0.409 f1: 0.407 
label: Sur, precision: 0.864 recall: 0.875 f1: 0.868 
label: Med, precision: 0.445 recall: 0.448 f1: 0.445 
label: Ana, precision: 0.929 recall: 0.952 f1: 0.940 
time consumption:23.44(min), precision: 0.944 recall: 0.957 f1: 0.950 accuracy: 0.993 
saved the new best model with f1: 0.950
epoch:2/100
training batch:    20, loss: 3.54391, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.991 
training batch:    40, loss: 2.74339, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.993 
training batch:    60, loss: 3.83511, precision: 0.897 recall: 0.921 f1: 0.909 accuracy: 0.984 
training batch:    80, loss: 4.94212, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.984 
training batch:   100, loss: 2.01138, precision: 0.903 recall: 0.875 f1: 0.889 accuracy: 0.993 
training batch:   120, loss: 3.96039, precision: 0.878 recall: 0.935 f1: 0.905 accuracy: 0.985 
training batch:   140, loss: 4.26991, precision: 0.853 recall: 0.879 f1: 0.866 accuracy: 0.986 
training batch:   160, loss: 2.07819, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.994 
training batch:   180, loss: 1.15411, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.998 
training batch:   200, loss: 3.39378, precision: 0.889 recall: 0.800 f1: 0.842 accuracy: 0.986 
training batch:   220, loss: 5.74611, precision: 0.853 recall: 0.853 f1: 0.853 accuracy: 0.984 
training batch:   240, loss: 3.82269, precision: 0.906 recall: 0.967 f1: 0.935 accuracy: 0.991 
training batch:   260, loss: 2.39862, precision: 0.892 recall: 0.943 f1: 0.917 accuracy: 0.991 
training batch:   280, loss: 5.01392, precision: 0.853 recall: 0.763 f1: 0.806 accuracy: 0.970 
training batch:   300, loss: 2.42923, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.989 
training batch:   320, loss: 1.21384, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:   340, loss: 3.60276, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.993 
training batch:   360, loss: 3.47452, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.989 
training batch:   380, loss: 0.87347, precision: 0.919 recall: 0.895 f1: 0.907 accuracy: 0.996 
training batch:   400, loss: 2.83731, precision: 0.902 recall: 0.902 f1: 0.902 accuracy: 0.994 
training batch:   420, loss: 4.60534, precision: 0.814 recall: 0.875 f1: 0.843 accuracy: 0.984 
training batch:   440, loss: 1.81518, precision: 0.939 recall: 0.886 f1: 0.912 accuracy: 0.995 
training batch:   460, loss: 0.76855, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.998 
training batch:   480, loss: 4.33163, precision: 0.878 recall: 0.900 f1: 0.889 accuracy: 0.980 
training batch:   500, loss: 1.01595, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.998 
training batch:   520, loss: 1.60187, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.994 
training batch:   540, loss: 3.00825, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.981 
training batch:   560, loss: 2.28359, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.991 
training batch:   580, loss: 6.07540, precision: 0.915 recall: 0.935 f1: 0.925 accuracy: 0.973 
training batch:   600, loss: 2.33916, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.996 
training batch:   620, loss: 1.62559, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.990 
training batch:   640, loss: 2.43809, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.990 
training batch:   660, loss: 1.09294, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.996 
training batch:   680, loss: 2.88937, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.993 
training batch:   700, loss: 2.60454, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.990 
training batch:   720, loss: 1.55603, precision: 0.902 recall: 0.974 f1: 0.937 accuracy: 0.996 
training batch:   740, loss: 2.27047, precision: 0.897 recall: 0.921 f1: 0.909 accuracy: 0.993 
training batch:   760, loss: 5.08276, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.981 
training batch:   780, loss: 3.79684, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.990 
training batch:   800, loss: 1.82271, precision: 0.932 recall: 0.976 f1: 0.953 accuracy: 0.998 
training batch:   820, loss: 2.94771, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.981 
training batch:   840, loss: 0.91320, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 1.61227, precision: 1.000 recall: 0.951 f1: 0.975 accuracy: 0.995 
training batch:   880, loss: 4.57468, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.988 
training batch:   900, loss: 5.87587, precision: 0.935 recall: 0.906 f1: 0.921 accuracy: 0.986 
training batch:   920, loss: 1.89192, precision: 0.909 recall: 0.930 f1: 0.920 accuracy: 0.994 
training batch:   940, loss: 2.02789, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.983 
training batch:   960, loss: 2.11722, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.995 
training batch:   980, loss: 3.87195, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.979 
training batch:  1000, loss: 4.32178, precision: 0.771 recall: 0.900 f1: 0.831 accuracy: 0.974 
training batch:  1020, loss: 1.18158, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:  1040, loss: 1.48515, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.994 
training batch:  1060, loss: 1.61015, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:  1080, loss: 0.91722, precision: 0.968 recall: 0.909 f1: 0.937 accuracy: 0.996 
training batch:  1100, loss: 4.80626, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.989 
training batch:  1120, loss: 8.11937, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.974 
training batch:  1140, loss: 0.78609, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.995 
training batch:  1160, loss: 2.16098, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.996 
training batch:  1180, loss: 1.18428, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.996 
training batch:  1200, loss: 1.73431, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.995 
training batch:  1220, loss: 4.23679, precision: 0.864 recall: 0.864 f1: 0.864 accuracy: 0.983 
training batch:  1240, loss: 2.73455, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.993 
training batch:  1260, loss: 2.96413, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.988 
training batch:  1280, loss: 0.82877, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.998 
training batch:  1300, loss: 1.83459, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.994 
training batch:  1320, loss: 1.66277, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:  1340, loss: 0.93081, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:  1360, loss: 2.55423, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.995 
training batch:  1380, loss: 1.00249, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.999 
training batch:  1400, loss: 1.82614, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.991 
training batch:  1420, loss: 3.14125, precision: 0.921 recall: 0.897 f1: 0.909 accuracy: 0.989 
training batch:  1440, loss: 5.42652, precision: 0.850 recall: 0.944 f1: 0.895 accuracy: 0.980 
training batch:  1460, loss: 2.61716, precision: 0.923 recall: 1.000 f1: 0.960 accuracy: 0.993 
training batch:  1480, loss: 1.25207, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.996 
training batch:  1500, loss: 0.77541, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.995 
training batch:  1520, loss: 1.02698, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.994 
training batch:  1540, loss: 0.99434, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.998 
training batch:  1560, loss: 4.40087, precision: 0.931 recall: 0.900 f1: 0.915 accuracy: 0.990 
training batch:  1580, loss: 1.05463, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.996 
training batch:  1600, loss: 2.17500, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.991 
training batch:  1620, loss: 0.72048, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.996 
training batch:  1640, loss: 1.78487, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:  1660, loss: 0.81842, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:  1680, loss: 0.68462, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:  1700, loss: 2.47510, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.996 
training batch:  1720, loss: 3.35286, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.991 
training batch:  1740, loss: 2.40144, precision: 0.872 recall: 0.919 f1: 0.895 accuracy: 0.989 
training batch:  1760, loss: 0.54745, precision: 0.957 recall: 0.978 f1: 0.967 accuracy: 0.999 
training batch:  1780, loss: 2.91744, precision: 0.861 recall: 0.861 f1: 0.861 accuracy: 0.985 
training batch:  1800, loss: 1.60815, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.995 
training batch:  1820, loss: 1.10580, precision: 0.949 recall: 0.902 f1: 0.925 accuracy: 0.995 
training batch:  1840, loss: 1.37540, precision: 0.947 recall: 0.923 f1: 0.935 accuracy: 0.991 
training batch:  1860, loss: 3.11067, precision: 0.949 recall: 0.881 f1: 0.914 accuracy: 0.990 
training batch:  1880, loss: 1.07512, precision: 0.927 recall: 0.974 f1: 0.950 accuracy: 0.996 
training batch:  1900, loss: 1.69633, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.990 
start evaluate engines...
label: Dsa, precision: 0.976 recall: 0.976 f1: 0.975 
label: Chk, precision: 0.710 recall: 0.709 f1: 0.709 
label: Ins, precision: 0.443 recall: 0.442 f1: 0.441 
label: Sur, precision: 0.889 recall: 0.887 f1: 0.888 
label: Med, precision: 0.467 recall: 0.467 f1: 0.467 
label: Ana, precision: 0.978 recall: 0.979 f1: 0.978 
time consumption:23.22(min), precision: 0.982 recall: 0.981 f1: 0.981 accuracy: 0.998 
saved the new best model with f1: 0.981
epoch:3/100
training batch:    20, loss: 1.39015, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.994 
training batch:    40, loss: 0.10947, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 2.55641, precision: 0.921 recall: 0.972 f1: 0.946 accuracy: 0.988 
training batch:    80, loss: 1.86183, precision: 0.900 recall: 0.931 f1: 0.915 accuracy: 0.995 
training batch:   100, loss: 0.91643, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:   120, loss: 0.35797, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.999 
training batch:   140, loss: 1.38376, precision: 0.950 recall: 0.927 f1: 0.938 accuracy: 0.998 
training batch:   160, loss: 1.27905, precision: 0.930 recall: 0.930 f1: 0.930 accuracy: 0.995 
training batch:   180, loss: 0.86967, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.996 
training batch:   200, loss: 1.54173, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.991 
training batch:   220, loss: 0.93033, precision: 0.947 recall: 1.000 f1: 0.973 accuracy: 0.998 
training batch:   240, loss: 0.79823, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.998 
training batch:   260, loss: 0.09294, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 2.04521, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.994 
training batch:   300, loss: 2.35178, precision: 0.816 recall: 0.861 f1: 0.838 accuracy: 0.989 
training batch:   320, loss: 3.16174, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.990 
training batch:   340, loss: 0.68317, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:   360, loss: 0.68446, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.998 
training batch:   380, loss: 0.20006, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.999 
training batch:   400, loss: 0.65314, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.996 
training batch:   420, loss: 1.46423, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.993 
training batch:   440, loss: 2.92386, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.995 
training batch:   460, loss: 2.26457, precision: 0.971 recall: 0.917 f1: 0.943 accuracy: 0.995 
training batch:   480, loss: 0.91599, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.998 
training batch:   500, loss: 0.47902, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.996 
training batch:   520, loss: 1.13458, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.998 
training batch:   540, loss: 1.83203, precision: 1.000 recall: 0.912 f1: 0.954 accuracy: 0.993 
training batch:   560, loss: 1.32214, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.998 
training batch:   580, loss: 1.25246, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.994 
training batch:   600, loss: 0.89001, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.996 
training batch:   620, loss: 0.81292, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.998 
training batch:   640, loss: 0.82204, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   660, loss: 2.22801, precision: 0.902 recall: 0.949 f1: 0.925 accuracy: 0.998 
training batch:   680, loss: 1.17697, precision: 0.917 recall: 0.971 f1: 0.943 accuracy: 0.993 
training batch:   700, loss: 0.34656, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.999 
training batch:   720, loss: 0.39662, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 1.54622, precision: 0.978 recall: 0.936 f1: 0.957 accuracy: 0.994 
training batch:   760, loss: 0.82098, precision: 0.920 recall: 0.920 f1: 0.920 accuracy: 0.995 
training batch:   780, loss: 0.80095, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.998 
training batch:   800, loss: 0.67448, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.998 
training batch:   820, loss: 1.15627, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.993 
training batch:   840, loss: 2.31834, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.994 
training batch:   860, loss: 2.49265, precision: 0.963 recall: 0.897 f1: 0.929 accuracy: 0.990 
training batch:   880, loss: 0.30300, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 1.54610, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.978 
training batch:   920, loss: 0.37390, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   940, loss: 2.48812, precision: 1.000 recall: 0.943 f1: 0.971 accuracy: 0.989 
training batch:   960, loss: 1.55151, precision: 0.927 recall: 0.927 f1: 0.927 accuracy: 0.995 
training batch:   980, loss: 0.47903, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 2.61874, precision: 0.903 recall: 0.848 f1: 0.875 accuracy: 0.984 
training batch:  1020, loss: 0.95058, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.998 
training batch:  1040, loss: 2.34876, precision: 0.911 recall: 0.932 f1: 0.921 accuracy: 0.984 
training batch:  1060, loss: 0.75121, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.999 
training batch:  1080, loss: 1.36111, precision: 0.977 recall: 1.000 f1: 0.988 accuracy: 0.998 
training batch:  1100, loss: 0.85291, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:  1120, loss: 1.17861, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.998 
training batch:  1140, loss: 2.70877, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.989 
training batch:  1160, loss: 0.65053, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.998 
training batch:  1180, loss: 1.61952, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.994 
training batch:  1200, loss: 0.39331, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 1.06134, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.995 
training batch:  1240, loss: 3.27845, precision: 0.889 recall: 0.930 f1: 0.909 accuracy: 0.983 
training batch:  1260, loss: 1.35033, precision: 0.923 recall: 0.900 f1: 0.911 accuracy: 0.995 
training batch:  1280, loss: 0.60046, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:  1300, loss: 0.37839, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.999 
training batch:  1320, loss: 0.55617, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.996 
training batch:  1340, loss: 1.00754, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.996 
training batch:  1360, loss: 1.01485, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.996 
training batch:  1380, loss: 0.52879, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:  1400, loss: 3.47466, precision: 0.930 recall: 0.889 f1: 0.909 accuracy: 0.988 
training batch:  1420, loss: 0.44969, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:  1440, loss: 4.13043, precision: 0.902 recall: 0.949 f1: 0.925 accuracy: 0.988 
training batch:  1460, loss: 1.73639, precision: 1.000 recall: 0.960 f1: 0.980 accuracy: 0.998 
training batch:  1480, loss: 1.24503, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.993 
training batch:  1500, loss: 1.23904, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.995 
training batch:  1520, loss: 1.37669, precision: 0.912 recall: 0.969 f1: 0.939 accuracy: 0.994 
training batch:  1540, loss: 0.95615, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.995 
training batch:  1560, loss: 0.88940, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.995 
training batch:  1580, loss: 0.30486, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.996 
training batch:  1600, loss: 2.86153, precision: 0.907 recall: 0.907 f1: 0.907 accuracy: 0.988 
training batch:  1620, loss: 0.23738, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1640, loss: 3.70277, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.988 
training batch:  1660, loss: 0.69261, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:  1680, loss: 5.90559, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.975 
training batch:  1700, loss: 0.33450, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:  1720, loss: 2.88673, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.995 
training batch:  1740, loss: 3.26752, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.981 
training batch:  1760, loss: 0.71638, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:  1780, loss: 1.72181, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.986 
training batch:  1800, loss: 0.74953, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:  1820, loss: 1.46578, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.996 
training batch:  1840, loss: 0.62791, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:  1860, loss: 1.36906, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.988 
training batch:  1880, loss: 0.39935, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1900, loss: 0.82341, precision: 1.000 recall: 0.929 f1: 0.963 accuracy: 0.994 
start evaluate engines...
label: Dsa, precision: 0.983 recall: 0.984 f1: 0.983 
label: Chk, precision: 0.713 recall: 0.713 f1: 0.713 
label: Ins, precision: 0.448 recall: 0.439 f1: 0.442 
label: Sur, precision: 0.897 recall: 0.895 f1: 0.895 
label: Med, precision: 0.467 recall: 0.470 f1: 0.468 
label: Ana, precision: 0.983 recall: 0.991 f1: 0.987 
time consumption:23.49(min), precision: 0.988 recall: 0.991 f1: 0.989 accuracy: 0.999 
saved the new best model with f1: 0.989
epoch:4/100
training batch:    20, loss: 0.23898, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    40, loss: 3.08361, precision: 0.891 recall: 0.911 f1: 0.901 accuracy: 0.990 
training batch:    60, loss: 1.38171, precision: 1.000 recall: 0.935 f1: 0.967 accuracy: 0.993 
training batch:    80, loss: 0.67101, precision: 0.962 recall: 0.943 f1: 0.952 accuracy: 0.996 
training batch:   100, loss: 0.78358, precision: 0.964 recall: 0.931 f1: 0.947 accuracy: 0.998 
training batch:   120, loss: 1.04639, precision: 0.867 recall: 0.929 f1: 0.897 accuracy: 0.993 
training batch:   140, loss: 1.33109, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.996 
training batch:   160, loss: 0.69902, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:   180, loss: 0.39841, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.27946, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 2.44720, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.993 
training batch:   240, loss: 0.14734, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   260, loss: 0.20259, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.78300, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.998 
training batch:   300, loss: 0.30606, precision: 0.958 recall: 0.958 f1: 0.958 accuracy: 0.999 
training batch:   320, loss: 0.68401, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:   340, loss: 1.41742, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.993 
training batch:   360, loss: 1.84540, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.990 
training batch:   380, loss: 1.12794, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.996 
training batch:   400, loss: 0.04993, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.69658, precision: 0.919 recall: 0.971 f1: 0.944 accuracy: 0.996 
training batch:   440, loss: 1.84995, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.995 
training batch:   460, loss: 1.63342, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.989 
training batch:   480, loss: 0.65708, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.998 
training batch:   500, loss: 0.31736, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.998 
training batch:   520, loss: 0.15697, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 1.52193, precision: 1.000 recall: 0.914 f1: 0.955 accuracy: 0.993 
training batch:   560, loss: 1.25856, precision: 0.964 recall: 0.931 f1: 0.947 accuracy: 0.995 
training batch:   580, loss: 0.25720, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   600, loss: 3.28468, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.981 
training batch:   620, loss: 4.64522, precision: 0.921 recall: 0.897 f1: 0.909 accuracy: 0.988 
training batch:   640, loss: 0.14807, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.48801, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.999 
training batch:   680, loss: 1.34654, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.996 
training batch:   700, loss: 0.66357, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.996 
training batch:   720, loss: 1.24485, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.996 
training batch:   740, loss: 1.59787, precision: 0.968 recall: 0.909 f1: 0.937 accuracy: 0.989 
training batch:   760, loss: 0.99954, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.998 
training batch:   780, loss: 0.66379, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:   800, loss: 0.89765, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.993 
training batch:   820, loss: 0.71084, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:   840, loss: 1.17012, precision: 0.900 recall: 0.931 f1: 0.915 accuracy: 0.996 
training batch:   860, loss: 0.98833, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.998 
training batch:   880, loss: 1.94267, precision: 0.931 recall: 0.900 f1: 0.915 accuracy: 0.995 
training batch:   900, loss: 0.74129, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:   920, loss: 2.04434, precision: 0.903 recall: 0.933 f1: 0.918 accuracy: 0.994 
training batch:   940, loss: 1.10899, precision: 1.000 recall: 0.978 f1: 0.989 accuracy: 0.998 
training batch:   960, loss: 0.85677, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.990 
training batch:   980, loss: 0.12494, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 0.38341, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1020, loss: 0.34557, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.998 
training batch:  1040, loss: 0.78937, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.998 
training batch:  1060, loss: 0.66090, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:  1080, loss: 0.66373, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.998 
training batch:  1100, loss: 0.37827, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:  1120, loss: 0.33147, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1140, loss: 0.57735, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.996 
training batch:  1160, loss: 1.36194, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.994 
training batch:  1180, loss: 1.51729, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.995 
training batch:  1200, loss: 0.51559, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:  1220, loss: 1.38326, precision: 0.971 recall: 0.850 f1: 0.907 accuracy: 0.994 
training batch:  1240, loss: 1.30473, precision: 1.000 recall: 0.950 f1: 0.974 accuracy: 0.994 
training batch:  1260, loss: 0.25375, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:  1280, loss: 0.47795, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:  1300, loss: 0.50832, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.996 
training batch:  1320, loss: 3.71938, precision: 0.824 recall: 0.933 f1: 0.875 accuracy: 0.983 
training batch:  1340, loss: 0.53809, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:  1360, loss: 0.88957, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.998 
training batch:  1380, loss: 0.50174, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.995 
training batch:  1400, loss: 0.93268, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.998 
training batch:  1420, loss: 0.80382, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.995 
training batch:  1440, loss: 0.98694, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.995 
training batch:  1460, loss: 0.11551, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1480, loss: 2.04620, precision: 0.927 recall: 0.905 f1: 0.916 accuracy: 0.986 
training batch:  1500, loss: 2.42754, precision: 0.842 recall: 0.914 f1: 0.877 accuracy: 0.988 
training batch:  1520, loss: 0.28337, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.998 
training batch:  1540, loss: 0.17310, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1560, loss: 0.73077, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:  1580, loss: 0.22636, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:  1600, loss: 0.69452, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.995 
training batch:  1620, loss: 0.88765, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.998 
training batch:  1640, loss: 0.57859, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.994 
training batch:  1660, loss: 0.35957, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.996 
training batch:  1680, loss: 1.63024, precision: 0.966 recall: 0.875 f1: 0.918 accuracy: 0.993 
training batch:  1700, loss: 0.39631, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:  1720, loss: 0.75320, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.999 
training batch:  1740, loss: 0.08955, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1760, loss: 0.25542, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1780, loss: 0.06720, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1800, loss: 0.66730, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.998 
training batch:  1820, loss: 2.23939, precision: 0.953 recall: 0.976 f1: 0.965 accuracy: 0.995 
training batch:  1840, loss: 0.22625, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1860, loss: 0.62898, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:  1880, loss: 0.20699, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1900, loss: 0.08895, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.986 recall: 0.988 f1: 0.987 
label: Chk, precision: 0.711 recall: 0.711 f1: 0.711 
label: Ins, precision: 0.454 recall: 0.454 f1: 0.453 
label: Sur, precision: 0.900 recall: 0.899 f1: 0.899 
label: Med, precision: 0.469 recall: 0.470 f1: 0.469 
label: Ana, precision: 0.992 recall: 0.989 f1: 0.991 
time consumption:23.29(min), precision: 0.993 recall: 0.993 f1: 0.993 accuracy: 0.999 
saved the new best model with f1: 0.993
epoch:5/100
training batch:    20, loss: 4.33603, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.988 
training batch:    40, loss: 0.27698, precision: 1.000 recall: 0.977 f1: 0.989 accuracy: 0.999 
training batch:    60, loss: 0.17577, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:    80, loss: 0.16193, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.19652, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.73920, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.999 
training batch:   140, loss: 3.83558, precision: 0.962 recall: 1.000 f1: 0.980 accuracy: 0.993 
training batch:   160, loss: 0.41011, precision: 1.000 recall: 0.929 f1: 0.963 accuracy: 0.998 
training batch:   180, loss: 0.64575, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:   200, loss: 0.99306, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.996 
training batch:   220, loss: 0.45114, precision: 0.978 recall: 0.957 f1: 0.967 accuracy: 0.996 
training batch:   240, loss: 0.66030, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.998 
training batch:   260, loss: 0.28638, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:   280, loss: 1.77454, precision: 0.909 recall: 0.976 f1: 0.941 accuracy: 0.991 
training batch:   300, loss: 2.01840, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.986 
training batch:   320, loss: 1.20524, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.993 
training batch:   340, loss: 0.19128, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   360, loss: 0.95555, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.996 
training batch:   380, loss: 0.52681, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.994 
training batch:   400, loss: 0.44859, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.998 
training batch:   420, loss: 0.28380, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   440, loss: 1.26726, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.998 
training batch:   460, loss: 0.11720, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 2.19598, precision: 0.838 recall: 0.969 f1: 0.899 accuracy: 0.994 
training batch:   500, loss: 0.22505, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.26820, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.999 
training batch:   540, loss: 0.55038, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:   560, loss: 0.41586, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   580, loss: 0.22389, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   600, loss: 0.53616, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   620, loss: 0.08948, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 0.75236, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.991 
training batch:   660, loss: 2.71369, precision: 0.833 recall: 0.882 f1: 0.857 accuracy: 0.983 
training batch:   680, loss: 0.16711, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   700, loss: 0.06539, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.25719, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.996 
training batch:   740, loss: 0.30643, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   760, loss: 1.37208, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.998 
training batch:   780, loss: 0.96776, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.994 
training batch:   800, loss: 0.06055, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   820, loss: 0.98124, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.999 
training batch:   840, loss: 0.58582, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.998 
training batch:   860, loss: 0.55554, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.996 
training batch:   880, loss: 0.12778, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.56315, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:   920, loss: 0.89117, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.996 
training batch:   940, loss: 1.00637, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.995 
training batch:   960, loss: 0.23962, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   980, loss: 0.24744, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.994 
training batch:  1000, loss: 0.06356, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1020, loss: 1.45320, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.995 
training batch:  1040, loss: 0.97986, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.998 
training batch:  1060, loss: 0.91518, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.991 
training batch:  1080, loss: 0.18526, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:  1100, loss: 0.62218, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.996 
training batch:  1120, loss: 0.26506, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:  1140, loss: 0.32413, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:  1160, loss: 1.89566, precision: 0.963 recall: 0.929 f1: 0.945 accuracy: 0.991 
training batch:  1180, loss: 2.81582, precision: 1.000 recall: 0.964 f1: 0.982 accuracy: 0.994 
training batch:  1200, loss: 0.43692, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:  1220, loss: 0.51753, precision: 0.964 recall: 0.931 f1: 0.947 accuracy: 0.998 
training batch:  1240, loss: 1.35782, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.994 
training batch:  1260, loss: 0.16354, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.29301, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.07990, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.72621, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.999 
training batch:  1340, loss: 0.26097, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.996 
training batch:  1360, loss: 0.29312, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 0.57914, precision: 0.951 recall: 1.000 f1: 0.975 accuracy: 0.998 
training batch:  1400, loss: 0.55310, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:  1420, loss: 0.17754, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:  1440, loss: 0.62148, precision: 0.871 recall: 0.900 f1: 0.885 accuracy: 0.989 
training batch:  1460, loss: 0.06448, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1480, loss: 0.98099, precision: 0.900 recall: 0.947 f1: 0.923 accuracy: 0.996 
training batch:  1500, loss: 0.96062, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.995 
training batch:  1520, loss: 0.10563, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1540, loss: 0.26810, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.999 
training batch:  1560, loss: 0.89849, precision: 1.000 recall: 0.952 f1: 0.976 accuracy: 0.998 
training batch:  1580, loss: 0.18665, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1600, loss: 0.97885, precision: 0.969 recall: 0.886 f1: 0.925 accuracy: 0.994 
training batch:  1620, loss: 0.08924, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1640, loss: 0.27637, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1660, loss: 0.25555, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.998 
training batch:  1680, loss: 0.41335, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.993 
training batch:  1700, loss: 0.05861, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1720, loss: 0.36898, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.998 
training batch:  1740, loss: 0.05764, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1760, loss: 0.46832, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.980 
training batch:  1780, loss: 0.50713, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:  1800, loss: 0.16574, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:  1820, loss: 0.63749, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:  1840, loss: 0.99208, precision: 0.950 recall: 1.000 f1: 0.974 accuracy: 0.995 
training batch:  1860, loss: 1.25312, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.988 
training batch:  1880, loss: 0.07002, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1900, loss: 0.59245, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.998 
start evaluate engines...
label: Dsa, precision: 0.980 recall: 0.978 f1: 0.979 
label: Chk, precision: 0.708 recall: 0.711 f1: 0.709 
label: Ins, precision: 0.456 recall: 0.458 f1: 0.457 
label: Sur, precision: 0.900 recall: 0.898 f1: 0.898 
label: Med, precision: 0.469 recall: 0.470 f1: 0.469 
label: Ana, precision: 0.990 recall: 0.993 f1: 0.991 
time consumption:23.19(min), precision: 0.990 recall: 0.991 f1: 0.990 accuracy: 0.999 
epoch:6/100
training batch:    20, loss: 0.23613, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.77848, precision: 1.000 recall: 0.949 f1: 0.974 accuracy: 0.994 
training batch:    60, loss: 0.13841, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:    80, loss: 0.15836, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.18196, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.996 
training batch:   120, loss: 0.11380, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 1.20293, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.984 
training batch:   160, loss: 1.02084, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:   180, loss: 1.01873, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.996 
training batch:   200, loss: 0.21674, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   220, loss: 0.28961, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:   240, loss: 0.04612, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   260, loss: 0.68884, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.996 
training batch:   280, loss: 1.80902, precision: 0.861 recall: 0.939 f1: 0.899 accuracy: 0.989 
training batch:   300, loss: 0.47383, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:   320, loss: 0.30235, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.999 
training batch:   340, loss: 0.40495, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.994 
training batch:   360, loss: 0.65634, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.996 
training batch:   380, loss: 0.15019, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 1.04391, precision: 0.885 recall: 0.958 f1: 0.920 accuracy: 0.994 
training batch:   420, loss: 0.62040, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:   440, loss: 0.15374, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.53735, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:   480, loss: 1.55177, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:   500, loss: 0.06953, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.92311, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.998 
training batch:   540, loss: 0.25997, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   560, loss: 0.13418, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.32487, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.998 
training batch:   600, loss: 0.49671, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:   620, loss: 0.04284, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 2.16164, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.991 
training batch:   660, loss: 0.81170, precision: 1.000 recall: 0.875 f1: 0.933 accuracy: 0.995 
training batch:   680, loss: 0.08918, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.27891, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.999 
training batch:   720, loss: 1.59369, precision: 0.978 recall: 1.000 f1: 0.989 accuracy: 0.995 
training batch:   740, loss: 1.09032, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.994 
training batch:   760, loss: 0.26453, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   780, loss: 0.79999, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.996 
training batch:   800, loss: 0.30451, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.998 
training batch:   820, loss: 2.32132, precision: 0.905 recall: 1.000 f1: 0.950 accuracy: 0.993 
training batch:   840, loss: 0.16985, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 0.70535, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.991 
training batch:   880, loss: 0.39249, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:   900, loss: 0.64890, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   920, loss: 0.67227, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.995 
training batch:   940, loss: 0.26675, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:   960, loss: 1.95963, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.996 
training batch:   980, loss: 0.78969, precision: 0.975 recall: 0.929 f1: 0.951 accuracy: 0.996 
training batch:  1000, loss: 0.21201, precision: 0.976 recall: 0.952 f1: 0.964 accuracy: 0.998 
training batch:  1020, loss: 0.23370, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.998 
training batch:  1040, loss: 0.58236, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:  1060, loss: 0.46014, precision: 0.978 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:  1080, loss: 0.57079, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.996 
training batch:  1100, loss: 0.09557, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1120, loss: 1.33743, precision: 0.977 recall: 0.933 f1: 0.955 accuracy: 0.993 
training batch:  1140, loss: 0.33599, precision: 1.000 recall: 0.978 f1: 0.989 accuracy: 0.998 
training batch:  1160, loss: 0.27202, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:  1180, loss: 1.27526, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:  1200, loss: 4.28769, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.991 
training batch:  1220, loss: 0.18777, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.14375, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 1.07981, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.995 
training batch:  1280, loss: 0.10268, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.38818, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.996 
training batch:  1320, loss: 0.96876, precision: 0.914 recall: 0.970 f1: 0.941 accuracy: 0.994 
training batch:  1340, loss: 0.04429, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 0.05376, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 0.02715, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1400, loss: 1.78271, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.994 
training batch:  1420, loss: 1.27259, precision: 0.923 recall: 0.973 f1: 0.947 accuracy: 0.984 
training batch:  1440, loss: 1.07150, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.994 
training batch:  1460, loss: 0.10281, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1480, loss: 0.25938, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.998 
training batch:  1500, loss: 0.08621, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1520, loss: 0.84715, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.988 
training batch:  1540, loss: 0.67574, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.998 
training batch:  1560, loss: 0.63878, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:  1580, loss: 0.13754, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1600, loss: 0.75213, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.998 
training batch:  1620, loss: 1.01207, precision: 0.920 recall: 1.000 f1: 0.958 accuracy: 0.991 
training batch:  1640, loss: 0.54283, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.991 
training batch:  1660, loss: 0.01789, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1680, loss: 0.74010, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.991 
training batch:  1700, loss: 0.22131, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:  1720, loss: 0.13725, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1740, loss: 0.14502, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1760, loss: 0.02049, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1780, loss: 0.03122, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1800, loss: 0.85233, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.988 
training batch:  1820, loss: 0.04517, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1840, loss: 0.10156, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1860, loss: 1.05287, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:  1880, loss: 0.02017, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1900, loss: 0.10638, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.988 recall: 0.989 f1: 0.988 
label: Chk, precision: 0.711 recall: 0.711 f1: 0.711 
label: Ins, precision: 0.458 recall: 0.455 f1: 0.456 
label: Sur, precision: 0.899 recall: 0.901 f1: 0.900 
label: Med, precision: 0.469 recall: 0.470 f1: 0.469 
label: Ana, precision: 0.992 recall: 0.992 f1: 0.992 
time consumption:23.86(min), precision: 0.993 recall: 0.994 f1: 0.994 accuracy: 0.999 
saved the new best model with f1: 0.994
epoch:7/100
training batch:    20, loss: 0.03926, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.58475, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.994 
training batch:    60, loss: 1.16506, precision: 0.955 recall: 0.977 f1: 0.966 accuracy: 0.998 
training batch:    80, loss: 0.33783, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   100, loss: 0.12627, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:   120, loss: 0.10817, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.33604, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:   160, loss: 0.13800, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   180, loss: 0.20649, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.23312, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   220, loss: 0.34260, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:   240, loss: 3.73370, precision: 0.946 recall: 0.921 f1: 0.933 accuracy: 0.981 
training batch:   260, loss: 0.12237, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.44017, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:   300, loss: 0.35809, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.995 
training batch:   320, loss: 0.02698, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 1.23429, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.984 
training batch:   360, loss: 0.52605, precision: 0.947 recall: 1.000 f1: 0.973 accuracy: 0.998 
training batch:   380, loss: 0.04356, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.15064, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.999 
training batch:   420, loss: 0.18962, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.999 
training batch:   440, loss: 0.25681, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:   460, loss: 0.23692, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.999 
training batch:   480, loss: 0.08657, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.54266, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:   520, loss: 0.36980, precision: 1.000 recall: 0.980 f1: 0.990 accuracy: 0.999 
training batch:   540, loss: 0.02013, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   560, loss: 0.03863, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.08270, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.06825, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 1.05659, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.996 
training batch:   640, loss: 0.22411, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.05035, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 1.11604, precision: 0.977 recall: 0.955 f1: 0.966 accuracy: 0.998 
training batch:   700, loss: 0.84976, precision: 0.950 recall: 1.000 f1: 0.974 accuracy: 0.995 
training batch:   720, loss: 0.03236, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 0.59461, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.995 
training batch:   760, loss: 0.56693, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.998 
training batch:   780, loss: 0.02607, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   800, loss: 0.28167, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   820, loss: 0.31968, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.998 
training batch:   840, loss: 0.26230, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 1.14079, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   880, loss: 0.05579, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.62758, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.995 
training batch:   920, loss: 0.28069, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   940, loss: 0.02618, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 0.09331, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   980, loss: 0.12120, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:  1000, loss: 0.05417, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1020, loss: 0.24433, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1040, loss: 0.92916, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:  1060, loss: 2.50407, precision: 0.977 recall: 0.955 f1: 0.966 accuracy: 0.990 
training batch:  1080, loss: 1.85728, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.988 
training batch:  1100, loss: 0.52304, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.998 
training batch:  1120, loss: 0.19909, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:  1140, loss: 1.46736, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.996 
training batch:  1160, loss: 1.58981, precision: 0.950 recall: 1.000 f1: 0.974 accuracy: 0.998 
training batch:  1180, loss: 0.10677, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.66499, precision: 0.903 recall: 0.966 f1: 0.933 accuracy: 0.995 
training batch:  1220, loss: 1.46688, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.993 
training batch:  1240, loss: 0.08466, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.32924, precision: 0.946 recall: 1.000 f1: 0.972 accuracy: 0.995 
training batch:  1280, loss: 0.09155, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.06963, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.16977, precision: 1.000 recall: 0.977 f1: 0.988 accuracy: 0.999 
training batch:  1340, loss: 0.67204, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.994 
training batch:  1360, loss: 0.40133, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.993 
training batch:  1380, loss: 0.33434, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.993 
training batch:  1400, loss: 0.56225, precision: 1.000 recall: 0.977 f1: 0.988 accuracy: 0.993 
training batch:  1420, loss: 0.05254, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1440, loss: 0.10108, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1460, loss: 1.34193, precision: 1.000 recall: 0.938 f1: 0.968 accuracy: 0.998 
training batch:  1480, loss: 0.13475, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1500, loss: 0.09272, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1520, loss: 0.68877, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.988 
training batch:  1540, loss: 1.58478, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.981 
training batch:  1560, loss: 0.16661, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1580, loss: 0.16933, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.998 
training batch:  1600, loss: 0.42398, precision: 0.957 recall: 0.978 f1: 0.967 accuracy: 0.998 
training batch:  1620, loss: 0.23545, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:  1640, loss: 0.12453, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1660, loss: 0.04826, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1680, loss: 0.48846, precision: 1.000 recall: 0.964 f1: 0.982 accuracy: 0.998 
training batch:  1700, loss: 0.68465, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.994 
training batch:  1720, loss: 0.61483, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:  1740, loss: 0.73626, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.993 
training batch:  1760, loss: 0.21055, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1780, loss: 0.58604, precision: 0.927 recall: 1.000 f1: 0.962 accuracy: 0.996 
training batch:  1800, loss: 1.04374, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.985 
training batch:  1820, loss: 0.08133, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1840, loss: 0.23489, precision: 1.000 recall: 0.979 f1: 0.989 accuracy: 0.999 
training batch:  1860, loss: 1.61755, precision: 0.913 recall: 0.933 f1: 0.923 accuracy: 0.983 
training batch:  1880, loss: 0.54358, precision: 0.950 recall: 1.000 f1: 0.974 accuracy: 0.993 
training batch:  1900, loss: 0.28573, precision: 0.979 recall: 0.958 f1: 0.968 accuracy: 0.996 
start evaluate engines...
label: Dsa, precision: 0.989 recall: 0.987 f1: 0.988 
label: Chk, precision: 0.711 recall: 0.711 f1: 0.711 
label: Ins, precision: 0.454 recall: 0.456 f1: 0.454 
label: Sur, precision: 0.902 recall: 0.902 f1: 0.902 
label: Med, precision: 0.468 recall: 0.462 f1: 0.464 
label: Ana, precision: 0.995 recall: 0.994 f1: 0.994 
time consumption:23.68(min), precision: 0.995 recall: 0.994 f1: 0.995 accuracy: 0.999 
saved the new best model with f1: 0.995
epoch:8/100
training batch:    20, loss: 2.75223, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.995 
training batch:    40, loss: 0.04436, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.21646, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:    80, loss: 0.06252, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.08111, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.20734, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   140, loss: 0.20866, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.996 
training batch:   160, loss: 0.10937, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   180, loss: 0.09327, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.29370, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.998 
training batch:   220, loss: 0.48524, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:   240, loss: 1.49479, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.995 
training batch:   260, loss: 0.58327, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.996 
training batch:   280, loss: 0.39308, precision: 1.000 recall: 0.975 f1: 0.987 accuracy: 0.999 
training batch:   300, loss: 0.12112, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 0.20702, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:   340, loss: 0.43392, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.998 
training batch:   360, loss: 0.22968, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.998 
training batch:   380, loss: 0.07162, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.03873, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.12379, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   440, loss: 0.05706, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.03195, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.38702, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:   500, loss: 0.05758, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.75233, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.999 
training batch:   540, loss: 0.43896, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.996 
training batch:   560, loss: 0.03506, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.04482, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.24287, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.999 
training batch:   620, loss: 0.43983, precision: 1.000 recall: 0.938 f1: 0.968 accuracy: 0.994 
training batch:   640, loss: 0.19500, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   660, loss: 0.01427, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.11602, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.998 
training batch:   700, loss: 0.13381, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.73244, precision: 0.926 recall: 1.000 f1: 0.962 accuracy: 0.995 
training batch:   740, loss: 0.72261, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.993 
training batch:   760, loss: 0.16721, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.998 
training batch:   780, loss: 0.10663, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   800, loss: 0.15491, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.998 
training batch:   820, loss: 0.22870, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.89314, precision: 0.968 recall: 0.833 f1: 0.896 accuracy: 0.994 
training batch:   860, loss: 0.99198, precision: 0.938 recall: 1.000 f1: 0.968 accuracy: 0.998 
training batch:   880, loss: 0.00804, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 1.02882, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.998 
training batch:   920, loss: 0.66785, precision: 0.919 recall: 0.971 f1: 0.944 accuracy: 0.995 
training batch:   940, loss: 0.42927, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.996 
training batch:   960, loss: 0.05957, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   980, loss: 0.07665, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 0.20872, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.999 
training batch:  1020, loss: 2.00681, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.988 
training batch:  1040, loss: 0.03662, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1060, loss: 0.61485, precision: 0.897 recall: 1.000 f1: 0.946 accuracy: 0.995 
training batch:  1080, loss: 0.19433, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:  1100, loss: 0.60558, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.996 
training batch:  1120, loss: 0.37564, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.998 
training batch:  1140, loss: 0.29419, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:  1160, loss: 0.02374, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.02264, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.01416, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 0.24654, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.83047, precision: 0.951 recall: 0.929 f1: 0.940 accuracy: 0.996 
training batch:  1260, loss: 0.01317, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.10708, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.01911, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.02733, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1340, loss: 0.88196, precision: 0.950 recall: 1.000 f1: 0.974 accuracy: 0.993 
training batch:  1360, loss: 0.24814, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.998 
training batch:  1380, loss: 0.79089, precision: 1.000 recall: 0.944 f1: 0.971 accuracy: 0.998 
training batch:  1400, loss: 0.05376, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1420, loss: 0.83617, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:  1440, loss: 0.03259, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1460, loss: 0.68845, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.990 
training batch:  1480, loss: 0.46439, precision: 1.000 recall: 0.939 f1: 0.969 accuracy: 0.998 
training batch:  1500, loss: 0.84787, precision: 1.000 recall: 0.977 f1: 0.989 accuracy: 0.999 
training batch:  1520, loss: 0.09722, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1540, loss: 0.27145, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.999 
training batch:  1560, loss: 0.37860, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:  1580, loss: 0.11789, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1600, loss: 0.13338, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1620, loss: 0.57873, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.995 
training batch:  1640, loss: 1.45054, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.993 
training batch:  1660, loss: 0.13953, precision: 1.000 recall: 0.977 f1: 0.988 accuracy: 0.999 
training batch:  1680, loss: 0.35061, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:  1700, loss: 1.63526, precision: 0.921 recall: 0.897 f1: 0.909 accuracy: 0.983 
training batch:  1720, loss: 0.00375, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1740, loss: 0.10405, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1760, loss: 0.12820, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1780, loss: 0.16322, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1800, loss: 0.04050, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1820, loss: 0.03043, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1840, loss: 0.12933, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:  1860, loss: 0.18233, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:  1880, loss: 0.04782, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1900, loss: 0.03775, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.986 recall: 0.988 f1: 0.987 
label: Chk, precision: 0.713 recall: 0.713 f1: 0.713 
label: Ins, precision: 0.454 recall: 0.459 f1: 0.456 
label: Sur, precision: 0.902 recall: 0.902 f1: 0.902 
label: Med, precision: 0.469 recall: 0.470 f1: 0.469 
label: Ana, precision: 0.994 recall: 0.994 f1: 0.994 
time consumption:23.70(min), precision: 0.994 recall: 0.996 f1: 0.995 accuracy: 0.999 
epoch:9/100
training batch:    20, loss: 0.00927, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.07214, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.38872, precision: 0.947 recall: 1.000 f1: 0.973 accuracy: 0.995 
training batch:    80, loss: 2.40087, precision: 0.967 recall: 0.906 f1: 0.935 accuracy: 0.983 
training batch:   100, loss: 0.04654, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.28428, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.999 
training batch:   140, loss: 0.01912, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   160, loss: 0.10595, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   180, loss: 0.08184, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.19074, precision: 1.000 recall: 0.977 f1: 0.988 accuracy: 0.998 
training batch:   220, loss: 0.70069, precision: 1.000 recall: 0.909 f1: 0.952 accuracy: 0.996 
training batch:   240, loss: 0.00952, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   260, loss: 0.01626, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 4.21052, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.983 
training batch:   300, loss: 0.04705, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 0.52471, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.998 
training batch:   340, loss: 0.67440, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.998 
training batch:   360, loss: 1.55829, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.975 
training batch:   380, loss: 0.27570, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.995 
training batch:   400, loss: 0.17988, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:   420, loss: 1.27816, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.994 
training batch:   440, loss: 1.24206, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:   460, loss: 0.07494, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.02702, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.10364, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.18203, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:   540, loss: 0.35445, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.990 
training batch:   560, loss: 0.06462, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.13675, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.40942, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.999 
training batch:   620, loss: 0.29790, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.993 
training batch:   640, loss: 0.33480, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.998 
training batch:   660, loss: 0.26002, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   680, loss: 0.17789, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:   700, loss: 0.30659, precision: 0.950 recall: 1.000 f1: 0.974 accuracy: 0.998 
training batch:   720, loss: 0.05489, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 0.01729, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   760, loss: 0.80669, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.999 
training batch:   780, loss: 0.20621, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   800, loss: 0.21709, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:   820, loss: 0.51111, precision: 0.929 recall: 1.000 f1: 0.963 accuracy: 0.994 
training batch:   840, loss: 0.20970, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:   860, loss: 0.01348, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   880, loss: 0.57542, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.994 
training batch:   900, loss: 1.25558, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.998 
training batch:   920, loss: 0.10358, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   940, loss: 0.04102, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 0.66678, precision: 1.000 recall: 0.933 f1: 0.966 accuracy: 0.996 
training batch:   980, loss: 0.44125, precision: 1.000 recall: 0.977 f1: 0.989 accuracy: 0.999 
training batch:  1000, loss: 0.37414, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.996 
training batch:  1020, loss: 0.16830, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:  1040, loss: 0.09433, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1060, loss: 0.11041, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 0.06846, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.11724, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1120, loss: 0.22166, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1140, loss: 0.09306, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1160, loss: 0.05006, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.04059, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.14626, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.996 
training batch:  1220, loss: 0.09499, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.05021, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.65022, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.995 
training batch:  1280, loss: 0.22319, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.994 
training batch:  1300, loss: 0.03406, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.97758, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:  1340, loss: 0.04696, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 0.02226, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 0.00528, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1400, loss: 0.12151, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1420, loss: 0.84274, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.998 
training batch:  1440, loss: 0.01723, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1460, loss: 0.04205, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1480, loss: 0.25779, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:  1500, loss: 1.31508, precision: 0.857 recall: 0.973 f1: 0.911 accuracy: 0.994 
training batch:  1520, loss: 0.47128, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:  1540, loss: 0.08656, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1560, loss: 0.14368, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:  1580, loss: 1.34648, precision: 0.927 recall: 0.927 f1: 0.927 accuracy: 0.984 
training batch:  1600, loss: 0.06135, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1620, loss: 0.39578, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.995 
training batch:  1640, loss: 0.35420, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:  1660, loss: 0.13548, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1680, loss: 0.11279, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1700, loss: 0.12371, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1720, loss: 0.38813, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.998 
training batch:  1740, loss: 0.50858, precision: 1.000 recall: 0.947 f1: 0.973 accuracy: 0.993 
training batch:  1760, loss: 0.86205, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:  1780, loss: 0.05692, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1800, loss: 0.56242, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.993 
training batch:  1820, loss: 0.04951, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1840, loss: 0.12994, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1860, loss: 0.25053, precision: 0.958 recall: 0.958 f1: 0.958 accuracy: 0.999 
training batch:  1880, loss: 1.05487, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.995 
training batch:  1900, loss: 2.08511, precision: 0.918 recall: 0.957 f1: 0.938 accuracy: 0.979 
start evaluate engines...
label: Dsa, precision: 0.986 recall: 0.987 f1: 0.986 
label: Chk, precision: 0.713 recall: 0.713 f1: 0.713 
label: Ins, precision: 0.454 recall: 0.452 f1: 0.452 
label: Sur, precision: 0.880 recall: 0.886 f1: 0.883 
label: Med, precision: 0.469 recall: 0.470 f1: 0.469 
label: Ana, precision: 0.995 recall: 0.994 f1: 0.994 
time consumption:23.99(min), precision: 0.992 recall: 0.993 f1: 0.992 accuracy: 0.999 
epoch:10/100
training batch:    20, loss: 0.71673, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:    40, loss: 0.05203, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.09309, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.08335, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.02773, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.04492, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.02937, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   160, loss: 0.10339, precision: 1.000 recall: 0.960 f1: 0.980 accuracy: 0.996 
training batch:   180, loss: 0.02025, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.45177, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.991 
training batch:   220, loss: 0.08421, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   240, loss: 0.01015, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   260, loss: 0.02887, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.02049, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   300, loss: 0.13455, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.999 
training batch:   320, loss: 0.87458, precision: 0.953 recall: 1.000 f1: 0.976 accuracy: 0.990 
training batch:   340, loss: 0.09365, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   360, loss: 0.11035, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 1.01667, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.996 
training batch:   400, loss: 0.79387, precision: 0.977 recall: 0.935 f1: 0.956 accuracy: 0.991 
training batch:   420, loss: 0.99268, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.994 
training batch:   440, loss: 0.05163, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.00465, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.80639, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:   500, loss: 0.15001, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.25611, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.02100, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   560, loss: 0.09227, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.01189, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.17209, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.72497, precision: 0.932 recall: 0.953 f1: 0.943 accuracy: 0.996 
training batch:   640, loss: 0.03084, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.33717, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:   680, loss: 0.01997, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.02151, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.03248, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 0.19678, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.999 
training batch:   760, loss: 0.32864, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:   780, loss: 0.46044, precision: 0.930 recall: 0.976 f1: 0.952 accuracy: 0.996 
training batch:   800, loss: 0.53870, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:   820, loss: 0.00610, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.10321, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 0.67262, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.998 
training batch:   880, loss: 0.67224, precision: 0.926 recall: 0.893 f1: 0.909 accuracy: 0.990 
training batch:   900, loss: 0.03741, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 0.04790, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   940, loss: 0.12306, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 0.13933, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:   980, loss: 0.41266, precision: 0.979 recall: 0.958 f1: 0.968 accuracy: 0.998 
training batch:  1000, loss: 0.39116, precision: 0.977 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:  1020, loss: 0.02227, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1040, loss: 0.10920, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1060, loss: 0.35873, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:  1080, loss: 0.15971, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 1.25633, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:  1120, loss: 0.33034, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:  1140, loss: 0.12392, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1160, loss: 0.01189, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.03399, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.01422, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 0.79984, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.984 
training batch:  1240, loss: 0.35075, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.998 
training batch:  1260, loss: 0.06500, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.02585, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 1.27728, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:  1320, loss: 1.50066, precision: 0.929 recall: 0.951 f1: 0.940 accuracy: 0.983 
training batch:  1340, loss: 0.21816, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.996 
training batch:  1360, loss: 1.54660, precision: 0.951 recall: 1.000 f1: 0.975 accuracy: 0.998 
training batch:  1380, loss: 0.03491, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1400, loss: 0.01264, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1420, loss: 0.10773, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1440, loss: 0.06211, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1460, loss: 0.27354, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:  1480, loss: 0.12954, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1500, loss: 0.39929, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.996 
training batch:  1520, loss: 0.01430, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1540, loss: 0.08732, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1560, loss: 0.93391, precision: 0.897 recall: 1.000 f1: 0.946 accuracy: 0.988 
training batch:  1580, loss: 0.00907, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1600, loss: 0.07140, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1620, loss: 0.04054, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1640, loss: 0.22124, precision: 1.000 recall: 0.978 f1: 0.989 accuracy: 0.998 
training batch:  1660, loss: 0.61115, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.998 
training batch:  1680, loss: 0.01531, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1700, loss: 0.57105, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.996 
training batch:  1720, loss: 0.68884, precision: 1.000 recall: 0.932 f1: 0.965 accuracy: 0.995 
training batch:  1740, loss: 0.08581, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1760, loss: 0.03992, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1780, loss: 0.32336, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:  1800, loss: 0.21072, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:  1820, loss: 0.15574, precision: 1.000 recall: 0.962 f1: 0.980 accuracy: 0.999 
training batch:  1840, loss: 0.33735, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.996 
training batch:  1860, loss: 0.08382, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1880, loss: 0.03432, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1900, loss: 0.09053, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.985 recall: 0.988 f1: 0.986 
label: Chk, precision: 0.713 recall: 0.712 f1: 0.713 
label: Ins, precision: 0.455 recall: 0.456 f1: 0.455 
label: Sur, precision: 0.902 recall: 0.903 f1: 0.902 
label: Med, precision: 0.469 recall: 0.470 f1: 0.469 
label: Ana, precision: 0.992 recall: 0.994 f1: 0.993 
time consumption:23.83(min), precision: 0.993 recall: 0.995 f1: 0.994 accuracy: 0.999 
epoch:11/100
training batch:    20, loss: 0.44374, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:    40, loss: 0.02707, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.15992, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.998 
training batch:    80, loss: 0.06590, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.00627, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.77095, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.990 
training batch:   140, loss: 0.08884, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   160, loss: 0.60663, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.993 
training batch:   180, loss: 0.05113, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.10479, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.28292, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:   240, loss: 0.64584, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.991 
training batch:   260, loss: 0.23656, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.999 
training batch:   280, loss: 0.65544, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.993 
training batch:   300, loss: 0.14506, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 0.74256, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.991 
training batch:   340, loss: 0.30090, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.998 
training batch:   360, loss: 0.01407, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 0.01331, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.22314, precision: 0.957 recall: 0.917 f1: 0.936 accuracy: 0.999 
training batch:   420, loss: 1.28137, precision: 0.879 recall: 0.935 f1: 0.906 accuracy: 0.995 
training batch:   440, loss: 0.09116, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.999 
training batch:   460, loss: 0.17683, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.37947, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:   500, loss: 0.19004, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:   520, loss: 0.03725, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.01268, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   560, loss: 0.78678, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:   580, loss: 0.01625, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.02594, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.18659, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 0.18533, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.04871, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.03481, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 1.48322, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:   720, loss: 0.45105, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.996 
training batch:   740, loss: 0.01942, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   760, loss: 0.05020, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   780, loss: 0.04973, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   800, loss: 0.58508, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.981 
training batch:   820, loss: 0.10625, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.05865, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 0.02723, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   880, loss: 0.06286, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.21242, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.996 
training batch:   920, loss: 0.42595, precision: 1.000 recall: 0.950 f1: 0.974 accuracy: 0.995 
training batch:   940, loss: 0.65238, precision: 0.960 recall: 1.000 f1: 0.980 accuracy: 0.999 
training batch:   960, loss: 0.25719, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.998 
training batch:   980, loss: 0.64981, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.996 
training batch:  1000, loss: 0.26550, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:  1020, loss: 0.45115, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:  1040, loss: 0.77123, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:  1060, loss: 0.29981, precision: 0.955 recall: 0.977 f1: 0.966 accuracy: 0.994 
training batch:  1080, loss: 0.04803, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.05906, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1120, loss: 0.21982, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:  1140, loss: 0.01791, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1160, loss: 0.03719, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.05374, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.51287, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:  1220, loss: 0.13300, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.999 
training batch:  1240, loss: 0.04780, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.03161, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.01309, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.01239, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.09624, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1340, loss: 0.14323, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:  1360, loss: 0.59364, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.998 
training batch:  1380, loss: 0.57794, precision: 1.000 recall: 0.917 f1: 0.957 accuracy: 0.996 
training batch:  1400, loss: 0.58392, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.996 
training batch:  1420, loss: 0.01414, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1440, loss: 0.33492, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:  1460, loss: 0.00937, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1480, loss: 0.04962, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1500, loss: 0.01617, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1520, loss: 0.03027, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1540, loss: 0.18276, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1560, loss: 0.06277, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1580, loss: 0.94922, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.995 
training batch:  1600, loss: 0.11697, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1620, loss: 0.03172, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1640, loss: 0.06832, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1660, loss: 0.06046, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1680, loss: 1.76656, precision: 0.892 recall: 0.917 f1: 0.904 accuracy: 0.979 
training batch:  1700, loss: 0.59643, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.995 
training batch:  1720, loss: 0.04758, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1740, loss: 0.29638, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:  1760, loss: 0.04620, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1780, loss: 1.05879, precision: 0.978 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:  1800, loss: 0.01359, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1820, loss: 0.01682, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1840, loss: 1.19044, precision: 0.968 recall: 0.833 f1: 0.896 accuracy: 0.994 
training batch:  1860, loss: 0.10586, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1880, loss: 0.02527, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1900, loss: 0.02502, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.986 recall: 0.988 f1: 0.987 
label: Chk, precision: 0.711 recall: 0.711 f1: 0.711 
label: Ins, precision: 0.455 recall: 0.453 f1: 0.453 
label: Sur, precision: 0.903 recall: 0.903 f1: 0.903 
label: Med, precision: 0.469 recall: 0.470 f1: 0.469 
label: Ana, precision: 0.996 recall: 0.992 f1: 0.994 
time consumption:23.88(min), precision: 0.996 recall: 0.994 f1: 0.995 accuracy: 0.999 
saved the new best model with f1: 0.995
epoch:12/100
training batch:    20, loss: 0.00713, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.28831, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.998 
training batch:    60, loss: 0.01427, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.03268, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.42088, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:   120, loss: 0.05947, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.25862, precision: 0.976 recall: 0.952 f1: 0.964 accuracy: 0.998 
training batch:   160, loss: 0.00449, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   180, loss: 0.05154, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.21834, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.995 
training batch:   220, loss: 0.03353, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   240, loss: 0.38059, precision: 0.956 recall: 1.000 f1: 0.977 accuracy: 0.998 
training batch:   260, loss: 0.16692, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.994 
training batch:   280, loss: 0.20303, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   300, loss: 0.00678, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 0.55811, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:   340, loss: 0.20757, precision: 0.963 recall: 0.929 f1: 0.945 accuracy: 0.998 
training batch:   360, loss: 0.48179, precision: 0.964 recall: 0.900 f1: 0.931 accuracy: 0.996 
training batch:   380, loss: 0.00928, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.01064, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.07024, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   440, loss: 0.19774, precision: 0.962 recall: 1.000 f1: 0.980 accuracy: 0.996 
training batch:   460, loss: 0.01000, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.00272, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.03959, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.01475, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.17496, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   560, loss: 1.65212, precision: 0.950 recall: 0.927 f1: 0.938 accuracy: 0.984 
training batch:   580, loss: 0.00949, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.32775, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.995 
training batch:   620, loss: 0.00990, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 1.22164, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.994 
training batch:   660, loss: 0.08630, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 1.25578, precision: 0.944 recall: 0.895 f1: 0.919 accuracy: 0.995 
training batch:   700, loss: 0.23306, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   720, loss: 0.12498, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 0.11082, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.999 
training batch:   760, loss: 0.12110, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   780, loss: 0.03169, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   800, loss: 0.78186, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.996 
training batch:   820, loss: 0.16695, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.36076, precision: 1.000 recall: 0.962 f1: 0.980 accuracy: 0.993 
training batch:   860, loss: 1.26884, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.995 
training batch:   880, loss: 2.48300, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.994 
training batch:   900, loss: 0.01491, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 0.13898, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   940, loss: 0.25740, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.995 
training batch:   960, loss: 0.31976, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.998 
training batch:   980, loss: 0.08550, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 0.26928, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.998 
training batch:  1020, loss: 0.01306, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1040, loss: 0.00893, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1060, loss: 0.12126, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 0.01387, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.10725, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1120, loss: 0.14795, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.995 
training batch:  1140, loss: 0.03658, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1160, loss: 0.14274, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.01460, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.13991, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:  1220, loss: 0.04350, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.03276, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.99548, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.998 
training batch:  1280, loss: 0.17119, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.28235, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.998 
training batch:  1320, loss: 0.03364, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1340, loss: 0.08737, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 1.05891, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:  1380, loss: 0.39728, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.998 
training batch:  1400, loss: 0.48137, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.995 
training batch:  1420, loss: 1.53524, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.995 
training batch:  1440, loss: 0.05117, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1460, loss: 1.01453, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.990 
training batch:  1480, loss: 0.50243, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.994 
training batch:  1500, loss: 0.18900, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.995 
training batch:  1520, loss: 0.00739, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1540, loss: 0.00571, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1560, loss: 0.04073, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1580, loss: 0.01198, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1600, loss: 0.00471, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1620, loss: 0.01962, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1640, loss: 0.12567, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1660, loss: 0.02075, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1680, loss: 0.10621, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1700, loss: 0.10454, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1720, loss: 0.06716, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1740, loss: 0.11208, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1760, loss: 0.45177, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.995 
training batch:  1780, loss: 0.01246, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1800, loss: 0.34305, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.999 
training batch:  1820, loss: 0.13750, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:  1840, loss: 0.47158, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.999 
training batch:  1860, loss: 0.22059, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:  1880, loss: 1.19936, precision: 0.850 recall: 0.971 f1: 0.907 accuracy: 0.994 
training batch:  1900, loss: 0.05037, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.989 recall: 0.987 f1: 0.988 
label: Chk, precision: 0.711 recall: 0.709 f1: 0.709 
label: Ins, precision: 0.450 recall: 0.447 f1: 0.448 
label: Sur, precision: 0.901 recall: 0.902 f1: 0.901 
label: Med, precision: 0.465 recall: 0.454 f1: 0.458 
label: Ana, precision: 0.997 recall: 0.987 f1: 0.992 
time consumption:23.80(min), precision: 0.997 recall: 0.989 f1: 0.993 accuracy: 0.999 
epoch:13/100
training batch:    20, loss: 0.00541, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.31304, precision: 1.000 recall: 0.931 f1: 0.964 accuracy: 0.993 
training batch:    60, loss: 0.20879, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.07779, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.00103, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.03007, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.00273, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   160, loss: 0.58290, precision: 0.947 recall: 1.000 f1: 0.973 accuracy: 0.993 
training batch:   180, loss: 0.06724, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.06001, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.24900, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.999 
training batch:   240, loss: 0.04549, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   260, loss: 0.43472, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.999 
training batch:   280, loss: 0.03094, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   300, loss: 0.19238, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   320, loss: 0.04650, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.01499, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   360, loss: 0.12574, precision: 1.000 recall: 0.964 f1: 0.982 accuracy: 0.999 
training batch:   380, loss: 0.00784, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.08524, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.02199, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   440, loss: 1.12434, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.990 
training batch:   460, loss: 0.21895, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.993 
training batch:   480, loss: 0.00497, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.09842, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.09544, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.24245, precision: 1.000 recall: 0.956 f1: 0.977 accuracy: 0.998 
training batch:   560, loss: 0.23525, precision: 0.978 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:   580, loss: 0.25455, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.04131, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.02960, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 0.46068, precision: 0.974 recall: 0.950 f1: 0.962 accuracy: 0.995 
training batch:   660, loss: 0.00930, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.02189, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.01252, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.24165, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.998 
training batch:   740, loss: 0.02956, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   760, loss: 0.25234, precision: 0.962 recall: 1.000 f1: 0.980 accuracy: 0.999 
training batch:   780, loss: 0.43723, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.996 
training batch:   800, loss: 0.04802, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   820, loss: 0.01733, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.46437, precision: 0.923 recall: 0.973 f1: 0.947 accuracy: 0.991 
training batch:   860, loss: 0.01933, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   880, loss: 0.19659, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:   900, loss: 0.31499, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.995 
training batch:   920, loss: 0.34653, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:   940, loss: 0.21165, precision: 1.000 recall: 0.950 f1: 0.974 accuracy: 0.999 
training batch:   960, loss: 0.27254, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.994 
training batch:   980, loss: 0.18380, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.999 
training batch:  1000, loss: 1.75628, precision: 0.929 recall: 0.867 f1: 0.897 accuracy: 0.974 
training batch:  1020, loss: 1.53755, precision: 0.862 recall: 1.000 f1: 0.926 accuracy: 0.988 
training batch:  1040, loss: 0.28628, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.998 
training batch:  1060, loss: 0.14819, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:  1080, loss: 0.15775, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.01843, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1120, loss: 0.80367, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.996 
training batch:  1140, loss: 0.30505, precision: 1.000 recall: 0.947 f1: 0.973 accuracy: 0.998 
training batch:  1160, loss: 0.08187, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.10360, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.11826, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:  1220, loss: 0.30146, precision: 1.000 recall: 0.958 f1: 0.979 accuracy: 0.998 
training batch:  1240, loss: 0.07008, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.15099, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.999 
training batch:  1280, loss: 0.04057, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.05447, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.24913, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.991 
training batch:  1340, loss: 0.52036, precision: 0.956 recall: 0.977 f1: 0.966 accuracy: 0.999 
training batch:  1360, loss: 0.03261, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 0.04221, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1400, loss: 0.01942, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1420, loss: 0.14780, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:  1440, loss: 0.13601, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1460, loss: 0.07358, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1480, loss: 0.02691, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1500, loss: 0.05302, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1520, loss: 0.01122, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1540, loss: 0.02259, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1560, loss: 0.02729, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1580, loss: 0.01709, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1600, loss: 0.00793, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1620, loss: 0.03001, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1640, loss: 0.01225, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1660, loss: 0.52572, precision: 0.977 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:  1680, loss: 0.10820, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:  1700, loss: 0.26508, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.998 
training batch:  1720, loss: 0.00661, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1740, loss: 0.13494, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:  1760, loss: 0.32481, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:  1780, loss: 0.00615, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1800, loss: 0.00636, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1820, loss: 0.18420, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.998 
training batch:  1840, loss: 0.02890, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1860, loss: 0.31268, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:  1880, loss: 0.11572, precision: 1.000 recall: 0.962 f1: 0.980 accuracy: 0.998 
training batch:  1900, loss: 1.01070, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.988 
start evaluate engines...
label: Dsa, precision: 0.990 recall: 0.990 f1: 0.990 
label: Chk, precision: 0.711 recall: 0.711 f1: 0.711 
label: Ins, precision: 0.457 recall: 0.458 f1: 0.457 
label: Sur, precision: 0.903 recall: 0.903 f1: 0.903 
label: Med, precision: 0.469 recall: 0.470 f1: 0.469 
label: Ana, precision: 0.996 recall: 0.993 f1: 0.995 
time consumption:23.81(min), precision: 0.997 recall: 0.995 f1: 0.996 accuracy: 0.999 
saved the new best model with f1: 0.996
epoch:14/100
training batch:    20, loss: 0.11744, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.20393, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.998 
training batch:    60, loss: 0.06557, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.43349, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.996 
training batch:   100, loss: 0.04926, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.07919, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.82031, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.989 
training batch:   160, loss: 1.49171, precision: 1.000 recall: 0.919 f1: 0.958 accuracy: 0.996 
training batch:   180, loss: 0.03667, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.03946, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.39555, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:   240, loss: 1.05488, precision: 0.949 recall: 0.925 f1: 0.937 accuracy: 0.984 
training batch:   260, loss: 0.06274, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.04749, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   300, loss: 0.00509, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 0.00874, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.34229, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:   360, loss: 0.02135, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 0.18248, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 1.12801, precision: 0.938 recall: 0.957 f1: 0.947 accuracy: 0.989 
training batch:   420, loss: 0.38245, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:   440, loss: 0.31050, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   460, loss: 0.00833, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.98065, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.994 
training batch:   500, loss: 0.15650, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   520, loss: 0.26734, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.995 
training batch:   540, loss: 0.02805, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   560, loss: 0.34155, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:   580, loss: 0.97743, precision: 0.956 recall: 0.915 f1: 0.935 accuracy: 0.985 
training batch:   600, loss: 0.58796, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.996 
training batch:   620, loss: 0.01101, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 0.13975, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.994 
training batch:   660, loss: 0.05515, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 1.32142, precision: 0.932 recall: 0.953 f1: 0.943 accuracy: 0.996 
training batch:   700, loss: 0.06202, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.07974, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 0.05882, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   760, loss: 0.08650, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   780, loss: 0.15465, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:   800, loss: 1.47802, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.994 
training batch:   820, loss: 0.01328, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.08389, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 0.02988, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   880, loss: 0.00988, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.01001, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 0.40443, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:   940, loss: 0.01900, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 0.03159, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   980, loss: 0.39997, precision: 1.000 recall: 0.946 f1: 0.972 accuracy: 0.998 
training batch:  1000, loss: 0.17471, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.998 
training batch:  1020, loss: 0.47818, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:  1040, loss: 1.04771, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.986 
training batch:  1060, loss: 0.01075, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 0.03738, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.18335, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:  1120, loss: 0.21749, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:  1140, loss: 0.17347, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.998 
training batch:  1160, loss: 0.04977, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.00671, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.01271, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 0.19735, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.990 
training batch:  1240, loss: 0.22465, precision: 1.000 recall: 0.975 f1: 0.987 accuracy: 0.999 
training batch:  1260, loss: 0.30254, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.998 
training batch:  1280, loss: 0.01043, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.07320, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.16425, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.999 
training batch:  1340, loss: 0.84908, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.998 
training batch:  1360, loss: 0.21098, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:  1380, loss: 0.27334, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.995 
training batch:  1400, loss: 0.12484, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.999 
training batch:  1420, loss: 0.16613, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:  1440, loss: 0.09399, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1460, loss: 0.68652, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.996 
training batch:  1480, loss: 0.22702, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:  1500, loss: 0.25108, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.996 
training batch:  1520, loss: 0.00903, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1540, loss: 0.95808, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.994 
training batch:  1560, loss: 0.38588, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.996 
training batch:  1580, loss: 0.03133, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1600, loss: 0.01457, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1620, loss: 0.00890, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1640, loss: 1.05807, precision: 0.919 recall: 0.971 f1: 0.944 accuracy: 0.996 
training batch:  1660, loss: 0.01885, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1680, loss: 0.03751, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1700, loss: 0.14199, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:  1720, loss: 0.01150, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1740, loss: 0.39933, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.991 
training batch:  1760, loss: 0.01672, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1780, loss: 0.13067, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1800, loss: 0.00221, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1820, loss: 0.10541, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:  1840, loss: 0.01344, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1860, loss: 0.01742, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1880, loss: 0.04302, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1900, loss: 0.12910, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
start evaluate engines...
label: Dsa, precision: 0.978 recall: 0.988 f1: 0.982 
label: Chk, precision: 0.713 recall: 0.713 f1: 0.713 
label: Ins, precision: 0.456 recall: 0.448 f1: 0.451 
label: Sur, precision: 0.903 recall: 0.903 f1: 0.903 
label: Med, precision: 0.468 recall: 0.462 f1: 0.464 
label: Ana, precision: 0.995 recall: 0.990 f1: 0.992 
time consumption:23.94(min), precision: 0.996 recall: 0.994 f1: 0.995 accuracy: 0.999 
epoch:15/100
training batch:    20, loss: 0.19997, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.998 
training batch:    40, loss: 0.04192, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.00259, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.26469, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.995 
training batch:   100, loss: 0.51295, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.993 
training batch:   120, loss: 0.13858, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.72126, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.985 
training batch:   160, loss: 0.36077, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.999 
training batch:   180, loss: 0.65145, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.998 
training batch:   200, loss: 0.01214, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.00377, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   240, loss: 0.04522, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   260, loss: 0.17283, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.999 
training batch:   280, loss: 0.01107, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   300, loss: 0.68654, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.993 
training batch:   320, loss: 0.01268, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 1.93486, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.989 
training batch:   360, loss: 0.01226, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 0.00788, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.01337, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.74528, precision: 0.927 recall: 0.950 f1: 0.938 accuracy: 0.984 
training batch:   440, loss: 0.47559, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   460, loss: 0.03322, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 1.03844, precision: 0.933 recall: 1.000 f1: 0.966 accuracy: 0.996 
training batch:   500, loss: 0.00615, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.03088, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.72591, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.994 
training batch:   560, loss: 0.02542, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.10169, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:   600, loss: 0.28739, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   620, loss: 0.04282, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 0.02818, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.09815, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   680, loss: 0.09437, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.00327, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.00625, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 1.15874, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:   760, loss: 0.82927, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.996 
training batch:   780, loss: 0.20362, precision: 1.000 recall: 0.962 f1: 0.980 accuracy: 0.994 
training batch:   800, loss: 0.39762, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.994 
training batch:   820, loss: 0.15753, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 0.02938, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 1.35842, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.993 
training batch:   880, loss: 0.10606, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.01199, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 0.35715, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.991 
training batch:   940, loss: 0.00541, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 1.34486, precision: 1.000 recall: 0.897 f1: 0.946 accuracy: 0.994 
training batch:   980, loss: 0.00897, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 0.01426, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1020, loss: 0.16470, precision: 0.978 recall: 0.978 f1: 0.978 accuracy: 0.999 
training batch:  1040, loss: 0.34142, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.998 
training batch:  1060, loss: 0.62615, precision: 0.938 recall: 0.833 f1: 0.882 accuracy: 0.995 
training batch:  1080, loss: 0.00355, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.13719, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1120, loss: 0.03779, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1140, loss: 0.02511, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1160, loss: 0.15407, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.01730, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.05112, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 0.02222, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.01427, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.04855, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.00441, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.00912, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.01584, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1340, loss: 0.02283, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 0.02081, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 0.11430, precision: 1.000 recall: 0.962 f1: 0.980 accuracy: 0.999 
training batch:  1400, loss: 0.02050, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1420, loss: 0.05705, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1440, loss: 0.27917, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.994 
training batch:  1460, loss: 0.12531, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:  1480, loss: 0.12340, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1500, loss: 0.02159, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1520, loss: 0.00692, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1540, loss: 0.01057, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1560, loss: 1.60410, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.988 
training batch:  1580, loss: 0.17101, precision: 1.000 recall: 0.977 f1: 0.988 accuracy: 0.998 
training batch:  1600, loss: 0.47402, precision: 0.958 recall: 0.979 f1: 0.968 accuracy: 0.994 
training batch:  1620, loss: 0.20444, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.999 
training batch:  1640, loss: 0.24404, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1660, loss: 0.02380, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1680, loss: 0.00202, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1700, loss: 0.01450, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1720, loss: 0.19603, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:  1740, loss: 0.00787, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1760, loss: 0.42191, precision: 0.955 recall: 1.000 f1: 0.977 accuracy: 0.998 
training batch:  1780, loss: 0.02702, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1800, loss: 0.00993, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1820, loss: 0.00109, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1840, loss: 0.01889, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1860, loss: 0.00423, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1880, loss: 0.04324, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1900, loss: 0.14120, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.996 
start evaluate engines...
label: Dsa, precision: 0.989 recall: 0.989 f1: 0.989 
label: Chk, precision: 0.713 recall: 0.713 f1: 0.713 
label: Ins, precision: 0.455 recall: 0.453 f1: 0.453 
label: Sur, precision: 0.902 recall: 0.902 f1: 0.902 
label: Med, precision: 0.467 recall: 0.470 f1: 0.468 
label: Ana, precision: 0.994 recall: 0.994 f1: 0.994 
time consumption:23.79(min), precision: 0.995 recall: 0.995 f1: 0.995 accuracy: 0.999 
epoch:16/100
training batch:    20, loss: 0.01909, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 1.06513, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.988 
training batch:    60, loss: 0.05466, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.02168, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.04526, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.03784, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 1.55054, precision: 0.912 recall: 0.816 f1: 0.861 accuracy: 0.990 
training batch:   160, loss: 0.00742, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   180, loss: 0.08806, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.66051, precision: 0.962 recall: 0.980 f1: 0.971 accuracy: 0.994 
training batch:   220, loss: 0.16156, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   240, loss: 0.20454, precision: 0.958 recall: 0.958 f1: 0.958 accuracy: 0.999 
training batch:   260, loss: 0.77335, precision: 1.000 recall: 0.949 f1: 0.974 accuracy: 0.995 
training batch:   280, loss: 0.18429, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   300, loss: 0.00176, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 0.00761, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.26822, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.995 
training batch:   360, loss: 0.22086, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.999 
training batch:   380, loss: 0.00139, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.00483, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.24763, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.996 
training batch:   440, loss: 0.08804, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.00589, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.03538, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.44711, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.984 
training batch:   520, loss: 0.02589, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   540, loss: 0.00379, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   560, loss: 0.23745, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.994 
training batch:   580, loss: 0.14791, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.999 
training batch:   600, loss: 0.00198, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.01730, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   640, loss: 0.00897, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.00778, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.02797, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.00573, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.38291, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.998 
training batch:   740, loss: 0.01469, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   760, loss: 0.22681, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.998 
training batch:   780, loss: 0.02650, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   800, loss: 0.00771, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   820, loss: 0.44284, precision: 0.944 recall: 0.919 f1: 0.932 accuracy: 0.991 
training batch:   840, loss: 0.01233, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 0.51304, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.994 
training batch:   880, loss: 0.01307, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.16812, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.998 
training batch:   920, loss: 0.32189, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:   940, loss: 0.00719, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   960, loss: 0.13231, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   980, loss: 0.00939, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 0.03299, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1020, loss: 0.43127, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.991 
training batch:  1040, loss: 0.00457, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1060, loss: 0.09615, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 0.03993, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.13239, precision: 0.960 recall: 1.000 f1: 0.980 accuracy: 0.999 
training batch:  1120, loss: 0.23202, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.998 
training batch:  1140, loss: 0.28320, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.994 
training batch:  1160, loss: 0.01223, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.07304, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.00695, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 0.05862, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.00226, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.03333, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 1.12959, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:  1300, loss: 0.23369, precision: 1.000 recall: 0.941 f1: 0.970 accuracy: 0.993 
training batch:  1320, loss: 0.00787, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1340, loss: 0.83936, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.980 
training batch:  1360, loss: 0.15641, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.999 
training batch:  1380, loss: 0.17473, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.998 
training batch:  1400, loss: 0.19869, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:  1420, loss: 0.05939, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1440, loss: 0.20415, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.998 
training batch:  1460, loss: 0.28455, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.991 
training batch:  1480, loss: 0.02386, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1500, loss: 0.18491, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.996 
training batch:  1520, loss: 0.48492, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:  1540, loss: 0.00392, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1560, loss: 0.01452, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1580, loss: 0.00161, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1600, loss: 0.15272, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1620, loss: 0.00401, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1640, loss: 0.00196, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1660, loss: 0.35094, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.998 
training batch:  1680, loss: 0.14925, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:  1700, loss: 0.03052, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1720, loss: 0.00562, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1740, loss: 0.15936, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1760, loss: 0.00830, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1780, loss: 0.01311, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1800, loss: 0.11916, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:  1820, loss: 0.06890, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1840, loss: 0.28194, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1860, loss: 0.01117, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1880, loss: 0.00145, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1900, loss: 0.07250, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.987 recall: 0.988 f1: 0.987 
label: Chk, precision: 0.711 recall: 0.711 f1: 0.711 
label: Ins, precision: 0.459 recall: 0.452 f1: 0.454 
label: Sur, precision: 0.902 recall: 0.902 f1: 0.902 
label: Med, precision: 0.469 recall: 0.470 f1: 0.469 
label: Ana, precision: 0.995 recall: 0.996 f1: 0.996 
time consumption:23.81(min), precision: 0.995 recall: 0.996 f1: 0.996 accuracy: 0.999 
epoch:17/100
training batch:    20, loss: 0.00713, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.00986, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.00385, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.08311, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.04389, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.06545, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.03197, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   160, loss: 0.78468, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.989 
training batch:   180, loss: 0.13390, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.998 
training batch:   200, loss: 0.00544, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.00135, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   240, loss: 0.62686, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.993 
training batch:   260, loss: 0.00226, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.12431, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   300, loss: 0.00631, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 0.02610, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.00761, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   360, loss: 0.10739, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:   380, loss: 0.79286, precision: 0.946 recall: 1.000 f1: 0.972 accuracy: 0.993 
training batch:   400, loss: 0.13004, precision: 1.000 recall: 0.964 f1: 0.982 accuracy: 0.999 
training batch:   420, loss: 0.00214, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   440, loss: 0.00197, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.00964, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.20956, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.999 
training batch:   500, loss: 0.03183, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.22894, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:   540, loss: 0.04084, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   560, loss: 0.35516, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.990 
training batch:   580, loss: 0.09895, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   600, loss: 0.00753, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.53824, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:   640, loss: 0.13131, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.01417, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.10213, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   700, loss: 0.06980, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.07224, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 0.02279, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   760, loss: 0.01943, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   780, loss: 0.37353, precision: 0.974 recall: 0.950 f1: 0.962 accuracy: 0.998 
training batch:   800, loss: 0.02670, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   820, loss: 0.04897, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   840, loss: 2.16416, precision: 0.825 recall: 0.943 f1: 0.880 accuracy: 0.993 
training batch:   860, loss: 1.16688, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.993 
training batch:   880, loss: 0.05381, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   900, loss: 0.01025, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   920, loss: 0.77994, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.998 
training batch:   940, loss: 0.88080, precision: 1.000 recall: 0.977 f1: 0.989 accuracy: 0.998 
training batch:   960, loss: 0.35402, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.996 
training batch:   980, loss: 0.01734, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1000, loss: 0.00456, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1020, loss: 0.52872, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:  1040, loss: 0.00733, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1060, loss: 0.01041, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 0.52985, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.995 
training batch:  1100, loss: 0.06168, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1120, loss: 0.06658, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1140, loss: 0.00183, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1160, loss: 0.03778, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.04343, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.32673, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.999 
training batch:  1220, loss: 0.11300, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.04867, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.35857, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.998 
training batch:  1280, loss: 0.00112, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.00193, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 1.59512, precision: 0.973 recall: 0.837 f1: 0.900 accuracy: 0.993 
training batch:  1340, loss: 0.03272, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1360, loss: 0.00233, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 1.08614, precision: 1.000 recall: 0.956 f1: 0.977 accuracy: 0.990 
training batch:  1400, loss: 0.00655, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1420, loss: 0.00842, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1440, loss: 0.00203, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1460, loss: 0.21699, precision: 0.979 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:  1480, loss: 0.16644, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:  1500, loss: 0.14864, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.994 
training batch:  1520, loss: 0.00257, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1540, loss: 0.00374, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1560, loss: 0.00407, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1580, loss: 0.00217, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1600, loss: 0.07773, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1620, loss: 0.00922, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1640, loss: 0.26695, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.993 
training batch:  1660, loss: 0.04858, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1680, loss: 0.00676, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1700, loss: 0.02631, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1720, loss: 0.00786, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1740, loss: 0.46360, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.994 
training batch:  1760, loss: 0.21120, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1780, loss: 0.01244, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1800, loss: 0.07314, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1820, loss: 0.05549, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1840, loss: 0.06954, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1860, loss: 0.00160, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1880, loss: 0.05032, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1900, loss: 0.18507, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.996 
start evaluate engines...
label: Dsa, precision: 0.986 recall: 0.985 f1: 0.986 
label: Chk, precision: 0.711 recall: 0.711 f1: 0.711 
label: Ins, precision: 0.455 recall: 0.451 f1: 0.452 
label: Sur, precision: 0.903 recall: 0.903 f1: 0.903 
label: Med, precision: 0.468 recall: 0.462 f1: 0.464 
label: Ana, precision: 0.995 recall: 0.992 f1: 0.993 
time consumption:23.73(min), precision: 0.996 recall: 0.993 f1: 0.994 accuracy: 0.999 
epoch:18/100
training batch:    20, loss: 0.52137, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    40, loss: 0.15948, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    60, loss: 0.23310, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    80, loss: 0.15784, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:   100, loss: 0.00606, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.05805, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 1.28422, precision: 0.800 recall: 0.960 f1: 0.873 accuracy: 0.994 
training batch:   160, loss: 0.09150, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   180, loss: 0.62537, precision: 0.921 recall: 1.000 f1: 0.959 accuracy: 0.996 
training batch:   200, loss: 0.01327, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.33951, precision: 1.000 recall: 0.977 f1: 0.989 accuracy: 0.998 
training batch:   240, loss: 0.45335, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:   260, loss: 0.00864, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.01051, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   300, loss: 0.00760, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   320, loss: 0.03443, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   340, loss: 0.02490, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   360, loss: 0.00313, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 0.01548, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.75736, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.988 
training batch:   420, loss: 0.21399, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.999 
training batch:   440, loss: 0.00797, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.00671, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   480, loss: 0.00579, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.00459, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.43044, precision: 0.935 recall: 0.956 f1: 0.945 accuracy: 0.994 
training batch:   540, loss: 0.02099, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   560, loss: 0.07219, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   580, loss: 0.15482, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.999 
training batch:   600, loss: 0.17468, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.28394, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.999 
training batch:   640, loss: 0.18945, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   660, loss: 0.02575, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   680, loss: 0.47352, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.980 
training batch:   700, loss: 0.02646, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.02067, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   740, loss: 0.50569, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   760, loss: 0.00535, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   780, loss: 0.04171, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   800, loss: 0.15263, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   820, loss: 0.32999, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.990 
training batch:   840, loss: 0.03092, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   860, loss: 0.07068, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   880, loss: 0.26169, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   900, loss: 0.22301, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   920, loss: 1.23821, precision: 0.946 recall: 0.921 f1: 0.933 accuracy: 0.986 
training batch:   940, loss: 1.03915, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.995 
training batch:   960, loss: 0.00262, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   980, loss: 0.14541, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.990 
training batch:  1000, loss: 0.05603, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1020, loss: 0.00086, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1040, loss: 0.33285, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.996 
training batch:  1060, loss: 0.12698, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1080, loss: 0.24075, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1100, loss: 0.35997, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.994 
training batch:  1120, loss: 0.00302, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1140, loss: 0.08418, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1160, loss: 0.00506, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1180, loss: 0.06603, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1200, loss: 0.10249, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1220, loss: 0.00190, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1240, loss: 0.10657, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1260, loss: 0.00504, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1280, loss: 0.06438, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1300, loss: 0.02627, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1320, loss: 0.00953, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1340, loss: 0.20073, precision: 0.978 recall: 1.000 f1: 0.989 accuracy: 0.998 
training batch:  1360, loss: 0.01419, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1380, loss: 0.63847, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.991 
training batch:  1400, loss: 0.00108, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1420, loss: 0.03734, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1440, loss: 0.42674, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:  1460, loss: 0.03397, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1480, loss: 0.08191, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1500, loss: 1.39312, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:  1520, loss: 0.32401, precision: 1.000 recall: 0.946 f1: 0.972 accuracy: 0.995 
training batch:  1540, loss: 0.02035, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1560, loss: 0.15619, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1580, loss: 0.00392, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1600, loss: 0.19262, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.990 
training batch:  1620, loss: 0.71073, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:  1640, loss: 0.05307, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1660, loss: 1.08286, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.998 
training batch:  1680, loss: 0.00702, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1700, loss: 0.05867, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1720, loss: 0.05226, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1740, loss: 0.02098, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1760, loss: 1.36368, precision: 0.927 recall: 0.927 f1: 0.927 accuracy: 0.980 
training batch:  1780, loss: 0.01595, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1800, loss: 0.49861, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.998 
training batch:  1820, loss: 0.03718, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1840, loss: 0.05981, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1860, loss: 0.02797, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1880, loss: 0.00183, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:  1900, loss: 0.35220, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.996 
start evaluate engines...
label: Dsa, precision: 0.990 recall: 0.987 f1: 0.988 
label: Chk, precision: 0.711 recall: 0.709 f1: 0.710 
label: Ins, precision: 0.457 recall: 0.458 f1: 0.457 
label: Sur, precision: 0.903 recall: 0.903 f1: 0.903 
label: Med, precision: 0.469 recall: 0.470 f1: 0.469 
label: Ana, precision: 0.992 recall: 0.996 f1: 0.994 
time consumption:23.50(min), precision: 0.995 recall: 0.996 f1: 0.995 accuracy: 0.999 
early stopped, no progress obtained within 5 epochs
overall best f1 is 0.9960296870464597 at 13 epoch
total training time consumption: 425.947(min)
