2022-10-04 15:55:15
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY++++++++++++++++++++++++++++++++++++++++
 Status:
     mode                 : train
 ++++++++++++++++++++++++++++++++++++++++
 Datasets:
     datasets         fold: data/example_datasets/datasets
     train            file: train20.csv
     validation       file: None
     vocab             dir: data/example_datasets/vocab/2020
     delimiter            : b
     use  pretrained model: True
     pretrained      model: Bert
     finetune             : False
     use    middle   model: True
     middle          model: bilstm+idcnn
     checkpoints       dir: checkpoints/BPBIC(2020)
     log               dir: data/example_datasets/logs
 ++++++++++++++++++++++++++++++++++++++++
Labeling Scheme:
     label          scheme: BIO
     label           level: 2
     suffixes             : ['Dsa', 'Chk', 'Ins', 'Sur', 'Med', 'Ana']
     measuring     metrics: ['precision', 'recall', 'f1', 'accuracy']
 ++++++++++++++++++++++++++++++++++++++++
Model Configuration:
     embedding         dim: 100
     max  sequence  length: 100
     hidden            dim: 128
     filter           nums: 64
     idcnn            nums: 3
     CUDA  VISIBLE  DEVICE: 0
     seed                 : 23
 ++++++++++++++++++++++++++++++++++++++++
 Training Settings:
     epoch                : 100
     batch            size: 8
     dropout              : 0.3
     learning         rate: 0.001
     optimizer            : Adam
     use               gan: True
     gan            method: pgd
     checkpoint       name: model_our
     max       checkpoints: 3
     print       per_batch: 1
     is     early     stop: True
     patient              : 5
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY END++++++++++++++++++++++++++++++++++++++++
label vocab files not exist, building label vocab...
dataManager initialed...
mode: train
loading data...
validating set is not exist, built...
training set size: 1060, validating set size: 118
++++++++++++++++++++training starting++++++++++++++++++++
epoch:1/100
training batch:     1, loss: 280.62704, precision: 0.014 recall: 0.031 f1: 0.019 accuracy: 0.360 
training batch:     2, loss: 272.15942, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.431 
training batch:     3, loss: 237.25079, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.799 
training batch:     4, loss: 259.80295, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.761 
training batch:     5, loss: 250.54111, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.431 
training batch:     6, loss: 248.72397, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.424 
training batch:     7, loss: 242.25839, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.434 
training batch:     8, loss: 218.42484, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.425 
training batch:     9, loss: 127.97678, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.672 
training batch:    10, loss: 208.47655, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.816 
training batch:    11, loss: 157.82642, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.797 
training batch:    12, loss: 148.86067, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.709 
training batch:    13, loss: 150.03339, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.476 
training batch:    14, loss: 166.35785, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.484 
training batch:    15, loss: 153.66248, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.477 
training batch:    16, loss: 132.83368, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.481 
training batch:    17, loss: 107.31895, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.744 
training batch:    18, loss: 87.93022, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.797 
training batch:    19, loss: 111.81245, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.779 
training batch:    20, loss: 110.57165, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.744 
training batch:    21, loss: 110.54371, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.825 
training batch:    22, loss: 145.88861, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.576 
training batch:    23, loss: 115.34813, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.616 
training batch:    24, loss: 90.86555, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.814 
training batch:    25, loss: 105.02183, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.744 
training batch:    26, loss: 83.20341, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.757 
training batch:    27, loss: 77.09200, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.776 
training batch:    28, loss: 62.44907, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.886 
training batch:    29, loss: 69.79827, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.809 
training batch:    30, loss: 62.15411, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.833 
training batch:    31, loss: 83.45144, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.786 
training batch:    32, loss: 63.16732, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.834 
training batch:    33, loss: 62.00050, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.810 
training batch:    34, loss: 72.07416, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.787 
training batch:    35, loss: 75.36964, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.848 
training batch:    36, loss: 63.37698, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.860 
training batch:    37, loss: 76.52509, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.725 
training batch:    38, loss: 58.22556, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.849 
training batch:    39, loss: 85.28609, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.814 
training batch:    40, loss: 46.99559, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.859 
training batch:    41, loss: 55.50891, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.844 
training batch:    42, loss: 79.80640, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.745 
training batch:    43, loss: 58.09989, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.815 
training batch:    44, loss: 33.42811, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.914 
training batch:    45, loss: 57.29232, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.849 
training batch:    46, loss: 45.37145, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.853 
training batch:    47, loss: 41.60456, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.896 
training batch:    48, loss: 42.17959, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.873 
training batch:    49, loss: 70.75898, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.858 
training batch:    50, loss: 52.21253, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.846 
training batch:    51, loss: 59.34515, precision: 0.333 recall: 0.040 f1: 0.071 accuracy: 0.870 
training batch:    52, loss: 44.13258, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.865 
training batch:    53, loss: 51.27625, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.866 
training batch:    54, loss: 48.59870, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.866 
training batch:    55, loss: 48.91163, precision: 0.167 recall: 0.029 f1: 0.050 accuracy: 0.870 
training batch:    56, loss: 45.40373, precision: 0.111 recall: 0.034 f1: 0.053 accuracy: 0.879 
training batch:    57, loss: 42.15836, precision: 0.167 recall: 0.036 f1: 0.059 accuracy: 0.904 
training batch:    58, loss: 32.94450, precision: 1.000 recall: 0.120 f1: 0.214 accuracy: 0.921 
training batch:    59, loss: 55.38683, precision: 0.118 recall: 0.065 f1: 0.083 accuracy: 0.839 
training batch:    60, loss: 42.96684, precision: 0.100 recall: 0.028 f1: 0.043 accuracy: 0.885 
training batch:    61, loss: 88.90791, precision: 0.400 recall: 0.154 f1: 0.222 accuracy: 0.806 
training batch:    62, loss: 38.35852, precision: 0.214 recall: 0.094 f1: 0.130 accuracy: 0.882 
training batch:    63, loss: 33.55689, precision: 0.059 recall: 0.031 f1: 0.041 accuracy: 0.885 
training batch:    64, loss: 38.65752, precision: 0.235 recall: 0.121 f1: 0.160 accuracy: 0.887 
training batch:    65, loss: 38.90455, precision: 0.167 recall: 0.086 f1: 0.113 accuracy: 0.870 
training batch:    66, loss: 33.78796, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.882 
training batch:    67, loss: 53.48853, precision: 0.182 recall: 0.054 f1: 0.083 accuracy: 0.869 
training batch:    68, loss: 51.96204, precision: 0.333 recall: 0.103 f1: 0.158 accuracy: 0.850 
training batch:    69, loss: 45.73323, precision: 0.444 recall: 0.095 f1: 0.157 accuracy: 0.853 
training batch:    70, loss: 34.29239, precision: 0.273 recall: 0.081 f1: 0.125 accuracy: 0.899 
training batch:    71, loss: 27.28426, precision: 0.400 recall: 0.207 f1: 0.273 accuracy: 0.931 
training batch:    72, loss: 38.61052, precision: 0.375 recall: 0.171 f1: 0.235 accuracy: 0.870 
training batch:    73, loss: 32.96980, precision: 0.625 recall: 0.405 f1: 0.492 accuracy: 0.915 
training batch:    74, loss: 42.59649, precision: 0.333 recall: 0.219 f1: 0.264 accuracy: 0.875 
training batch:    75, loss: 41.19118, precision: 0.280 recall: 0.184 f1: 0.222 accuracy: 0.871 
training batch:    76, loss: 28.16888, precision: 0.318 recall: 0.212 f1: 0.255 accuracy: 0.902 
training batch:    77, loss: 37.18754, precision: 0.194 recall: 0.231 f1: 0.211 accuracy: 0.899 
training batch:    78, loss: 42.16136, precision: 0.440 recall: 0.256 f1: 0.324 accuracy: 0.885 
training batch:    79, loss: 52.59949, precision: 0.348 recall: 0.216 f1: 0.267 accuracy: 0.880 
training batch:    80, loss: 27.72359, precision: 0.286 recall: 0.111 f1: 0.160 accuracy: 0.921 
training batch:    81, loss: 54.10381, precision: 0.450 recall: 0.231 f1: 0.305 accuracy: 0.853 
training batch:    82, loss: 44.80994, precision: 0.381 recall: 0.211 f1: 0.271 accuracy: 0.894 
training batch:    83, loss: 47.60515, precision: 0.531 recall: 0.436 f1: 0.479 accuracy: 0.887 
training batch:    84, loss: 37.62225, precision: 0.463 recall: 0.487 f1: 0.475 accuracy: 0.905 
training batch:    85, loss: 30.24488, precision: 0.396 recall: 0.655 f1: 0.494 accuracy: 0.927 
training batch:    86, loss: 28.35480, precision: 0.500 recall: 0.595 f1: 0.543 accuracy: 0.936 
training batch:    87, loss: 38.87693, precision: 0.360 recall: 0.191 f1: 0.250 accuracy: 0.882 
training batch:    88, loss: 49.70034, precision: 0.400 recall: 0.133 f1: 0.200 accuracy: 0.840 
training batch:    89, loss: 29.54737, precision: 0.429 recall: 0.171 f1: 0.245 accuracy: 0.925 
training batch:    90, loss: 14.85004, precision: 0.700 recall: 0.292 f1: 0.412 accuracy: 0.958 
training batch:    91, loss: 34.70385, precision: 0.278 recall: 0.152 f1: 0.196 accuracy: 0.891 
training batch:    92, loss: 33.99191, precision: 0.556 recall: 0.286 f1: 0.377 accuracy: 0.904 
training batch:    93, loss: 21.56908, precision: 0.500 recall: 0.194 f1: 0.279 accuracy: 0.930 
training batch:    94, loss: 35.72915, precision: 0.308 recall: 0.129 f1: 0.182 accuracy: 0.912 
training batch:    95, loss: 28.11005, precision: 0.323 recall: 0.278 f1: 0.299 accuracy: 0.902 
training batch:    96, loss: 18.87341, precision: 0.714 recall: 0.667 f1: 0.690 accuracy: 0.948 
training batch:    97, loss: 25.03840, precision: 0.367 recall: 0.407 f1: 0.386 accuracy: 0.939 
training batch:    98, loss: 22.04088, precision: 0.500 recall: 0.513 f1: 0.506 accuracy: 0.924 
training batch:    99, loss: 36.32438, precision: 0.463 recall: 0.528 f1: 0.494 accuracy: 0.896 
training batch:   100, loss: 31.80956, precision: 0.370 recall: 0.531 f1: 0.436 accuracy: 0.894 
training batch:   101, loss: 18.76957, precision: 0.581 recall: 0.562 f1: 0.571 accuracy: 0.945 
training batch:   102, loss: 27.13489, precision: 0.750 recall: 0.778 f1: 0.764 accuracy: 0.929 
training batch:   103, loss: 66.05702, precision: 0.382 recall: 0.371 f1: 0.377 accuracy: 0.877 
training batch:   104, loss: 20.71170, precision: 0.650 recall: 0.394 f1: 0.491 accuracy: 0.939 
training batch:   105, loss: 23.80067, precision: 0.387 recall: 0.353 f1: 0.369 accuracy: 0.911 
training batch:   106, loss: 39.33847, precision: 0.654 recall: 0.447 f1: 0.531 accuracy: 0.897 
training batch:   107, loss: 35.59268, precision: 0.500 recall: 0.477 f1: 0.488 accuracy: 0.876 
training batch:   108, loss: 28.59853, precision: 0.800 recall: 0.488 f1: 0.606 accuracy: 0.925 
training batch:   109, loss: 13.82062, precision: 0.750 recall: 0.692 f1: 0.720 accuracy: 0.964 
training batch:   110, loss: 33.56770, precision: 0.560 recall: 0.412 f1: 0.475 accuracy: 0.909 
training batch:   111, loss: 16.97903, precision: 0.562 recall: 0.514 f1: 0.537 accuracy: 0.955 
training batch:   112, loss: 19.07760, precision: 0.688 recall: 0.579 f1: 0.629 accuracy: 0.948 
training batch:   113, loss: 29.60672, precision: 0.314 recall: 0.407 f1: 0.355 accuracy: 0.901 
training batch:   114, loss: 38.72237, precision: 0.545 recall: 0.316 f1: 0.400 accuracy: 0.889 
training batch:   115, loss: 43.90129, precision: 0.667 recall: 0.474 f1: 0.554 accuracy: 0.884 
training batch:   116, loss: 26.54558, precision: 0.538 recall: 0.438 f1: 0.483 accuracy: 0.930 
training batch:   117, loss: 31.57506, precision: 0.560 recall: 0.500 f1: 0.528 accuracy: 0.921 
training batch:   118, loss: 21.23470, precision: 0.480 recall: 0.387 f1: 0.429 accuracy: 0.920 
training batch:   119, loss: 47.58409, precision: 0.586 recall: 0.472 f1: 0.523 accuracy: 0.891 
training batch:   120, loss: 19.30502, precision: 0.407 recall: 0.379 f1: 0.393 accuracy: 0.929 
training batch:   121, loss: 22.43687, precision: 0.568 recall: 0.568 f1: 0.568 accuracy: 0.943 
training batch:   122, loss: 36.16507, precision: 0.429 recall: 0.366 f1: 0.395 accuracy: 0.906 
training batch:   123, loss: 20.81120, precision: 0.562 recall: 0.545 f1: 0.554 accuracy: 0.936 
training batch:   124, loss: 19.62637, precision: 0.513 recall: 0.588 f1: 0.548 accuracy: 0.939 
training batch:   125, loss: 18.96951, precision: 0.654 recall: 0.586 f1: 0.618 accuracy: 0.940 
training batch:   126, loss: 23.84705, precision: 0.522 recall: 0.500 f1: 0.511 accuracy: 0.941 
training batch:   127, loss: 33.18956, precision: 0.559 recall: 0.422 f1: 0.481 accuracy: 0.905 
training batch:   128, loss: 21.96418, precision: 0.567 recall: 0.548 f1: 0.557 accuracy: 0.938 
training batch:   129, loss: 33.50470, precision: 0.591 recall: 0.464 f1: 0.520 accuracy: 0.909 
training batch:   130, loss: 30.16927, precision: 0.571 recall: 0.324 f1: 0.414 accuracy: 0.919 
training batch:   131, loss: 18.37928, precision: 0.640 recall: 0.640 f1: 0.640 accuracy: 0.959 
training batch:   132, loss: 44.53258, precision: 0.500 recall: 0.471 f1: 0.485 accuracy: 0.863 
start evaluate engines...
label: Dsa, precision: 0.602 recall: 0.567 f1: 0.576 
label: Chk, precision: 0.000 recall: 0.000 f1: 0.000 
label: Ins, precision: 0.000 recall: 0.000 f1: 0.000 
label: Sur, precision: 0.694 recall: 0.673 f1: 0.676 
label: Med, precision: 0.000 recall: 0.000 f1: 0.000 
label: Ana, precision: 0.697 recall: 0.637 f1: 0.661 
time consumption:1.94(min), precision: 0.699 recall: 0.586 f1: 0.635 accuracy: 0.944 
saved the new best model with f1: 0.635
epoch:2/100
training batch:     1, loss: 21.66401, precision: 0.719 recall: 0.697 f1: 0.708 accuracy: 0.939 
training batch:     2, loss: 19.48205, precision: 0.640 recall: 0.593 f1: 0.615 accuracy: 0.939 
training batch:     3, loss: 34.96516, precision: 0.667 recall: 0.538 f1: 0.596 accuracy: 0.899 
training batch:     4, loss: 30.60445, precision: 0.692 recall: 0.400 f1: 0.507 accuracy: 0.909 
training batch:     5, loss: 25.12253, precision: 0.792 recall: 0.594 f1: 0.679 accuracy: 0.930 
training batch:     6, loss: 10.69732, precision: 0.545 recall: 0.522 f1: 0.533 accuracy: 0.964 
training batch:     7, loss: 19.09541, precision: 0.681 recall: 0.780 f1: 0.727 accuracy: 0.951 
training batch:     8, loss: 17.37440, precision: 0.744 recall: 0.690 f1: 0.716 accuracy: 0.953 
training batch:     9, loss: 19.11944, precision: 0.680 recall: 0.567 f1: 0.618 accuracy: 0.948 
training batch:    10, loss: 26.48666, precision: 0.450 recall: 0.462 f1: 0.456 accuracy: 0.920 
training batch:    11, loss: 23.47505, precision: 0.697 recall: 0.605 f1: 0.648 accuracy: 0.917 
training batch:    12, loss: 16.08476, precision: 0.636 recall: 0.583 f1: 0.609 accuracy: 0.950 
training batch:    13, loss: 17.12474, precision: 0.542 recall: 0.565 f1: 0.553 accuracy: 0.959 
training batch:    14, loss: 16.22552, precision: 0.636 recall: 0.568 f1: 0.600 accuracy: 0.949 
training batch:    15, loss: 16.89028, precision: 0.690 recall: 0.606 f1: 0.645 accuracy: 0.939 
training batch:    16, loss: 15.36188, precision: 0.500 recall: 0.310 f1: 0.383 accuracy: 0.954 
training batch:    17, loss: 22.23260, precision: 0.688 recall: 0.344 f1: 0.458 accuracy: 0.945 
training batch:    18, loss: 30.90604, precision: 0.619 recall: 0.448 f1: 0.520 accuracy: 0.917 
training batch:    19, loss: 15.77747, precision: 0.793 recall: 0.622 f1: 0.697 accuracy: 0.951 
training batch:    20, loss: 33.12406, precision: 0.727 recall: 0.686 f1: 0.706 accuracy: 0.924 
training batch:    21, loss: 17.54255, precision: 0.578 recall: 0.650 f1: 0.612 accuracy: 0.946 
training batch:    22, loss: 22.21226, precision: 0.381 recall: 0.516 f1: 0.438 accuracy: 0.930 
training batch:    23, loss: 21.57977, precision: 0.395 recall: 0.472 f1: 0.430 accuracy: 0.930 
training batch:    24, loss: 17.58267, precision: 0.419 recall: 0.562 f1: 0.480 accuracy: 0.940 
training batch:    25, loss: 29.82836, precision: 0.583 recall: 0.538 f1: 0.560 accuracy: 0.886 
training batch:    26, loss: 33.25668, precision: 0.588 recall: 0.541 f1: 0.563 accuracy: 0.912 
training batch:    27, loss: 24.42669, precision: 0.733 recall: 0.733 f1: 0.733 accuracy: 0.936 
training batch:    28, loss: 27.80222, precision: 0.600 recall: 0.480 f1: 0.533 accuracy: 0.901 
training batch:    29, loss: 16.33088, precision: 0.609 recall: 0.412 f1: 0.491 accuracy: 0.949 
training batch:    30, loss: 16.28297, precision: 0.750 recall: 0.656 f1: 0.700 accuracy: 0.941 
training batch:    31, loss: 17.33681, precision: 0.607 recall: 0.531 f1: 0.567 accuracy: 0.948 
training batch:    32, loss: 17.42663, precision: 0.889 recall: 0.533 f1: 0.667 accuracy: 0.949 
training batch:    33, loss: 11.89432, precision: 0.794 recall: 0.659 f1: 0.720 accuracy: 0.966 
training batch:    34, loss: 13.71875, precision: 0.680 recall: 0.586 f1: 0.630 accuracy: 0.966 
training batch:    35, loss: 46.34290, precision: 0.385 recall: 0.357 f1: 0.370 accuracy: 0.858 
training batch:    36, loss: 16.61041, precision: 0.677 recall: 0.600 f1: 0.636 accuracy: 0.939 
training batch:    37, loss: 18.52057, precision: 0.806 recall: 0.694 f1: 0.746 accuracy: 0.951 
training batch:    38, loss: 26.20772, precision: 0.552 recall: 0.500 f1: 0.525 accuracy: 0.897 
training batch:    39, loss: 20.50594, precision: 0.567 recall: 0.447 f1: 0.500 accuracy: 0.931 
training batch:    40, loss: 23.37364, precision: 0.708 recall: 0.567 f1: 0.630 accuracy: 0.941 
training batch:    41, loss: 32.27615, precision: 0.567 recall: 0.436 f1: 0.493 accuracy: 0.877 
training batch:    42, loss: 29.38152, precision: 0.516 recall: 0.485 f1: 0.500 accuracy: 0.922 
training batch:    43, loss: 15.83582, precision: 0.467 recall: 0.483 f1: 0.475 accuracy: 0.955 
training batch:    44, loss: 12.18442, precision: 0.545 recall: 0.632 f1: 0.585 accuracy: 0.959 
training batch:    45, loss: 23.86278, precision: 0.614 recall: 0.675 f1: 0.643 accuracy: 0.931 
training batch:    46, loss: 11.12096, precision: 0.737 recall: 0.737 f1: 0.737 accuracy: 0.970 
training batch:    47, loss: 15.13544, precision: 0.654 recall: 0.680 f1: 0.667 accuracy: 0.961 
training batch:    48, loss: 17.27266, precision: 0.812 recall: 0.743 f1: 0.776 accuracy: 0.959 
training batch:    49, loss: 26.11494, precision: 0.606 recall: 0.571 f1: 0.588 accuracy: 0.926 
training batch:    50, loss: 14.61076, precision: 0.629 recall: 0.710 f1: 0.667 accuracy: 0.954 
training batch:    51, loss: 25.13815, precision: 0.710 recall: 0.629 f1: 0.667 accuracy: 0.922 
training batch:    52, loss: 22.36041, precision: 0.381 recall: 0.235 f1: 0.291 accuracy: 0.938 
training batch:    53, loss: 15.57399, precision: 0.667 recall: 0.452 f1: 0.538 accuracy: 0.955 
training batch:    54, loss: 15.62756, precision: 0.864 recall: 0.731 f1: 0.792 accuracy: 0.970 
training batch:    55, loss: 9.82214, precision: 0.808 recall: 0.583 f1: 0.677 accuracy: 0.963 
training batch:    56, loss: 17.49230, precision: 0.583 recall: 0.424 f1: 0.491 accuracy: 0.945 
training batch:    57, loss: 19.13729, precision: 0.788 recall: 0.667 f1: 0.722 accuracy: 0.944 
training batch:    58, loss: 15.85808, precision: 0.727 recall: 0.667 f1: 0.696 accuracy: 0.963 
training batch:    59, loss: 30.58006, precision: 0.579 recall: 0.579 f1: 0.579 accuracy: 0.892 
training batch:    60, loss: 14.95440, precision: 0.651 recall: 0.667 f1: 0.659 accuracy: 0.950 
training batch:    61, loss: 19.58453, precision: 0.561 recall: 0.639 f1: 0.597 accuracy: 0.935 
training batch:    62, loss: 10.13309, precision: 0.838 recall: 0.838 f1: 0.838 accuracy: 0.965 
training batch:    63, loss: 19.75763, precision: 0.800 recall: 0.757 f1: 0.778 accuracy: 0.943 
training batch:    64, loss: 59.66431, precision: 0.415 recall: 0.405 f1: 0.410 accuracy: 0.814 
training batch:    65, loss: 13.63511, precision: 0.759 recall: 0.667 f1: 0.710 accuracy: 0.951 
training batch:    66, loss: 16.45531, precision: 0.793 recall: 0.767 f1: 0.780 accuracy: 0.959 
training batch:    67, loss: 18.49986, precision: 0.697 recall: 0.575 f1: 0.630 accuracy: 0.949 
training batch:    68, loss: 42.93785, precision: 0.543 recall: 0.559 f1: 0.551 accuracy: 0.885 
training batch:    69, loss: 11.92557, precision: 0.722 recall: 0.684 f1: 0.703 accuracy: 0.956 
training batch:    70, loss: 20.06023, precision: 0.656 recall: 0.600 f1: 0.627 accuracy: 0.934 
training batch:    71, loss: 25.86691, precision: 0.719 recall: 0.605 f1: 0.657 accuracy: 0.927 
training batch:    72, loss: 20.27142, precision: 0.667 recall: 0.595 f1: 0.629 accuracy: 0.941 
training batch:    73, loss: 28.10336, precision: 0.688 recall: 0.579 f1: 0.629 accuracy: 0.920 
training batch:    74, loss: 28.34269, precision: 0.500 recall: 0.514 f1: 0.507 accuracy: 0.916 
training batch:    75, loss: 21.42626, precision: 0.688 recall: 0.579 f1: 0.629 accuracy: 0.951 
training batch:    76, loss: 19.05739, precision: 0.577 recall: 0.600 f1: 0.588 accuracy: 0.940 
training batch:    77, loss: 23.59038, precision: 0.571 recall: 0.571 f1: 0.571 accuracy: 0.926 
training batch:    78, loss: 14.76237, precision: 0.722 recall: 0.684 f1: 0.703 accuracy: 0.960 
training batch:    79, loss: 15.98757, precision: 0.792 recall: 0.792 f1: 0.792 accuracy: 0.963 
training batch:    80, loss: 20.63711, precision: 0.533 recall: 0.457 f1: 0.492 accuracy: 0.921 
training batch:    81, loss: 16.29372, precision: 0.625 recall: 0.517 f1: 0.566 accuracy: 0.959 
training batch:    82, loss: 23.61259, precision: 0.700 recall: 0.636 f1: 0.667 accuracy: 0.929 
training batch:    83, loss: 12.96767, precision: 0.821 recall: 0.727 f1: 0.771 accuracy: 0.959 
training batch:    84, loss: 8.76842, precision: 0.645 recall: 0.571 f1: 0.606 accuracy: 0.965 
training batch:    85, loss: 21.13627, precision: 0.786 recall: 0.688 f1: 0.733 accuracy: 0.945 
training batch:    86, loss: 23.19815, precision: 0.711 recall: 0.659 f1: 0.684 accuracy: 0.935 
training batch:    87, loss: 39.00095, precision: 0.727 recall: 0.615 f1: 0.667 accuracy: 0.915 
training batch:    88, loss: 13.99722, precision: 0.842 recall: 0.711 f1: 0.771 accuracy: 0.955 
training batch:    89, loss: 16.61495, precision: 0.732 recall: 0.698 f1: 0.714 accuracy: 0.945 
training batch:    90, loss: 13.32179, precision: 0.625 recall: 0.600 f1: 0.612 accuracy: 0.966 
training batch:    91, loss: 16.00925, precision: 0.579 recall: 0.611 f1: 0.595 accuracy: 0.940 
training batch:    92, loss: 15.82245, precision: 0.606 recall: 0.541 f1: 0.571 accuracy: 0.946 
training batch:    93, loss: 16.28017, precision: 0.615 recall: 0.632 f1: 0.623 accuracy: 0.948 
training batch:    94, loss: 23.83004, precision: 0.667 recall: 0.722 f1: 0.693 accuracy: 0.920 
training batch:    95, loss: 60.10020, precision: 0.641 recall: 0.568 f1: 0.602 accuracy: 0.886 
training batch:    96, loss: 29.71038, precision: 0.621 recall: 0.643 f1: 0.632 accuracy: 0.910 
training batch:    97, loss: 19.82527, precision: 0.529 recall: 0.600 f1: 0.562 accuracy: 0.950 
training batch:    98, loss: 16.82199, precision: 0.656 recall: 0.636 f1: 0.646 accuracy: 0.936 
training batch:    99, loss: 27.46725, precision: 0.390 recall: 0.364 f1: 0.376 accuracy: 0.912 
training batch:   100, loss: 13.83140, precision: 0.735 recall: 0.735 f1: 0.735 accuracy: 0.963 
training batch:   101, loss: 14.00136, precision: 0.600 recall: 0.621 f1: 0.610 accuracy: 0.968 
training batch:   102, loss: 10.15022, precision: 0.778 recall: 0.700 f1: 0.737 accuracy: 0.973 
training batch:   103, loss: 21.64167, precision: 0.564 recall: 0.611 f1: 0.587 accuracy: 0.936 
training batch:   104, loss: 17.05310, precision: 0.739 recall: 0.607 f1: 0.667 accuracy: 0.954 
training batch:   105, loss: 16.12587, precision: 0.607 recall: 0.548 f1: 0.576 accuracy: 0.945 
training batch:   106, loss: 9.58002, precision: 0.875 recall: 0.724 f1: 0.792 accuracy: 0.969 
training batch:   107, loss: 13.85087, precision: 0.760 recall: 0.633 f1: 0.691 accuracy: 0.946 
training batch:   108, loss: 19.58296, precision: 0.684 recall: 0.433 f1: 0.531 accuracy: 0.948 
training batch:   109, loss: 24.71191, precision: 0.800 recall: 0.636 f1: 0.709 accuracy: 0.938 
training batch:   110, loss: 23.89971, precision: 0.762 recall: 0.471 f1: 0.582 accuracy: 0.939 
training batch:   111, loss: 7.39694, precision: 0.867 recall: 0.788 f1: 0.825 accuracy: 0.980 
training batch:   112, loss: 9.37579, precision: 0.760 recall: 0.655 f1: 0.704 accuracy: 0.975 
training batch:   113, loss: 20.04549, precision: 0.839 recall: 0.650 f1: 0.732 accuracy: 0.953 
training batch:   114, loss: 14.70718, precision: 0.684 recall: 0.634 f1: 0.658 accuracy: 0.944 
training batch:   115, loss: 18.10352, precision: 0.767 recall: 0.697 f1: 0.730 accuracy: 0.939 
training batch:   116, loss: 27.02404, precision: 0.720 recall: 0.692 f1: 0.706 accuracy: 0.951 
training batch:   117, loss: 19.95951, precision: 0.682 recall: 0.469 f1: 0.556 accuracy: 0.943 
training batch:   118, loss: 11.50987, precision: 0.719 recall: 0.639 f1: 0.676 accuracy: 0.968 
training batch:   119, loss: 14.56678, precision: 0.800 recall: 0.686 f1: 0.738 accuracy: 0.955 
training batch:   120, loss: 12.05867, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.961 
training batch:   121, loss: 20.42227, precision: 0.533 recall: 0.552 f1: 0.542 accuracy: 0.936 
training batch:   122, loss: 17.37656, precision: 0.727 recall: 0.774 f1: 0.750 accuracy: 0.958 
training batch:   123, loss: 12.77269, precision: 0.634 recall: 0.619 f1: 0.627 accuracy: 0.955 
training batch:   124, loss: 17.47330, precision: 0.761 recall: 0.761 f1: 0.761 accuracy: 0.943 
training batch:   125, loss: 11.41508, precision: 0.708 recall: 0.567 f1: 0.630 accuracy: 0.965 
training batch:   126, loss: 16.99816, precision: 0.742 recall: 0.793 f1: 0.767 accuracy: 0.948 
training batch:   127, loss: 30.32343, precision: 0.641 recall: 0.735 f1: 0.685 accuracy: 0.925 
training batch:   128, loss: 19.37485, precision: 0.923 recall: 0.706 f1: 0.800 accuracy: 0.963 
training batch:   129, loss: 11.62689, precision: 0.744 recall: 0.763 f1: 0.753 accuracy: 0.963 
training batch:   130, loss: 4.42635, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.989 
training batch:   131, loss: 13.43736, precision: 0.707 recall: 0.674 f1: 0.690 accuracy: 0.953 
training batch:   132, loss: 16.87000, precision: 0.750 recall: 0.714 f1: 0.732 accuracy: 0.948 
start evaluate engines...
label: Dsa, precision: 0.743 recall: 0.737 f1: 0.734 
label: Chk, precision: 0.467 recall: 0.433 f1: 0.444 
label: Ins, precision: 0.000 recall: 0.000 f1: 0.000 
label: Sur, precision: 0.873 recall: 0.876 f1: 0.869 
label: Med, precision: 0.300 recall: 0.333 f1: 0.311 
label: Ana, precision: 0.782 recall: 0.769 f1: 0.772 
time consumption:1.83(min), precision: 0.793 recall: 0.741 f1: 0.763 accuracy: 0.956 
saved the new best model with f1: 0.763
epoch:3/100
training batch:     1, loss: 15.39985, precision: 0.714 recall: 0.588 f1: 0.645 accuracy: 0.940 
training batch:     2, loss: 10.37285, precision: 0.812 recall: 0.743 f1: 0.776 accuracy: 0.970 
training batch:     3, loss: 14.31183, precision: 0.744 recall: 0.707 f1: 0.725 accuracy: 0.948 
training batch:     4, loss: 8.66487, precision: 0.780 recall: 0.800 f1: 0.790 accuracy: 0.970 
training batch:     5, loss: 17.83382, precision: 0.733 recall: 0.688 f1: 0.710 accuracy: 0.945 
training batch:     6, loss: 23.67352, precision: 0.625 recall: 0.595 f1: 0.610 accuracy: 0.916 
training batch:     7, loss: 13.05569, precision: 0.719 recall: 0.767 f1: 0.742 accuracy: 0.963 
training batch:     8, loss: 13.17252, precision: 0.781 recall: 0.781 f1: 0.781 accuracy: 0.948 
training batch:     9, loss: 19.19260, precision: 0.889 recall: 0.667 f1: 0.762 accuracy: 0.951 
training batch:    10, loss: 18.35220, precision: 0.688 recall: 0.710 f1: 0.698 accuracy: 0.943 
training batch:    11, loss: 15.97527, precision: 0.680 recall: 0.607 f1: 0.642 accuracy: 0.946 
training batch:    12, loss: 10.44623, precision: 0.710 recall: 0.667 f1: 0.688 accuracy: 0.973 
training batch:    13, loss: 16.21594, precision: 0.703 recall: 0.650 f1: 0.675 accuracy: 0.949 
training batch:    14, loss: 16.00303, precision: 0.556 recall: 0.667 f1: 0.606 accuracy: 0.950 
training batch:    15, loss: 20.49949, precision: 0.781 recall: 0.714 f1: 0.746 accuracy: 0.927 
training batch:    16, loss: 18.84628, precision: 0.615 recall: 0.533 f1: 0.571 accuracy: 0.929 
training batch:    17, loss: 13.65724, precision: 0.700 recall: 0.656 f1: 0.677 accuracy: 0.955 
training batch:    18, loss: 14.51347, precision: 0.680 recall: 0.500 f1: 0.576 accuracy: 0.946 
training batch:    19, loss: 7.25844, precision: 0.793 recall: 0.767 f1: 0.780 accuracy: 0.968 
training batch:    20, loss: 19.63116, precision: 0.685 recall: 0.661 f1: 0.673 accuracy: 0.935 
training batch:    21, loss: 20.38785, precision: 0.548 recall: 0.515 f1: 0.531 accuracy: 0.931 
training batch:    22, loss: 6.86168, precision: 0.815 recall: 0.846 f1: 0.830 accuracy: 0.981 
training batch:    23, loss: 20.09129, precision: 0.485 recall: 0.410 f1: 0.444 accuracy: 0.916 
training batch:    24, loss: 14.14595, precision: 0.743 recall: 0.722 f1: 0.732 accuracy: 0.945 
training batch:    25, loss: 13.34383, precision: 0.700 recall: 0.677 f1: 0.689 accuracy: 0.953 
training batch:    26, loss: 9.82375, precision: 0.781 recall: 0.714 f1: 0.746 accuracy: 0.975 
training batch:    27, loss: 11.50760, precision: 0.679 recall: 0.655 f1: 0.667 accuracy: 0.964 
training batch:    28, loss: 18.15332, precision: 0.517 recall: 0.517 f1: 0.517 accuracy: 0.926 
training batch:    29, loss: 19.78865, precision: 0.553 recall: 0.636 f1: 0.592 accuracy: 0.940 
training batch:    30, loss: 14.17963, precision: 0.765 recall: 0.722 f1: 0.743 accuracy: 0.943 
training batch:    31, loss: 33.96396, precision: 0.667 recall: 0.545 f1: 0.600 accuracy: 0.921 
training batch:    32, loss: 11.20200, precision: 0.667 recall: 0.743 f1: 0.703 accuracy: 0.965 
training batch:    33, loss: 12.84569, precision: 0.759 recall: 0.759 f1: 0.759 accuracy: 0.964 
training batch:    34, loss: 23.63992, precision: 0.921 recall: 0.833 f1: 0.875 accuracy: 0.963 
training batch:    35, loss: 13.80011, precision: 0.793 recall: 0.697 f1: 0.742 accuracy: 0.960 
training batch:    36, loss: 8.32779, precision: 0.933 recall: 0.757 f1: 0.836 accuracy: 0.976 
training batch:    37, loss: 17.64618, precision: 0.562 recall: 0.562 f1: 0.562 accuracy: 0.931 
training batch:    38, loss: 16.24422, precision: 0.707 recall: 0.763 f1: 0.734 accuracy: 0.943 
training batch:    39, loss: 10.87231, precision: 0.786 recall: 0.892 f1: 0.835 accuracy: 0.975 
training batch:    40, loss: 7.84018, precision: 0.812 recall: 0.788 f1: 0.800 accuracy: 0.970 
training batch:    41, loss: 22.29266, precision: 0.812 recall: 0.722 f1: 0.765 accuracy: 0.944 
training batch:    42, loss: 21.16970, precision: 0.700 recall: 0.600 f1: 0.646 accuracy: 0.921 
training batch:    43, loss: 13.44063, precision: 0.533 recall: 0.571 f1: 0.552 accuracy: 0.953 
training batch:    44, loss: 20.86128, precision: 0.844 recall: 0.750 f1: 0.794 accuracy: 0.936 
training batch:    45, loss: 31.79193, precision: 0.667 recall: 0.667 f1: 0.667 accuracy: 0.885 
training batch:    46, loss: 12.45325, precision: 0.688 recall: 0.710 f1: 0.698 accuracy: 0.958 
training batch:    47, loss: 10.00819, precision: 0.703 recall: 0.788 f1: 0.743 accuracy: 0.965 
training batch:    48, loss: 11.64769, precision: 0.800 recall: 0.848 f1: 0.824 accuracy: 0.975 
training batch:    49, loss: 13.33562, precision: 0.765 recall: 0.765 f1: 0.765 accuracy: 0.960 
training batch:    50, loss: 7.37267, precision: 0.829 recall: 0.784 f1: 0.806 accuracy: 0.976 
training batch:    51, loss: 12.49020, precision: 0.758 recall: 0.714 f1: 0.735 accuracy: 0.965 
training batch:    52, loss: 19.15755, precision: 0.636 recall: 0.636 f1: 0.636 accuracy: 0.938 
training batch:    53, loss: 15.49396, precision: 0.821 recall: 0.639 f1: 0.719 accuracy: 0.946 
training batch:    54, loss: 8.78534, precision: 0.692 recall: 0.643 f1: 0.667 accuracy: 0.961 
training batch:    55, loss: 10.70540, precision: 0.739 recall: 0.531 f1: 0.618 accuracy: 0.965 
training batch:    56, loss: 15.22777, precision: 0.893 recall: 0.926 f1: 0.909 accuracy: 0.940 
training batch:    57, loss: 6.83216, precision: 0.857 recall: 0.889 f1: 0.873 accuracy: 0.973 
training batch:    58, loss: 11.31762, precision: 0.821 recall: 0.821 f1: 0.821 accuracy: 0.968 
training batch:    59, loss: 4.95056, precision: 0.833 recall: 0.811 f1: 0.822 accuracy: 0.988 
training batch:    60, loss: 13.20930, precision: 0.892 recall: 0.717 f1: 0.795 accuracy: 0.969 
training batch:    61, loss: 5.14425, precision: 0.688 recall: 0.759 f1: 0.721 accuracy: 0.983 
training batch:    62, loss: 6.34277, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.984 
training batch:    63, loss: 8.82807, precision: 0.839 recall: 0.897 f1: 0.867 accuracy: 0.975 
training batch:    64, loss: 7.24960, precision: 0.800 recall: 0.889 f1: 0.842 accuracy: 0.980 
training batch:    65, loss: 17.25281, precision: 0.556 recall: 0.500 f1: 0.526 accuracy: 0.943 
training batch:    66, loss: 8.06621, precision: 0.625 recall: 0.588 f1: 0.606 accuracy: 0.958 
training batch:    67, loss: 30.50929, precision: 0.703 recall: 0.605 f1: 0.650 accuracy: 0.910 
training batch:    68, loss: 10.08698, precision: 0.833 recall: 0.789 f1: 0.811 accuracy: 0.969 
training batch:    69, loss: 6.52527, precision: 0.750 recall: 0.771 f1: 0.761 accuracy: 0.980 
training batch:    70, loss: 12.75017, precision: 0.714 recall: 0.714 f1: 0.714 accuracy: 0.955 
training batch:    71, loss: 36.03212, precision: 0.593 recall: 0.471 f1: 0.525 accuracy: 0.902 
training batch:    72, loss: 19.53255, precision: 0.710 recall: 0.786 f1: 0.746 accuracy: 0.938 
training batch:    73, loss: 7.84832, precision: 0.727 recall: 0.780 f1: 0.753 accuracy: 0.969 
training batch:    74, loss: 8.31206, precision: 0.783 recall: 0.818 f1: 0.800 accuracy: 0.976 
training batch:    75, loss: 6.97994, precision: 0.633 recall: 0.704 f1: 0.667 accuracy: 0.965 
training batch:    76, loss: 15.99702, precision: 0.675 recall: 0.692 f1: 0.684 accuracy: 0.955 
training batch:    77, loss: 38.78970, precision: 0.675 recall: 0.587 f1: 0.628 accuracy: 0.866 
training batch:    78, loss: 20.04405, precision: 0.660 recall: 0.648 f1: 0.654 accuracy: 0.932 
training batch:    79, loss: 4.33151, precision: 0.864 recall: 0.792 f1: 0.826 accuracy: 0.989 
training batch:    80, loss: 10.84612, precision: 0.875 recall: 0.824 f1: 0.848 accuracy: 0.973 
training batch:    81, loss: 8.35387, precision: 0.750 recall: 0.581 f1: 0.655 accuracy: 0.970 
training batch:    82, loss: 11.94856, precision: 0.706 recall: 0.343 f1: 0.462 accuracy: 0.958 
training batch:    83, loss: 14.31546, precision: 0.750 recall: 0.636 f1: 0.689 accuracy: 0.961 
training batch:    84, loss: 19.82997, precision: 0.857 recall: 0.789 f1: 0.822 accuracy: 0.951 
training batch:    85, loss: 12.08386, precision: 0.781 recall: 0.806 f1: 0.794 accuracy: 0.971 
training batch:    86, loss: 18.51335, precision: 0.654 recall: 0.586 f1: 0.618 accuracy: 0.941 
training batch:    87, loss: 17.48189, precision: 0.724 recall: 0.600 f1: 0.656 accuracy: 0.938 
training batch:    88, loss: 13.22159, precision: 0.778 recall: 0.848 f1: 0.812 accuracy: 0.950 
training batch:    89, loss: 9.42727, precision: 0.708 recall: 0.548 f1: 0.618 accuracy: 0.974 
training batch:    90, loss: 15.87897, precision: 0.694 recall: 0.756 f1: 0.723 accuracy: 0.943 
training batch:    91, loss: 10.38927, precision: 0.788 recall: 0.765 f1: 0.776 accuracy: 0.963 
training batch:    92, loss: 9.65026, precision: 0.660 recall: 0.767 f1: 0.710 accuracy: 0.970 
training batch:    93, loss: 6.29536, precision: 0.710 recall: 0.815 f1: 0.759 accuracy: 0.980 
training batch:    94, loss: 7.75168, precision: 0.867 recall: 0.867 f1: 0.867 accuracy: 0.976 
training batch:    95, loss: 13.49876, precision: 0.793 recall: 0.719 f1: 0.754 accuracy: 0.960 
training batch:    96, loss: 11.69480, precision: 0.741 recall: 0.833 f1: 0.784 accuracy: 0.964 
training batch:    97, loss: 13.88161, precision: 0.667 recall: 0.621 f1: 0.643 accuracy: 0.948 
training batch:    98, loss: 10.90567, precision: 0.667 recall: 0.643 f1: 0.655 accuracy: 0.958 
training batch:    99, loss: 13.89222, precision: 0.848 recall: 0.800 f1: 0.824 accuracy: 0.960 
training batch:   100, loss: 10.57552, precision: 0.733 recall: 0.647 f1: 0.688 accuracy: 0.960 
training batch:   101, loss: 5.44128, precision: 0.788 recall: 0.788 f1: 0.788 accuracy: 0.979 
training batch:   102, loss: 5.55965, precision: 0.818 recall: 0.750 f1: 0.783 accuracy: 0.984 
training batch:   103, loss: 13.17389, precision: 0.812 recall: 0.765 f1: 0.788 accuracy: 0.955 
training batch:   104, loss: 15.89890, precision: 0.875 recall: 0.737 f1: 0.800 accuracy: 0.958 
training batch:   105, loss: 10.25415, precision: 0.865 recall: 0.914 f1: 0.889 accuracy: 0.950 
training batch:   106, loss: 13.48994, precision: 0.733 recall: 0.579 f1: 0.647 accuracy: 0.965 
training batch:   107, loss: 14.63239, precision: 0.839 recall: 0.839 f1: 0.839 accuracy: 0.969 
training batch:   108, loss: 11.15160, precision: 0.846 recall: 0.825 f1: 0.835 accuracy: 0.959 
training batch:   109, loss: 7.37090, precision: 0.793 recall: 0.767 f1: 0.780 accuracy: 0.970 
training batch:   110, loss: 16.18692, precision: 0.758 recall: 0.735 f1: 0.746 accuracy: 0.963 
training batch:   111, loss: 7.53645, precision: 0.824 recall: 0.824 f1: 0.824 accuracy: 0.974 
training batch:   112, loss: 15.57980, precision: 0.649 recall: 0.632 f1: 0.640 accuracy: 0.956 
training batch:   113, loss: 8.05880, precision: 0.784 recall: 0.763 f1: 0.773 accuracy: 0.975 
training batch:   114, loss: 8.78311, precision: 0.690 recall: 0.690 f1: 0.690 accuracy: 0.975 
training batch:   115, loss: 14.01272, precision: 0.800 recall: 0.741 f1: 0.769 accuracy: 0.968 
training batch:   116, loss: 16.50289, precision: 0.718 recall: 0.667 f1: 0.691 accuracy: 0.939 
training batch:   117, loss: 12.52014, precision: 0.862 recall: 0.833 f1: 0.847 accuracy: 0.976 
training batch:   118, loss: 11.86523, precision: 0.719 recall: 0.742 f1: 0.730 accuracy: 0.959 
training batch:   119, loss: 12.86090, precision: 0.758 recall: 0.735 f1: 0.746 accuracy: 0.963 
training batch:   120, loss: 10.86507, precision: 0.794 recall: 0.794 f1: 0.794 accuracy: 0.963 
training batch:   121, loss: 6.55343, precision: 0.800 recall: 0.903 f1: 0.848 accuracy: 0.979 
training batch:   122, loss: 13.73675, precision: 0.633 recall: 0.633 f1: 0.633 accuracy: 0.946 
training batch:   123, loss: 6.63991, precision: 0.864 recall: 0.905 f1: 0.884 accuracy: 0.980 
training batch:   124, loss: 17.47176, precision: 0.735 recall: 0.833 f1: 0.781 accuracy: 0.951 
training batch:   125, loss: 7.17631, precision: 0.879 recall: 0.744 f1: 0.806 accuracy: 0.970 
training batch:   126, loss: 8.54662, precision: 0.862 recall: 0.833 f1: 0.847 accuracy: 0.976 
training batch:   127, loss: 14.70663, precision: 0.750 recall: 0.727 f1: 0.738 accuracy: 0.956 
training batch:   128, loss: 21.34106, precision: 0.763 recall: 0.617 f1: 0.682 accuracy: 0.948 
training batch:   129, loss: 13.35777, precision: 0.750 recall: 0.750 f1: 0.750 accuracy: 0.959 
training batch:   130, loss: 7.44685, precision: 0.750 recall: 0.700 f1: 0.724 accuracy: 0.973 
training batch:   131, loss: 30.29244, precision: 0.860 recall: 0.925 f1: 0.892 accuracy: 0.948 
training batch:   132, loss: 17.08389, precision: 0.615 recall: 0.615 f1: 0.615 accuracy: 0.927 
start evaluate engines...
label: Dsa, precision: 0.791 recall: 0.758 f1: 0.770 
label: Chk, precision: 0.533 recall: 0.500 f1: 0.511 
label: Ins, precision: 0.214 recall: 0.155 f1: 0.170 
label: Sur, precision: 0.918 recall: 0.914 f1: 0.911 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.804 recall: 0.823 f1: 0.811 
time consumption:1.81(min), precision: 0.825 recall: 0.798 f1: 0.810 accuracy: 0.965 
saved the new best model with f1: 0.810
epoch:4/100
training batch:     1, loss: 8.56467, precision: 0.769 recall: 0.690 f1: 0.727 accuracy: 0.978 
training batch:     2, loss: 9.08177, precision: 0.714 recall: 0.750 f1: 0.732 accuracy: 0.966 
training batch:     3, loss: 8.34331, precision: 0.839 recall: 0.839 f1: 0.839 accuracy: 0.980 
training batch:     4, loss: 8.02563, precision: 0.816 recall: 0.886 f1: 0.849 accuracy: 0.976 
training batch:     5, loss: 5.88329, precision: 0.920 recall: 0.852 f1: 0.885 accuracy: 0.990 
training batch:     6, loss: 8.74277, precision: 0.853 recall: 0.853 f1: 0.853 accuracy: 0.976 
training batch:     7, loss: 8.71770, precision: 0.833 recall: 0.926 f1: 0.877 accuracy: 0.979 
training batch:     8, loss: 8.29008, precision: 0.812 recall: 0.839 f1: 0.825 accuracy: 0.981 
training batch:     9, loss: 5.24684, precision: 0.867 recall: 0.848 f1: 0.857 accuracy: 0.981 
training batch:    10, loss: 9.24863, precision: 0.824 recall: 0.800 f1: 0.812 accuracy: 0.968 
training batch:    11, loss: 9.11423, precision: 0.786 recall: 0.786 f1: 0.786 accuracy: 0.956 
training batch:    12, loss: 9.96637, precision: 0.758 recall: 0.641 f1: 0.694 accuracy: 0.958 
training batch:    13, loss: 9.45761, precision: 0.684 recall: 0.703 f1: 0.693 accuracy: 0.960 
training batch:    14, loss: 6.98158, precision: 0.844 recall: 0.818 f1: 0.831 accuracy: 0.980 
training batch:    15, loss: 5.62694, precision: 0.861 recall: 0.886 f1: 0.873 accuracy: 0.985 
training batch:    16, loss: 8.93024, precision: 0.840 recall: 0.750 f1: 0.792 accuracy: 0.973 
training batch:    17, loss: 9.98102, precision: 0.710 recall: 0.688 f1: 0.698 accuracy: 0.970 
training batch:    18, loss: 6.13692, precision: 0.852 recall: 0.793 f1: 0.821 accuracy: 0.986 
training batch:    19, loss: 6.00552, precision: 0.853 recall: 0.784 f1: 0.817 accuracy: 0.984 
training batch:    20, loss: 11.44313, precision: 0.647 recall: 0.733 f1: 0.688 accuracy: 0.966 
training batch:    21, loss: 4.40147, precision: 0.788 recall: 0.897 f1: 0.839 accuracy: 0.983 
training batch:    22, loss: 8.04634, precision: 0.719 recall: 0.697 f1: 0.708 accuracy: 0.976 
training batch:    23, loss: 7.02888, precision: 0.781 recall: 0.833 f1: 0.806 accuracy: 0.975 
training batch:    24, loss: 10.01053, precision: 0.757 recall: 0.737 f1: 0.747 accuracy: 0.963 
training batch:    25, loss: 8.30183, precision: 0.893 recall: 0.893 f1: 0.893 accuracy: 0.981 
training batch:    26, loss: 12.59055, precision: 0.833 recall: 0.833 f1: 0.833 accuracy: 0.964 
training batch:    27, loss: 16.36159, precision: 0.800 recall: 0.800 f1: 0.800 accuracy: 0.955 
training batch:    28, loss: 6.64104, precision: 0.743 recall: 0.743 f1: 0.743 accuracy: 0.979 
training batch:    29, loss: 16.77478, precision: 0.640 recall: 0.640 f1: 0.640 accuracy: 0.954 
training batch:    30, loss: 9.15144, precision: 0.800 recall: 0.762 f1: 0.780 accuracy: 0.971 
training batch:    31, loss: 8.34383, precision: 0.842 recall: 0.780 f1: 0.810 accuracy: 0.980 
training batch:    32, loss: 12.46292, precision: 0.844 recall: 0.794 f1: 0.818 accuracy: 0.961 
training batch:    33, loss: 7.48244, precision: 0.758 recall: 0.758 f1: 0.758 accuracy: 0.964 
training batch:    34, loss: 6.02397, precision: 0.640 recall: 0.667 f1: 0.653 accuracy: 0.975 
training batch:    35, loss: 11.50003, precision: 0.762 recall: 0.727 f1: 0.744 accuracy: 0.956 
training batch:    36, loss: 6.52725, precision: 0.871 recall: 0.844 f1: 0.857 accuracy: 0.976 
training batch:    37, loss: 11.21986, precision: 0.783 recall: 0.750 f1: 0.766 accuracy: 0.975 
training batch:    38, loss: 6.47368, precision: 0.784 recall: 0.879 f1: 0.829 accuracy: 0.978 
training batch:    39, loss: 16.38884, precision: 0.543 recall: 0.594 f1: 0.567 accuracy: 0.948 
training batch:    40, loss: 22.52066, precision: 0.789 recall: 0.750 f1: 0.769 accuracy: 0.914 
training batch:    41, loss: 10.08392, precision: 0.625 recall: 0.606 f1: 0.615 accuracy: 0.958 
training batch:    42, loss: 12.17039, precision: 0.750 recall: 0.811 f1: 0.779 accuracy: 0.965 
training batch:    43, loss: 16.26912, precision: 0.943 recall: 0.767 f1: 0.846 accuracy: 0.965 
training batch:    44, loss: 15.31544, precision: 0.853 recall: 0.806 f1: 0.829 accuracy: 0.958 
training batch:    45, loss: 8.38361, precision: 0.700 recall: 0.677 f1: 0.689 accuracy: 0.970 
training batch:    46, loss: 6.94568, precision: 0.861 recall: 0.886 f1: 0.873 accuracy: 0.978 
training batch:    47, loss: 11.94272, precision: 0.861 recall: 0.816 f1: 0.838 accuracy: 0.976 
training batch:    48, loss: 14.14864, precision: 0.697 recall: 0.742 f1: 0.719 accuracy: 0.946 
training batch:    49, loss: 6.61583, precision: 0.878 recall: 0.900 f1: 0.889 accuracy: 0.988 
training batch:    50, loss: 12.26929, precision: 0.658 recall: 0.641 f1: 0.649 accuracy: 0.968 
training batch:    51, loss: 11.60772, precision: 0.825 recall: 0.846 f1: 0.835 accuracy: 0.960 
training batch:    52, loss: 8.83873, precision: 0.853 recall: 0.829 f1: 0.841 accuracy: 0.965 
training batch:    53, loss: 10.06497, precision: 0.771 recall: 0.794 f1: 0.783 accuracy: 0.963 
training batch:    54, loss: 8.94681, precision: 0.846 recall: 0.917 f1: 0.880 accuracy: 0.971 
training batch:    55, loss: 5.37029, precision: 0.839 recall: 0.839 f1: 0.839 accuracy: 0.984 
training batch:    56, loss: 13.54776, precision: 0.722 recall: 0.667 f1: 0.693 accuracy: 0.960 
training batch:    57, loss: 6.80606, precision: 0.800 recall: 0.706 f1: 0.750 accuracy: 0.974 
training batch:    58, loss: 6.20024, precision: 0.829 recall: 0.853 f1: 0.841 accuracy: 0.976 
training batch:    59, loss: 6.82887, precision: 0.786 recall: 0.688 f1: 0.733 accuracy: 0.981 
training batch:    60, loss: 7.00388, precision: 0.829 recall: 0.690 f1: 0.753 accuracy: 0.975 
training batch:    61, loss: 4.26106, precision: 0.912 recall: 0.861 f1: 0.886 accuracy: 0.984 
training batch:    62, loss: 15.55614, precision: 0.786 recall: 0.688 f1: 0.733 accuracy: 0.956 
training batch:    63, loss: 3.90141, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.988 
training batch:    64, loss: 10.09273, precision: 0.674 recall: 0.763 f1: 0.716 accuracy: 0.963 
training batch:    65, loss: 14.01006, precision: 0.714 recall: 0.735 f1: 0.725 accuracy: 0.958 
training batch:    66, loss: 9.67413, precision: 0.750 recall: 0.811 f1: 0.779 accuracy: 0.961 
training batch:    67, loss: 7.92981, precision: 0.743 recall: 0.765 f1: 0.754 accuracy: 0.974 
training batch:    68, loss: 12.73221, precision: 0.824 recall: 0.757 f1: 0.789 accuracy: 0.961 
training batch:    69, loss: 6.26672, precision: 0.950 recall: 0.864 f1: 0.905 accuracy: 0.989 
training batch:    70, loss: 15.02173, precision: 0.581 recall: 0.625 f1: 0.602 accuracy: 0.946 
training batch:    71, loss: 10.46420, precision: 0.697 recall: 0.697 f1: 0.697 accuracy: 0.961 
training batch:    72, loss: 8.47696, precision: 0.767 recall: 0.852 f1: 0.807 accuracy: 0.969 
training batch:    73, loss: 5.89209, precision: 0.750 recall: 0.818 f1: 0.783 accuracy: 0.981 
training batch:    74, loss: 12.25570, precision: 0.794 recall: 0.771 f1: 0.783 accuracy: 0.958 
training batch:    75, loss: 11.70826, precision: 0.821 recall: 0.889 f1: 0.853 accuracy: 0.965 
training batch:    76, loss: 10.92007, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.970 
training batch:    77, loss: 6.68800, precision: 0.872 recall: 0.895 f1: 0.883 accuracy: 0.980 
training batch:    78, loss: 9.19472, precision: 0.854 recall: 0.875 f1: 0.864 accuracy: 0.973 
training batch:    79, loss: 7.18761, precision: 0.882 recall: 0.833 f1: 0.857 accuracy: 0.974 
training batch:    80, loss: 19.35912, precision: 0.964 recall: 0.900 f1: 0.931 accuracy: 0.968 
training batch:    81, loss: 13.24582, precision: 0.677 recall: 0.538 f1: 0.600 accuracy: 0.958 
training batch:    82, loss: 7.50586, precision: 0.805 recall: 0.750 f1: 0.776 accuracy: 0.969 
training batch:    83, loss: 5.10228, precision: 0.966 recall: 0.778 f1: 0.862 accuracy: 0.986 
training batch:    84, loss: 13.58268, precision: 0.758 recall: 0.714 f1: 0.735 accuracy: 0.970 
training batch:    85, loss: 16.12024, precision: 0.759 recall: 0.815 f1: 0.786 accuracy: 0.953 
training batch:    86, loss: 19.79493, precision: 0.632 recall: 0.649 f1: 0.640 accuracy: 0.931 
training batch:    87, loss: 10.08382, precision: 0.710 recall: 0.629 f1: 0.667 accuracy: 0.963 
training batch:    88, loss: 11.26071, precision: 0.786 recall: 0.767 f1: 0.776 accuracy: 0.965 
training batch:    89, loss: 6.86910, precision: 0.788 recall: 0.812 f1: 0.800 accuracy: 0.975 
training batch:    90, loss: 12.22246, precision: 0.615 recall: 0.667 f1: 0.640 accuracy: 0.941 
training batch:    91, loss: 12.40288, precision: 0.700 recall: 0.808 f1: 0.750 accuracy: 0.970 
training batch:    92, loss: 10.80058, precision: 0.647 recall: 0.595 f1: 0.620 accuracy: 0.969 
training batch:    93, loss: 8.97421, precision: 0.706 recall: 0.686 f1: 0.696 accuracy: 0.970 
training batch:    94, loss: 7.82581, precision: 0.778 recall: 0.778 f1: 0.778 accuracy: 0.956 
training batch:    95, loss: 6.55775, precision: 0.846 recall: 0.892 f1: 0.868 accuracy: 0.981 
training batch:    96, loss: 16.50343, precision: 0.824 recall: 0.903 f1: 0.862 accuracy: 0.939 
training batch:    97, loss: 15.93685, precision: 0.805 recall: 0.846 f1: 0.825 accuracy: 0.946 
training batch:    98, loss: 9.54800, precision: 0.862 recall: 0.714 f1: 0.781 accuracy: 0.973 
training batch:    99, loss: 9.29305, precision: 0.815 recall: 0.786 f1: 0.800 accuracy: 0.970 
training batch:   100, loss: 13.90425, precision: 0.782 recall: 0.796 f1: 0.789 accuracy: 0.955 
training batch:   101, loss: 12.96523, precision: 0.759 recall: 0.759 f1: 0.759 accuracy: 0.969 
training batch:   102, loss: 8.03735, precision: 0.789 recall: 0.882 f1: 0.833 accuracy: 0.971 
training batch:   103, loss: 13.79735, precision: 0.781 recall: 0.781 f1: 0.781 accuracy: 0.953 
training batch:   104, loss: 13.82893, precision: 0.765 recall: 0.722 f1: 0.743 accuracy: 0.949 
training batch:   105, loss: 6.40088, precision: 0.786 recall: 0.733 f1: 0.759 accuracy: 0.976 
training batch:   106, loss: 4.45222, precision: 0.964 recall: 0.844 f1: 0.900 accuracy: 0.993 
training batch:   107, loss: 4.35211, precision: 0.846 recall: 0.892 f1: 0.868 accuracy: 0.988 
training batch:   108, loss: 6.30919, precision: 0.783 recall: 0.783 f1: 0.783 accuracy: 0.983 
training batch:   109, loss: 18.16331, precision: 0.833 recall: 0.758 f1: 0.794 accuracy: 0.953 
training batch:   110, loss: 3.59505, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.994 
training batch:   111, loss: 10.40681, precision: 0.722 recall: 0.743 f1: 0.732 accuracy: 0.961 
training batch:   112, loss: 8.37057, precision: 0.781 recall: 0.806 f1: 0.794 accuracy: 0.963 
training batch:   113, loss: 4.92201, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.991 
training batch:   114, loss: 6.38061, precision: 0.844 recall: 0.900 f1: 0.871 accuracy: 0.976 
training batch:   115, loss: 5.15143, precision: 0.839 recall: 0.897 f1: 0.867 accuracy: 0.984 
training batch:   116, loss: 6.60204, precision: 0.881 recall: 0.841 f1: 0.860 accuracy: 0.983 
training batch:   117, loss: 5.20760, precision: 0.774 recall: 0.727 f1: 0.750 accuracy: 0.981 
training batch:   118, loss: 9.97270, precision: 0.781 recall: 0.758 f1: 0.769 accuracy: 0.956 
training batch:   119, loss: 12.10677, precision: 0.697 recall: 0.719 f1: 0.708 accuracy: 0.949 
training batch:   120, loss: 4.12872, precision: 0.946 recall: 0.897 f1: 0.921 accuracy: 0.984 
training batch:   121, loss: 7.70284, precision: 0.833 recall: 0.882 f1: 0.857 accuracy: 0.969 
training batch:   122, loss: 18.13902, precision: 0.700 recall: 0.778 f1: 0.737 accuracy: 0.931 
training batch:   123, loss: 17.12968, precision: 0.750 recall: 0.808 f1: 0.778 accuracy: 0.953 
training batch:   124, loss: 12.58289, precision: 0.932 recall: 0.837 f1: 0.882 accuracy: 0.975 
training batch:   125, loss: 16.19402, precision: 0.800 recall: 0.750 f1: 0.774 accuracy: 0.959 
training batch:   126, loss: 7.79170, precision: 0.875 recall: 0.800 f1: 0.836 accuracy: 0.973 
training batch:   127, loss: 7.33577, precision: 0.839 recall: 0.765 f1: 0.800 accuracy: 0.981 
training batch:   128, loss: 5.32175, precision: 0.800 recall: 0.889 f1: 0.842 accuracy: 0.973 
training batch:   129, loss: 15.14941, precision: 0.800 recall: 0.848 f1: 0.824 accuracy: 0.950 
training batch:   130, loss: 26.00275, precision: 0.818 recall: 0.844 f1: 0.831 accuracy: 0.904 
training batch:   131, loss: 10.50652, precision: 0.881 recall: 0.771 f1: 0.822 accuracy: 0.954 
training batch:   132, loss: 11.66528, precision: 0.867 recall: 0.812 f1: 0.839 accuracy: 0.958 
start evaluate engines...
label: Dsa, precision: 0.837 recall: 0.820 f1: 0.824 
label: Chk, precision: 0.589 recall: 0.633 f1: 0.600 
label: Ins, precision: 0.306 recall: 0.254 f1: 0.269 
label: Sur, precision: 0.867 recall: 0.901 f1: 0.880 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.854 recall: 0.849 f1: 0.849 
time consumption:1.83(min), precision: 0.843 recall: 0.838 f1: 0.839 accuracy: 0.968 
saved the new best model with f1: 0.839
epoch:5/100
training batch:     1, loss: 11.46770, precision: 0.786 recall: 0.733 f1: 0.759 accuracy: 0.961 
training batch:     2, loss: 4.20444, precision: 0.861 recall: 0.861 f1: 0.861 accuracy: 0.989 
training batch:     3, loss: 7.92410, precision: 0.773 recall: 0.829 f1: 0.800 accuracy: 0.964 
training batch:     4, loss: 6.91414, precision: 0.839 recall: 0.867 f1: 0.852 accuracy: 0.975 
training batch:     5, loss: 7.83043, precision: 0.793 recall: 0.821 f1: 0.807 accuracy: 0.969 
training batch:     6, loss: 8.01294, precision: 0.781 recall: 0.806 f1: 0.794 accuracy: 0.973 
training batch:     7, loss: 25.24953, precision: 0.576 recall: 0.500 f1: 0.535 accuracy: 0.899 
training batch:     8, loss: 5.87946, precision: 0.848 recall: 0.824 f1: 0.836 accuracy: 0.981 
training batch:     9, loss: 3.95622, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.991 
training batch:    10, loss: 6.94896, precision: 0.920 recall: 1.000 f1: 0.958 accuracy: 0.981 
training batch:    11, loss: 7.82432, precision: 0.731 recall: 0.731 f1: 0.731 accuracy: 0.965 
training batch:    12, loss: 7.23389, precision: 0.895 recall: 0.829 f1: 0.861 accuracy: 0.974 
training batch:    13, loss: 6.48520, precision: 0.815 recall: 0.759 f1: 0.786 accuracy: 0.971 
training batch:    14, loss: 7.72659, precision: 0.895 recall: 0.895 f1: 0.895 accuracy: 0.978 
training batch:    15, loss: 6.19763, precision: 0.833 recall: 0.857 f1: 0.845 accuracy: 0.981 
training batch:    16, loss: 10.39014, precision: 0.830 recall: 0.796 f1: 0.812 accuracy: 0.964 
training batch:    17, loss: 6.57810, precision: 0.800 recall: 0.800 f1: 0.800 accuracy: 0.985 
training batch:    18, loss: 5.72293, precision: 0.806 recall: 0.744 f1: 0.773 accuracy: 0.971 
training batch:    19, loss: 2.46860, precision: 0.840 recall: 0.955 f1: 0.894 accuracy: 0.993 
training batch:    20, loss: 5.01770, precision: 0.889 recall: 0.865 f1: 0.877 accuracy: 0.985 
training batch:    21, loss: 7.81206, precision: 0.667 recall: 0.800 f1: 0.727 accuracy: 0.955 
training batch:    22, loss: 6.94432, precision: 0.842 recall: 0.780 f1: 0.810 accuracy: 0.966 
training batch:    23, loss: 8.68929, precision: 0.857 recall: 0.878 f1: 0.867 accuracy: 0.974 
training batch:    24, loss: 15.78181, precision: 0.839 recall: 0.788 f1: 0.812 accuracy: 0.959 
training batch:    25, loss: 5.01141, precision: 0.733 recall: 0.667 f1: 0.698 accuracy: 0.984 
training batch:    26, loss: 9.88635, precision: 0.769 recall: 0.833 f1: 0.800 accuracy: 0.966 
training batch:    27, loss: 28.64867, precision: 0.900 recall: 0.794 f1: 0.844 accuracy: 0.924 
training batch:    28, loss: 5.32672, precision: 0.765 recall: 0.812 f1: 0.788 accuracy: 0.983 
training batch:    29, loss: 13.08231, precision: 0.594 recall: 0.704 f1: 0.644 accuracy: 0.945 
training batch:    30, loss: 8.73872, precision: 0.725 recall: 0.806 f1: 0.763 accuracy: 0.961 
training batch:    31, loss: 9.30721, precision: 0.765 recall: 0.867 f1: 0.812 accuracy: 0.964 
training batch:    32, loss: 10.01389, precision: 0.879 recall: 0.879 f1: 0.879 accuracy: 0.971 
training batch:    33, loss: 11.99820, precision: 0.677 recall: 0.750 f1: 0.712 accuracy: 0.960 
training batch:    34, loss: 3.01202, precision: 0.846 recall: 0.917 f1: 0.880 accuracy: 0.988 
training batch:    35, loss: 9.96249, precision: 0.750 recall: 0.677 f1: 0.712 accuracy: 0.970 
training batch:    36, loss: 6.56036, precision: 0.778 recall: 0.737 f1: 0.757 accuracy: 0.970 
training batch:    37, loss: 4.46623, precision: 0.733 recall: 0.759 f1: 0.746 accuracy: 0.981 
training batch:    38, loss: 7.26450, precision: 0.842 recall: 0.800 f1: 0.821 accuracy: 0.973 
training batch:    39, loss: 4.35741, precision: 0.897 recall: 0.854 f1: 0.875 accuracy: 0.983 
training batch:    40, loss: 4.31625, precision: 0.821 recall: 0.821 f1: 0.821 accuracy: 0.985 
training batch:    41, loss: 4.16734, precision: 0.903 recall: 0.933 f1: 0.918 accuracy: 0.989 
training batch:    42, loss: 9.09346, precision: 0.816 recall: 0.775 f1: 0.795 accuracy: 0.964 
training batch:    43, loss: 7.95976, precision: 0.767 recall: 0.793 f1: 0.780 accuracy: 0.974 
training batch:    44, loss: 5.84589, precision: 0.897 recall: 0.814 f1: 0.854 accuracy: 0.983 
training batch:    45, loss: 12.96381, precision: 0.771 recall: 0.818 f1: 0.794 accuracy: 0.960 
training batch:    46, loss: 6.19777, precision: 0.767 recall: 0.767 f1: 0.767 accuracy: 0.975 
training batch:    47, loss: 9.05450, precision: 0.860 recall: 0.804 f1: 0.831 accuracy: 0.969 
training batch:    48, loss: 7.71671, precision: 0.750 recall: 0.808 f1: 0.778 accuracy: 0.958 
training batch:    49, loss: 4.58598, precision: 0.815 recall: 0.846 f1: 0.830 accuracy: 0.978 
training batch:    50, loss: 9.77791, precision: 0.885 recall: 0.793 f1: 0.836 accuracy: 0.969 
training batch:    51, loss: 12.29909, precision: 0.677 recall: 0.700 f1: 0.689 accuracy: 0.961 
training batch:    52, loss: 3.69818, precision: 0.897 recall: 0.788 f1: 0.839 accuracy: 0.989 
training batch:    53, loss: 9.06351, precision: 0.711 recall: 0.818 f1: 0.761 accuracy: 0.968 
training batch:    54, loss: 12.98563, precision: 0.667 recall: 0.683 f1: 0.675 accuracy: 0.948 
training batch:    55, loss: 9.83734, precision: 0.800 recall: 0.870 f1: 0.833 accuracy: 0.968 
training batch:    56, loss: 5.18350, precision: 0.860 recall: 0.902 f1: 0.881 accuracy: 0.983 
training batch:    57, loss: 7.16119, precision: 0.758 recall: 0.735 f1: 0.746 accuracy: 0.979 
training batch:    58, loss: 5.00906, precision: 0.846 recall: 0.892 f1: 0.868 accuracy: 0.981 
training batch:    59, loss: 3.49797, precision: 0.793 recall: 0.852 f1: 0.821 accuracy: 0.990 
training batch:    60, loss: 16.18690, precision: 0.882 recall: 0.865 f1: 0.874 accuracy: 0.945 
training batch:    61, loss: 10.86244, precision: 0.848 recall: 0.757 f1: 0.800 accuracy: 0.969 
training batch:    62, loss: 7.73802, precision: 0.793 recall: 0.605 f1: 0.687 accuracy: 0.968 
training batch:    63, loss: 5.54170, precision: 0.833 recall: 0.833 f1: 0.833 accuracy: 0.989 
training batch:    64, loss: 5.02776, precision: 0.913 recall: 0.913 f1: 0.913 accuracy: 0.985 
training batch:    65, loss: 11.31456, precision: 0.743 recall: 0.812 f1: 0.776 accuracy: 0.964 
training batch:    66, loss: 7.81147, precision: 0.848 recall: 0.848 f1: 0.848 accuracy: 0.974 
training batch:    67, loss: 8.44731, precision: 0.829 recall: 0.806 f1: 0.817 accuracy: 0.970 
training batch:    68, loss: 10.32533, precision: 0.919 recall: 0.895 f1: 0.907 accuracy: 0.969 
training batch:    69, loss: 10.64650, precision: 0.806 recall: 0.879 f1: 0.841 accuracy: 0.963 
training batch:    70, loss: 7.17105, precision: 0.870 recall: 0.870 f1: 0.870 accuracy: 0.971 
training batch:    71, loss: 15.54713, precision: 0.742 recall: 0.767 f1: 0.754 accuracy: 0.943 
training batch:    72, loss: 15.06528, precision: 0.865 recall: 0.889 f1: 0.877 accuracy: 0.963 
training batch:    73, loss: 7.35829, precision: 0.750 recall: 0.750 f1: 0.750 accuracy: 0.971 
training batch:    74, loss: 5.27235, precision: 0.900 recall: 0.844 f1: 0.871 accuracy: 0.983 
training batch:    75, loss: 21.62758, precision: 0.938 recall: 0.882 f1: 0.909 accuracy: 0.936 
training batch:    76, loss: 13.58435, precision: 0.656 recall: 0.808 f1: 0.724 accuracy: 0.940 
training batch:    77, loss: 7.34830, precision: 0.815 recall: 0.611 f1: 0.698 accuracy: 0.966 
training batch:    78, loss: 9.37093, precision: 0.821 recall: 0.821 f1: 0.821 accuracy: 0.966 
training batch:    79, loss: 7.36995, precision: 0.774 recall: 0.774 f1: 0.774 accuracy: 0.968 
training batch:    80, loss: 10.78444, precision: 0.862 recall: 0.806 f1: 0.833 accuracy: 0.950 
training batch:    81, loss: 6.73645, precision: 0.842 recall: 0.821 f1: 0.831 accuracy: 0.971 
training batch:    82, loss: 9.70270, precision: 0.788 recall: 0.743 f1: 0.765 accuracy: 0.975 
training batch:    83, loss: 6.93190, precision: 0.926 recall: 0.893 f1: 0.909 accuracy: 0.976 
training batch:    84, loss: 7.15085, precision: 0.806 recall: 0.829 f1: 0.817 accuracy: 0.989 
training batch:    85, loss: 8.04996, precision: 0.844 recall: 0.818 f1: 0.831 accuracy: 0.970 
training batch:    86, loss: 12.77801, precision: 0.811 recall: 0.833 f1: 0.822 accuracy: 0.965 
training batch:    87, loss: 8.10194, precision: 0.833 recall: 0.921 f1: 0.875 accuracy: 0.963 
training batch:    88, loss: 5.98375, precision: 0.833 recall: 0.781 f1: 0.806 accuracy: 0.978 
training batch:    89, loss: 3.43604, precision: 0.857 recall: 0.828 f1: 0.842 accuracy: 0.990 
training batch:    90, loss: 3.14478, precision: 0.818 recall: 0.900 f1: 0.857 accuracy: 0.989 
training batch:    91, loss: 3.02309, precision: 0.966 recall: 0.875 f1: 0.918 accuracy: 0.988 
training batch:    92, loss: 4.58578, precision: 0.794 recall: 0.771 f1: 0.783 accuracy: 0.984 
training batch:    93, loss: 9.74454, precision: 0.810 recall: 0.791 f1: 0.800 accuracy: 0.970 
training batch:    94, loss: 10.94373, precision: 0.842 recall: 0.842 f1: 0.842 accuracy: 0.964 
training batch:    95, loss: 4.90904, precision: 0.778 recall: 0.824 f1: 0.800 accuracy: 0.976 
training batch:    96, loss: 11.03185, precision: 0.824 recall: 0.848 f1: 0.836 accuracy: 0.951 
training batch:    97, loss: 4.66473, precision: 0.897 recall: 0.867 f1: 0.881 accuracy: 0.979 
training batch:    98, loss: 6.34877, precision: 0.923 recall: 0.857 f1: 0.889 accuracy: 0.981 
training batch:    99, loss: 5.61211, precision: 0.839 recall: 0.765 f1: 0.800 accuracy: 0.984 
training batch:   100, loss: 12.85817, precision: 0.913 recall: 0.677 f1: 0.778 accuracy: 0.961 
training batch:   101, loss: 4.15906, precision: 1.000 recall: 0.951 f1: 0.975 accuracy: 0.995 
training batch:   102, loss: 6.30556, precision: 0.786 recall: 0.786 f1: 0.786 accuracy: 0.979 
training batch:   103, loss: 5.70708, precision: 0.962 recall: 0.926 f1: 0.943 accuracy: 0.989 
training batch:   104, loss: 14.80226, precision: 0.618 recall: 0.723 f1: 0.667 accuracy: 0.954 
training batch:   105, loss: 8.81850, precision: 0.800 recall: 0.851 f1: 0.825 accuracy: 0.974 
training batch:   106, loss: 9.86114, precision: 0.864 recall: 0.864 f1: 0.864 accuracy: 0.968 
training batch:   107, loss: 7.43175, precision: 0.756 recall: 0.886 f1: 0.816 accuracy: 0.968 
training batch:   108, loss: 15.53987, precision: 0.812 recall: 0.867 f1: 0.839 accuracy: 0.965 
training batch:   109, loss: 3.48235, precision: 0.871 recall: 0.844 f1: 0.857 accuracy: 0.981 
training batch:   110, loss: 3.36159, precision: 0.833 recall: 0.833 f1: 0.833 accuracy: 0.993 
training batch:   111, loss: 13.02377, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.978 
training batch:   112, loss: 6.06538, precision: 0.786 recall: 0.846 f1: 0.815 accuracy: 0.988 
training batch:   113, loss: 10.14896, precision: 0.806 recall: 0.806 f1: 0.806 accuracy: 0.964 
training batch:   114, loss: 7.78447, precision: 0.833 recall: 0.781 f1: 0.806 accuracy: 0.968 
training batch:   115, loss: 11.78447, precision: 0.778 recall: 0.757 f1: 0.767 accuracy: 0.955 
training batch:   116, loss: 10.56985, precision: 0.865 recall: 0.744 f1: 0.800 accuracy: 0.960 
training batch:   117, loss: 12.32776, precision: 0.744 recall: 0.784 f1: 0.763 accuracy: 0.959 
training batch:   118, loss: 5.49529, precision: 0.886 recall: 0.861 f1: 0.873 accuracy: 0.981 
training batch:   119, loss: 11.47166, precision: 0.903 recall: 0.848 f1: 0.875 accuracy: 0.970 
training batch:   120, loss: 5.32117, precision: 0.833 recall: 0.806 f1: 0.820 accuracy: 0.981 
training batch:   121, loss: 14.27623, precision: 0.806 recall: 0.853 f1: 0.829 accuracy: 0.949 
training batch:   122, loss: 7.16591, precision: 0.909 recall: 0.930 f1: 0.920 accuracy: 0.979 
training batch:   123, loss: 10.99504, precision: 0.724 recall: 0.750 f1: 0.737 accuracy: 0.961 
training batch:   124, loss: 2.63270, precision: 0.879 recall: 0.853 f1: 0.866 accuracy: 0.993 
training batch:   125, loss: 5.76173, precision: 0.828 recall: 0.800 f1: 0.814 accuracy: 0.980 
training batch:   126, loss: 14.79970, precision: 0.818 recall: 0.675 f1: 0.740 accuracy: 0.960 
training batch:   127, loss: 3.94510, precision: 0.871 recall: 0.794 f1: 0.831 accuracy: 0.988 
training batch:   128, loss: 3.97092, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.996 
training batch:   129, loss: 6.65816, precision: 0.848 recall: 0.848 f1: 0.848 accuracy: 0.985 
training batch:   130, loss: 13.36089, precision: 0.842 recall: 0.800 f1: 0.821 accuracy: 0.980 
training batch:   131, loss: 18.63368, precision: 0.718 recall: 0.700 f1: 0.709 accuracy: 0.953 
training batch:   132, loss: 8.64066, precision: 0.778 recall: 0.875 f1: 0.824 accuracy: 0.963 
start evaluate engines...
label: Dsa, precision: 0.894 recall: 0.894 f1: 0.891 
label: Chk, precision: 0.700 recall: 0.700 f1: 0.689 
label: Ins, precision: 0.253 recall: 0.120 f1: 0.156 
label: Sur, precision: 0.916 recall: 0.931 f1: 0.921 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.863 recall: 0.882 f1: 0.872 
time consumption:1.82(min), precision: 0.881 recall: 0.867 f1: 0.873 accuracy: 0.976 
saved the new best model with f1: 0.873
epoch:6/100
training batch:     1, loss: 7.20107, precision: 0.806 recall: 0.853 f1: 0.829 accuracy: 0.968 
training batch:     2, loss: 6.50999, precision: 0.861 recall: 0.838 f1: 0.849 accuracy: 0.968 
training batch:     3, loss: 10.94171, precision: 0.917 recall: 0.971 f1: 0.943 accuracy: 0.975 
training batch:     4, loss: 6.23280, precision: 0.842 recall: 0.780 f1: 0.810 accuracy: 0.983 
training batch:     5, loss: 4.52083, precision: 0.935 recall: 0.853 f1: 0.892 accuracy: 0.988 
training batch:     6, loss: 4.55835, precision: 0.871 recall: 0.818 f1: 0.844 accuracy: 0.975 
training batch:     7, loss: 10.45766, precision: 0.824 recall: 0.683 f1: 0.747 accuracy: 0.963 
training batch:     8, loss: 6.04565, precision: 0.872 recall: 0.872 f1: 0.872 accuracy: 0.976 
training batch:     9, loss: 12.70285, precision: 0.833 recall: 0.789 f1: 0.811 accuracy: 0.970 
training batch:    10, loss: 6.80865, precision: 0.889 recall: 0.909 f1: 0.899 accuracy: 0.983 
training batch:    11, loss: 5.53357, precision: 0.840 recall: 0.913 f1: 0.875 accuracy: 0.985 
training batch:    12, loss: 6.59889, precision: 0.791 recall: 0.872 f1: 0.829 accuracy: 0.970 
training batch:    13, loss: 4.32260, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.988 
training batch:    14, loss: 5.54771, precision: 0.879 recall: 0.967 f1: 0.921 accuracy: 0.984 
training batch:    15, loss: 6.04254, precision: 0.778 recall: 0.875 f1: 0.824 accuracy: 0.983 
training batch:    16, loss: 3.19371, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.990 
training batch:    17, loss: 6.19063, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.974 
training batch:    18, loss: 16.25521, precision: 0.833 recall: 0.833 f1: 0.833 accuracy: 0.921 
training batch:    19, loss: 4.07146, precision: 0.889 recall: 0.865 f1: 0.877 accuracy: 0.986 
training batch:    20, loss: 2.82246, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.995 
training batch:    21, loss: 4.81903, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.978 
training batch:    22, loss: 5.32855, precision: 0.871 recall: 0.818 f1: 0.844 accuracy: 0.984 
training batch:    23, loss: 3.56389, precision: 0.955 recall: 0.913 f1: 0.933 accuracy: 0.988 
training batch:    24, loss: 9.12836, precision: 0.967 recall: 0.829 f1: 0.892 accuracy: 0.971 
training batch:    25, loss: 3.07974, precision: 0.852 recall: 0.742 f1: 0.793 accuracy: 0.986 
training batch:    26, loss: 8.61845, precision: 0.794 recall: 0.871 f1: 0.831 accuracy: 0.975 
training batch:    27, loss: 6.51439, precision: 0.852 recall: 0.767 f1: 0.807 accuracy: 0.980 
training batch:    28, loss: 12.54631, precision: 0.686 recall: 0.706 f1: 0.696 accuracy: 0.948 
training batch:    29, loss: 9.41182, precision: 0.848 recall: 0.824 f1: 0.836 accuracy: 0.959 
training batch:    30, loss: 3.09836, precision: 0.917 recall: 0.892 f1: 0.904 accuracy: 0.986 
training batch:    31, loss: 8.80777, precision: 0.735 recall: 0.758 f1: 0.746 accuracy: 0.963 
training batch:    32, loss: 8.12877, precision: 0.781 recall: 0.735 f1: 0.758 accuracy: 0.980 
training batch:    33, loss: 8.39748, precision: 0.811 recall: 0.750 f1: 0.779 accuracy: 0.965 
training batch:    34, loss: 3.50169, precision: 0.862 recall: 0.781 f1: 0.820 accuracy: 0.991 
training batch:    35, loss: 4.70554, precision: 0.882 recall: 0.909 f1: 0.896 accuracy: 0.981 
training batch:    36, loss: 3.91273, precision: 0.862 recall: 0.926 f1: 0.893 accuracy: 0.984 
training batch:    37, loss: 5.31960, precision: 0.786 recall: 0.759 f1: 0.772 accuracy: 0.985 
training batch:    38, loss: 6.95067, precision: 0.875 recall: 0.814 f1: 0.843 accuracy: 0.975 
training batch:    39, loss: 3.77373, precision: 0.833 recall: 0.893 f1: 0.862 accuracy: 0.989 
training batch:    40, loss: 3.39832, precision: 0.812 recall: 0.788 f1: 0.800 accuracy: 0.990 
training batch:    41, loss: 15.98917, precision: 0.789 recall: 0.811 f1: 0.800 accuracy: 0.960 
training batch:    42, loss: 9.64316, precision: 0.821 recall: 0.780 f1: 0.800 accuracy: 0.969 
training batch:    43, loss: 3.44717, precision: 0.871 recall: 0.818 f1: 0.844 accuracy: 0.989 
training batch:    44, loss: 3.61244, precision: 0.824 recall: 0.757 f1: 0.789 accuracy: 0.985 
training batch:    45, loss: 4.91225, precision: 0.919 recall: 0.829 f1: 0.872 accuracy: 0.984 
training batch:    46, loss: 8.17034, precision: 0.879 recall: 0.935 f1: 0.906 accuracy: 0.968 
training batch:    47, loss: 2.06471, precision: 0.978 recall: 0.978 f1: 0.978 accuracy: 0.995 
training batch:    48, loss: 6.48293, precision: 0.763 recall: 0.784 f1: 0.773 accuracy: 0.975 
training batch:    49, loss: 8.41585, precision: 0.842 recall: 0.842 f1: 0.842 accuracy: 0.968 
training batch:    50, loss: 4.09943, precision: 0.895 recall: 0.850 f1: 0.872 accuracy: 0.985 
training batch:    51, loss: 3.21335, precision: 0.879 recall: 0.879 f1: 0.879 accuracy: 0.989 
training batch:    52, loss: 7.76886, precision: 0.794 recall: 0.844 f1: 0.818 accuracy: 0.983 
training batch:    53, loss: 9.76241, precision: 0.812 recall: 0.812 f1: 0.812 accuracy: 0.961 
training batch:    54, loss: 6.45943, precision: 0.793 recall: 0.885 f1: 0.836 accuracy: 0.978 
training batch:    55, loss: 4.05817, precision: 0.875 recall: 0.903 f1: 0.889 accuracy: 0.990 
training batch:    56, loss: 7.83856, precision: 0.769 recall: 0.857 f1: 0.811 accuracy: 0.974 
training batch:    57, loss: 7.78159, precision: 0.878 recall: 0.878 f1: 0.878 accuracy: 0.976 
training batch:    58, loss: 6.44792, precision: 0.821 recall: 0.842 f1: 0.831 accuracy: 0.971 
training batch:    59, loss: 3.06277, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.988 
training batch:    60, loss: 2.20006, precision: 0.917 recall: 0.815 f1: 0.863 accuracy: 0.991 
training batch:    61, loss: 10.02673, precision: 0.842 recall: 0.681 f1: 0.753 accuracy: 0.973 
training batch:    62, loss: 5.25078, precision: 0.879 recall: 0.967 f1: 0.921 accuracy: 0.978 
training batch:    63, loss: 7.00967, precision: 0.872 recall: 0.872 f1: 0.872 accuracy: 0.969 
training batch:    64, loss: 11.62109, precision: 0.825 recall: 0.805 f1: 0.815 accuracy: 0.960 
training batch:    65, loss: 5.20436, precision: 0.857 recall: 0.900 f1: 0.878 accuracy: 0.984 
training batch:    66, loss: 5.19273, precision: 0.794 recall: 0.794 f1: 0.794 accuracy: 0.984 
training batch:    67, loss: 3.50386, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.986 
training batch:    68, loss: 3.87343, precision: 0.895 recall: 0.895 f1: 0.895 accuracy: 0.988 
training batch:    69, loss: 6.72308, precision: 0.860 recall: 0.925 f1: 0.892 accuracy: 0.974 
training batch:    70, loss: 10.29637, precision: 0.767 recall: 0.821 f1: 0.793 accuracy: 0.971 
training batch:    71, loss: 8.39657, precision: 0.791 recall: 0.791 f1: 0.791 accuracy: 0.970 
training batch:    72, loss: 17.32471, precision: 0.774 recall: 0.828 f1: 0.800 accuracy: 0.944 
training batch:    73, loss: 4.81113, precision: 0.865 recall: 0.889 f1: 0.877 accuracy: 0.981 
training batch:    74, loss: 9.07278, precision: 0.815 recall: 0.815 f1: 0.815 accuracy: 0.975 
training batch:    75, loss: 7.11957, precision: 0.794 recall: 0.871 f1: 0.831 accuracy: 0.980 
training batch:    76, loss: 6.48551, precision: 0.811 recall: 0.857 f1: 0.833 accuracy: 0.981 
training batch:    77, loss: 2.51099, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.993 
training batch:    78, loss: 9.96985, precision: 0.852 recall: 0.793 f1: 0.821 accuracy: 0.966 
training batch:    79, loss: 2.35847, precision: 0.885 recall: 0.885 f1: 0.885 accuracy: 0.990 
training batch:    80, loss: 11.21489, precision: 0.750 recall: 0.811 f1: 0.779 accuracy: 0.954 
training batch:    81, loss: 7.97644, precision: 0.897 recall: 0.722 f1: 0.800 accuracy: 0.969 
training batch:    82, loss: 3.02943, precision: 0.964 recall: 0.871 f1: 0.915 accuracy: 0.993 
training batch:    83, loss: 7.91205, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.984 
training batch:    84, loss: 7.80457, precision: 0.885 recall: 0.657 f1: 0.754 accuracy: 0.976 
training batch:    85, loss: 4.56052, precision: 0.960 recall: 0.800 f1: 0.873 accuracy: 0.988 
training batch:    86, loss: 2.64301, precision: 0.925 recall: 0.974 f1: 0.949 accuracy: 0.994 
training batch:    87, loss: 3.54391, precision: 0.903 recall: 0.824 f1: 0.862 accuracy: 0.989 
training batch:    88, loss: 2.45934, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.995 
training batch:    89, loss: 8.10796, precision: 0.844 recall: 0.818 f1: 0.831 accuracy: 0.971 
training batch:    90, loss: 8.98903, precision: 0.864 recall: 0.826 f1: 0.844 accuracy: 0.971 
training batch:    91, loss: 9.27718, precision: 0.795 recall: 0.897 f1: 0.843 accuracy: 0.974 
training batch:    92, loss: 6.79028, precision: 0.850 recall: 0.850 f1: 0.850 accuracy: 0.984 
training batch:    93, loss: 4.28380, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.989 
training batch:    94, loss: 9.22588, precision: 0.825 recall: 0.825 f1: 0.825 accuracy: 0.966 
training batch:    95, loss: 10.44726, precision: 0.812 recall: 0.929 f1: 0.867 accuracy: 0.961 
training batch:    96, loss: 4.27400, precision: 0.763 recall: 0.906 f1: 0.829 accuracy: 0.985 
training batch:    97, loss: 6.94067, precision: 0.881 recall: 0.881 f1: 0.881 accuracy: 0.973 
training batch:    98, loss: 3.88197, precision: 0.912 recall: 0.861 f1: 0.886 accuracy: 0.981 
training batch:    99, loss: 9.90822, precision: 0.762 recall: 0.727 f1: 0.744 accuracy: 0.963 
training batch:   100, loss: 6.43777, precision: 0.806 recall: 0.806 f1: 0.806 accuracy: 0.980 
training batch:   101, loss: 6.85971, precision: 0.829 recall: 0.829 f1: 0.829 accuracy: 0.974 
training batch:   102, loss: 5.35547, precision: 0.750 recall: 0.730 f1: 0.740 accuracy: 0.974 
training batch:   103, loss: 5.63889, precision: 0.931 recall: 0.871 f1: 0.900 accuracy: 0.991 
training batch:   104, loss: 4.67715, precision: 0.930 recall: 0.952 f1: 0.941 accuracy: 0.991 
training batch:   105, loss: 6.96358, precision: 0.833 recall: 0.769 f1: 0.800 accuracy: 0.979 
training batch:   106, loss: 4.25810, precision: 0.839 recall: 0.867 f1: 0.852 accuracy: 0.990 
training batch:   107, loss: 7.22340, precision: 0.886 recall: 0.912 f1: 0.899 accuracy: 0.978 
training batch:   108, loss: 2.55019, precision: 0.886 recall: 0.939 f1: 0.912 accuracy: 0.986 
training batch:   109, loss: 4.02269, precision: 0.808 recall: 0.913 f1: 0.857 accuracy: 0.983 
training batch:   110, loss: 5.50314, precision: 0.842 recall: 0.842 f1: 0.842 accuracy: 0.975 
training batch:   111, loss: 8.67215, precision: 0.773 recall: 0.829 f1: 0.800 accuracy: 0.968 
training batch:   112, loss: 5.16675, precision: 0.761 recall: 0.778 f1: 0.769 accuracy: 0.980 
training batch:   113, loss: 12.67877, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.944 
training batch:   114, loss: 14.26936, precision: 0.805 recall: 0.750 f1: 0.776 accuracy: 0.944 
training batch:   115, loss: 7.41100, precision: 0.775 recall: 0.838 f1: 0.805 accuracy: 0.978 
training batch:   116, loss: 6.65569, precision: 0.892 recall: 0.971 f1: 0.930 accuracy: 0.988 
training batch:   117, loss: 11.47594, precision: 0.861 recall: 0.795 f1: 0.827 accuracy: 0.965 
training batch:   118, loss: 8.03889, precision: 0.793 recall: 0.793 f1: 0.793 accuracy: 0.978 
training batch:   119, loss: 12.27991, precision: 0.805 recall: 0.786 f1: 0.795 accuracy: 0.954 
training batch:   120, loss: 4.18999, precision: 0.871 recall: 0.871 f1: 0.871 accuracy: 0.986 
training batch:   121, loss: 13.42794, precision: 0.846 recall: 0.825 f1: 0.835 accuracy: 0.958 
training batch:   122, loss: 3.76692, precision: 0.880 recall: 0.880 f1: 0.880 accuracy: 0.983 
training batch:   123, loss: 11.01334, precision: 0.848 recall: 0.848 f1: 0.848 accuracy: 0.968 
training batch:   124, loss: 8.35700, precision: 0.769 recall: 0.909 f1: 0.833 accuracy: 0.973 
training batch:   125, loss: 4.94824, precision: 0.912 recall: 0.886 f1: 0.899 accuracy: 0.985 
training batch:   126, loss: 4.35028, precision: 0.824 recall: 0.737 f1: 0.778 accuracy: 0.984 
training batch:   127, loss: 3.70987, precision: 0.921 recall: 0.854 f1: 0.886 accuracy: 0.986 
training batch:   128, loss: 8.80887, precision: 0.882 recall: 0.811 f1: 0.845 accuracy: 0.969 
training batch:   129, loss: 8.65633, precision: 0.806 recall: 0.735 f1: 0.769 accuracy: 0.975 
training batch:   130, loss: 9.04585, precision: 0.806 recall: 0.926 f1: 0.862 accuracy: 0.960 
training batch:   131, loss: 2.63846, precision: 0.900 recall: 0.844 f1: 0.871 accuracy: 0.991 
training batch:   132, loss: 10.16483, precision: 0.900 recall: 0.692 f1: 0.783 accuracy: 0.970 
start evaluate engines...
label: Dsa, precision: 0.842 recall: 0.865 f1: 0.850 
label: Chk, precision: 0.700 recall: 0.733 f1: 0.711 
label: Ins, precision: 0.289 recall: 0.190 f1: 0.223 
label: Sur, precision: 0.877 recall: 0.914 f1: 0.890 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.847 recall: 0.872 f1: 0.858 
time consumption:1.85(min), precision: 0.861 recall: 0.858 f1: 0.858 accuracy: 0.974 
epoch:7/100
training batch:     1, loss: 2.96919, precision: 0.818 recall: 0.871 f1: 0.844 accuracy: 0.991 
training batch:     2, loss: 3.52898, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.989 
training batch:     3, loss: 4.11867, precision: 0.875 recall: 0.921 f1: 0.897 accuracy: 0.974 
training batch:     4, loss: 4.20807, precision: 0.800 recall: 0.848 f1: 0.824 accuracy: 0.979 
training batch:     5, loss: 7.15861, precision: 0.808 recall: 0.778 f1: 0.792 accuracy: 0.978 
training batch:     6, loss: 10.71341, precision: 0.839 recall: 0.839 f1: 0.839 accuracy: 0.965 
training batch:     7, loss: 4.68060, precision: 0.875 recall: 0.833 f1: 0.854 accuracy: 0.985 
training batch:     8, loss: 7.96275, precision: 0.767 recall: 0.767 f1: 0.767 accuracy: 0.975 
training batch:     9, loss: 3.74969, precision: 0.898 recall: 0.957 f1: 0.926 accuracy: 0.993 
training batch:    10, loss: 4.31540, precision: 0.953 recall: 0.932 f1: 0.943 accuracy: 0.983 
training batch:    11, loss: 2.57736, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.988 
training batch:    12, loss: 12.80386, precision: 0.903 recall: 0.848 f1: 0.875 accuracy: 0.959 
training batch:    13, loss: 5.38979, precision: 0.812 recall: 0.788 f1: 0.800 accuracy: 0.986 
training batch:    14, loss: 3.35390, precision: 0.829 recall: 0.784 f1: 0.806 accuracy: 0.990 
training batch:    15, loss: 4.74318, precision: 0.844 recall: 0.871 f1: 0.857 accuracy: 0.985 
training batch:    16, loss: 4.45897, precision: 0.806 recall: 0.935 f1: 0.866 accuracy: 0.984 
training batch:    17, loss: 4.83739, precision: 0.867 recall: 0.839 f1: 0.852 accuracy: 0.988 
training batch:    18, loss: 2.59084, precision: 0.920 recall: 0.852 f1: 0.885 accuracy: 0.991 
training batch:    19, loss: 2.00156, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    20, loss: 2.74722, precision: 0.962 recall: 1.000 f1: 0.980 accuracy: 0.994 
training batch:    21, loss: 2.14816, precision: 1.000 recall: 0.926 f1: 0.962 accuracy: 0.996 
training batch:    22, loss: 5.72646, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.983 
training batch:    23, loss: 2.07373, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.990 
training batch:    24, loss: 4.43365, precision: 0.861 recall: 0.816 f1: 0.838 accuracy: 0.981 
training batch:    25, loss: 4.27649, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.984 
training batch:    26, loss: 3.47134, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.988 
training batch:    27, loss: 3.03960, precision: 0.864 recall: 0.884 f1: 0.874 accuracy: 0.991 
training batch:    28, loss: 10.16000, precision: 0.838 recall: 0.838 f1: 0.838 accuracy: 0.961 
training batch:    29, loss: 4.81717, precision: 0.793 recall: 0.821 f1: 0.807 accuracy: 0.983 
training batch:    30, loss: 2.31627, precision: 0.905 recall: 0.864 f1: 0.884 accuracy: 0.996 
training batch:    31, loss: 7.03055, precision: 0.789 recall: 0.769 f1: 0.779 accuracy: 0.975 
training batch:    32, loss: 3.61372, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.990 
training batch:    33, loss: 6.47058, precision: 0.905 recall: 0.884 f1: 0.894 accuracy: 0.975 
training batch:    34, loss: 3.94020, precision: 0.867 recall: 0.867 f1: 0.867 accuracy: 0.985 
training batch:    35, loss: 9.08482, precision: 0.829 recall: 0.853 f1: 0.841 accuracy: 0.968 
training batch:    36, loss: 11.31950, precision: 0.750 recall: 0.805 f1: 0.776 accuracy: 0.950 
training batch:    37, loss: 2.31836, precision: 0.907 recall: 0.929 f1: 0.918 accuracy: 0.994 
training batch:    38, loss: 3.59680, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.993 
training batch:    39, loss: 3.17708, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.989 
training batch:    40, loss: 7.27319, precision: 0.882 recall: 0.909 f1: 0.896 accuracy: 0.968 
training batch:    41, loss: 3.24249, precision: 0.824 recall: 0.875 f1: 0.848 accuracy: 0.986 
training batch:    42, loss: 10.00801, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.985 
training batch:    43, loss: 3.50053, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.990 
training batch:    44, loss: 4.16997, precision: 0.862 recall: 0.893 f1: 0.877 accuracy: 0.988 
training batch:    45, loss: 3.39027, precision: 0.914 recall: 0.941 f1: 0.928 accuracy: 0.989 
training batch:    46, loss: 6.00854, precision: 0.898 recall: 0.880 f1: 0.889 accuracy: 0.984 
training batch:    47, loss: 8.80281, precision: 0.812 recall: 0.765 f1: 0.788 accuracy: 0.976 
training batch:    48, loss: 5.03848, precision: 0.867 recall: 0.743 f1: 0.800 accuracy: 0.981 
training batch:    49, loss: 4.51871, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.980 
training batch:    50, loss: 2.31544, precision: 0.892 recall: 0.943 f1: 0.917 accuracy: 0.993 
training batch:    51, loss: 7.04361, precision: 0.875 recall: 0.921 f1: 0.897 accuracy: 0.979 
training batch:    52, loss: 7.37250, precision: 0.766 recall: 0.766 f1: 0.766 accuracy: 0.970 
training batch:    53, loss: 9.93913, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.978 
training batch:    54, loss: 2.98177, precision: 0.871 recall: 0.931 f1: 0.900 accuracy: 0.994 
training batch:    55, loss: 3.26291, precision: 0.862 recall: 0.926 f1: 0.893 accuracy: 0.986 
training batch:    56, loss: 7.06929, precision: 0.837 recall: 0.878 f1: 0.857 accuracy: 0.970 
training batch:    57, loss: 5.71397, precision: 0.914 recall: 0.941 f1: 0.928 accuracy: 0.979 
training batch:    58, loss: 2.42349, precision: 0.864 recall: 0.950 f1: 0.905 accuracy: 0.990 
training batch:    59, loss: 12.13887, precision: 0.865 recall: 0.865 f1: 0.865 accuracy: 0.954 
training batch:    60, loss: 1.55000, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.995 
training batch:    61, loss: 9.95398, precision: 0.829 recall: 0.853 f1: 0.841 accuracy: 0.975 
training batch:    62, loss: 6.18898, precision: 0.806 recall: 0.833 f1: 0.820 accuracy: 0.980 
training batch:    63, loss: 13.21086, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.932 
training batch:    64, loss: 3.75645, precision: 0.903 recall: 0.875 f1: 0.889 accuracy: 0.989 
training batch:    65, loss: 9.49036, precision: 0.867 recall: 0.812 f1: 0.839 accuracy: 0.970 
training batch:    66, loss: 12.91747, precision: 0.867 recall: 0.867 f1: 0.867 accuracy: 0.953 
training batch:    67, loss: 3.66347, precision: 0.941 recall: 0.889 f1: 0.914 accuracy: 0.989 
training batch:    68, loss: 4.34001, precision: 0.903 recall: 0.800 f1: 0.848 accuracy: 0.991 
training batch:    69, loss: 2.34734, precision: 0.919 recall: 0.850 f1: 0.883 accuracy: 0.993 
training batch:    70, loss: 2.01717, precision: 0.938 recall: 1.000 f1: 0.968 accuracy: 0.995 
training batch:    71, loss: 5.52635, precision: 0.912 recall: 0.969 f1: 0.939 accuracy: 0.979 
training batch:    72, loss: 5.37460, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.988 
training batch:    73, loss: 3.48294, precision: 0.892 recall: 0.943 f1: 0.917 accuracy: 0.981 
training batch:    74, loss: 6.93187, precision: 0.846 recall: 0.702 f1: 0.767 accuracy: 0.983 
training batch:    75, loss: 4.39546, precision: 0.857 recall: 0.923 f1: 0.889 accuracy: 0.990 
training batch:    76, loss: 1.66870, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.996 
training batch:    77, loss: 5.95021, precision: 0.844 recall: 0.871 f1: 0.857 accuracy: 0.976 
training batch:    78, loss: 2.20976, precision: 0.862 recall: 0.926 f1: 0.893 accuracy: 0.993 
training batch:    79, loss: 15.44507, precision: 0.696 recall: 0.727 f1: 0.711 accuracy: 0.949 
training batch:    80, loss: 5.50905, precision: 0.848 recall: 0.778 f1: 0.812 accuracy: 0.989 
training batch:    81, loss: 2.80360, precision: 0.850 recall: 0.895 f1: 0.872 accuracy: 0.986 
training batch:    82, loss: 15.14784, precision: 0.964 recall: 0.844 f1: 0.900 accuracy: 0.965 
training batch:    83, loss: 4.49107, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.986 
training batch:    84, loss: 4.66330, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.990 
training batch:    85, loss: 4.95662, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.980 
training batch:    86, loss: 10.31663, precision: 0.800 recall: 0.824 f1: 0.812 accuracy: 0.970 
training batch:    87, loss: 6.80399, precision: 0.769 recall: 0.800 f1: 0.784 accuracy: 0.973 
training batch:    88, loss: 5.29776, precision: 0.800 recall: 0.780 f1: 0.790 accuracy: 0.980 
training batch:    89, loss: 8.47289, precision: 0.889 recall: 0.865 f1: 0.877 accuracy: 0.981 
training batch:    90, loss: 3.78285, precision: 0.846 recall: 0.815 f1: 0.830 accuracy: 0.980 
training batch:    91, loss: 5.56953, precision: 0.880 recall: 0.815 f1: 0.846 accuracy: 0.984 
training batch:    92, loss: 10.24522, precision: 0.897 recall: 0.814 f1: 0.854 accuracy: 0.976 
training batch:    93, loss: 8.90335, precision: 0.771 recall: 0.794 f1: 0.783 accuracy: 0.973 
training batch:    94, loss: 8.70795, precision: 0.765 recall: 0.897 f1: 0.825 accuracy: 0.961 
training batch:    95, loss: 4.47310, precision: 0.805 recall: 0.786 f1: 0.795 accuracy: 0.980 
training batch:    96, loss: 4.31395, precision: 0.892 recall: 0.971 f1: 0.930 accuracy: 0.988 
training batch:    97, loss: 4.47401, precision: 0.774 recall: 0.857 f1: 0.814 accuracy: 0.988 
training batch:    98, loss: 6.82779, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.973 
training batch:    99, loss: 3.99628, precision: 0.909 recall: 0.870 f1: 0.889 accuracy: 0.986 
training batch:   100, loss: 5.78712, precision: 0.854 recall: 0.854 f1: 0.854 accuracy: 0.979 
training batch:   101, loss: 2.80020, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.989 
training batch:   102, loss: 3.54184, precision: 0.935 recall: 0.879 f1: 0.906 accuracy: 0.989 
training batch:   103, loss: 3.30167, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.993 
training batch:   104, loss: 4.53898, precision: 0.870 recall: 0.952 f1: 0.909 accuracy: 0.980 
training batch:   105, loss: 3.68665, precision: 0.875 recall: 0.897 f1: 0.886 accuracy: 0.985 
training batch:   106, loss: 9.64867, precision: 0.839 recall: 0.867 f1: 0.852 accuracy: 0.964 
training batch:   107, loss: 3.14629, precision: 0.812 recall: 0.788 f1: 0.800 accuracy: 0.985 
training batch:   108, loss: 3.11456, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.993 
training batch:   109, loss: 3.70335, precision: 0.848 recall: 0.875 f1: 0.862 accuracy: 0.988 
training batch:   110, loss: 3.76389, precision: 0.950 recall: 0.905 f1: 0.927 accuracy: 0.989 
training batch:   111, loss: 5.52434, precision: 0.875 recall: 0.840 f1: 0.857 accuracy: 0.991 
training batch:   112, loss: 4.00298, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.986 
training batch:   113, loss: 3.24040, precision: 0.939 recall: 0.886 f1: 0.912 accuracy: 0.985 
training batch:   114, loss: 2.91760, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.991 
training batch:   115, loss: 4.40858, precision: 0.893 recall: 0.862 f1: 0.877 accuracy: 0.991 
training batch:   116, loss: 16.07797, precision: 0.912 recall: 0.838 f1: 0.873 accuracy: 0.955 
training batch:   117, loss: 5.15080, precision: 0.955 recall: 0.840 f1: 0.894 accuracy: 0.985 
training batch:   118, loss: 5.05176, precision: 0.778 recall: 0.778 f1: 0.778 accuracy: 0.981 
training batch:   119, loss: 2.92992, precision: 0.742 recall: 0.793 f1: 0.767 accuracy: 0.985 
training batch:   120, loss: 9.49802, precision: 0.886 recall: 0.886 f1: 0.886 accuracy: 0.966 
training batch:   121, loss: 5.73135, precision: 0.758 recall: 0.862 f1: 0.806 accuracy: 0.983 
training batch:   122, loss: 4.22240, precision: 0.829 recall: 0.879 f1: 0.853 accuracy: 0.990 
training batch:   123, loss: 3.83810, precision: 0.758 recall: 0.735 f1: 0.746 accuracy: 0.983 
training batch:   124, loss: 2.88770, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.989 
training batch:   125, loss: 5.76300, precision: 0.892 recall: 0.943 f1: 0.917 accuracy: 0.979 
training batch:   126, loss: 4.03688, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.990 
training batch:   127, loss: 10.49213, precision: 0.568 recall: 0.724 f1: 0.636 accuracy: 0.966 
training batch:   128, loss: 4.66212, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.989 
training batch:   129, loss: 3.72136, precision: 0.889 recall: 0.865 f1: 0.877 accuracy: 0.990 
training batch:   130, loss: 3.47722, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.978 
training batch:   131, loss: 6.20261, precision: 0.854 recall: 0.875 f1: 0.864 accuracy: 0.981 
training batch:   132, loss: 1.92102, precision: 0.846 recall: 0.786 f1: 0.815 accuracy: 0.993 
start evaluate engines...
label: Dsa, precision: 0.887 recall: 0.882 f1: 0.878 
label: Chk, precision: 0.600 recall: 0.567 f1: 0.578 
label: Ins, precision: 0.293 recall: 0.245 f1: 0.260 
label: Sur, precision: 0.907 recall: 0.931 f1: 0.915 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.876 recall: 0.893 f1: 0.884 
time consumption:2.25(min), precision: 0.887 recall: 0.885 f1: 0.885 accuracy: 0.978 
saved the new best model with f1: 0.885
epoch:8/100
training batch:     1, loss: 5.92503, precision: 0.912 recall: 0.969 f1: 0.939 accuracy: 0.981 
training batch:     2, loss: 1.99764, precision: 0.909 recall: 0.882 f1: 0.896 accuracy: 0.994 
training batch:     3, loss: 14.97777, precision: 0.750 recall: 0.818 f1: 0.783 accuracy: 0.940 
training batch:     4, loss: 7.27724, precision: 0.829 recall: 0.806 f1: 0.817 accuracy: 0.975 
training batch:     5, loss: 3.80283, precision: 0.929 recall: 0.907 f1: 0.918 accuracy: 0.980 
training batch:     6, loss: 6.99191, precision: 0.867 recall: 0.867 f1: 0.867 accuracy: 0.988 
training batch:     7, loss: 3.55261, precision: 0.939 recall: 0.861 f1: 0.899 accuracy: 0.993 
training batch:     8, loss: 8.37756, precision: 0.867 recall: 0.839 f1: 0.852 accuracy: 0.971 
training batch:     9, loss: 5.80357, precision: 0.852 recall: 0.852 f1: 0.852 accuracy: 0.975 
training batch:    10, loss: 4.68045, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.988 
training batch:    11, loss: 5.22005, precision: 0.848 recall: 0.867 f1: 0.857 accuracy: 0.983 
training batch:    12, loss: 2.05760, precision: 0.969 recall: 0.912 f1: 0.939 accuracy: 0.989 
training batch:    13, loss: 7.32652, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.978 
training batch:    14, loss: 2.35460, precision: 0.963 recall: 0.839 f1: 0.897 accuracy: 0.990 
training batch:    15, loss: 4.32191, precision: 0.931 recall: 0.871 f1: 0.900 accuracy: 0.985 
training batch:    16, loss: 4.17090, precision: 0.900 recall: 0.750 f1: 0.818 accuracy: 0.981 
training batch:    17, loss: 5.04781, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.979 
training batch:    18, loss: 4.61137, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.983 
training batch:    19, loss: 6.32542, precision: 0.857 recall: 0.750 f1: 0.800 accuracy: 0.980 
training batch:    20, loss: 3.69402, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.988 
training batch:    21, loss: 5.32574, precision: 0.889 recall: 0.857 f1: 0.873 accuracy: 0.981 
training batch:    22, loss: 9.28619, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.980 
training batch:    23, loss: 5.58490, precision: 0.711 recall: 0.871 f1: 0.783 accuracy: 0.970 
training batch:    24, loss: 4.20923, precision: 0.875 recall: 0.966 f1: 0.918 accuracy: 0.985 
training batch:    25, loss: 4.83105, precision: 0.795 recall: 0.838 f1: 0.816 accuracy: 0.981 
training batch:    26, loss: 3.70576, precision: 0.784 recall: 0.829 f1: 0.806 accuracy: 0.988 
training batch:    27, loss: 7.55640, precision: 0.875 recall: 0.757 f1: 0.812 accuracy: 0.981 
training batch:    28, loss: 3.62640, precision: 0.886 recall: 0.939 f1: 0.912 accuracy: 0.988 
training batch:    29, loss: 0.84070, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.998 
training batch:    30, loss: 1.37698, precision: 0.867 recall: 0.867 f1: 0.867 accuracy: 0.993 
training batch:    31, loss: 2.66176, precision: 0.839 recall: 0.867 f1: 0.852 accuracy: 0.988 
training batch:    32, loss: 4.58791, precision: 0.903 recall: 0.778 f1: 0.836 accuracy: 0.988 
training batch:    33, loss: 5.22580, precision: 0.914 recall: 0.889 f1: 0.901 accuracy: 0.984 
training batch:    34, loss: 2.62399, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.996 
training batch:    35, loss: 11.86528, precision: 0.889 recall: 0.923 f1: 0.906 accuracy: 0.973 
training batch:    36, loss: 2.41010, precision: 0.930 recall: 0.930 f1: 0.930 accuracy: 0.995 
training batch:    37, loss: 4.28609, precision: 0.811 recall: 0.750 f1: 0.779 accuracy: 0.988 
training batch:    38, loss: 1.45811, precision: 0.900 recall: 0.964 f1: 0.931 accuracy: 0.994 
training batch:    39, loss: 3.63872, precision: 0.854 recall: 0.897 f1: 0.875 accuracy: 0.988 
training batch:    40, loss: 3.42070, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.985 
training batch:    41, loss: 11.50757, precision: 0.724 recall: 0.840 f1: 0.778 accuracy: 0.966 
training batch:    42, loss: 2.89214, precision: 0.862 recall: 0.926 f1: 0.893 accuracy: 0.994 
training batch:    43, loss: 3.80383, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.989 
training batch:    44, loss: 5.07362, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.975 
training batch:    45, loss: 6.37021, precision: 0.833 recall: 0.781 f1: 0.806 accuracy: 0.978 
training batch:    46, loss: 4.27791, precision: 0.808 recall: 0.808 f1: 0.808 accuracy: 0.979 
training batch:    47, loss: 3.39482, precision: 0.821 recall: 0.842 f1: 0.831 accuracy: 0.988 
training batch:    48, loss: 7.41614, precision: 0.830 recall: 0.765 f1: 0.796 accuracy: 0.975 
training batch:    49, loss: 7.69809, precision: 0.867 recall: 0.963 f1: 0.912 accuracy: 0.984 
training batch:    50, loss: 1.81628, precision: 0.964 recall: 0.900 f1: 0.931 accuracy: 0.996 
training batch:    51, loss: 2.95543, precision: 0.953 recall: 0.976 f1: 0.965 accuracy: 0.985 
training batch:    52, loss: 3.78241, precision: 0.903 recall: 0.848 f1: 0.875 accuracy: 0.990 
training batch:    53, loss: 2.94861, precision: 0.909 recall: 0.882 f1: 0.896 accuracy: 0.994 
training batch:    54, loss: 2.95128, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.990 
training batch:    55, loss: 4.42184, precision: 0.867 recall: 0.897 f1: 0.881 accuracy: 0.988 
training batch:    56, loss: 2.83119, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.991 
training batch:    57, loss: 3.53004, precision: 0.925 recall: 0.902 f1: 0.914 accuracy: 0.990 
training batch:    58, loss: 1.76248, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.993 
training batch:    59, loss: 6.36267, precision: 0.818 recall: 0.794 f1: 0.806 accuracy: 0.980 
training batch:    60, loss: 2.04848, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.993 
training batch:    61, loss: 10.12126, precision: 0.806 recall: 0.879 f1: 0.841 accuracy: 0.974 
training batch:    62, loss: 3.47137, precision: 0.816 recall: 0.795 f1: 0.805 accuracy: 0.979 
training batch:    63, loss: 1.21494, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.998 
training batch:    64, loss: 5.31065, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.988 
training batch:    65, loss: 2.80496, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.994 
training batch:    66, loss: 3.58418, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.983 
training batch:    67, loss: 3.33727, precision: 0.853 recall: 0.829 f1: 0.841 accuracy: 0.989 
training batch:    68, loss: 5.12262, precision: 0.886 recall: 0.939 f1: 0.912 accuracy: 0.988 
training batch:    69, loss: 0.86371, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.998 
training batch:    70, loss: 5.70876, precision: 0.795 recall: 0.795 f1: 0.795 accuracy: 0.975 
training batch:    71, loss: 3.18703, precision: 0.905 recall: 0.826 f1: 0.864 accuracy: 0.988 
training batch:    72, loss: 1.36420, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.996 
training batch:    73, loss: 5.02773, precision: 0.786 recall: 0.786 f1: 0.786 accuracy: 0.983 
training batch:    74, loss: 2.17607, precision: 0.902 recall: 0.902 f1: 0.902 accuracy: 0.988 
training batch:    75, loss: 5.69017, precision: 0.871 recall: 0.844 f1: 0.857 accuracy: 0.981 
training batch:    76, loss: 3.19402, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.991 
training batch:    77, loss: 2.24570, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.996 
training batch:    78, loss: 3.63675, precision: 0.892 recall: 0.892 f1: 0.892 accuracy: 0.981 
training batch:    79, loss: 1.85483, precision: 0.953 recall: 0.932 f1: 0.943 accuracy: 0.995 
training batch:    80, loss: 5.81079, precision: 0.860 recall: 0.841 f1: 0.851 accuracy: 0.980 
training batch:    81, loss: 5.38612, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.986 
training batch:    82, loss: 5.36758, precision: 0.775 recall: 0.816 f1: 0.795 accuracy: 0.984 
training batch:    83, loss: 3.50107, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.986 
training batch:    84, loss: 6.94041, precision: 0.861 recall: 0.886 f1: 0.873 accuracy: 0.975 
training batch:    85, loss: 2.43155, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.991 
training batch:    86, loss: 2.12978, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.995 
training batch:    87, loss: 6.51746, precision: 0.821 recall: 0.889 f1: 0.853 accuracy: 0.978 
training batch:    88, loss: 2.82123, precision: 0.861 recall: 0.969 f1: 0.912 accuracy: 0.993 
training batch:    89, loss: 3.60039, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.989 
training batch:    90, loss: 6.04797, precision: 0.806 recall: 0.806 f1: 0.806 accuracy: 0.980 
training batch:    91, loss: 4.45509, precision: 0.935 recall: 0.879 f1: 0.906 accuracy: 0.991 
training batch:    92, loss: 3.28780, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.989 
training batch:    93, loss: 1.58243, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.996 
training batch:    94, loss: 2.36264, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.994 
training batch:    95, loss: 2.93823, precision: 0.867 recall: 0.897 f1: 0.881 accuracy: 0.985 
training batch:    96, loss: 5.97601, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.984 
training batch:    97, loss: 1.47803, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.995 
training batch:    98, loss: 5.23946, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.989 
training batch:    99, loss: 3.87421, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.984 
training batch:   100, loss: 5.88470, precision: 0.903 recall: 0.933 f1: 0.918 accuracy: 0.976 
training batch:   101, loss: 3.00111, precision: 0.848 recall: 0.875 f1: 0.862 accuracy: 0.985 
training batch:   102, loss: 6.20941, precision: 0.897 recall: 0.921 f1: 0.909 accuracy: 0.976 
training batch:   103, loss: 4.87996, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.981 
training batch:   104, loss: 2.24353, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.989 
training batch:   105, loss: 4.67328, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.990 
training batch:   106, loss: 3.97356, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.994 
training batch:   107, loss: 6.78922, precision: 0.844 recall: 0.818 f1: 0.831 accuracy: 0.984 
training batch:   108, loss: 5.35072, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.976 
training batch:   109, loss: 6.45467, precision: 0.900 recall: 0.794 f1: 0.844 accuracy: 0.988 
training batch:   110, loss: 5.79262, precision: 0.884 recall: 0.927 f1: 0.905 accuracy: 0.984 
training batch:   111, loss: 3.59923, precision: 0.872 recall: 0.971 f1: 0.919 accuracy: 0.991 
training batch:   112, loss: 1.46092, precision: 0.913 recall: 0.875 f1: 0.894 accuracy: 0.991 
training batch:   113, loss: 4.26553, precision: 0.853 recall: 1.000 f1: 0.921 accuracy: 0.985 
training batch:   114, loss: 4.30495, precision: 0.878 recall: 0.947 f1: 0.911 accuracy: 0.985 
training batch:   115, loss: 5.15883, precision: 0.867 recall: 0.839 f1: 0.852 accuracy: 0.983 
training batch:   116, loss: 7.42114, precision: 0.829 recall: 0.784 f1: 0.806 accuracy: 0.970 
training batch:   117, loss: 3.88820, precision: 0.865 recall: 0.889 f1: 0.877 accuracy: 0.986 
training batch:   118, loss: 3.90164, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.989 
training batch:   119, loss: 5.14841, precision: 0.850 recall: 0.829 f1: 0.840 accuracy: 0.981 
training batch:   120, loss: 3.46802, precision: 0.970 recall: 0.889 f1: 0.928 accuracy: 0.995 
training batch:   121, loss: 3.67671, precision: 0.814 recall: 0.921 f1: 0.864 accuracy: 0.989 
training batch:   122, loss: 2.74790, precision: 0.906 recall: 0.853 f1: 0.879 accuracy: 0.991 
training batch:   123, loss: 5.76907, precision: 0.865 recall: 0.821 f1: 0.842 accuracy: 0.980 
training batch:   124, loss: 13.34906, precision: 0.833 recall: 0.833 f1: 0.833 accuracy: 0.959 
training batch:   125, loss: 4.26910, precision: 0.879 recall: 0.967 f1: 0.921 accuracy: 0.990 
training batch:   126, loss: 4.17294, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.989 
training batch:   127, loss: 5.22693, precision: 0.848 recall: 0.848 f1: 0.848 accuracy: 0.980 
training batch:   128, loss: 9.34628, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.984 
training batch:   129, loss: 2.46710, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.991 
training batch:   130, loss: 5.57237, precision: 0.763 recall: 0.853 f1: 0.806 accuracy: 0.971 
training batch:   131, loss: 1.33827, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   132, loss: 3.97266, precision: 0.955 recall: 1.000 f1: 0.977 accuracy: 0.990 
start evaluate engines...
label: Dsa, precision: 0.942 recall: 0.901 f1: 0.917 
label: Chk, precision: 0.667 recall: 0.733 f1: 0.687 
label: Ins, precision: 0.353 recall: 0.267 f1: 0.294 
label: Sur, precision: 0.884 recall: 0.931 f1: 0.901 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.905 recall: 0.887 f1: 0.895 
time consumption:2.31(min), precision: 0.902 recall: 0.883 f1: 0.892 accuracy: 0.980 
saved the new best model with f1: 0.892
epoch:9/100
training batch:     1, loss: 1.73198, precision: 0.950 recall: 1.000 f1: 0.974 accuracy: 0.996 
training batch:     2, loss: 3.48050, precision: 0.878 recall: 0.878 f1: 0.878 accuracy: 0.983 
training batch:     3, loss: 3.00502, precision: 0.925 recall: 0.860 f1: 0.892 accuracy: 0.988 
training batch:     4, loss: 1.61830, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.995 
training batch:     5, loss: 6.11697, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.981 
training batch:     6, loss: 1.88290, precision: 0.971 recall: 0.919 f1: 0.944 accuracy: 0.994 
training batch:     7, loss: 3.96162, precision: 0.950 recall: 0.905 f1: 0.927 accuracy: 0.979 
training batch:     8, loss: 2.83995, precision: 0.917 recall: 0.892 f1: 0.904 accuracy: 0.985 
training batch:     9, loss: 3.38896, precision: 0.895 recall: 0.872 f1: 0.883 accuracy: 0.990 
training batch:    10, loss: 2.76511, precision: 0.968 recall: 0.909 f1: 0.937 accuracy: 0.990 
training batch:    11, loss: 6.19383, precision: 0.821 recall: 0.821 f1: 0.821 accuracy: 0.974 
training batch:    12, loss: 4.06380, precision: 0.833 recall: 0.789 f1: 0.811 accuracy: 0.984 
training batch:    13, loss: 2.98425, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.991 
training batch:    14, loss: 1.16399, precision: 0.920 recall: 1.000 f1: 0.958 accuracy: 0.998 
training batch:    15, loss: 4.59244, precision: 0.848 recall: 0.800 f1: 0.824 accuracy: 0.980 
training batch:    16, loss: 2.63011, precision: 0.865 recall: 0.941 f1: 0.901 accuracy: 0.989 
training batch:    17, loss: 3.05981, precision: 0.868 recall: 0.917 f1: 0.892 accuracy: 0.988 
training batch:    18, loss: 2.17361, precision: 0.857 recall: 0.909 f1: 0.882 accuracy: 0.995 
training batch:    19, loss: 2.62296, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.993 
training batch:    20, loss: 2.35182, precision: 0.872 recall: 0.895 f1: 0.883 accuracy: 0.993 
training batch:    21, loss: 2.34856, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.994 
training batch:    22, loss: 4.61298, precision: 0.857 recall: 0.909 f1: 0.882 accuracy: 0.986 
training batch:    23, loss: 2.80267, precision: 0.882 recall: 0.857 f1: 0.870 accuracy: 0.985 
training batch:    24, loss: 1.86026, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.991 
training batch:    25, loss: 6.77275, precision: 0.870 recall: 0.909 f1: 0.889 accuracy: 0.986 
training batch:    26, loss: 1.41263, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.995 
training batch:    27, loss: 3.78088, precision: 0.953 recall: 0.932 f1: 0.943 accuracy: 0.985 
training batch:    28, loss: 2.35193, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.994 
training batch:    29, loss: 1.65263, precision: 0.892 recall: 0.892 f1: 0.892 accuracy: 0.995 
training batch:    30, loss: 2.42113, precision: 0.862 recall: 0.862 f1: 0.862 accuracy: 0.989 
training batch:    31, loss: 2.79726, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.993 
training batch:    32, loss: 4.96423, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.979 
training batch:    33, loss: 2.18265, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:    34, loss: 7.67563, precision: 0.857 recall: 0.968 f1: 0.909 accuracy: 0.976 
training batch:    35, loss: 4.14052, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.989 
training batch:    36, loss: 0.60481, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.999 
training batch:    37, loss: 2.08611, precision: 0.946 recall: 0.921 f1: 0.933 accuracy: 0.991 
training batch:    38, loss: 11.28539, precision: 0.857 recall: 0.789 f1: 0.822 accuracy: 0.974 
training batch:    39, loss: 2.95570, precision: 0.879 recall: 0.806 f1: 0.841 accuracy: 0.990 
training batch:    40, loss: 0.46127, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:    41, loss: 1.18910, precision: 0.864 recall: 0.826 f1: 0.844 accuracy: 0.995 
training batch:    42, loss: 0.95094, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:    43, loss: 6.04443, precision: 0.969 recall: 0.912 f1: 0.939 accuracy: 0.991 
training batch:    44, loss: 3.22716, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.989 
training batch:    45, loss: 7.94926, precision: 0.837 recall: 0.766 f1: 0.800 accuracy: 0.974 
training batch:    46, loss: 2.17236, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.995 
training batch:    47, loss: 3.26844, precision: 0.913 recall: 0.955 f1: 0.933 accuracy: 0.988 
training batch:    48, loss: 1.53804, precision: 0.925 recall: 0.925 f1: 0.925 accuracy: 0.995 
training batch:    49, loss: 3.51447, precision: 0.902 recall: 0.949 f1: 0.925 accuracy: 0.988 
training batch:    50, loss: 1.36800, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.998 
training batch:    51, loss: 1.52397, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.998 
training batch:    52, loss: 1.64757, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.995 
training batch:    53, loss: 2.25648, precision: 0.857 recall: 0.923 f1: 0.889 accuracy: 0.989 
training batch:    54, loss: 1.83760, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.993 
training batch:    55, loss: 2.41412, precision: 0.857 recall: 0.909 f1: 0.882 accuracy: 0.991 
training batch:    56, loss: 16.72072, precision: 0.933 recall: 0.848 f1: 0.889 accuracy: 0.930 
training batch:    57, loss: 7.48834, precision: 0.946 recall: 0.921 f1: 0.933 accuracy: 0.989 
training batch:    58, loss: 5.58926, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.970 
training batch:    59, loss: 1.12213, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:    60, loss: 1.62321, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.994 
training batch:    61, loss: 0.95715, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:    62, loss: 2.09061, precision: 0.872 recall: 0.944 f1: 0.907 accuracy: 0.990 
training batch:    63, loss: 3.51147, precision: 0.875 recall: 0.903 f1: 0.889 accuracy: 0.986 
training batch:    64, loss: 5.70702, precision: 0.806 recall: 0.879 f1: 0.841 accuracy: 0.983 
training batch:    65, loss: 6.92903, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.979 
training batch:    66, loss: 5.91006, precision: 0.833 recall: 0.862 f1: 0.847 accuracy: 0.974 
training batch:    67, loss: 3.33443, precision: 0.929 recall: 0.975 f1: 0.951 accuracy: 0.988 
training batch:    68, loss: 2.98741, precision: 0.939 recall: 0.816 f1: 0.873 accuracy: 0.986 
training batch:    69, loss: 3.03534, precision: 0.833 recall: 0.893 f1: 0.862 accuracy: 0.990 
training batch:    70, loss: 3.28897, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.993 
training batch:    71, loss: 4.22743, precision: 0.882 recall: 0.833 f1: 0.857 accuracy: 0.983 
training batch:    72, loss: 3.78717, precision: 0.818 recall: 0.931 f1: 0.871 accuracy: 0.990 
training batch:    73, loss: 4.31598, precision: 0.844 recall: 0.750 f1: 0.794 accuracy: 0.983 
training batch:    74, loss: 3.23180, precision: 0.966 recall: 0.824 f1: 0.889 accuracy: 0.993 
training batch:    75, loss: 4.62500, precision: 0.857 recall: 0.833 f1: 0.845 accuracy: 0.979 
training batch:    76, loss: 3.22824, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.988 
training batch:    77, loss: 3.89180, precision: 0.947 recall: 0.923 f1: 0.935 accuracy: 0.991 
training batch:    78, loss: 6.30321, precision: 0.968 recall: 0.882 f1: 0.923 accuracy: 0.986 
training batch:    79, loss: 3.88936, precision: 0.811 recall: 0.811 f1: 0.811 accuracy: 0.984 
training batch:    80, loss: 1.68710, precision: 0.906 recall: 0.967 f1: 0.935 accuracy: 0.995 
training batch:    81, loss: 6.23923, precision: 0.905 recall: 0.927 f1: 0.916 accuracy: 0.970 
training batch:    82, loss: 5.57007, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.978 
training batch:    83, loss: 3.25395, precision: 0.909 recall: 0.968 f1: 0.937 accuracy: 0.989 
training batch:    84, loss: 2.90154, precision: 0.875 recall: 0.933 f1: 0.903 accuracy: 0.988 
training batch:    85, loss: 2.37262, precision: 0.955 recall: 0.933 f1: 0.944 accuracy: 0.994 
training batch:    86, loss: 1.83931, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.993 
training batch:    87, loss: 2.85211, precision: 0.806 recall: 0.781 f1: 0.794 accuracy: 0.991 
training batch:    88, loss: 4.25476, precision: 0.857 recall: 0.800 f1: 0.828 accuracy: 0.989 
training batch:    89, loss: 1.25035, precision: 0.936 recall: 0.957 f1: 0.946 accuracy: 0.996 
training batch:    90, loss: 3.84088, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.988 
training batch:    91, loss: 3.62486, precision: 0.900 recall: 0.931 f1: 0.915 accuracy: 0.991 
training batch:    92, loss: 1.74835, precision: 0.939 recall: 0.886 f1: 0.912 accuracy: 0.994 
training batch:    93, loss: 8.06207, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.985 
training batch:    94, loss: 1.13406, precision: 0.946 recall: 0.921 f1: 0.933 accuracy: 0.994 
training batch:    95, loss: 3.91513, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.984 
training batch:    96, loss: 3.25127, precision: 0.875 recall: 0.933 f1: 0.903 accuracy: 0.983 
training batch:    97, loss: 1.40392, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.995 
training batch:    98, loss: 5.67203, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.970 
training batch:    99, loss: 2.10985, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.994 
training batch:   100, loss: 3.59727, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.981 
training batch:   101, loss: 4.07648, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.991 
training batch:   102, loss: 2.11873, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.989 
training batch:   103, loss: 2.30727, precision: 0.879 recall: 1.000 f1: 0.935 accuracy: 0.994 
training batch:   104, loss: 4.17532, precision: 0.857 recall: 0.882 f1: 0.870 accuracy: 0.984 
training batch:   105, loss: 17.99930, precision: 0.861 recall: 0.861 f1: 0.861 accuracy: 0.955 
training batch:   106, loss: 2.55540, precision: 0.917 recall: 0.880 f1: 0.898 accuracy: 0.994 
training batch:   107, loss: 7.01990, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.985 
training batch:   108, loss: 1.79193, precision: 0.892 recall: 0.868 f1: 0.880 accuracy: 0.993 
training batch:   109, loss: 2.32678, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.995 
training batch:   110, loss: 0.96011, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.999 
training batch:   111, loss: 4.10892, precision: 0.886 recall: 0.886 f1: 0.886 accuracy: 0.976 
training batch:   112, loss: 4.54417, precision: 0.861 recall: 0.838 f1: 0.849 accuracy: 0.983 
training batch:   113, loss: 2.75612, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.984 
training batch:   114, loss: 7.52711, precision: 0.773 recall: 0.810 f1: 0.791 accuracy: 0.973 
training batch:   115, loss: 5.54347, precision: 0.842 recall: 0.865 f1: 0.853 accuracy: 0.986 
training batch:   116, loss: 2.36984, precision: 0.867 recall: 0.886 f1: 0.876 accuracy: 0.990 
training batch:   117, loss: 2.30092, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.995 
training batch:   118, loss: 1.85545, precision: 0.871 recall: 0.931 f1: 0.900 accuracy: 0.990 
training batch:   119, loss: 2.41132, precision: 0.914 recall: 0.889 f1: 0.901 accuracy: 0.993 
training batch:   120, loss: 4.30626, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.984 
training batch:   121, loss: 4.42085, precision: 0.857 recall: 0.889 f1: 0.873 accuracy: 0.984 
training batch:   122, loss: 17.21225, precision: 0.706 recall: 0.774 f1: 0.738 accuracy: 0.946 
training batch:   123, loss: 2.02216, precision: 0.885 recall: 0.958 f1: 0.920 accuracy: 0.989 
training batch:   124, loss: 3.61383, precision: 0.936 recall: 0.957 f1: 0.946 accuracy: 0.993 
training batch:   125, loss: 3.40013, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.991 
training batch:   126, loss: 5.32344, precision: 0.804 recall: 0.902 f1: 0.851 accuracy: 0.985 
training batch:   127, loss: 0.85960, precision: 0.952 recall: 1.000 f1: 0.976 accuracy: 0.998 
training batch:   128, loss: 2.97388, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.990 
training batch:   129, loss: 6.72826, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.985 
training batch:   130, loss: 2.55785, precision: 0.886 recall: 0.939 f1: 0.912 accuracy: 0.989 
training batch:   131, loss: 2.83849, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.991 
training batch:   132, loss: 4.61548, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.988 
start evaluate engines...
label: Dsa, precision: 0.967 recall: 0.922 f1: 0.942 
label: Chk, precision: 0.667 recall: 0.667 f1: 0.667 
label: Ins, precision: 0.344 recall: 0.217 f1: 0.258 
label: Sur, precision: 0.918 recall: 0.944 f1: 0.928 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.907 recall: 0.901 f1: 0.902 
time consumption:2.24(min), precision: 0.926 recall: 0.890 f1: 0.907 accuracy: 0.983 
saved the new best model with f1: 0.907
epoch:10/100
training batch:     1, loss: 1.14986, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.995 
training batch:     2, loss: 2.16815, precision: 0.880 recall: 0.815 f1: 0.846 accuracy: 0.995 
training batch:     3, loss: 3.92926, precision: 0.812 recall: 0.703 f1: 0.754 accuracy: 0.985 
training batch:     4, loss: 2.22820, precision: 0.926 recall: 0.893 f1: 0.909 accuracy: 0.989 
training batch:     5, loss: 4.01199, precision: 0.750 recall: 0.889 f1: 0.814 accuracy: 0.989 
training batch:     6, loss: 2.97328, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.993 
training batch:     7, loss: 1.58945, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.995 
training batch:     8, loss: 2.68977, precision: 0.850 recall: 0.850 f1: 0.850 accuracy: 0.991 
training batch:     9, loss: 1.69873, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.994 
training batch:    10, loss: 1.79657, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.991 
training batch:    11, loss: 1.87952, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.993 
training batch:    12, loss: 4.25281, precision: 0.879 recall: 0.853 f1: 0.866 accuracy: 0.986 
training batch:    13, loss: 4.54510, precision: 0.857 recall: 0.909 f1: 0.882 accuracy: 0.986 
training batch:    14, loss: 2.56180, precision: 0.878 recall: 0.857 f1: 0.867 accuracy: 0.990 
training batch:    15, loss: 2.13455, precision: 0.903 recall: 0.966 f1: 0.933 accuracy: 0.995 
training batch:    16, loss: 3.80522, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.990 
training batch:    17, loss: 1.84048, precision: 0.963 recall: 0.897 f1: 0.929 accuracy: 0.995 
training batch:    18, loss: 2.41350, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.989 
training batch:    19, loss: 1.60658, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.995 
training batch:    20, loss: 2.38667, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.990 
training batch:    21, loss: 1.77585, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.991 
training batch:    22, loss: 1.42770, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.994 
training batch:    23, loss: 4.74431, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.984 
training batch:    24, loss: 1.52806, precision: 0.968 recall: 0.909 f1: 0.937 accuracy: 0.995 
training batch:    25, loss: 0.50938, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    26, loss: 1.41136, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.995 
training batch:    27, loss: 3.61511, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.988 
training batch:    28, loss: 1.82823, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.996 
training batch:    29, loss: 1.39967, precision: 0.903 recall: 0.875 f1: 0.889 accuracy: 0.993 
training batch:    30, loss: 1.56641, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.995 
training batch:    31, loss: 3.25922, precision: 0.879 recall: 0.879 f1: 0.879 accuracy: 0.991 
training batch:    32, loss: 1.91614, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.995 
training batch:    33, loss: 0.67731, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    34, loss: 1.67659, precision: 0.882 recall: 0.938 f1: 0.909 accuracy: 0.991 
training batch:    35, loss: 1.20053, precision: 0.875 recall: 0.933 f1: 0.903 accuracy: 0.995 
training batch:    36, loss: 0.33199, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    37, loss: 1.92458, precision: 0.900 recall: 0.871 f1: 0.885 accuracy: 0.996 
training batch:    38, loss: 1.12985, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.998 
training batch:    39, loss: 4.91747, precision: 0.966 recall: 0.824 f1: 0.889 accuracy: 0.994 
training batch:    40, loss: 4.17014, precision: 0.900 recall: 0.931 f1: 0.915 accuracy: 0.993 
training batch:    41, loss: 4.72530, precision: 0.935 recall: 0.956 f1: 0.945 accuracy: 0.985 
training batch:    42, loss: 2.13402, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.998 
training batch:    43, loss: 1.66080, precision: 0.944 recall: 0.919 f1: 0.932 accuracy: 0.994 
training batch:    44, loss: 4.84570, precision: 0.692 recall: 0.900 f1: 0.783 accuracy: 0.984 
training batch:    45, loss: 0.79277, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    46, loss: 3.07130, precision: 0.947 recall: 0.923 f1: 0.935 accuracy: 0.991 
training batch:    47, loss: 2.50870, precision: 0.900 recall: 0.878 f1: 0.889 accuracy: 0.989 
training batch:    48, loss: 6.14030, precision: 0.862 recall: 0.862 f1: 0.862 accuracy: 0.976 
training batch:    49, loss: 3.86337, precision: 0.960 recall: 0.889 f1: 0.923 accuracy: 0.983 
training batch:    50, loss: 3.28914, precision: 0.833 recall: 0.833 f1: 0.833 accuracy: 0.986 
training batch:    51, loss: 2.68016, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.994 
training batch:    52, loss: 1.84802, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.995 
training batch:    53, loss: 7.41576, precision: 0.861 recall: 0.912 f1: 0.886 accuracy: 0.980 
training batch:    54, loss: 1.36217, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:    55, loss: 2.22067, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.989 
training batch:    56, loss: 1.31087, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.994 
training batch:    57, loss: 4.40497, precision: 0.907 recall: 1.000 f1: 0.951 accuracy: 0.991 
training batch:    58, loss: 1.82854, precision: 0.921 recall: 0.972 f1: 0.946 accuracy: 0.994 
training batch:    59, loss: 1.39734, precision: 0.923 recall: 0.900 f1: 0.911 accuracy: 0.995 
training batch:    60, loss: 3.34506, precision: 0.871 recall: 0.771 f1: 0.818 accuracy: 0.986 
training batch:    61, loss: 1.82458, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.995 
training batch:    62, loss: 2.45430, precision: 0.821 recall: 0.842 f1: 0.831 accuracy: 0.990 
training batch:    63, loss: 4.82249, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.983 
training batch:    64, loss: 1.73402, precision: 0.824 recall: 0.875 f1: 0.848 accuracy: 0.994 
training batch:    65, loss: 4.07896, precision: 0.911 recall: 0.911 f1: 0.911 accuracy: 0.985 
training batch:    66, loss: 1.06520, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    67, loss: 2.14392, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:    68, loss: 1.72212, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.998 
training batch:    69, loss: 2.51053, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.986 
training batch:    70, loss: 7.49702, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.980 
training batch:    71, loss: 3.74957, precision: 0.929 recall: 0.867 f1: 0.897 accuracy: 0.985 
training batch:    72, loss: 2.51257, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.993 
training batch:    73, loss: 2.77090, precision: 0.892 recall: 0.917 f1: 0.904 accuracy: 0.993 
training batch:    74, loss: 1.70444, precision: 0.946 recall: 0.921 f1: 0.933 accuracy: 0.995 
training batch:    75, loss: 5.07664, precision: 0.907 recall: 0.907 f1: 0.907 accuracy: 0.981 
training batch:    76, loss: 4.71104, precision: 0.865 recall: 0.842 f1: 0.853 accuracy: 0.984 
training batch:    77, loss: 1.85422, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.996 
training batch:    78, loss: 2.62315, precision: 0.905 recall: 0.974 f1: 0.938 accuracy: 0.991 
training batch:    79, loss: 2.07574, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.991 
training batch:    80, loss: 1.47452, precision: 0.917 recall: 0.892 f1: 0.904 accuracy: 0.995 
training batch:    81, loss: 1.44868, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.995 
training batch:    82, loss: 2.09944, precision: 0.917 recall: 0.846 f1: 0.880 accuracy: 0.995 
training batch:    83, loss: 0.87476, precision: 0.955 recall: 1.000 f1: 0.977 accuracy: 0.998 
training batch:    84, loss: 2.87268, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.988 
training batch:    85, loss: 3.48251, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.988 
training batch:    86, loss: 1.96814, precision: 0.821 recall: 0.852 f1: 0.836 accuracy: 0.990 
training batch:    87, loss: 1.46620, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.995 
training batch:    88, loss: 4.30109, precision: 0.902 recall: 0.925 f1: 0.914 accuracy: 0.984 
training batch:    89, loss: 3.97534, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.983 
training batch:    90, loss: 3.57300, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.983 
training batch:    91, loss: 2.45306, precision: 0.861 recall: 0.861 f1: 0.861 accuracy: 0.993 
training batch:    92, loss: 1.33478, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.996 
training batch:    93, loss: 1.27367, precision: 0.932 recall: 0.953 f1: 0.943 accuracy: 0.996 
training batch:    94, loss: 1.84346, precision: 0.897 recall: 0.972 f1: 0.933 accuracy: 0.995 
training batch:    95, loss: 0.90536, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    96, loss: 6.48743, precision: 0.868 recall: 0.868 f1: 0.868 accuracy: 0.974 
training batch:    97, loss: 2.58972, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.993 
training batch:    98, loss: 3.17357, precision: 0.976 recall: 0.952 f1: 0.964 accuracy: 0.991 
training batch:    99, loss: 2.58920, precision: 0.895 recall: 0.919 f1: 0.907 accuracy: 0.990 
training batch:   100, loss: 4.37810, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.986 
training batch:   101, loss: 2.12427, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.996 
training batch:   102, loss: 5.00317, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.985 
training batch:   103, loss: 2.93301, precision: 0.864 recall: 0.864 f1: 0.864 accuracy: 0.986 
training batch:   104, loss: 3.94377, precision: 0.971 recall: 0.917 f1: 0.943 accuracy: 0.989 
training batch:   105, loss: 4.67505, precision: 0.875 recall: 0.921 f1: 0.897 accuracy: 0.986 
training batch:   106, loss: 1.25841, precision: 0.900 recall: 0.964 f1: 0.931 accuracy: 0.995 
training batch:   107, loss: 4.45851, precision: 0.882 recall: 0.857 f1: 0.870 accuracy: 0.984 
training batch:   108, loss: 4.63522, precision: 0.929 recall: 0.839 f1: 0.881 accuracy: 0.973 
training batch:   109, loss: 2.23582, precision: 0.971 recall: 0.917 f1: 0.943 accuracy: 0.995 
training batch:   110, loss: 1.95000, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.996 
training batch:   111, loss: 1.71815, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.996 
training batch:   112, loss: 2.68315, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.989 
training batch:   113, loss: 2.51959, precision: 0.885 recall: 0.920 f1: 0.902 accuracy: 0.991 
training batch:   114, loss: 4.17270, precision: 0.795 recall: 0.838 f1: 0.816 accuracy: 0.981 
training batch:   115, loss: 2.07231, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.996 
training batch:   116, loss: 2.47682, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.988 
training batch:   117, loss: 1.17288, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.998 
training batch:   118, loss: 4.18129, precision: 0.920 recall: 0.920 f1: 0.920 accuracy: 0.990 
training batch:   119, loss: 2.86302, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.986 
training batch:   120, loss: 5.57715, precision: 0.862 recall: 0.862 f1: 0.862 accuracy: 0.989 
training batch:   121, loss: 1.22186, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.998 
training batch:   122, loss: 1.33371, precision: 0.929 recall: 0.907 f1: 0.918 accuracy: 0.994 
training batch:   123, loss: 2.24908, precision: 0.923 recall: 0.960 f1: 0.941 accuracy: 0.991 
training batch:   124, loss: 7.26050, precision: 0.811 recall: 0.857 f1: 0.833 accuracy: 0.974 
training batch:   125, loss: 2.75139, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.990 
training batch:   126, loss: 1.39182, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.995 
training batch:   127, loss: 1.17082, precision: 0.906 recall: 0.967 f1: 0.935 accuracy: 0.996 
training batch:   128, loss: 2.37985, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.991 
training batch:   129, loss: 11.45485, precision: 0.842 recall: 0.842 f1: 0.842 accuracy: 0.935 
training batch:   130, loss: 2.04887, precision: 0.808 recall: 0.808 f1: 0.808 accuracy: 0.988 
training batch:   131, loss: 1.47882, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:   132, loss: 3.64954, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.975 
start evaluate engines...
label: Dsa, precision: 0.868 recall: 0.883 f1: 0.872 
label: Chk, precision: 0.633 recall: 0.667 f1: 0.644 
label: Ins, precision: 0.333 recall: 0.281 f1: 0.297 
label: Sur, precision: 0.953 recall: 0.931 f1: 0.941 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.904 recall: 0.890 f1: 0.896 
time consumption:2.26(min), precision: 0.902 recall: 0.885 f1: 0.892 accuracy: 0.979 
epoch:11/100
training batch:     1, loss: 3.47594, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.991 
training batch:     2, loss: 2.17734, precision: 0.865 recall: 0.800 f1: 0.831 accuracy: 0.994 
training batch:     3, loss: 2.51636, precision: 0.935 recall: 0.906 f1: 0.921 accuracy: 0.988 
training batch:     4, loss: 2.72061, precision: 0.886 recall: 0.861 f1: 0.873 accuracy: 0.989 
training batch:     5, loss: 0.90114, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.998 
training batch:     6, loss: 1.37332, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.999 
training batch:     7, loss: 5.32289, precision: 0.622 recall: 0.767 f1: 0.687 accuracy: 0.978 
training batch:     8, loss: 2.00935, precision: 1.000 recall: 0.960 f1: 0.980 accuracy: 0.993 
training batch:     9, loss: 2.17876, precision: 0.886 recall: 0.886 f1: 0.886 accuracy: 0.988 
training batch:    10, loss: 5.19611, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.983 
training batch:    11, loss: 1.53165, precision: 1.000 recall: 0.953 f1: 0.976 accuracy: 0.996 
training batch:    12, loss: 1.18907, precision: 1.000 recall: 0.905 f1: 0.950 accuracy: 0.998 
training batch:    13, loss: 5.06851, precision: 0.897 recall: 0.765 f1: 0.825 accuracy: 0.984 
training batch:    14, loss: 4.07816, precision: 0.912 recall: 0.861 f1: 0.886 accuracy: 0.986 
training batch:    15, loss: 0.95578, precision: 0.963 recall: 0.929 f1: 0.945 accuracy: 0.989 
training batch:    16, loss: 1.75774, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.996 
training batch:    17, loss: 1.85834, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.995 
training batch:    18, loss: 2.91801, precision: 0.909 recall: 0.976 f1: 0.941 accuracy: 0.991 
training batch:    19, loss: 1.43767, precision: 0.923 recall: 0.900 f1: 0.911 accuracy: 0.994 
training batch:    20, loss: 3.14978, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.981 
training batch:    21, loss: 4.34320, precision: 0.903 recall: 0.933 f1: 0.918 accuracy: 0.990 
training batch:    22, loss: 2.56758, precision: 0.841 recall: 0.925 f1: 0.881 accuracy: 0.993 
training batch:    23, loss: 1.92206, precision: 0.868 recall: 0.917 f1: 0.892 accuracy: 0.993 
training batch:    24, loss: 3.86920, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.988 
training batch:    25, loss: 1.61348, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.993 
training batch:    26, loss: 5.05130, precision: 0.962 recall: 0.758 f1: 0.847 accuracy: 0.991 
training batch:    27, loss: 6.12822, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.991 
training batch:    28, loss: 1.40892, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.995 
training batch:    29, loss: 1.08081, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.998 
training batch:    30, loss: 2.51605, precision: 0.882 recall: 0.938 f1: 0.909 accuracy: 0.990 
training batch:    31, loss: 3.38826, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.986 
training batch:    32, loss: 3.00259, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.994 
training batch:    33, loss: 2.93845, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.990 
training batch:    34, loss: 1.41620, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.994 
training batch:    35, loss: 2.23216, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.989 
training batch:    36, loss: 1.67415, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.993 
training batch:    37, loss: 2.63382, precision: 0.875 recall: 0.903 f1: 0.889 accuracy: 0.993 
training batch:    38, loss: 2.85457, precision: 0.889 recall: 0.828 f1: 0.857 accuracy: 0.993 
training batch:    39, loss: 4.94789, precision: 0.923 recall: 0.973 f1: 0.947 accuracy: 0.966 
training batch:    40, loss: 1.40950, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.998 
training batch:    41, loss: 2.32797, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.989 
training batch:    42, loss: 1.83109, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.993 
training batch:    43, loss: 1.05864, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.995 
training batch:    44, loss: 2.36324, precision: 0.879 recall: 0.906 f1: 0.892 accuracy: 0.990 
training batch:    45, loss: 1.51210, precision: 1.000 recall: 0.943 f1: 0.971 accuracy: 0.996 
training batch:    46, loss: 1.80396, precision: 0.871 recall: 0.931 f1: 0.900 accuracy: 0.994 
training batch:    47, loss: 2.12102, precision: 0.882 recall: 0.857 f1: 0.870 accuracy: 0.991 
training batch:    48, loss: 1.19109, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:    49, loss: 12.82063, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.978 
training batch:    50, loss: 2.41237, precision: 0.861 recall: 0.912 f1: 0.886 accuracy: 0.991 
training batch:    51, loss: 1.34543, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.996 
training batch:    52, loss: 3.87149, precision: 0.853 recall: 1.000 f1: 0.921 accuracy: 0.994 
training batch:    53, loss: 0.87437, precision: 0.930 recall: 0.930 f1: 0.930 accuracy: 0.996 
training batch:    54, loss: 1.55414, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.995 
training batch:    55, loss: 2.54910, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.985 
training batch:    56, loss: 6.58374, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.981 
training batch:    57, loss: 2.15492, precision: 0.880 recall: 0.917 f1: 0.898 accuracy: 0.991 
training batch:    58, loss: 2.97903, precision: 0.868 recall: 0.846 f1: 0.857 accuracy: 0.985 
training batch:    59, loss: 2.86179, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.989 
training batch:    60, loss: 2.03325, precision: 0.946 recall: 0.897 f1: 0.921 accuracy: 0.994 
training batch:    61, loss: 2.80650, precision: 0.895 recall: 0.872 f1: 0.883 accuracy: 0.991 
training batch:    62, loss: 1.32541, precision: 0.943 recall: 0.892 f1: 0.917 accuracy: 0.995 
training batch:    63, loss: 4.37476, precision: 0.925 recall: 0.925 f1: 0.925 accuracy: 0.986 
training batch:    64, loss: 2.63620, precision: 0.967 recall: 0.906 f1: 0.935 accuracy: 0.981 
training batch:    65, loss: 2.53207, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.984 
training batch:    66, loss: 3.36423, precision: 0.949 recall: 0.925 f1: 0.937 accuracy: 0.995 
training batch:    67, loss: 1.68436, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.995 
training batch:    68, loss: 2.26920, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.989 
training batch:    69, loss: 1.95276, precision: 0.979 recall: 1.000 f1: 0.989 accuracy: 0.994 
training batch:    70, loss: 4.13750, precision: 0.935 recall: 0.879 f1: 0.906 accuracy: 0.979 
training batch:    71, loss: 4.09946, precision: 0.875 recall: 0.913 f1: 0.894 accuracy: 0.986 
training batch:    72, loss: 2.98325, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.988 
training batch:    73, loss: 1.28653, precision: 0.909 recall: 0.968 f1: 0.937 accuracy: 0.995 
training batch:    74, loss: 6.45392, precision: 0.878 recall: 0.857 f1: 0.867 accuracy: 0.970 
training batch:    75, loss: 2.39954, precision: 0.875 recall: 0.897 f1: 0.886 accuracy: 0.989 
training batch:    76, loss: 4.51552, precision: 0.871 recall: 0.871 f1: 0.871 accuracy: 0.981 
training batch:    77, loss: 2.09871, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.993 
training batch:    78, loss: 1.60201, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.993 
training batch:    79, loss: 10.46419, precision: 0.915 recall: 0.977 f1: 0.945 accuracy: 0.965 
training batch:    80, loss: 4.24805, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.988 
training batch:    81, loss: 2.99371, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.989 
training batch:    82, loss: 4.31235, precision: 0.932 recall: 0.976 f1: 0.953 accuracy: 0.989 
training batch:    83, loss: 5.42557, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.983 
training batch:    84, loss: 5.09356, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.994 
training batch:    85, loss: 4.77533, precision: 0.917 recall: 0.892 f1: 0.904 accuracy: 0.978 
training batch:    86, loss: 1.15962, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.998 
training batch:    87, loss: 2.95667, precision: 0.944 recall: 0.919 f1: 0.932 accuracy: 0.994 
training batch:    88, loss: 3.70667, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.991 
training batch:    89, loss: 3.24260, precision: 0.882 recall: 0.857 f1: 0.870 accuracy: 0.993 
training batch:    90, loss: 2.79610, precision: 0.844 recall: 0.771 f1: 0.806 accuracy: 0.990 
training batch:    91, loss: 1.70633, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.995 
training batch:    92, loss: 3.53659, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.986 
training batch:    93, loss: 5.16528, precision: 0.867 recall: 0.867 f1: 0.867 accuracy: 0.979 
training batch:    94, loss: 6.40427, precision: 0.818 recall: 0.818 f1: 0.818 accuracy: 0.976 
training batch:    95, loss: 1.18697, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:    96, loss: 10.61020, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.963 
training batch:    97, loss: 1.07092, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    98, loss: 2.20972, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.993 
training batch:    99, loss: 4.00017, precision: 0.838 recall: 0.912 f1: 0.873 accuracy: 0.985 
training batch:   100, loss: 1.21211, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.998 
training batch:   101, loss: 4.06947, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.974 
training batch:   102, loss: 2.90919, precision: 1.000 recall: 0.914 f1: 0.955 accuracy: 0.993 
training batch:   103, loss: 0.94321, precision: 0.889 recall: 0.923 f1: 0.906 accuracy: 0.995 
training batch:   104, loss: 5.02278, precision: 0.759 recall: 0.786 f1: 0.772 accuracy: 0.976 
training batch:   105, loss: 6.97679, precision: 0.759 recall: 0.815 f1: 0.786 accuracy: 0.986 
training batch:   106, loss: 3.20828, precision: 0.931 recall: 1.000 f1: 0.964 accuracy: 0.986 
training batch:   107, loss: 3.46776, precision: 0.857 recall: 0.947 f1: 0.900 accuracy: 0.990 
training batch:   108, loss: 8.28496, precision: 0.879 recall: 0.784 f1: 0.829 accuracy: 0.979 
training batch:   109, loss: 1.79144, precision: 0.870 recall: 1.000 f1: 0.930 accuracy: 0.993 
training batch:   110, loss: 1.06560, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.998 
training batch:   111, loss: 2.65233, precision: 1.000 recall: 0.938 f1: 0.968 accuracy: 0.988 
training batch:   112, loss: 1.12274, precision: 0.946 recall: 0.897 f1: 0.921 accuracy: 0.995 
training batch:   113, loss: 1.95723, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.990 
training batch:   114, loss: 2.75034, precision: 0.897 recall: 0.963 f1: 0.929 accuracy: 0.990 
training batch:   115, loss: 3.79149, precision: 0.967 recall: 0.806 f1: 0.879 accuracy: 0.983 
training batch:   116, loss: 3.94070, precision: 0.941 recall: 0.842 f1: 0.889 accuracy: 0.985 
training batch:   117, loss: 5.17848, precision: 0.667 recall: 0.686 f1: 0.676 accuracy: 0.976 
training batch:   118, loss: 2.26898, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.991 
training batch:   119, loss: 3.12691, precision: 0.796 recall: 0.830 f1: 0.812 accuracy: 0.986 
training batch:   120, loss: 2.12074, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.995 
training batch:   121, loss: 4.93652, precision: 0.783 recall: 0.837 f1: 0.809 accuracy: 0.983 
training batch:   122, loss: 1.34793, precision: 0.875 recall: 0.933 f1: 0.903 accuracy: 0.994 
training batch:   123, loss: 1.97452, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.994 
training batch:   124, loss: 3.11038, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.993 
training batch:   125, loss: 4.63663, precision: 0.806 recall: 0.862 f1: 0.833 accuracy: 0.979 
training batch:   126, loss: 2.85539, precision: 0.919 recall: 1.000 f1: 0.958 accuracy: 0.990 
training batch:   127, loss: 2.66620, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.991 
training batch:   128, loss: 1.85306, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.991 
training batch:   129, loss: 5.61966, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.978 
training batch:   130, loss: 9.42210, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.979 
training batch:   131, loss: 3.33510, precision: 1.000 recall: 0.846 f1: 0.917 accuracy: 0.991 
training batch:   132, loss: 3.60880, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.995 
start evaluate engines...
label: Dsa, precision: 0.918 recall: 0.905 f1: 0.909 
label: Chk, precision: 0.733 recall: 0.733 f1: 0.733 
label: Ins, precision: 0.367 recall: 0.257 f1: 0.296 
label: Sur, precision: 0.927 recall: 0.907 f1: 0.914 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.901 recall: 0.906 f1: 0.902 
time consumption:2.11(min), precision: 0.922 recall: 0.898 f1: 0.909 accuracy: 0.984 
saved the new best model with f1: 0.909
epoch:12/100
training batch:     1, loss: 1.02205, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:     2, loss: 2.30659, precision: 0.907 recall: 0.867 f1: 0.886 accuracy: 0.991 
training batch:     3, loss: 3.13309, precision: 0.865 recall: 0.842 f1: 0.853 accuracy: 0.986 
training batch:     4, loss: 2.04007, precision: 0.889 recall: 0.865 f1: 0.877 accuracy: 0.989 
training batch:     5, loss: 8.53258, precision: 0.952 recall: 0.976 f1: 0.964 accuracy: 0.963 
training batch:     6, loss: 2.70653, precision: 0.903 recall: 1.000 f1: 0.949 accuracy: 0.990 
training batch:     7, loss: 2.61081, precision: 0.936 recall: 0.917 f1: 0.926 accuracy: 0.993 
training batch:     8, loss: 3.56328, precision: 0.882 recall: 0.857 f1: 0.870 accuracy: 0.989 
training batch:     9, loss: 1.60460, precision: 0.921 recall: 0.875 f1: 0.897 accuracy: 0.995 
training batch:    10, loss: 1.30853, precision: 0.833 recall: 0.833 f1: 0.833 accuracy: 0.994 
training batch:    11, loss: 3.54781, precision: 0.829 recall: 0.853 f1: 0.841 accuracy: 0.983 
training batch:    12, loss: 2.06598, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.993 
training batch:    13, loss: 2.95079, precision: 0.800 recall: 0.800 f1: 0.800 accuracy: 0.989 
training batch:    14, loss: 6.16747, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.968 
training batch:    15, loss: 1.59355, precision: 0.897 recall: 0.946 f1: 0.921 accuracy: 0.991 
training batch:    16, loss: 3.28188, precision: 0.913 recall: 0.913 f1: 0.913 accuracy: 0.986 
training batch:    17, loss: 1.38847, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.993 
training batch:    18, loss: 3.94281, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.985 
training batch:    19, loss: 1.07445, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.996 
training batch:    20, loss: 0.97311, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.998 
training batch:    21, loss: 3.15215, precision: 0.841 recall: 0.949 f1: 0.892 accuracy: 0.988 
training batch:    22, loss: 3.49596, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.990 
training batch:    23, loss: 1.37114, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.994 
training batch:    24, loss: 1.61383, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.995 
training batch:    25, loss: 2.82181, precision: 0.925 recall: 0.974 f1: 0.949 accuracy: 0.989 
training batch:    26, loss: 1.86729, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.994 
training batch:    27, loss: 3.96422, precision: 0.900 recall: 0.871 f1: 0.885 accuracy: 0.985 
training batch:    28, loss: 1.31726, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.994 
training batch:    29, loss: 2.83083, precision: 0.941 recall: 0.865 f1: 0.901 accuracy: 0.991 
training batch:    30, loss: 3.98637, precision: 0.960 recall: 0.800 f1: 0.873 accuracy: 0.986 
training batch:    31, loss: 1.81969, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.994 
training batch:    32, loss: 3.56917, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.983 
training batch:    33, loss: 2.76572, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    34, loss: 1.47101, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:    35, loss: 3.66913, precision: 0.852 recall: 0.958 f1: 0.902 accuracy: 0.988 
training batch:    36, loss: 2.30508, precision: 0.889 recall: 0.842 f1: 0.865 accuracy: 0.990 
training batch:    37, loss: 2.76503, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.986 
training batch:    38, loss: 5.26088, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.995 
training batch:    39, loss: 1.50540, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.998 
training batch:    40, loss: 3.61163, precision: 0.833 recall: 0.938 f1: 0.882 accuracy: 0.988 
training batch:    41, loss: 6.42462, precision: 0.875 recall: 0.946 f1: 0.909 accuracy: 0.986 
training batch:    42, loss: 1.96176, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.993 
training batch:    43, loss: 1.50908, precision: 0.911 recall: 0.932 f1: 0.921 accuracy: 0.995 
training batch:    44, loss: 1.08362, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.996 
training batch:    45, loss: 3.03741, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.989 
training batch:    46, loss: 0.89874, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:    47, loss: 2.13484, precision: 0.914 recall: 0.889 f1: 0.901 accuracy: 0.990 
training batch:    48, loss: 1.14374, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.998 
training batch:    49, loss: 2.48395, precision: 0.919 recall: 0.895 f1: 0.907 accuracy: 0.993 
training batch:    50, loss: 2.33719, precision: 0.917 recall: 0.892 f1: 0.904 accuracy: 0.993 
training batch:    51, loss: 3.29471, precision: 0.905 recall: 0.950 f1: 0.927 accuracy: 0.990 
training batch:    52, loss: 1.40874, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.995 
training batch:    53, loss: 1.80879, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:    54, loss: 0.78127, precision: 0.955 recall: 0.875 f1: 0.913 accuracy: 0.995 
training batch:    55, loss: 2.11482, precision: 0.933 recall: 0.955 f1: 0.944 accuracy: 0.988 
training batch:    56, loss: 0.64883, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:    57, loss: 1.63480, precision: 0.879 recall: 0.935 f1: 0.906 accuracy: 0.993 
training batch:    58, loss: 2.11337, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.994 
training batch:    59, loss: 1.21815, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.994 
training batch:    60, loss: 1.70891, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.994 
training batch:    61, loss: 1.74249, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.996 
training batch:    62, loss: 1.18164, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.994 
training batch:    63, loss: 1.40274, precision: 0.978 recall: 0.978 f1: 0.978 accuracy: 0.999 
training batch:    64, loss: 2.92055, precision: 0.871 recall: 0.931 f1: 0.900 accuracy: 0.995 
training batch:    65, loss: 0.44141, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    66, loss: 2.09177, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.990 
training batch:    67, loss: 1.57173, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:    68, loss: 4.21585, precision: 0.824 recall: 0.848 f1: 0.836 accuracy: 0.979 
training batch:    69, loss: 1.51663, precision: 0.886 recall: 0.912 f1: 0.899 accuracy: 0.995 
training batch:    70, loss: 0.95480, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.996 
training batch:    71, loss: 10.33237, precision: 0.933 recall: 1.000 f1: 0.966 accuracy: 0.976 
training batch:    72, loss: 1.80437, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.995 
training batch:    73, loss: 9.31287, precision: 0.838 recall: 0.861 f1: 0.849 accuracy: 0.966 
training batch:    74, loss: 1.57048, precision: 0.960 recall: 0.889 f1: 0.923 accuracy: 0.994 
training batch:    75, loss: 2.63811, precision: 0.872 recall: 0.944 f1: 0.907 accuracy: 0.984 
training batch:    76, loss: 1.91840, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.996 
training batch:    77, loss: 2.99263, precision: 0.892 recall: 0.943 f1: 0.917 accuracy: 0.991 
training batch:    78, loss: 1.92174, precision: 0.914 recall: 0.970 f1: 0.941 accuracy: 0.995 
training batch:    79, loss: 4.46288, precision: 0.862 recall: 0.862 f1: 0.862 accuracy: 0.989 
training batch:    80, loss: 2.35887, precision: 0.974 recall: 0.864 f1: 0.916 accuracy: 0.989 
training batch:    81, loss: 0.99223, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    82, loss: 3.53436, precision: 0.949 recall: 0.925 f1: 0.937 accuracy: 0.994 
training batch:    83, loss: 1.91618, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.993 
training batch:    84, loss: 1.19733, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.996 
training batch:    85, loss: 2.46515, precision: 0.879 recall: 0.906 f1: 0.892 accuracy: 0.991 
training batch:    86, loss: 1.12106, precision: 1.000 recall: 0.939 f1: 0.969 accuracy: 0.995 
training batch:    87, loss: 2.33279, precision: 0.882 recall: 0.968 f1: 0.923 accuracy: 0.991 
training batch:    88, loss: 1.83292, precision: 1.000 recall: 0.946 f1: 0.972 accuracy: 0.994 
training batch:    89, loss: 2.07300, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.994 
training batch:    90, loss: 1.29482, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.995 
training batch:    91, loss: 1.62373, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.993 
training batch:    92, loss: 2.66808, precision: 0.900 recall: 0.837 f1: 0.867 accuracy: 0.989 
training batch:    93, loss: 0.86691, precision: 0.889 recall: 0.923 f1: 0.906 accuracy: 0.996 
training batch:    94, loss: 1.04547, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.999 
training batch:    95, loss: 0.83173, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.998 
training batch:    96, loss: 2.16260, precision: 0.920 recall: 0.958 f1: 0.939 accuracy: 0.993 
training batch:    97, loss: 1.91382, precision: 0.879 recall: 0.879 f1: 0.879 accuracy: 0.991 
training batch:    98, loss: 0.73378, precision: 0.867 recall: 0.963 f1: 0.912 accuracy: 0.996 
training batch:    99, loss: 1.00467, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:   100, loss: 3.83957, precision: 0.897 recall: 0.921 f1: 0.909 accuracy: 0.994 
training batch:   101, loss: 1.20602, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.996 
training batch:   102, loss: 4.59436, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.991 
training batch:   103, loss: 2.17827, precision: 1.000 recall: 0.939 f1: 0.969 accuracy: 0.991 
training batch:   104, loss: 1.31895, precision: 0.925 recall: 0.925 f1: 0.925 accuracy: 0.995 
training batch:   105, loss: 4.92207, precision: 0.862 recall: 0.893 f1: 0.877 accuracy: 0.970 
training batch:   106, loss: 1.84758, precision: 0.867 recall: 0.839 f1: 0.852 accuracy: 0.993 
training batch:   107, loss: 1.98378, precision: 0.919 recall: 0.850 f1: 0.883 accuracy: 0.994 
training batch:   108, loss: 3.21634, precision: 0.971 recall: 0.917 f1: 0.943 accuracy: 0.993 
training batch:   109, loss: 1.66202, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.995 
training batch:   110, loss: 1.86639, precision: 0.871 recall: 0.931 f1: 0.900 accuracy: 0.994 
training batch:   111, loss: 1.23811, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.995 
training batch:   112, loss: 0.76208, precision: 0.927 recall: 0.950 f1: 0.938 accuracy: 0.998 
training batch:   113, loss: 1.63170, precision: 0.885 recall: 0.852 f1: 0.868 accuracy: 0.990 
training batch:   114, loss: 3.70398, precision: 0.889 recall: 0.952 f1: 0.920 accuracy: 0.986 
training batch:   115, loss: 1.13585, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.996 
training batch:   116, loss: 2.51888, precision: 0.941 recall: 0.889 f1: 0.914 accuracy: 0.993 
training batch:   117, loss: 0.84732, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.995 
training batch:   118, loss: 2.51227, precision: 0.932 recall: 0.932 f1: 0.932 accuracy: 0.990 
training batch:   119, loss: 1.50760, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:   120, loss: 5.30298, precision: 0.879 recall: 0.853 f1: 0.866 accuracy: 0.984 
training batch:   121, loss: 0.47559, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   122, loss: 3.62181, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.986 
training batch:   123, loss: 0.56622, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   124, loss: 1.49852, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.996 
training batch:   125, loss: 1.70473, precision: 0.853 recall: 0.967 f1: 0.906 accuracy: 0.995 
training batch:   126, loss: 3.76091, precision: 0.816 recall: 0.838 f1: 0.827 accuracy: 0.978 
training batch:   127, loss: 1.74178, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.994 
training batch:   128, loss: 7.30017, precision: 0.958 recall: 0.958 f1: 0.958 accuracy: 0.973 
training batch:   129, loss: 3.20436, precision: 0.846 recall: 0.892 f1: 0.868 accuracy: 0.988 
training batch:   130, loss: 2.56982, precision: 0.963 recall: 0.929 f1: 0.945 accuracy: 0.991 
training batch:   131, loss: 5.18477, precision: 0.886 recall: 0.838 f1: 0.861 accuracy: 0.988 
training batch:   132, loss: 2.03528, precision: 0.913 recall: 0.875 f1: 0.894 accuracy: 0.993 
start evaluate engines...
label: Dsa, precision: 0.977 recall: 0.951 f1: 0.962 
label: Chk, precision: 0.667 recall: 0.633 f1: 0.644 
label: Ins, precision: 0.311 recall: 0.218 f1: 0.250 
label: Sur, precision: 0.987 recall: 0.978 f1: 0.982 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.920 recall: 0.912 f1: 0.915 
time consumption:1.86(min), precision: 0.949 recall: 0.907 f1: 0.926 accuracy: 0.986 
saved the new best model with f1: 0.926
epoch:13/100
training batch:     1, loss: 0.56372, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:     2, loss: 5.58418, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.983 
training batch:     3, loss: 1.83836, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.995 
training batch:     4, loss: 1.40714, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.998 
training batch:     5, loss: 1.57999, precision: 0.935 recall: 1.000 f1: 0.967 accuracy: 0.994 
training batch:     6, loss: 0.93719, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.998 
training batch:     7, loss: 0.82947, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:     8, loss: 4.68730, precision: 0.854 recall: 0.872 f1: 0.863 accuracy: 0.979 
training batch:     9, loss: 1.13174, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.998 
training batch:    10, loss: 6.03430, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.971 
training batch:    11, loss: 1.60437, precision: 0.947 recall: 0.900 f1: 0.923 accuracy: 0.996 
training batch:    12, loss: 1.08098, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    13, loss: 1.78015, precision: 0.926 recall: 0.962 f1: 0.943 accuracy: 0.991 
training batch:    14, loss: 3.68669, precision: 0.879 recall: 0.935 f1: 0.906 accuracy: 0.985 
training batch:    15, loss: 1.44591, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.998 
training batch:    16, loss: 8.50060, precision: 0.897 recall: 0.921 f1: 0.909 accuracy: 0.975 
training batch:    17, loss: 3.83118, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.984 
training batch:    18, loss: 1.42352, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.991 
training batch:    19, loss: 1.58989, precision: 0.932 recall: 0.953 f1: 0.943 accuracy: 0.996 
training batch:    20, loss: 1.95776, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.998 
training batch:    21, loss: 2.38153, precision: 0.923 recall: 0.900 f1: 0.911 accuracy: 0.991 
training batch:    22, loss: 4.98950, precision: 0.892 recall: 0.892 f1: 0.892 accuracy: 0.981 
training batch:    23, loss: 1.45049, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.996 
training batch:    24, loss: 1.21100, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.995 
training batch:    25, loss: 0.75316, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    26, loss: 2.81258, precision: 0.974 recall: 0.925 f1: 0.949 accuracy: 0.989 
training batch:    27, loss: 1.45479, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.993 
training batch:    28, loss: 1.82571, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.998 
training batch:    29, loss: 3.42468, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.985 
training batch:    30, loss: 2.95903, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.991 
training batch:    31, loss: 2.53514, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.986 
training batch:    32, loss: 2.42561, precision: 0.974 recall: 0.881 f1: 0.925 accuracy: 0.991 
training batch:    33, loss: 6.23222, precision: 0.917 recall: 1.000 f1: 0.957 accuracy: 0.980 
training batch:    34, loss: 1.64508, precision: 0.976 recall: 0.930 f1: 0.952 accuracy: 0.996 
training batch:    35, loss: 0.97516, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.995 
training batch:    36, loss: 1.25388, precision: 0.926 recall: 0.962 f1: 0.943 accuracy: 0.995 
training batch:    37, loss: 2.20203, precision: 0.853 recall: 0.853 f1: 0.853 accuracy: 0.991 
training batch:    38, loss: 2.53017, precision: 0.846 recall: 0.917 f1: 0.880 accuracy: 0.989 
training batch:    39, loss: 2.11609, precision: 0.947 recall: 0.923 f1: 0.935 accuracy: 0.994 
training batch:    40, loss: 3.49529, precision: 0.818 recall: 0.818 f1: 0.818 accuracy: 0.995 
training batch:    41, loss: 0.42773, precision: 0.958 recall: 0.958 f1: 0.958 accuracy: 0.999 
training batch:    42, loss: 3.97476, precision: 0.902 recall: 0.974 f1: 0.937 accuracy: 0.985 
training batch:    43, loss: 2.11098, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.993 
training batch:    44, loss: 0.67171, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.996 
training batch:    45, loss: 0.88269, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.998 
training batch:    46, loss: 0.82407, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.998 
training batch:    47, loss: 0.57158, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    48, loss: 1.12114, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:    49, loss: 1.33359, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.998 
training batch:    50, loss: 13.00690, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.973 
training batch:    51, loss: 3.76276, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.976 
training batch:    52, loss: 1.37740, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.998 
training batch:    53, loss: 4.20837, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.980 
training batch:    54, loss: 1.63503, precision: 1.000 recall: 0.926 f1: 0.962 accuracy: 0.998 
training batch:    55, loss: 1.67136, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.995 
training batch:    56, loss: 2.66798, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.993 
training batch:    57, loss: 1.77522, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.990 
training batch:    58, loss: 4.40198, precision: 0.889 recall: 0.970 f1: 0.928 accuracy: 0.985 
training batch:    59, loss: 6.24043, precision: 0.806 recall: 0.879 f1: 0.841 accuracy: 0.979 
training batch:    60, loss: 2.06528, precision: 0.943 recall: 0.892 f1: 0.917 accuracy: 0.995 
training batch:    61, loss: 2.17352, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.996 
training batch:    62, loss: 3.34489, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.995 
training batch:    63, loss: 4.20184, precision: 0.925 recall: 0.804 f1: 0.860 accuracy: 0.984 
training batch:    64, loss: 3.16609, precision: 0.864 recall: 0.826 f1: 0.844 accuracy: 0.984 
training batch:    65, loss: 3.06734, precision: 0.912 recall: 0.886 f1: 0.899 accuracy: 0.990 
training batch:    66, loss: 3.40022, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.989 
training batch:    67, loss: 3.26015, precision: 0.882 recall: 0.857 f1: 0.870 accuracy: 0.980 
training batch:    68, loss: 2.78200, precision: 0.861 recall: 0.969 f1: 0.912 accuracy: 0.994 
training batch:    69, loss: 1.39531, precision: 0.917 recall: 1.000 f1: 0.957 accuracy: 0.996 
training batch:    70, loss: 3.31535, precision: 0.936 recall: 0.978 f1: 0.957 accuracy: 0.988 
training batch:    71, loss: 1.33070, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.995 
training batch:    72, loss: 1.69522, precision: 0.902 recall: 0.949 f1: 0.925 accuracy: 0.994 
training batch:    73, loss: 1.76495, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.991 
training batch:    74, loss: 5.80725, precision: 0.900 recall: 0.978 f1: 0.938 accuracy: 0.986 
training batch:    75, loss: 2.52473, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.990 
training batch:    76, loss: 3.67833, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.991 
training batch:    77, loss: 3.72807, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.988 
training batch:    78, loss: 2.36470, precision: 0.977 recall: 1.000 f1: 0.989 accuracy: 0.996 
training batch:    79, loss: 2.21516, precision: 0.902 recall: 0.939 f1: 0.920 accuracy: 0.991 
training batch:    80, loss: 4.45880, precision: 0.970 recall: 0.889 f1: 0.928 accuracy: 0.986 
training batch:    81, loss: 1.96321, precision: 0.971 recall: 0.892 f1: 0.930 accuracy: 0.993 
training batch:    82, loss: 1.65764, precision: 1.000 recall: 0.912 f1: 0.954 accuracy: 0.996 
training batch:    83, loss: 0.93901, precision: 0.905 recall: 0.905 f1: 0.905 accuracy: 0.993 
training batch:    84, loss: 2.69768, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.991 
training batch:    85, loss: 1.92711, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.990 
training batch:    86, loss: 3.52043, precision: 0.920 recall: 0.920 f1: 0.920 accuracy: 0.988 
training batch:    87, loss: 0.94405, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.999 
training batch:    88, loss: 1.30992, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.991 
training batch:    89, loss: 0.83182, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.996 
training batch:    90, loss: 3.07137, precision: 0.925 recall: 0.925 f1: 0.925 accuracy: 0.986 
training batch:    91, loss: 1.22124, precision: 0.929 recall: 0.975 f1: 0.951 accuracy: 0.998 
training batch:    92, loss: 1.61212, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.993 
training batch:    93, loss: 9.19064, precision: 0.800 recall: 0.837 f1: 0.818 accuracy: 0.966 
training batch:    94, loss: 2.27859, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.990 
training batch:    95, loss: 0.83406, precision: 0.966 recall: 0.903 f1: 0.933 accuracy: 0.996 
training batch:    96, loss: 1.15013, precision: 0.958 recall: 0.958 f1: 0.958 accuracy: 0.998 
training batch:    97, loss: 7.33267, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.971 
training batch:    98, loss: 4.33916, precision: 0.841 recall: 0.949 f1: 0.892 accuracy: 0.984 
training batch:    99, loss: 2.11526, precision: 0.900 recall: 0.931 f1: 0.915 accuracy: 0.996 
training batch:   100, loss: 0.82115, precision: 0.900 recall: 0.931 f1: 0.915 accuracy: 0.995 
training batch:   101, loss: 3.22786, precision: 0.865 recall: 0.914 f1: 0.889 accuracy: 0.983 
training batch:   102, loss: 2.06053, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.989 
training batch:   103, loss: 0.78607, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.998 
training batch:   104, loss: 1.81184, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.995 
training batch:   105, loss: 2.96614, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.990 
training batch:   106, loss: 5.41376, precision: 0.900 recall: 0.878 f1: 0.889 accuracy: 0.975 
training batch:   107, loss: 3.97508, precision: 0.912 recall: 0.861 f1: 0.886 accuracy: 0.991 
training batch:   108, loss: 1.07419, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.994 
training batch:   109, loss: 2.26492, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.993 
training batch:   110, loss: 1.00420, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   111, loss: 5.35884, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.984 
training batch:   112, loss: 1.76508, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.995 
training batch:   113, loss: 1.58405, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.994 
training batch:   114, loss: 2.34071, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.993 
training batch:   115, loss: 1.40921, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:   116, loss: 5.03636, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.988 
training batch:   117, loss: 1.88284, precision: 0.867 recall: 0.951 f1: 0.907 accuracy: 0.994 
training batch:   118, loss: 1.65454, precision: 0.902 recall: 0.949 f1: 0.925 accuracy: 0.995 
training batch:   119, loss: 1.85265, precision: 0.867 recall: 1.000 f1: 0.929 accuracy: 0.988 
training batch:   120, loss: 2.00507, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.991 
training batch:   121, loss: 2.62094, precision: 0.833 recall: 0.909 f1: 0.870 accuracy: 0.993 
training batch:   122, loss: 5.26021, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.990 
training batch:   123, loss: 2.06389, precision: 0.925 recall: 0.925 f1: 0.925 accuracy: 0.994 
training batch:   124, loss: 1.65352, precision: 0.929 recall: 0.867 f1: 0.897 accuracy: 0.993 
training batch:   125, loss: 1.02872, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.996 
training batch:   126, loss: 3.98483, precision: 0.833 recall: 0.800 f1: 0.816 accuracy: 0.984 
training batch:   127, loss: 1.61754, precision: 0.925 recall: 0.925 f1: 0.925 accuracy: 0.995 
training batch:   128, loss: 1.80589, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.990 
training batch:   129, loss: 5.01964, precision: 0.949 recall: 0.841 f1: 0.892 accuracy: 0.984 
training batch:   130, loss: 3.83263, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.990 
training batch:   131, loss: 2.41742, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.993 
training batch:   132, loss: 0.77206, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.973 recall: 0.940 f1: 0.954 
label: Chk, precision: 0.700 recall: 0.733 f1: 0.711 
label: Ins, precision: 0.338 recall: 0.269 f1: 0.294 
label: Sur, precision: 0.871 recall: 0.851 f1: 0.859 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.911 recall: 0.934 f1: 0.921 
time consumption:1.88(min), precision: 0.921 recall: 0.913 f1: 0.916 accuracy: 0.985 
epoch:14/100
training batch:     1, loss: 1.92223, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.994 
training batch:     2, loss: 2.36322, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.984 
training batch:     3, loss: 0.47264, precision: 0.935 recall: 1.000 f1: 0.967 accuracy: 0.998 
training batch:     4, loss: 2.28188, precision: 0.897 recall: 0.946 f1: 0.921 accuracy: 0.993 
training batch:     5, loss: 0.94115, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:     6, loss: 4.36711, precision: 0.886 recall: 0.912 f1: 0.899 accuracy: 0.984 
training batch:     7, loss: 2.51495, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.991 
training batch:     8, loss: 3.07817, precision: 0.892 recall: 0.917 f1: 0.904 accuracy: 0.993 
training batch:     9, loss: 0.83067, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.996 
training batch:    10, loss: 3.35561, precision: 0.927 recall: 0.905 f1: 0.916 accuracy: 0.990 
training batch:    11, loss: 0.88211, precision: 0.951 recall: 1.000 f1: 0.975 accuracy: 0.998 
training batch:    12, loss: 1.42743, precision: 1.000 recall: 0.949 f1: 0.974 accuracy: 0.996 
training batch:    13, loss: 1.37553, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.993 
training batch:    14, loss: 9.54898, precision: 0.886 recall: 0.848 f1: 0.867 accuracy: 0.978 
training batch:    15, loss: 0.58916, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    16, loss: 1.26112, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.998 
training batch:    17, loss: 4.92506, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.988 
training batch:    18, loss: 3.43524, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.991 
training batch:    19, loss: 0.87309, precision: 0.921 recall: 0.972 f1: 0.946 accuracy: 0.996 
training batch:    20, loss: 2.67094, precision: 0.903 recall: 1.000 f1: 0.949 accuracy: 0.990 
training batch:    21, loss: 1.03149, precision: 0.978 recall: 0.978 f1: 0.978 accuracy: 0.996 
training batch:    22, loss: 1.66547, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.990 
training batch:    23, loss: 3.40044, precision: 0.857 recall: 0.828 f1: 0.842 accuracy: 0.988 
training batch:    24, loss: 1.84221, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.995 
training batch:    25, loss: 5.00053, precision: 0.875 recall: 0.848 f1: 0.862 accuracy: 0.983 
training batch:    26, loss: 2.67560, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.988 
training batch:    27, loss: 0.94592, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.995 
training batch:    28, loss: 0.36389, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    29, loss: 2.98376, precision: 0.927 recall: 0.927 f1: 0.927 accuracy: 0.990 
training batch:    30, loss: 1.49977, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.998 
training batch:    31, loss: 1.52943, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.998 
training batch:    32, loss: 2.76653, precision: 0.909 recall: 0.952 f1: 0.930 accuracy: 0.993 
training batch:    33, loss: 1.38336, precision: 0.938 recall: 1.000 f1: 0.968 accuracy: 0.996 
training batch:    34, loss: 2.40266, precision: 0.892 recall: 0.892 f1: 0.892 accuracy: 0.990 
training batch:    35, loss: 0.38391, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    36, loss: 1.13397, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:    37, loss: 2.44292, precision: 1.000 recall: 0.949 f1: 0.974 accuracy: 0.993 
training batch:    38, loss: 4.22354, precision: 0.919 recall: 0.872 f1: 0.895 accuracy: 0.988 
training batch:    39, loss: 0.62057, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:    40, loss: 1.36867, precision: 0.914 recall: 0.941 f1: 0.928 accuracy: 0.994 
training batch:    41, loss: 0.78819, precision: 0.958 recall: 0.958 f1: 0.958 accuracy: 0.995 
training batch:    42, loss: 2.42987, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.994 
training batch:    43, loss: 1.68762, precision: 0.875 recall: 0.955 f1: 0.913 accuracy: 0.994 
training batch:    44, loss: 3.55009, precision: 0.897 recall: 0.972 f1: 0.933 accuracy: 0.991 
training batch:    45, loss: 3.23283, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.983 
training batch:    46, loss: 0.82524, precision: 0.953 recall: 0.976 f1: 0.965 accuracy: 0.998 
training batch:    47, loss: 0.56580, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.999 
training batch:    48, loss: 3.84143, precision: 0.933 recall: 0.800 f1: 0.862 accuracy: 0.991 
training batch:    49, loss: 1.66006, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.995 
training batch:    50, loss: 1.06918, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.995 
training batch:    51, loss: 2.11221, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.994 
training batch:    52, loss: 1.97620, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.993 
training batch:    53, loss: 0.70522, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.995 
training batch:    54, loss: 1.40297, precision: 0.973 recall: 0.923 f1: 0.947 accuracy: 0.995 
training batch:    55, loss: 3.28041, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.990 
training batch:    56, loss: 4.89714, precision: 0.903 recall: 0.875 f1: 0.889 accuracy: 0.989 
training batch:    57, loss: 0.41269, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.999 
training batch:    58, loss: 1.06525, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.995 
training batch:    59, loss: 3.89418, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.989 
training batch:    60, loss: 1.29768, precision: 0.979 recall: 1.000 f1: 0.989 accuracy: 0.996 
training batch:    61, loss: 1.71951, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.993 
training batch:    62, loss: 1.76868, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.994 
training batch:    63, loss: 1.46269, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.994 
training batch:    64, loss: 2.05351, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.989 
training batch:    65, loss: 1.19078, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:    66, loss: 1.88861, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.993 
training batch:    67, loss: 1.55627, precision: 0.897 recall: 0.963 f1: 0.929 accuracy: 0.994 
training batch:    68, loss: 3.13333, precision: 0.907 recall: 0.975 f1: 0.940 accuracy: 0.990 
training batch:    69, loss: 1.99702, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.993 
training batch:    70, loss: 3.04817, precision: 0.898 recall: 0.957 f1: 0.926 accuracy: 0.994 
training batch:    71, loss: 1.75558, precision: 0.909 recall: 0.952 f1: 0.930 accuracy: 0.991 
training batch:    72, loss: 3.56721, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.991 
training batch:    73, loss: 2.42773, precision: 0.939 recall: 0.861 f1: 0.899 accuracy: 0.989 
training batch:    74, loss: 1.00778, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.999 
training batch:    75, loss: 1.82526, precision: 0.925 recall: 0.925 f1: 0.925 accuracy: 0.994 
training batch:    76, loss: 1.22272, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.998 
training batch:    77, loss: 2.23851, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.989 
training batch:    78, loss: 1.46539, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:    79, loss: 0.87152, precision: 0.931 recall: 1.000 f1: 0.964 accuracy: 0.998 
training batch:    80, loss: 1.27406, precision: 0.893 recall: 0.962 f1: 0.926 accuracy: 0.996 
training batch:    81, loss: 1.05353, precision: 0.923 recall: 0.973 f1: 0.947 accuracy: 0.995 
training batch:    82, loss: 5.14169, precision: 0.867 recall: 0.839 f1: 0.852 accuracy: 0.984 
training batch:    83, loss: 2.26071, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.994 
training batch:    84, loss: 0.48015, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:    85, loss: 10.81952, precision: 0.935 recall: 0.906 f1: 0.921 accuracy: 0.974 
training batch:    86, loss: 0.44675, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    87, loss: 0.72162, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:    88, loss: 2.54021, precision: 0.893 recall: 0.893 f1: 0.893 accuracy: 0.993 
training batch:    89, loss: 1.92761, precision: 0.909 recall: 0.889 f1: 0.899 accuracy: 0.990 
training batch:    90, loss: 6.43233, precision: 0.846 recall: 0.892 f1: 0.868 accuracy: 0.979 
training batch:    91, loss: 1.24411, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.996 
training batch:    92, loss: 0.76743, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.998 
training batch:    93, loss: 1.29564, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.996 
training batch:    94, loss: 1.78946, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.989 
training batch:    95, loss: 2.84151, precision: 0.939 recall: 0.861 f1: 0.899 accuracy: 0.990 
training batch:    96, loss: 6.13187, precision: 0.923 recall: 0.889 f1: 0.906 accuracy: 0.965 
training batch:    97, loss: 1.49983, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.998 
training batch:    98, loss: 1.58037, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.996 
training batch:    99, loss: 1.57298, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.994 
training batch:   100, loss: 2.52710, precision: 0.885 recall: 1.000 f1: 0.939 accuracy: 0.991 
training batch:   101, loss: 1.00833, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.998 
training batch:   102, loss: 2.69962, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.993 
training batch:   103, loss: 2.16676, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.993 
training batch:   104, loss: 3.19221, precision: 0.933 recall: 0.848 f1: 0.889 accuracy: 0.993 
training batch:   105, loss: 1.04843, precision: 0.880 recall: 0.880 f1: 0.880 accuracy: 0.990 
training batch:   106, loss: 2.19362, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.996 
training batch:   107, loss: 2.81096, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.993 
training batch:   108, loss: 1.31709, precision: 0.932 recall: 0.976 f1: 0.953 accuracy: 0.995 
training batch:   109, loss: 1.83463, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.993 
training batch:   110, loss: 4.12675, precision: 0.867 recall: 0.867 f1: 0.867 accuracy: 0.984 
training batch:   111, loss: 2.22783, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.996 
training batch:   112, loss: 1.38086, precision: 1.000 recall: 0.903 f1: 0.949 accuracy: 0.993 
training batch:   113, loss: 1.25690, precision: 0.969 recall: 0.912 f1: 0.939 accuracy: 0.994 
training batch:   114, loss: 0.80722, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.996 
training batch:   115, loss: 2.05461, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.994 
training batch:   116, loss: 1.17183, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.995 
training batch:   117, loss: 4.46942, precision: 0.892 recall: 0.892 f1: 0.892 accuracy: 0.991 
training batch:   118, loss: 1.23514, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.991 
training batch:   119, loss: 2.22742, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.989 
training batch:   120, loss: 0.53040, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   121, loss: 1.56836, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.996 
training batch:   122, loss: 0.72467, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.996 
training batch:   123, loss: 4.10394, precision: 0.912 recall: 0.861 f1: 0.886 accuracy: 0.990 
training batch:   124, loss: 1.53752, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.998 
training batch:   125, loss: 2.45570, precision: 0.897 recall: 1.000 f1: 0.945 accuracy: 0.996 
training batch:   126, loss: 3.69489, precision: 0.912 recall: 0.969 f1: 0.939 accuracy: 0.986 
training batch:   127, loss: 1.51857, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:   128, loss: 2.09743, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   129, loss: 1.94302, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.991 
training batch:   130, loss: 1.66391, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.996 
training batch:   131, loss: 2.46410, precision: 0.893 recall: 0.962 f1: 0.926 accuracy: 0.986 
training batch:   132, loss: 1.39328, precision: 0.867 recall: 1.000 f1: 0.929 accuracy: 0.993 
start evaluate engines...
label: Dsa, precision: 0.951 recall: 0.926 f1: 0.936 
label: Chk, precision: 0.733 recall: 0.700 f1: 0.711 
label: Ins, precision: 0.302 recall: 0.240 f1: 0.262 
label: Sur, precision: 0.987 recall: 0.978 f1: 0.982 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.930 recall: 0.919 f1: 0.923 
time consumption:2.14(min), precision: 0.935 recall: 0.907 f1: 0.920 accuracy: 0.987 
epoch:15/100
training batch:     1, loss: 1.82553, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:     2, loss: 3.60028, precision: 0.852 recall: 0.767 f1: 0.807 accuracy: 0.985 
training batch:     3, loss: 1.86264, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.996 
training batch:     4, loss: 1.63550, precision: 0.947 recall: 0.923 f1: 0.935 accuracy: 0.996 
training batch:     5, loss: 0.92976, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:     6, loss: 1.06285, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.998 
training batch:     7, loss: 0.84721, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:     8, loss: 1.04466, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.996 
training batch:     9, loss: 1.59315, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.995 
training batch:    10, loss: 0.64513, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.996 
training batch:    11, loss: 0.69205, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.999 
training batch:    12, loss: 1.18648, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.996 
training batch:    13, loss: 1.96950, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.993 
training batch:    14, loss: 2.49637, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.985 
training batch:    15, loss: 3.01517, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.978 
training batch:    16, loss: 0.77187, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    17, loss: 0.37772, precision: 1.000 recall: 0.960 f1: 0.980 accuracy: 0.999 
training batch:    18, loss: 1.83723, precision: 0.902 recall: 0.949 f1: 0.925 accuracy: 0.995 
training batch:    19, loss: 4.62012, precision: 0.917 recall: 0.936 f1: 0.926 accuracy: 0.985 
training batch:    20, loss: 0.71931, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.998 
training batch:    21, loss: 1.34830, precision: 0.949 recall: 0.925 f1: 0.937 accuracy: 0.994 
training batch:    22, loss: 0.44649, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    23, loss: 1.20758, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.996 
training batch:    24, loss: 1.14883, precision: 0.968 recall: 0.882 f1: 0.923 accuracy: 0.995 
training batch:    25, loss: 3.45242, precision: 0.868 recall: 0.892 f1: 0.880 accuracy: 0.980 
training batch:    26, loss: 1.17346, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.998 
training batch:    27, loss: 1.38393, precision: 1.000 recall: 0.923 f1: 0.960 accuracy: 0.994 
training batch:    28, loss: 0.54134, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:    29, loss: 1.94826, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.991 
training batch:    30, loss: 1.43379, precision: 0.930 recall: 0.952 f1: 0.941 accuracy: 0.995 
training batch:    31, loss: 0.23462, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    32, loss: 0.22408, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    33, loss: 0.75600, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.998 
training batch:    34, loss: 0.98828, precision: 0.923 recall: 0.900 f1: 0.911 accuracy: 0.995 
training batch:    35, loss: 0.94637, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.996 
training batch:    36, loss: 2.22461, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.994 
training batch:    37, loss: 0.88818, precision: 0.923 recall: 0.960 f1: 0.941 accuracy: 0.998 
training batch:    38, loss: 2.24335, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.993 
training batch:    39, loss: 1.57396, precision: 0.913 recall: 0.913 f1: 0.913 accuracy: 0.998 
training batch:    40, loss: 0.98488, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.994 
training batch:    41, loss: 0.97723, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    42, loss: 1.12997, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.995 
training batch:    43, loss: 1.47130, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.994 
training batch:    44, loss: 0.75487, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.996 
training batch:    45, loss: 1.36525, precision: 0.962 recall: 0.893 f1: 0.926 accuracy: 0.991 
training batch:    46, loss: 1.77220, precision: 0.976 recall: 0.930 f1: 0.952 accuracy: 0.993 
training batch:    47, loss: 1.65474, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.996 
training batch:    48, loss: 4.67758, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.989 
training batch:    49, loss: 0.63174, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.999 
training batch:    50, loss: 1.84415, precision: 0.892 recall: 0.971 f1: 0.930 accuracy: 0.995 
training batch:    51, loss: 1.32599, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.996 
training batch:    52, loss: 0.44994, precision: 0.957 recall: 1.000 f1: 0.978 accuracy: 0.999 
training batch:    53, loss: 2.96721, precision: 0.871 recall: 0.931 f1: 0.900 accuracy: 0.995 
training batch:    54, loss: 1.34076, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.996 
training batch:    55, loss: 1.39380, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.994 
training batch:    56, loss: 0.94397, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.995 
training batch:    57, loss: 1.34906, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.996 
training batch:    58, loss: 6.00688, precision: 0.862 recall: 0.806 f1: 0.833 accuracy: 0.986 
training batch:    59, loss: 0.56308, precision: 1.000 recall: 0.955 f1: 0.977 accuracy: 0.998 
training batch:    60, loss: 0.74380, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:    61, loss: 0.62109, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.998 
training batch:    62, loss: 0.29710, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    63, loss: 2.13104, precision: 0.925 recall: 0.925 f1: 0.925 accuracy: 0.995 
training batch:    64, loss: 1.37633, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.995 
training batch:    65, loss: 1.43199, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.995 
training batch:    66, loss: 1.79347, precision: 0.865 recall: 0.889 f1: 0.877 accuracy: 0.994 
training batch:    67, loss: 1.71573, precision: 0.812 recall: 0.929 f1: 0.867 accuracy: 0.990 
training batch:    68, loss: 0.71909, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    69, loss: 1.49890, precision: 0.886 recall: 0.939 f1: 0.912 accuracy: 0.993 
training batch:    70, loss: 2.18953, precision: 0.940 recall: 0.940 f1: 0.940 accuracy: 0.994 
training batch:    71, loss: 0.68741, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:    72, loss: 1.57208, precision: 0.952 recall: 1.000 f1: 0.976 accuracy: 0.998 
training batch:    73, loss: 2.20241, precision: 0.953 recall: 0.976 f1: 0.965 accuracy: 0.995 
training batch:    74, loss: 0.61958, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.998 
training batch:    75, loss: 0.99211, precision: 0.953 recall: 1.000 f1: 0.976 accuracy: 0.998 
training batch:    76, loss: 0.27826, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    77, loss: 2.10568, precision: 0.821 recall: 0.970 f1: 0.889 accuracy: 0.993 
training batch:    78, loss: 4.43298, precision: 0.861 recall: 0.861 f1: 0.861 accuracy: 0.986 
training batch:    79, loss: 0.55688, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:    80, loss: 2.97380, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.988 
training batch:    81, loss: 1.00256, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    82, loss: 4.85071, precision: 0.946 recall: 0.897 f1: 0.921 accuracy: 0.984 
training batch:    83, loss: 1.96021, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.995 
training batch:    84, loss: 1.50334, precision: 1.000 recall: 0.917 f1: 0.957 accuracy: 0.995 
training batch:    85, loss: 4.42747, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.989 
training batch:    86, loss: 2.44542, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.991 
training batch:    87, loss: 1.60266, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.994 
training batch:    88, loss: 6.50536, precision: 0.900 recall: 0.844 f1: 0.871 accuracy: 0.978 
training batch:    89, loss: 1.12976, precision: 0.950 recall: 0.927 f1: 0.938 accuracy: 0.995 
training batch:    90, loss: 2.08112, precision: 0.926 recall: 0.893 f1: 0.909 accuracy: 0.988 
training batch:    91, loss: 2.67467, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.989 
training batch:    92, loss: 2.46022, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.993 
training batch:    93, loss: 0.95949, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.998 
training batch:    94, loss: 2.16951, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.994 
training batch:    95, loss: 0.83047, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    96, loss: 0.90326, precision: 0.955 recall: 0.933 f1: 0.944 accuracy: 0.994 
training batch:    97, loss: 9.13744, precision: 0.872 recall: 0.829 f1: 0.850 accuracy: 0.968 
training batch:    98, loss: 0.98398, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.996 
training batch:    99, loss: 2.79575, precision: 0.893 recall: 0.926 f1: 0.909 accuracy: 0.988 
training batch:   100, loss: 1.80804, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.993 
training batch:   101, loss: 0.93915, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.996 
training batch:   102, loss: 1.92854, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.994 
training batch:   103, loss: 2.44206, precision: 0.900 recall: 0.923 f1: 0.911 accuracy: 0.990 
training batch:   104, loss: 1.64502, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.996 
training batch:   105, loss: 3.05827, precision: 0.917 recall: 0.971 f1: 0.943 accuracy: 0.983 
training batch:   106, loss: 2.12570, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.995 
training batch:   107, loss: 1.54849, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.993 
training batch:   108, loss: 3.36853, precision: 0.833 recall: 0.921 f1: 0.875 accuracy: 0.990 
training batch:   109, loss: 1.90070, precision: 0.905 recall: 0.950 f1: 0.927 accuracy: 0.991 
training batch:   110, loss: 2.03671, precision: 0.923 recall: 0.900 f1: 0.911 accuracy: 0.993 
training batch:   111, loss: 1.77269, precision: 0.955 recall: 0.913 f1: 0.933 accuracy: 0.996 
training batch:   112, loss: 1.74565, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.995 
training batch:   113, loss: 2.32011, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.990 
training batch:   114, loss: 1.06087, precision: 0.967 recall: 0.906 f1: 0.935 accuracy: 0.996 
training batch:   115, loss: 4.03938, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.991 
training batch:   116, loss: 1.03856, precision: 0.930 recall: 0.952 f1: 0.941 accuracy: 0.996 
training batch:   117, loss: 1.62439, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.995 
training batch:   118, loss: 2.49548, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.993 
training batch:   119, loss: 1.47292, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.994 
training batch:   120, loss: 2.61653, precision: 0.974 recall: 0.927 f1: 0.950 accuracy: 0.994 
training batch:   121, loss: 2.89128, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.986 
training batch:   122, loss: 1.69730, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.995 
training batch:   123, loss: 0.99519, precision: 1.000 recall: 0.952 f1: 0.976 accuracy: 0.998 
training batch:   124, loss: 0.79065, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:   125, loss: 1.73679, precision: 0.911 recall: 0.932 f1: 0.921 accuracy: 0.994 
training batch:   126, loss: 1.79076, precision: 0.976 recall: 0.952 f1: 0.964 accuracy: 0.993 
training batch:   127, loss: 3.15459, precision: 0.789 recall: 0.909 f1: 0.845 accuracy: 0.988 
training batch:   128, loss: 1.44937, precision: 0.895 recall: 0.971 f1: 0.932 accuracy: 0.996 
training batch:   129, loss: 1.35027, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.991 
training batch:   130, loss: 1.25989, precision: 0.957 recall: 0.917 f1: 0.936 accuracy: 0.996 
training batch:   131, loss: 2.72067, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.993 
training batch:   132, loss: 0.71616, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.998 
start evaluate engines...
label: Dsa, precision: 0.953 recall: 0.969 f1: 0.958 
label: Chk, precision: 0.667 recall: 0.667 f1: 0.667 
label: Ins, precision: 0.322 recall: 0.222 f1: 0.251 
label: Sur, precision: 0.987 recall: 0.978 f1: 0.982 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.915 recall: 0.931 f1: 0.921 
time consumption:2.26(min), precision: 0.938 recall: 0.919 f1: 0.927 accuracy: 0.986 
saved the new best model with f1: 0.927
epoch:16/100
training batch:     1, loss: 0.80463, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:     2, loss: 0.81306, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.998 
training batch:     3, loss: 0.94060, precision: 0.946 recall: 1.000 f1: 0.972 accuracy: 0.998 
training batch:     4, loss: 0.68315, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:     5, loss: 1.45862, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.993 
training batch:     6, loss: 0.63693, precision: 1.000 recall: 0.931 f1: 0.964 accuracy: 0.996 
training batch:     7, loss: 1.44363, precision: 0.912 recall: 0.886 f1: 0.899 accuracy: 0.995 
training batch:     8, loss: 3.15900, precision: 1.000 recall: 0.925 f1: 0.961 accuracy: 0.980 
training batch:     9, loss: 0.30673, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    10, loss: 1.28009, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.996 
training batch:    11, loss: 0.76135, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:    12, loss: 0.81383, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    13, loss: 1.12192, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.998 
training batch:    14, loss: 1.15405, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.998 
training batch:    15, loss: 0.65611, precision: 0.903 recall: 0.966 f1: 0.933 accuracy: 0.996 
training batch:    16, loss: 0.77763, precision: 0.957 recall: 0.978 f1: 0.967 accuracy: 0.996 
training batch:    17, loss: 3.65111, precision: 0.914 recall: 0.941 f1: 0.928 accuracy: 0.983 
training batch:    18, loss: 0.34131, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:    19, loss: 1.07379, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:    20, loss: 0.32039, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    21, loss: 1.40320, precision: 0.917 recall: 0.971 f1: 0.943 accuracy: 0.998 
training batch:    22, loss: 1.38071, precision: 0.949 recall: 0.902 f1: 0.925 accuracy: 0.991 
training batch:    23, loss: 0.56058, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    24, loss: 1.11905, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:    25, loss: 0.83812, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.998 
training batch:    26, loss: 0.83278, precision: 0.917 recall: 0.957 f1: 0.936 accuracy: 0.996 
training batch:    27, loss: 0.42604, precision: 0.897 recall: 0.963 f1: 0.929 accuracy: 0.998 
training batch:    28, loss: 1.82364, precision: 0.861 recall: 0.861 f1: 0.861 accuracy: 0.989 
training batch:    29, loss: 0.58939, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.999 
training batch:    30, loss: 1.66473, precision: 0.929 recall: 0.975 f1: 0.951 accuracy: 0.994 
training batch:    31, loss: 0.39944, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    32, loss: 0.35109, precision: 0.977 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:    33, loss: 0.63647, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.998 
training batch:    34, loss: 1.11012, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.998 
training batch:    35, loss: 0.41272, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.998 
training batch:    36, loss: 1.82715, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.993 
training batch:    37, loss: 1.02005, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.998 
training batch:    38, loss: 0.91470, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.998 
training batch:    39, loss: 1.27739, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.998 
training batch:    40, loss: 1.18573, precision: 0.956 recall: 0.977 f1: 0.966 accuracy: 0.998 
training batch:    41, loss: 1.58957, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.994 
training batch:    42, loss: 1.96953, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.991 
training batch:    43, loss: 0.36575, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    44, loss: 4.21777, precision: 1.000 recall: 0.931 f1: 0.964 accuracy: 0.990 
training batch:    45, loss: 3.66632, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.994 
training batch:    46, loss: 0.81818, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:    47, loss: 0.69020, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:    48, loss: 0.42148, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    49, loss: 1.29095, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.995 
training batch:    50, loss: 2.01730, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.995 
training batch:    51, loss: 0.61179, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    52, loss: 1.02016, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.996 
training batch:    53, loss: 1.64705, precision: 0.973 recall: 0.923 f1: 0.947 accuracy: 0.990 
training batch:    54, loss: 2.89619, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.991 
training batch:    55, loss: 2.14505, precision: 0.909 recall: 0.882 f1: 0.896 accuracy: 0.991 
training batch:    56, loss: 1.02135, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.993 
training batch:    57, loss: 0.82602, precision: 1.000 recall: 0.941 f1: 0.970 accuracy: 0.996 
training batch:    58, loss: 0.97496, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.996 
training batch:    59, loss: 0.74268, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    60, loss: 2.81517, precision: 0.950 recall: 0.809 f1: 0.874 accuracy: 0.986 
training batch:    61, loss: 1.36241, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.994 
training batch:    62, loss: 0.52669, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    63, loss: 1.02269, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.996 
training batch:    64, loss: 1.23141, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.995 
training batch:    65, loss: 2.47768, precision: 0.838 recall: 0.939 f1: 0.886 accuracy: 0.991 
training batch:    66, loss: 0.89313, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:    67, loss: 0.98730, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.995 
training batch:    68, loss: 2.67766, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.989 
training batch:    69, loss: 0.69833, precision: 1.000 recall: 0.941 f1: 0.970 accuracy: 0.996 
training batch:    70, loss: 1.54982, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.995 
training batch:    71, loss: 5.26845, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.979 
training batch:    72, loss: 0.63977, precision: 0.950 recall: 1.000 f1: 0.974 accuracy: 0.996 
training batch:    73, loss: 1.11931, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    74, loss: 1.02298, precision: 0.909 recall: 0.976 f1: 0.941 accuracy: 0.995 
training batch:    75, loss: 0.57385, precision: 0.974 recall: 0.927 f1: 0.950 accuracy: 0.995 
training batch:    76, loss: 1.32373, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.995 
training batch:    77, loss: 2.39970, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.995 
training batch:    78, loss: 1.03192, precision: 0.947 recall: 0.923 f1: 0.935 accuracy: 0.996 
training batch:    79, loss: 2.47246, precision: 0.846 recall: 0.971 f1: 0.904 accuracy: 0.991 
training batch:    80, loss: 0.85649, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.998 
training batch:    81, loss: 0.35442, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    82, loss: 1.41747, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.996 
training batch:    83, loss: 1.03244, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.998 
training batch:    84, loss: 1.11404, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.998 
training batch:    85, loss: 1.35396, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.996 
training batch:    86, loss: 0.81195, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.998 
training batch:    87, loss: 0.64778, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:    88, loss: 1.69905, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.994 
training batch:    89, loss: 1.71132, precision: 0.971 recall: 0.919 f1: 0.944 accuracy: 0.994 
training batch:    90, loss: 0.62335, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    91, loss: 0.88222, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.996 
training batch:    92, loss: 4.08240, precision: 0.912 recall: 0.969 f1: 0.939 accuracy: 0.989 
training batch:    93, loss: 0.45825, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    94, loss: 0.58559, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.994 
training batch:    95, loss: 0.33266, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    96, loss: 2.15173, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:    97, loss: 1.51611, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.995 
training batch:    98, loss: 1.29556, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.995 
training batch:    99, loss: 1.07983, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.993 
training batch:   100, loss: 3.20436, precision: 0.886 recall: 1.000 f1: 0.939 accuracy: 0.995 
training batch:   101, loss: 1.37817, precision: 0.920 recall: 0.885 f1: 0.902 accuracy: 0.993 
training batch:   102, loss: 1.96960, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.993 
training batch:   103, loss: 0.87099, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.996 
training batch:   104, loss: 1.69991, precision: 0.929 recall: 0.897 f1: 0.912 accuracy: 0.991 
training batch:   105, loss: 0.82617, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   106, loss: 1.40109, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.995 
training batch:   107, loss: 1.45372, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.998 
training batch:   108, loss: 1.17445, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.994 
training batch:   109, loss: 0.46826, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   110, loss: 2.67654, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.994 
training batch:   111, loss: 0.79918, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.999 
training batch:   112, loss: 2.25923, precision: 0.944 recall: 0.919 f1: 0.932 accuracy: 0.986 
training batch:   113, loss: 2.71297, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.996 
training batch:   114, loss: 2.19331, precision: 1.000 recall: 0.964 f1: 0.982 accuracy: 0.995 
training batch:   115, loss: 1.32668, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.995 
training batch:   116, loss: 0.80023, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   117, loss: 0.91107, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.996 
training batch:   118, loss: 0.22850, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   119, loss: 0.55290, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.998 
training batch:   120, loss: 0.98102, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.996 
training batch:   121, loss: 0.74397, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.998 
training batch:   122, loss: 0.72137, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   123, loss: 0.74883, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.998 
training batch:   124, loss: 1.59676, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.991 
training batch:   125, loss: 0.59239, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:   126, loss: 0.85539, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:   127, loss: 1.67052, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.996 
training batch:   128, loss: 1.06363, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.994 
training batch:   129, loss: 3.79312, precision: 0.927 recall: 0.974 f1: 0.950 accuracy: 0.993 
training batch:   130, loss: 0.46884, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.996 
training batch:   131, loss: 2.91568, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.985 
training batch:   132, loss: 10.59604, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.960 
start evaluate engines...
label: Dsa, precision: 0.928 recall: 0.941 f1: 0.932 
label: Chk, precision: 0.667 recall: 0.667 f1: 0.667 
label: Ins, precision: 0.313 recall: 0.240 f1: 0.267 
label: Sur, precision: 0.926 recall: 0.944 f1: 0.932 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.915 recall: 0.926 f1: 0.919 
time consumption:2.25(min), precision: 0.922 recall: 0.912 f1: 0.916 accuracy: 0.986 
epoch:17/100
training batch:     1, loss: 1.38023, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.991 
training batch:     2, loss: 0.66884, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.998 
training batch:     3, loss: 0.88222, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:     4, loss: 0.76611, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:     5, loss: 0.64111, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.996 
training batch:     6, loss: 4.36809, precision: 0.907 recall: 0.886 f1: 0.897 accuracy: 0.986 
training batch:     7, loss: 0.68858, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:     8, loss: 0.30402, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:     9, loss: 0.43027, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:    10, loss: 11.72116, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.975 
training batch:    11, loss: 1.48846, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.993 
training batch:    12, loss: 0.89629, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    13, loss: 1.93629, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.990 
training batch:    14, loss: 3.91661, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.965 
training batch:    15, loss: 0.19467, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    16, loss: 2.23822, precision: 0.878 recall: 0.947 f1: 0.911 accuracy: 0.990 
training batch:    17, loss: 2.08777, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.990 
training batch:    18, loss: 1.12628, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.999 
training batch:    19, loss: 1.70503, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.995 
training batch:    20, loss: 2.09309, precision: 0.973 recall: 0.923 f1: 0.947 accuracy: 0.995 
training batch:    21, loss: 9.66283, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.976 
training batch:    22, loss: 7.11166, precision: 0.932 recall: 1.000 f1: 0.965 accuracy: 0.978 
training batch:    23, loss: 2.97066, precision: 0.846 recall: 0.710 f1: 0.772 accuracy: 0.990 
training batch:    24, loss: 0.58591, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.999 
training batch:    25, loss: 3.32812, precision: 0.850 recall: 0.810 f1: 0.829 accuracy: 0.983 
training batch:    26, loss: 0.90701, precision: 0.933 recall: 0.955 f1: 0.944 accuracy: 0.996 
training batch:    27, loss: 0.66048, precision: 0.970 recall: 0.914 f1: 0.941 accuracy: 0.998 
training batch:    28, loss: 0.97050, precision: 0.964 recall: 0.931 f1: 0.947 accuracy: 0.995 
training batch:    29, loss: 2.01338, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.994 
training batch:    30, loss: 0.62914, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.996 
training batch:    31, loss: 0.93394, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.995 
training batch:    32, loss: 2.53345, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.994 
training batch:    33, loss: 2.50194, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.993 
training batch:    34, loss: 0.95227, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.995 
training batch:    35, loss: 2.71999, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.994 
training batch:    36, loss: 8.57372, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.971 
training batch:    37, loss: 2.88040, precision: 0.816 recall: 0.939 f1: 0.873 accuracy: 0.990 
training batch:    38, loss: 1.66896, precision: 0.917 recall: 0.880 f1: 0.898 accuracy: 0.995 
training batch:    39, loss: 0.74059, precision: 0.913 recall: 0.955 f1: 0.933 accuracy: 0.998 
training batch:    40, loss: 2.21352, precision: 0.837 recall: 0.900 f1: 0.867 accuracy: 0.985 
training batch:    41, loss: 4.10349, precision: 0.789 recall: 0.857 f1: 0.822 accuracy: 0.985 
training batch:    42, loss: 2.28912, precision: 0.839 recall: 0.867 f1: 0.852 accuracy: 0.989 
training batch:    43, loss: 1.61931, precision: 0.913 recall: 0.933 f1: 0.923 accuracy: 0.991 
training batch:    44, loss: 0.92992, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.996 
training batch:    45, loss: 1.43053, precision: 1.000 recall: 0.952 f1: 0.976 accuracy: 0.996 
training batch:    46, loss: 2.41168, precision: 0.880 recall: 0.957 f1: 0.917 accuracy: 0.986 
training batch:    47, loss: 3.67578, precision: 0.977 recall: 0.955 f1: 0.966 accuracy: 0.994 
training batch:    48, loss: 0.68304, precision: 1.000 recall: 0.962 f1: 0.980 accuracy: 0.998 
training batch:    49, loss: 0.24107, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:    50, loss: 1.02133, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.996 
training batch:    51, loss: 0.79622, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.998 
training batch:    52, loss: 0.82562, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.998 
training batch:    53, loss: 0.78026, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.998 
training batch:    54, loss: 0.67519, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    55, loss: 0.97496, precision: 0.931 recall: 0.900 f1: 0.915 accuracy: 0.993 
training batch:    56, loss: 1.02612, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.998 
training batch:    57, loss: 0.67450, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:    58, loss: 2.30734, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.991 
training batch:    59, loss: 3.01985, precision: 0.886 recall: 0.886 f1: 0.886 accuracy: 0.990 
training batch:    60, loss: 2.46834, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.995 
training batch:    61, loss: 2.32408, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.993 
training batch:    62, loss: 1.27545, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:    63, loss: 1.46136, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.996 
training batch:    64, loss: 1.95244, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.994 
training batch:    65, loss: 0.60612, precision: 0.977 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:    66, loss: 1.84685, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.991 
training batch:    67, loss: 0.98178, precision: 0.977 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:    68, loss: 1.56541, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.995 
training batch:    69, loss: 2.78706, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.991 
training batch:    70, loss: 1.13921, precision: 0.903 recall: 0.933 f1: 0.918 accuracy: 0.995 
training batch:    71, loss: 0.89417, precision: 0.976 recall: 0.952 f1: 0.964 accuracy: 0.996 
training batch:    72, loss: 1.17667, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.994 
training batch:    73, loss: 0.99347, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.998 
training batch:    74, loss: 2.22629, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.994 
training batch:    75, loss: 1.20302, precision: 1.000 recall: 0.935 f1: 0.967 accuracy: 0.998 
training batch:    76, loss: 0.52556, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.998 
training batch:    77, loss: 4.22064, precision: 0.833 recall: 0.870 f1: 0.851 accuracy: 0.989 
training batch:    78, loss: 3.49968, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.990 
training batch:    79, loss: 4.78691, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.986 
training batch:    80, loss: 1.06926, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:    81, loss: 1.53554, precision: 0.929 recall: 0.951 f1: 0.940 accuracy: 0.996 
training batch:    82, loss: 0.87230, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:    83, loss: 0.75510, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.996 
training batch:    84, loss: 1.86751, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.996 
training batch:    85, loss: 1.75169, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.996 
training batch:    86, loss: 1.61852, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.993 
training batch:    87, loss: 0.46492, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    88, loss: 1.45676, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.996 
training batch:    89, loss: 0.32379, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    90, loss: 10.18356, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.973 
training batch:    91, loss: 1.57288, precision: 0.885 recall: 0.920 f1: 0.902 accuracy: 0.993 
training batch:    92, loss: 1.76518, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.988 
training batch:    93, loss: 1.73836, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.999 
training batch:    94, loss: 1.66342, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.995 
training batch:    95, loss: 2.70763, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.993 
training batch:    96, loss: 0.36594, precision: 1.000 recall: 0.962 f1: 0.980 accuracy: 0.999 
training batch:    97, loss: 3.89507, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.994 
training batch:    98, loss: 3.71982, precision: 0.818 recall: 0.771 f1: 0.794 accuracy: 0.986 
training batch:    99, loss: 1.73087, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.993 
training batch:   100, loss: 0.81848, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.996 
training batch:   101, loss: 0.77417, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.996 
training batch:   102, loss: 1.31680, precision: 0.923 recall: 0.889 f1: 0.906 accuracy: 0.995 
training batch:   103, loss: 0.74068, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:   104, loss: 1.71346, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.995 
training batch:   105, loss: 14.06459, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.979 
training batch:   106, loss: 0.64726, precision: 0.978 recall: 0.957 f1: 0.968 accuracy: 0.998 
training batch:   107, loss: 0.95558, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:   108, loss: 1.78233, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.996 
training batch:   109, loss: 5.08104, precision: 0.879 recall: 0.879 f1: 0.879 accuracy: 0.984 
training batch:   110, loss: 2.99442, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.983 
training batch:   111, loss: 1.56644, precision: 0.902 recall: 0.902 f1: 0.902 accuracy: 0.995 
training batch:   112, loss: 2.03307, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.995 
training batch:   113, loss: 1.68298, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.996 
training batch:   114, loss: 1.77937, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.995 
training batch:   115, loss: 0.91968, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   116, loss: 2.50868, precision: 0.962 recall: 1.000 f1: 0.980 accuracy: 0.983 
training batch:   117, loss: 2.55331, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.996 
training batch:   118, loss: 3.90518, precision: 0.907 recall: 0.975 f1: 0.940 accuracy: 0.990 
training batch:   119, loss: 2.18462, precision: 0.865 recall: 0.941 f1: 0.901 accuracy: 0.993 
training batch:   120, loss: 0.99113, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.998 
training batch:   121, loss: 2.18047, precision: 0.893 recall: 1.000 f1: 0.943 accuracy: 0.994 
training batch:   122, loss: 1.08560, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.994 
training batch:   123, loss: 1.61542, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.995 
training batch:   124, loss: 0.40477, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   125, loss: 1.55528, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.998 
training batch:   126, loss: 2.33011, precision: 0.970 recall: 0.914 f1: 0.941 accuracy: 0.993 
training batch:   127, loss: 2.35803, precision: 1.000 recall: 0.917 f1: 0.957 accuracy: 0.994 
training batch:   128, loss: 1.38324, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   129, loss: 4.26862, precision: 1.000 recall: 0.884 f1: 0.938 accuracy: 0.989 
training batch:   130, loss: 1.22090, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.996 
training batch:   131, loss: 1.03339, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.994 
training batch:   132, loss: 0.23233, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.963 recall: 0.961 f1: 0.960 
label: Chk, precision: 0.633 recall: 0.667 f1: 0.644 
label: Ins, precision: 0.333 recall: 0.241 f1: 0.273 
label: Sur, precision: 0.927 recall: 0.931 f1: 0.928 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.907 recall: 0.938 f1: 0.921 
time consumption:2.24(min), precision: 0.933 recall: 0.924 f1: 0.928 accuracy: 0.985 
saved the new best model with f1: 0.928
epoch:18/100
training batch:     1, loss: 2.48759, precision: 0.828 recall: 1.000 f1: 0.906 accuracy: 0.993 
training batch:     2, loss: 0.50256, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.999 
training batch:     3, loss: 2.01846, precision: 0.963 recall: 0.929 f1: 0.945 accuracy: 0.995 
training batch:     4, loss: 1.17337, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.995 
training batch:     5, loss: 0.35402, precision: 0.958 recall: 1.000 f1: 0.979 accuracy: 0.999 
training batch:     6, loss: 1.01230, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.996 
training batch:     7, loss: 0.56154, precision: 0.958 recall: 1.000 f1: 0.979 accuracy: 0.999 
training batch:     8, loss: 1.02766, precision: 0.952 recall: 0.976 f1: 0.964 accuracy: 0.998 
training batch:     9, loss: 1.13170, precision: 0.979 recall: 1.000 f1: 0.989 accuracy: 0.994 
training batch:    10, loss: 0.49651, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    11, loss: 0.68123, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    12, loss: 0.82729, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:    13, loss: 1.18939, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.996 
training batch:    14, loss: 0.73604, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    15, loss: 0.53668, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    16, loss: 0.56363, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.996 
training batch:    17, loss: 0.60562, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.996 
training batch:    18, loss: 0.20607, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    19, loss: 2.14751, precision: 0.952 recall: 0.930 f1: 0.941 accuracy: 0.994 
training batch:    20, loss: 1.22011, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:    21, loss: 2.36214, precision: 0.897 recall: 1.000 f1: 0.946 accuracy: 0.994 
training batch:    22, loss: 0.34061, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    23, loss: 1.69141, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.993 
training batch:    24, loss: 0.94157, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.998 
training batch:    25, loss: 0.67032, precision: 0.977 recall: 1.000 f1: 0.988 accuracy: 0.996 
training batch:    26, loss: 1.41382, precision: 0.927 recall: 0.974 f1: 0.950 accuracy: 0.996 
training batch:    27, loss: 5.19460, precision: 0.973 recall: 0.923 f1: 0.947 accuracy: 0.989 
training batch:    28, loss: 0.65317, precision: 1.000 recall: 0.964 f1: 0.982 accuracy: 0.999 
training batch:    29, loss: 1.18155, precision: 0.932 recall: 0.953 f1: 0.943 accuracy: 0.994 
training batch:    30, loss: 1.27751, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.996 
training batch:    31, loss: 0.96323, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.996 
training batch:    32, loss: 0.89871, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.999 
training batch:    33, loss: 0.41649, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.998 
training batch:    34, loss: 0.14388, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    35, loss: 1.21452, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.999 
training batch:    36, loss: 0.49953, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.999 
training batch:    37, loss: 0.33351, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:    38, loss: 6.47266, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.980 
training batch:    39, loss: 0.17007, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 1.20160, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.994 
training batch:    41, loss: 2.15881, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.995 
training batch:    42, loss: 0.97479, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    43, loss: 1.06854, precision: 0.906 recall: 0.967 f1: 0.935 accuracy: 0.998 
training batch:    44, loss: 0.45595, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    45, loss: 0.21902, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.999 
training batch:    46, loss: 1.36394, precision: 0.889 recall: 0.960 f1: 0.923 accuracy: 0.995 
training batch:    47, loss: 0.49127, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:    48, loss: 1.95454, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.995 
training batch:    49, loss: 1.01352, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:    50, loss: 4.95958, precision: 0.844 recall: 0.844 f1: 0.844 accuracy: 0.984 
training batch:    51, loss: 3.25276, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.990 
training batch:    52, loss: 0.59528, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:    53, loss: 2.31015, precision: 0.925 recall: 0.902 f1: 0.914 accuracy: 0.993 
training batch:    54, loss: 1.08293, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.995 
training batch:    55, loss: 3.70036, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.990 
training batch:    56, loss: 1.14781, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.995 
training batch:    57, loss: 1.63216, precision: 0.929 recall: 0.951 f1: 0.940 accuracy: 0.996 
training batch:    58, loss: 0.60408, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.996 
training batch:    59, loss: 0.77081, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    60, loss: 0.70508, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    61, loss: 2.54073, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.993 
training batch:    62, loss: 1.48833, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.995 
training batch:    63, loss: 0.57841, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.998 
training batch:    64, loss: 1.46089, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.994 
training batch:    65, loss: 2.94681, precision: 0.935 recall: 1.000 f1: 0.967 accuracy: 0.995 
training batch:    66, loss: 1.99219, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.994 
training batch:    67, loss: 4.60214, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.985 
training batch:    68, loss: 3.15794, precision: 0.844 recall: 0.844 f1: 0.844 accuracy: 0.988 
training batch:    69, loss: 1.14380, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.996 
training batch:    70, loss: 0.68930, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:    71, loss: 0.38837, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    72, loss: 1.21719, precision: 0.917 recall: 0.957 f1: 0.936 accuracy: 0.995 
training batch:    73, loss: 1.38965, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.996 
training batch:    74, loss: 1.06149, precision: 0.966 recall: 0.903 f1: 0.933 accuracy: 0.996 
training batch:    75, loss: 1.78313, precision: 0.889 recall: 0.865 f1: 0.877 accuracy: 0.993 
training batch:    76, loss: 1.17250, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.993 
training batch:    77, loss: 1.09743, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.995 
training batch:    78, loss: 3.02040, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.990 
training batch:    79, loss: 0.41707, precision: 0.960 recall: 1.000 f1: 0.980 accuracy: 0.999 
training batch:    80, loss: 0.61877, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:    81, loss: 1.98460, precision: 0.977 recall: 0.956 f1: 0.966 accuracy: 0.996 
training batch:    82, loss: 0.17427, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    83, loss: 0.62459, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:    84, loss: 0.88263, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.998 
training batch:    85, loss: 0.63501, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.998 
training batch:    86, loss: 0.27486, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    87, loss: 0.82948, precision: 0.956 recall: 0.977 f1: 0.966 accuracy: 0.998 
training batch:    88, loss: 0.18806, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    89, loss: 1.00562, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.998 
training batch:    90, loss: 0.77721, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.996 
training batch:    91, loss: 0.64235, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.998 
training batch:    92, loss: 0.57893, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.999 
training batch:    93, loss: 0.30037, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    94, loss: 1.66985, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.996 
training batch:    95, loss: 2.00450, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.994 
training batch:    96, loss: 0.60489, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.999 
training batch:    97, loss: 0.40556, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.999 
training batch:    98, loss: 0.42650, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:    99, loss: 1.07239, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.995 
training batch:   100, loss: 1.69130, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.988 
training batch:   101, loss: 0.36241, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   102, loss: 0.28922, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   103, loss: 0.27704, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:   104, loss: 0.73381, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:   105, loss: 1.81802, precision: 0.861 recall: 0.939 f1: 0.899 accuracy: 0.991 
training batch:   106, loss: 0.84724, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.998 
training batch:   107, loss: 0.83728, precision: 0.970 recall: 0.914 f1: 0.941 accuracy: 0.996 
training batch:   108, loss: 0.24606, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   109, loss: 0.33640, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.999 
training batch:   110, loss: 0.79695, precision: 0.962 recall: 1.000 f1: 0.980 accuracy: 0.999 
training batch:   111, loss: 1.43242, precision: 0.957 recall: 1.000 f1: 0.978 accuracy: 0.998 
training batch:   112, loss: 0.72861, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.995 
training batch:   113, loss: 1.07877, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.996 
training batch:   114, loss: 1.28709, precision: 0.920 recall: 0.920 f1: 0.920 accuracy: 0.996 
training batch:   115, loss: 2.61766, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.998 
training batch:   116, loss: 3.42038, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.991 
training batch:   117, loss: 0.48338, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:   118, loss: 0.96815, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.996 
training batch:   119, loss: 1.16994, precision: 0.933 recall: 1.000 f1: 0.966 accuracy: 0.998 
training batch:   120, loss: 3.31670, precision: 0.967 recall: 0.806 f1: 0.879 accuracy: 0.989 
training batch:   121, loss: 1.18481, precision: 0.964 recall: 0.871 f1: 0.915 accuracy: 0.995 
training batch:   122, loss: 1.05272, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.996 
training batch:   123, loss: 0.41600, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:   124, loss: 0.51324, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:   125, loss: 0.61601, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   126, loss: 3.02559, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.994 
training batch:   127, loss: 0.63885, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.998 
training batch:   128, loss: 1.04362, precision: 0.923 recall: 1.000 f1: 0.960 accuracy: 0.998 
training batch:   129, loss: 0.61613, precision: 0.846 recall: 0.917 f1: 0.880 accuracy: 0.995 
training batch:   130, loss: 1.09610, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.998 
training batch:   131, loss: 0.45526, precision: 0.867 recall: 0.929 f1: 0.897 accuracy: 0.998 
training batch:   132, loss: 0.10986, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.948 recall: 0.955 f1: 0.948 
label: Chk, precision: 0.633 recall: 0.667 f1: 0.644 
label: Ins, precision: 0.300 recall: 0.260 f1: 0.272 
label: Sur, precision: 0.940 recall: 0.944 f1: 0.941 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.919 recall: 0.941 f1: 0.929 
time consumption:2.26(min), precision: 0.930 recall: 0.931 f1: 0.930 accuracy: 0.987 
saved the new best model with f1: 0.930
epoch:19/100
training batch:     1, loss: 1.16225, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.999 
training batch:     2, loss: 2.47319, precision: 0.920 recall: 0.979 f1: 0.948 accuracy: 0.991 
training batch:     3, loss: 0.27318, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:     4, loss: 0.25130, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:     5, loss: 0.60106, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:     6, loss: 0.65785, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.998 
training batch:     7, loss: 0.36284, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:     8, loss: 1.27129, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.998 
training batch:     9, loss: 0.72322, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    10, loss: 1.19131, precision: 0.909 recall: 0.882 f1: 0.896 accuracy: 0.994 
training batch:    11, loss: 0.37167, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.998 
training batch:    12, loss: 0.73164, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    13, loss: 0.24600, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    14, loss: 0.40965, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    15, loss: 1.53271, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.995 
training batch:    16, loss: 0.69254, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.998 
training batch:    17, loss: 0.57716, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:    18, loss: 3.71248, precision: 1.000 recall: 0.978 f1: 0.989 accuracy: 0.998 
training batch:    19, loss: 0.15321, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    20, loss: 0.53728, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    21, loss: 0.28050, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    22, loss: 0.21399, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    23, loss: 0.92064, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:    24, loss: 0.60406, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    25, loss: 2.19595, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.995 
training batch:    26, loss: 0.56442, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.995 
training batch:    27, loss: 0.72032, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.999 
training batch:    28, loss: 1.03119, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.996 
training batch:    29, loss: 0.78629, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.996 
training batch:    30, loss: 0.94441, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.998 
training batch:    31, loss: 2.11464, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.988 
training batch:    32, loss: 4.36290, precision: 0.767 recall: 0.821 f1: 0.793 accuracy: 0.979 
training batch:    33, loss: 0.56616, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    34, loss: 0.37567, precision: 0.960 recall: 1.000 f1: 0.980 accuracy: 0.999 
training batch:    35, loss: 0.38472, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    36, loss: 0.42908, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:    37, loss: 1.09380, precision: 0.885 recall: 1.000 f1: 0.939 accuracy: 0.996 
training batch:    38, loss: 2.16330, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.988 
training batch:    39, loss: 0.17863, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.62308, precision: 0.938 recall: 1.000 f1: 0.968 accuracy: 0.998 
training batch:    41, loss: 1.42313, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.996 
training batch:    42, loss: 0.39333, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    43, loss: 0.95813, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:    44, loss: 0.32005, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    45, loss: 2.16277, precision: 0.927 recall: 0.950 f1: 0.938 accuracy: 0.996 
training batch:    46, loss: 0.72797, precision: 1.000 recall: 0.944 f1: 0.971 accuracy: 0.998 
training batch:    47, loss: 1.22292, precision: 0.905 recall: 0.950 f1: 0.927 accuracy: 0.995 
training batch:    48, loss: 0.30128, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    49, loss: 1.65340, precision: 0.939 recall: 0.958 f1: 0.948 accuracy: 0.994 
training batch:    50, loss: 2.09454, precision: 0.900 recall: 0.844 f1: 0.871 accuracy: 0.993 
training batch:    51, loss: 0.49577, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    52, loss: 0.43883, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    53, loss: 1.35938, precision: 0.893 recall: 0.962 f1: 0.926 accuracy: 0.996 
training batch:    54, loss: 1.60950, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.996 
training batch:    55, loss: 0.92464, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.996 
training batch:    56, loss: 1.89824, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.994 
training batch:    57, loss: 1.13263, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.996 
training batch:    58, loss: 0.31726, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    59, loss: 1.02269, precision: 0.923 recall: 0.973 f1: 0.947 accuracy: 0.996 
training batch:    60, loss: 0.49963, precision: 1.000 recall: 0.977 f1: 0.989 accuracy: 0.999 
training batch:    61, loss: 0.66829, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    62, loss: 0.74580, precision: 0.919 recall: 0.872 f1: 0.895 accuracy: 0.996 
training batch:    63, loss: 0.05505, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    64, loss: 0.71384, precision: 0.927 recall: 0.974 f1: 0.950 accuracy: 0.998 
training batch:    65, loss: 2.85739, precision: 0.897 recall: 1.000 f1: 0.946 accuracy: 0.995 
training batch:    66, loss: 0.15564, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.999 
training batch:    67, loss: 0.16299, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    68, loss: 0.41632, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:    69, loss: 0.68785, precision: 0.953 recall: 0.976 f1: 0.965 accuracy: 0.998 
training batch:    70, loss: 1.51508, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.998 
training batch:    71, loss: 2.23807, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.994 
training batch:    72, loss: 0.94431, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.999 
training batch:    73, loss: 1.63132, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.996 
training batch:    74, loss: 0.61966, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    75, loss: 0.47032, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.999 
training batch:    76, loss: 1.18858, precision: 0.886 recall: 0.939 f1: 0.912 accuracy: 0.993 
training batch:    77, loss: 0.37506, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:    78, loss: 0.94861, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.995 
training batch:    79, loss: 2.48402, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.994 
training batch:    80, loss: 2.06764, precision: 0.800 recall: 0.960 f1: 0.873 accuracy: 0.994 
training batch:    81, loss: 1.16299, precision: 0.914 recall: 0.889 f1: 0.901 accuracy: 0.993 
training batch:    82, loss: 0.47881, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.998 
training batch:    83, loss: 0.59099, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:    84, loss: 2.76282, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.991 
training batch:    85, loss: 0.91078, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.998 
training batch:    86, loss: 0.70110, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:    87, loss: 0.32932, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    88, loss: 1.33025, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.990 
training batch:    89, loss: 0.68874, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:    90, loss: 1.34183, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.994 
training batch:    91, loss: 1.52576, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.996 
training batch:    92, loss: 0.52612, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.998 
training batch:    93, loss: 1.54660, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.988 
training batch:    94, loss: 0.27278, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.999 
training batch:    95, loss: 0.33202, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    96, loss: 1.09070, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.996 
training batch:    97, loss: 1.67113, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.995 
training batch:    98, loss: 0.43590, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:    99, loss: 2.20357, precision: 0.946 recall: 0.897 f1: 0.921 accuracy: 0.991 
training batch:   100, loss: 0.37959, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.999 
training batch:   101, loss: 1.42093, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.996 
training batch:   102, loss: 0.44232, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.998 
training batch:   103, loss: 1.78992, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.986 
training batch:   104, loss: 1.21753, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:   105, loss: 0.57684, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:   106, loss: 3.25722, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.993 
training batch:   107, loss: 1.01103, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.996 
training batch:   108, loss: 1.10019, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.996 
training batch:   109, loss: 0.77281, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.998 
training batch:   110, loss: 1.10890, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.998 
training batch:   111, loss: 1.23317, precision: 0.892 recall: 0.943 f1: 0.917 accuracy: 0.995 
training batch:   112, loss: 0.83517, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.996 
training batch:   113, loss: 1.22983, precision: 1.000 recall: 0.952 f1: 0.976 accuracy: 0.998 
training batch:   114, loss: 3.65150, precision: 0.932 recall: 0.976 f1: 0.953 accuracy: 0.991 
training batch:   115, loss: 5.90022, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.980 
training batch:   116, loss: 1.82588, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.994 
training batch:   117, loss: 1.08992, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.998 
training batch:   118, loss: 0.66089, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   119, loss: 2.94894, precision: 0.903 recall: 0.848 f1: 0.875 accuracy: 0.993 
training batch:   120, loss: 1.13480, precision: 0.900 recall: 0.923 f1: 0.911 accuracy: 0.996 
training batch:   121, loss: 0.41838, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.996 
training batch:   122, loss: 0.71686, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:   123, loss: 0.48651, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   124, loss: 1.15376, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.991 
training batch:   125, loss: 0.84579, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.996 
training batch:   126, loss: 0.95166, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.993 
training batch:   127, loss: 0.37788, precision: 0.957 recall: 1.000 f1: 0.978 accuracy: 0.999 
training batch:   128, loss: 0.67349, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:   129, loss: 1.60854, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.996 
training batch:   130, loss: 1.08113, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.995 
training batch:   131, loss: 1.34709, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.996 
training batch:   132, loss: 0.47433, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.998 
start evaluate engines...
label: Dsa, precision: 0.988 recall: 0.953 f1: 0.968 
label: Chk, precision: 0.633 recall: 0.667 f1: 0.644 
label: Ins, precision: 0.322 recall: 0.222 f1: 0.251 
label: Sur, precision: 0.987 recall: 0.987 f1: 0.987 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.930 recall: 0.939 f1: 0.933 
time consumption:2.09(min), precision: 0.952 recall: 0.922 f1: 0.935 accuracy: 0.986 
saved the new best model with f1: 0.935
epoch:20/100
training batch:     1, loss: 1.09651, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.998 
training batch:     2, loss: 0.39221, precision: 0.958 recall: 0.958 f1: 0.958 accuracy: 0.999 
training batch:     3, loss: 0.62041, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.998 
training batch:     4, loss: 0.43288, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.999 
training batch:     5, loss: 0.46959, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:     6, loss: 0.25812, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:     7, loss: 1.10201, precision: 0.913 recall: 0.913 f1: 0.913 accuracy: 0.996 
training batch:     8, loss: 2.50668, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.993 
training batch:     9, loss: 0.29243, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.999 
training batch:    10, loss: 0.51318, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.998 
training batch:    11, loss: 0.13155, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    12, loss: 1.21011, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.998 
training batch:    13, loss: 3.56311, precision: 0.925 recall: 1.000 f1: 0.961 accuracy: 0.993 
training batch:    14, loss: 0.39001, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:    15, loss: 1.06721, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.995 
training batch:    16, loss: 0.84607, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    17, loss: 0.88510, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.993 
training batch:    18, loss: 0.16187, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    19, loss: 1.40070, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.998 
training batch:    20, loss: 0.20073, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    21, loss: 0.67404, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    22, loss: 0.43263, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    23, loss: 1.58232, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.993 
training batch:    24, loss: 0.60242, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    25, loss: 1.28922, precision: 0.958 recall: 0.920 f1: 0.939 accuracy: 0.995 
training batch:    26, loss: 0.31564, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:    27, loss: 0.49060, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.999 
training batch:    28, loss: 1.66669, precision: 0.953 recall: 1.000 f1: 0.976 accuracy: 0.990 
training batch:    29, loss: 1.03482, precision: 0.950 recall: 0.927 f1: 0.938 accuracy: 0.996 
training batch:    30, loss: 0.60942, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:    31, loss: 0.52426, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:    32, loss: 1.13054, precision: 0.952 recall: 0.976 f1: 0.964 accuracy: 0.995 
training batch:    33, loss: 0.91730, precision: 0.889 recall: 0.923 f1: 0.906 accuracy: 0.996 
training batch:    34, loss: 0.84918, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:    35, loss: 0.28830, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    36, loss: 0.91556, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:    37, loss: 3.10826, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.984 
training batch:    38, loss: 0.75601, precision: 1.000 recall: 0.978 f1: 0.989 accuracy: 0.998 
training batch:    39, loss: 0.40793, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:    40, loss: 0.59175, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    41, loss: 1.52293, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.996 
training batch:    42, loss: 0.30435, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:    43, loss: 0.56844, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.998 
training batch:    44, loss: 0.27042, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:    45, loss: 0.69937, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:    46, loss: 0.32040, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:    47, loss: 0.65727, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.998 
training batch:    48, loss: 0.17610, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    49, loss: 0.45255, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    50, loss: 2.94093, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.993 
training batch:    51, loss: 0.39156, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.999 
training batch:    52, loss: 1.67133, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.995 
training batch:    53, loss: 0.52058, precision: 0.951 recall: 1.000 f1: 0.975 accuracy: 0.998 
training batch:    54, loss: 0.26140, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    55, loss: 1.37138, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.993 
training batch:    56, loss: 0.54381, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    57, loss: 0.77763, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.996 
training batch:    58, loss: 0.84117, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    59, loss: 0.52808, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    60, loss: 0.49495, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.995 
training batch:    61, loss: 1.77142, precision: 0.969 recall: 0.912 f1: 0.939 accuracy: 0.995 
training batch:    62, loss: 1.05325, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.996 
training batch:    63, loss: 0.72998, precision: 0.953 recall: 0.976 f1: 0.965 accuracy: 0.998 
training batch:    64, loss: 0.33908, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    65, loss: 1.55920, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:    66, loss: 2.75691, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.993 
training batch:    67, loss: 1.19838, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.995 
training batch:    68, loss: 1.18533, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.994 
training batch:    69, loss: 1.75946, precision: 0.893 recall: 1.000 f1: 0.943 accuracy: 0.996 
training batch:    70, loss: 3.44383, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:    71, loss: 3.04222, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.986 
training batch:    72, loss: 4.17766, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.980 
training batch:    73, loss: 0.44037, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    74, loss: 3.12099, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.991 
training batch:    75, loss: 0.49893, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:    76, loss: 0.74574, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:    77, loss: 0.37952, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.999 
training batch:    78, loss: 0.58969, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.998 
training batch:    79, loss: 0.41136, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:    80, loss: 1.90865, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.998 
training batch:    81, loss: 0.78871, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    82, loss: 0.54813, precision: 0.923 recall: 0.960 f1: 0.941 accuracy: 0.998 
training batch:    83, loss: 1.15318, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.996 
training batch:    84, loss: 2.38138, precision: 0.867 recall: 0.897 f1: 0.881 accuracy: 0.990 
training batch:    85, loss: 0.95558, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.994 
training batch:    86, loss: 0.73370, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.996 
training batch:    87, loss: 1.30765, precision: 0.971 recall: 0.919 f1: 0.944 accuracy: 0.994 
training batch:    88, loss: 1.08006, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    89, loss: 1.45140, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:    90, loss: 0.70613, precision: 0.976 recall: 0.932 f1: 0.953 accuracy: 0.995 
training batch:    91, loss: 1.94310, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.991 
training batch:    92, loss: 0.36603, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:    93, loss: 1.44832, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.998 
training batch:    94, loss: 0.47662, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:    95, loss: 3.43311, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.980 
training batch:    96, loss: 0.16705, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    97, loss: 1.02951, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.998 
training batch:    98, loss: 2.78773, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.994 
training batch:    99, loss: 0.13054, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 2.25198, precision: 0.824 recall: 0.933 f1: 0.875 accuracy: 0.993 
training batch:   101, loss: 0.66246, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:   102, loss: 0.21783, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   103, loss: 0.47713, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:   104, loss: 3.61884, precision: 0.871 recall: 0.818 f1: 0.844 accuracy: 0.986 
training batch:   105, loss: 4.36569, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.986 
training batch:   106, loss: 1.49132, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.995 
training batch:   107, loss: 0.99632, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:   108, loss: 1.45648, precision: 0.966 recall: 0.875 f1: 0.918 accuracy: 0.993 
training batch:   109, loss: 0.60989, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   110, loss: 0.81197, precision: 0.951 recall: 1.000 f1: 0.975 accuracy: 0.998 
training batch:   111, loss: 0.36945, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   112, loss: 0.65120, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.996 
training batch:   113, loss: 0.73692, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   114, loss: 0.97714, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.996 
training batch:   115, loss: 2.06390, precision: 0.964 recall: 0.931 f1: 0.947 accuracy: 0.998 
training batch:   116, loss: 0.11157, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   117, loss: 0.31241, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   118, loss: 1.86671, precision: 0.769 recall: 0.909 f1: 0.833 accuracy: 0.991 
training batch:   119, loss: 0.18205, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.98674, precision: 0.920 recall: 0.958 f1: 0.939 accuracy: 0.994 
training batch:   121, loss: 3.94542, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.990 
training batch:   122, loss: 0.39917, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   123, loss: 0.52815, precision: 0.947 recall: 1.000 f1: 0.973 accuracy: 0.998 
training batch:   124, loss: 0.65146, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.999 
training batch:   125, loss: 1.09209, precision: 0.917 recall: 0.957 f1: 0.936 accuracy: 0.996 
training batch:   126, loss: 0.28204, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.999 
training batch:   127, loss: 0.69409, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:   128, loss: 0.53615, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.998 
training batch:   129, loss: 0.40253, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.999 
training batch:   130, loss: 2.24156, precision: 0.976 recall: 0.870 f1: 0.920 accuracy: 0.994 
training batch:   131, loss: 1.12035, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   132, loss: 0.77890, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.995 
start evaluate engines...
label: Dsa, precision: 0.948 recall: 0.955 f1: 0.948 
label: Chk, precision: 0.667 recall: 0.667 f1: 0.667 
label: Ins, precision: 0.322 recall: 0.240 f1: 0.269 
label: Sur, precision: 0.964 recall: 0.978 f1: 0.968 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.921 recall: 0.939 f1: 0.928 
time consumption:1.99(min), precision: 0.936 recall: 0.924 f1: 0.929 accuracy: 0.986 
epoch:21/100
training batch:     1, loss: 0.87712, precision: 0.974 recall: 0.902 f1: 0.937 accuracy: 0.995 
training batch:     2, loss: 0.44418, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:     3, loss: 0.34389, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.998 
training batch:     4, loss: 0.34830, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.999 
training batch:     5, loss: 0.85829, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.998 
training batch:     6, loss: 0.83151, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.995 
training batch:     7, loss: 0.74998, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.996 
training batch:     8, loss: 0.44200, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:     9, loss: 0.80568, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.993 
training batch:    10, loss: 1.62950, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.996 
training batch:    11, loss: 1.72710, precision: 0.914 recall: 0.970 f1: 0.941 accuracy: 0.993 
training batch:    12, loss: 0.62444, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.999 
training batch:    13, loss: 0.57330, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.998 
training batch:    14, loss: 0.84879, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.998 
training batch:    15, loss: 0.69847, precision: 0.929 recall: 0.907 f1: 0.918 accuracy: 0.995 
training batch:    16, loss: 0.91524, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.998 
training batch:    17, loss: 0.32831, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    18, loss: 0.34840, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.999 
training batch:    19, loss: 0.98959, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.996 
training batch:    20, loss: 3.45779, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.994 
training batch:    21, loss: 0.20819, precision: 0.953 recall: 0.976 f1: 0.965 accuracy: 0.999 
training batch:    22, loss: 0.37744, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:    23, loss: 1.36960, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.995 
training batch:    24, loss: 0.21881, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    25, loss: 1.24153, precision: 0.973 recall: 0.900 f1: 0.935 accuracy: 0.996 
training batch:    26, loss: 1.95197, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.995 
training batch:    27, loss: 0.43936, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:    28, loss: 1.65793, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.986 
training batch:    29, loss: 0.25757, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    30, loss: 1.33995, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.995 
training batch:    31, loss: 0.57562, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.998 
training batch:    32, loss: 0.62003, precision: 0.912 recall: 0.969 f1: 0.939 accuracy: 0.996 
training batch:    33, loss: 2.22592, precision: 0.960 recall: 0.828 f1: 0.889 accuracy: 0.994 
training batch:    34, loss: 0.53735, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.999 
training batch:    35, loss: 2.78702, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.995 
training batch:    36, loss: 2.83810, precision: 0.968 recall: 0.909 f1: 0.937 accuracy: 0.990 
training batch:    37, loss: 0.94746, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    38, loss: 1.17659, precision: 0.921 recall: 0.972 f1: 0.946 accuracy: 0.998 
training batch:    39, loss: 0.10071, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.85562, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    41, loss: 0.17714, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    42, loss: 0.55183, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:    43, loss: 0.40489, precision: 0.958 recall: 0.958 f1: 0.958 accuracy: 0.999 
training batch:    44, loss: 4.61673, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.995 
training batch:    45, loss: 0.57452, precision: 0.962 recall: 1.000 f1: 0.980 accuracy: 0.999 
training batch:    46, loss: 0.88344, precision: 1.000 recall: 0.958 f1: 0.979 accuracy: 0.996 
training batch:    47, loss: 0.60667, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    48, loss: 0.25018, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    49, loss: 0.21254, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    50, loss: 0.99178, precision: 0.947 recall: 1.000 f1: 0.973 accuracy: 0.996 
training batch:    51, loss: 0.34431, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:    52, loss: 3.78244, precision: 0.826 recall: 0.974 f1: 0.894 accuracy: 0.989 
training batch:    53, loss: 0.23595, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    54, loss: 0.93712, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.998 
training batch:    55, loss: 0.74870, precision: 0.913 recall: 0.913 f1: 0.913 accuracy: 0.995 
training batch:    56, loss: 0.56012, precision: 0.958 recall: 1.000 f1: 0.979 accuracy: 0.998 
training batch:    57, loss: 1.37755, precision: 1.000 recall: 0.943 f1: 0.971 accuracy: 0.998 
training batch:    58, loss: 0.39934, precision: 0.962 recall: 1.000 f1: 0.980 accuracy: 0.999 
training batch:    59, loss: 1.14021, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.995 
training batch:    60, loss: 0.52718, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:    61, loss: 0.55373, precision: 0.977 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:    62, loss: 0.55516, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:    63, loss: 0.63564, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.999 
training batch:    64, loss: 0.95149, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.996 
training batch:    65, loss: 0.51959, precision: 0.968 recall: 0.909 f1: 0.937 accuracy: 0.998 
training batch:    66, loss: 1.10297, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.996 
training batch:    67, loss: 0.31506, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    68, loss: 0.25549, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    69, loss: 0.56543, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    70, loss: 1.90218, precision: 0.933 recall: 0.977 f1: 0.955 accuracy: 0.993 
training batch:    71, loss: 0.89772, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:    72, loss: 0.34816, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.999 
training batch:    73, loss: 0.63049, precision: 1.000 recall: 0.980 f1: 0.990 accuracy: 0.999 
training batch:    74, loss: 0.22459, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    75, loss: 0.81010, precision: 0.953 recall: 1.000 f1: 0.976 accuracy: 0.998 
training batch:    76, loss: 0.93701, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.998 
training batch:    77, loss: 0.51006, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.999 
training batch:    78, loss: 0.08636, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    79, loss: 1.59384, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.990 
training batch:    80, loss: 1.04555, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.993 
training batch:    81, loss: 0.68359, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:    82, loss: 0.97462, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.996 
training batch:    83, loss: 0.68709, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    84, loss: 0.75797, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    85, loss: 0.55461, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:    86, loss: 0.29172, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.999 
training batch:    87, loss: 0.28680, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:    88, loss: 0.81433, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:    89, loss: 0.33708, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:    90, loss: 2.28917, precision: 0.920 recall: 1.000 f1: 0.958 accuracy: 0.995 
training batch:    91, loss: 1.84879, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.995 
training batch:    92, loss: 0.25476, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    93, loss: 1.38846, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.996 
training batch:    94, loss: 0.83272, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.998 
training batch:    95, loss: 0.76099, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.998 
training batch:    96, loss: 0.74484, precision: 0.960 recall: 1.000 f1: 0.980 accuracy: 0.998 
training batch:    97, loss: 0.78432, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.996 
training batch:    98, loss: 0.98805, precision: 0.974 recall: 0.925 f1: 0.949 accuracy: 0.995 
training batch:    99, loss: 0.32368, precision: 1.000 recall: 0.978 f1: 0.989 accuracy: 0.999 
training batch:   100, loss: 1.00241, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.998 
training batch:   101, loss: 0.54330, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   102, loss: 1.93141, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.988 
training batch:   103, loss: 1.69931, precision: 0.923 recall: 1.000 f1: 0.960 accuracy: 0.996 
training batch:   104, loss: 0.63733, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.998 
training batch:   105, loss: 1.56819, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.996 
training batch:   106, loss: 1.79083, precision: 0.929 recall: 0.897 f1: 0.912 accuracy: 0.995 
training batch:   107, loss: 0.59492, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.999 
training batch:   108, loss: 0.98824, precision: 0.935 recall: 1.000 f1: 0.967 accuracy: 0.998 
training batch:   109, loss: 0.13667, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   110, loss: 1.34731, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.995 
training batch:   111, loss: 0.39552, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:   112, loss: 1.12650, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:   113, loss: 0.61647, precision: 0.962 recall: 0.926 f1: 0.943 accuracy: 0.998 
training batch:   114, loss: 0.50722, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.996 
training batch:   115, loss: 0.31160, precision: 1.000 recall: 0.952 f1: 0.976 accuracy: 0.999 
training batch:   116, loss: 0.68469, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.998 
training batch:   117, loss: 0.51503, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.999 
training batch:   118, loss: 0.82991, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   119, loss: 0.94778, precision: 0.940 recall: 0.959 f1: 0.949 accuracy: 0.996 
training batch:   120, loss: 0.19928, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   121, loss: 2.33263, precision: 0.884 recall: 0.927 f1: 0.905 accuracy: 0.991 
training batch:   122, loss: 0.47575, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   123, loss: 0.70239, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:   124, loss: 0.44821, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.998 
training batch:   125, loss: 1.06689, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.996 
training batch:   126, loss: 0.15628, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   127, loss: 0.48991, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   128, loss: 0.40407, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.998 
training batch:   129, loss: 6.81430, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.979 
training batch:   130, loss: 0.17059, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   131, loss: 0.17157, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   132, loss: 0.17593, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.960 recall: 0.969 f1: 0.962 
label: Chk, precision: 0.667 recall: 0.633 f1: 0.644 
label: Ins, precision: 0.306 recall: 0.240 f1: 0.264 
label: Sur, precision: 1.000 recall: 1.000 f1: 1.000 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.911 recall: 0.930 f1: 0.919 
time consumption:1.98(min), precision: 0.938 recall: 0.928 f1: 0.932 accuracy: 0.988 
epoch:22/100
training batch:     1, loss: 1.07103, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.998 
training batch:     2, loss: 0.58951, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:     3, loss: 0.79257, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.993 
training batch:     4, loss: 0.68898, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.996 
training batch:     5, loss: 0.58684, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.999 
training batch:     6, loss: 1.60649, precision: 0.889 recall: 1.000 f1: 0.941 accuracy: 0.995 
training batch:     7, loss: 0.22797, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:     8, loss: 0.67514, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:     9, loss: 1.38066, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.998 
training batch:    10, loss: 1.49324, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.993 
training batch:    11, loss: 1.72678, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.996 
training batch:    12, loss: 1.21945, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    13, loss: 1.85919, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.998 
training batch:    14, loss: 1.29604, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.994 
training batch:    15, loss: 0.42291, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    16, loss: 0.39700, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.999 
training batch:    17, loss: 1.13480, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.996 
training batch:    18, loss: 1.02429, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.996 
training batch:    19, loss: 3.04747, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.991 
training batch:    20, loss: 0.33502, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    21, loss: 0.41652, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    22, loss: 0.33044, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    23, loss: 0.78014, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:    24, loss: 0.24734, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:    25, loss: 0.54843, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:    26, loss: 0.44505, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    27, loss: 0.82484, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    28, loss: 0.46135, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.999 
training batch:    29, loss: 0.56691, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.999 
training batch:    30, loss: 0.39104, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.999 
training batch:    31, loss: 0.61067, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    32, loss: 0.78876, precision: 0.917 recall: 0.971 f1: 0.943 accuracy: 0.996 
training batch:    33, loss: 2.24258, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.991 
training batch:    34, loss: 0.56453, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    35, loss: 0.62361, precision: 0.944 recall: 0.919 f1: 0.932 accuracy: 0.996 
training batch:    36, loss: 0.36629, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:    37, loss: 0.16936, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    38, loss: 0.10635, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    39, loss: 4.52162, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.988 
training batch:    40, loss: 0.52170, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    41, loss: 0.09959, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    42, loss: 1.06711, precision: 0.865 recall: 0.970 f1: 0.914 accuracy: 0.995 
training batch:    43, loss: 0.59537, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.998 
training batch:    44, loss: 3.27550, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.984 
training batch:    45, loss: 1.10516, precision: 0.977 recall: 1.000 f1: 0.988 accuracy: 0.996 
training batch:    46, loss: 1.88470, precision: 0.879 recall: 0.967 f1: 0.921 accuracy: 0.995 
training batch:    47, loss: 1.12230, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.995 
training batch:    48, loss: 2.90472, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.991 
training batch:    49, loss: 0.86215, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:    50, loss: 6.92506, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.989 
training batch:    51, loss: 0.66278, precision: 1.000 recall: 0.975 f1: 0.987 accuracy: 0.999 
training batch:    52, loss: 1.50784, precision: 0.971 recall: 0.919 f1: 0.944 accuracy: 0.996 
training batch:    53, loss: 0.63158, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.998 
training batch:    54, loss: 0.84717, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.998 
training batch:    55, loss: 1.26593, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.994 
training batch:    56, loss: 4.24884, precision: 0.884 recall: 0.927 f1: 0.905 accuracy: 0.985 
training batch:    57, loss: 0.47464, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:    58, loss: 2.68864, precision: 0.943 recall: 0.846 f1: 0.892 accuracy: 0.993 
training batch:    59, loss: 2.80614, precision: 0.879 recall: 0.879 f1: 0.879 accuracy: 0.989 
training batch:    60, loss: 0.50142, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    61, loss: 1.84985, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.995 
training batch:    62, loss: 0.61217, precision: 0.938 recall: 1.000 f1: 0.968 accuracy: 0.998 
training batch:    63, loss: 0.99657, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    64, loss: 1.20065, precision: 1.000 recall: 0.975 f1: 0.987 accuracy: 0.995 
training batch:    65, loss: 2.44080, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.988 
training batch:    66, loss: 3.81395, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.976 
training batch:    67, loss: 0.77591, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.998 
training batch:    68, loss: 2.15451, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.989 
training batch:    69, loss: 5.55753, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.993 
training batch:    70, loss: 1.84816, precision: 0.952 recall: 0.930 f1: 0.941 accuracy: 0.989 
training batch:    71, loss: 0.85988, precision: 0.893 recall: 0.962 f1: 0.926 accuracy: 0.996 
training batch:    72, loss: 1.79958, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.996 
training batch:    73, loss: 4.27536, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.994 
training batch:    74, loss: 1.22469, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    75, loss: 0.59036, precision: 0.957 recall: 1.000 f1: 0.978 accuracy: 0.999 
training batch:    76, loss: 3.34792, precision: 0.880 recall: 0.917 f1: 0.898 accuracy: 0.991 
training batch:    77, loss: 0.14812, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    78, loss: 0.61259, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.998 
training batch:    79, loss: 0.99117, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.998 
training batch:    80, loss: 2.66965, precision: 0.892 recall: 0.943 f1: 0.917 accuracy: 0.990 
training batch:    81, loss: 3.84932, precision: 0.909 recall: 0.833 f1: 0.870 accuracy: 0.990 
training batch:    82, loss: 0.89474, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.996 
training batch:    83, loss: 2.38432, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.993 
training batch:    84, loss: 0.63326, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:    85, loss: 0.96710, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.996 
training batch:    86, loss: 0.77362, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.998 
training batch:    87, loss: 1.62971, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.993 
training batch:    88, loss: 1.31212, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.996 
training batch:    89, loss: 2.57904, precision: 0.909 recall: 0.882 f1: 0.896 accuracy: 0.991 
training batch:    90, loss: 2.57678, precision: 0.944 recall: 0.919 f1: 0.932 accuracy: 0.994 
training batch:    91, loss: 0.41254, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.999 
training batch:    92, loss: 1.33237, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.998 
training batch:    93, loss: 2.00655, precision: 0.938 recall: 0.918 f1: 0.928 accuracy: 0.993 
training batch:    94, loss: 1.49905, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.998 
training batch:    95, loss: 3.07039, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.994 
training batch:    96, loss: 0.28397, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    97, loss: 2.81340, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.989 
training batch:    98, loss: 1.91302, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.989 
training batch:    99, loss: 0.75902, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   100, loss: 0.60672, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   101, loss: 1.25522, precision: 0.923 recall: 0.960 f1: 0.941 accuracy: 0.995 
training batch:   102, loss: 1.33978, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.996 
training batch:   103, loss: 0.96208, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.996 
training batch:   104, loss: 0.26801, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.999 
training batch:   105, loss: 2.33298, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.985 
training batch:   106, loss: 0.31575, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.999 
training batch:   107, loss: 1.15074, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.995 
training batch:   108, loss: 0.95898, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.996 
training batch:   109, loss: 0.77844, precision: 0.974 recall: 0.950 f1: 0.962 accuracy: 0.993 
training batch:   110, loss: 0.79002, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.998 
training batch:   111, loss: 1.70303, precision: 0.957 recall: 0.880 f1: 0.917 accuracy: 0.993 
training batch:   112, loss: 0.16682, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   113, loss: 0.62515, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   114, loss: 2.89401, precision: 0.952 recall: 0.909 f1: 0.930 accuracy: 0.994 
training batch:   115, loss: 1.75708, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.995 
training batch:   116, loss: 1.48787, precision: 0.861 recall: 0.912 f1: 0.886 accuracy: 0.995 
training batch:   117, loss: 3.00725, precision: 0.894 recall: 0.955 f1: 0.923 accuracy: 0.988 
training batch:   118, loss: 1.22336, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.994 
training batch:   119, loss: 0.07713, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 2.12895, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.988 
training batch:   121, loss: 3.80267, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.986 
training batch:   122, loss: 0.57072, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:   123, loss: 0.63089, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:   124, loss: 1.94104, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.988 
training batch:   125, loss: 0.43944, precision: 1.000 recall: 0.962 f1: 0.980 accuracy: 0.999 
training batch:   126, loss: 0.19832, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   127, loss: 2.09532, precision: 0.920 recall: 0.939 f1: 0.929 accuracy: 0.985 
training batch:   128, loss: 0.82910, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:   129, loss: 3.21361, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.985 
training batch:   130, loss: 0.35185, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.998 
training batch:   131, loss: 0.94191, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.996 
training batch:   132, loss: 0.61218, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.998 
start evaluate engines...
label: Dsa, precision: 0.920 recall: 0.880 f1: 0.898 
label: Chk, precision: 0.633 recall: 0.667 f1: 0.644 
label: Ins, precision: 0.300 recall: 0.196 f1: 0.232 
label: Sur, precision: 0.948 recall: 1.000 f1: 0.970 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.928 recall: 0.921 f1: 0.923 
time consumption:1.88(min), precision: 0.934 recall: 0.900 f1: 0.916 accuracy: 0.984 
epoch:23/100
training batch:     1, loss: 0.37267, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.999 
training batch:     2, loss: 1.36690, precision: 0.947 recall: 0.900 f1: 0.923 accuracy: 0.995 
training batch:     3, loss: 1.25665, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.998 
training batch:     4, loss: 0.74306, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.996 
training batch:     5, loss: 0.39261, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:     6, loss: 2.32402, precision: 0.927 recall: 0.927 f1: 0.927 accuracy: 0.993 
training batch:     7, loss: 0.22795, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:     8, loss: 1.08931, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.995 
training batch:     9, loss: 1.93614, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.996 
training batch:    10, loss: 0.30907, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:    11, loss: 3.71622, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.994 
training batch:    12, loss: 0.45845, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    13, loss: 3.03700, precision: 0.929 recall: 0.951 f1: 0.940 accuracy: 0.991 
training batch:    14, loss: 1.33603, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.998 
training batch:    15, loss: 1.50652, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.996 
training batch:    16, loss: 0.89397, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.996 
training batch:    17, loss: 1.30536, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.998 
training batch:    18, loss: 2.70334, precision: 0.944 recall: 0.919 f1: 0.932 accuracy: 0.990 
training batch:    19, loss: 1.30490, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.993 
training batch:    20, loss: 1.52675, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.995 
training batch:    21, loss: 0.79691, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.996 
training batch:    22, loss: 0.65591, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:    23, loss: 0.61044, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.998 
training batch:    24, loss: 0.94310, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.998 
training batch:    25, loss: 0.94676, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.996 
training batch:    26, loss: 0.97607, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.998 
training batch:    27, loss: 1.24271, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.998 
training batch:    28, loss: 0.29434, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    29, loss: 0.69397, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    30, loss: 0.37209, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    31, loss: 0.66943, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:    32, loss: 0.79083, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.998 
training batch:    33, loss: 2.10695, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.993 
training batch:    34, loss: 2.24059, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.990 
training batch:    35, loss: 1.07219, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.995 
training batch:    36, loss: 1.36694, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.991 
training batch:    37, loss: 0.24103, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    38, loss: 0.99661, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    39, loss: 0.47008, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    40, loss: 0.08075, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    41, loss: 2.12135, precision: 0.946 recall: 1.000 f1: 0.972 accuracy: 0.995 
training batch:    42, loss: 1.47418, precision: 0.947 recall: 0.923 f1: 0.935 accuracy: 0.995 
training batch:    43, loss: 0.76883, precision: 0.974 recall: 0.925 f1: 0.949 accuracy: 0.998 
training batch:    44, loss: 0.43559, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:    45, loss: 1.21638, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.995 
training batch:    46, loss: 1.50346, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.994 
training batch:    47, loss: 1.02654, precision: 0.929 recall: 0.951 f1: 0.940 accuracy: 0.995 
training batch:    48, loss: 1.89389, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.996 
training batch:    49, loss: 0.27795, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    50, loss: 0.25639, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    51, loss: 0.39729, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    52, loss: 1.23268, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.998 
training batch:    53, loss: 0.12402, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    54, loss: 1.40367, precision: 0.932 recall: 0.976 f1: 0.953 accuracy: 0.995 
training batch:    55, loss: 1.36246, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.996 
training batch:    56, loss: 0.36163, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:    57, loss: 1.29131, precision: 0.968 recall: 0.909 f1: 0.937 accuracy: 0.995 
training batch:    58, loss: 0.48743, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:    59, loss: 0.72990, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.998 
training batch:    60, loss: 0.19543, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    61, loss: 0.42783, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.999 
training batch:    62, loss: 0.85349, precision: 0.971 recall: 0.917 f1: 0.943 accuracy: 0.996 
training batch:    63, loss: 0.30083, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:    64, loss: 0.86763, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.998 
training batch:    65, loss: 1.06718, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.998 
training batch:    66, loss: 0.23924, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    67, loss: 0.92543, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:    68, loss: 0.50288, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:    69, loss: 0.32494, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.999 
training batch:    70, loss: 1.76892, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    71, loss: 1.12886, precision: 0.860 recall: 0.925 f1: 0.892 accuracy: 0.995 
training batch:    72, loss: 0.57780, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    73, loss: 0.47908, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    74, loss: 1.66019, precision: 0.955 recall: 1.000 f1: 0.977 accuracy: 0.998 
training batch:    75, loss: 0.90329, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.998 
training batch:    76, loss: 0.31734, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    77, loss: 0.34393, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    78, loss: 0.22826, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:    79, loss: 0.83688, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.998 
training batch:    80, loss: 1.66377, precision: 0.875 recall: 0.933 f1: 0.903 accuracy: 0.995 
training batch:    81, loss: 1.19194, precision: 1.000 recall: 0.931 f1: 0.964 accuracy: 0.998 
training batch:    82, loss: 1.28905, precision: 1.000 recall: 0.900 f1: 0.947 accuracy: 0.995 
training batch:    83, loss: 2.23613, precision: 0.977 recall: 0.956 f1: 0.966 accuracy: 0.998 
training batch:    84, loss: 0.84067, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.996 
training batch:    85, loss: 0.68692, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    86, loss: 0.09863, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    87, loss: 0.21355, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    88, loss: 0.78560, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:    89, loss: 1.12598, precision: 0.964 recall: 0.931 f1: 0.947 accuracy: 0.996 
training batch:    90, loss: 4.71754, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.985 
training batch:    91, loss: 0.32848, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.999 
training batch:    92, loss: 0.32404, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.999 
training batch:    93, loss: 0.80826, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.996 
training batch:    94, loss: 0.30844, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.998 
training batch:    95, loss: 0.66353, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    96, loss: 0.41998, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:    97, loss: 0.60355, precision: 0.958 recall: 0.958 f1: 0.958 accuracy: 0.995 
training batch:    98, loss: 0.54234, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    99, loss: 1.65964, precision: 0.893 recall: 1.000 f1: 0.943 accuracy: 0.995 
training batch:   100, loss: 0.62389, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.998 
training batch:   101, loss: 0.28445, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   102, loss: 5.47353, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.980 
training batch:   103, loss: 1.10643, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.996 
training batch:   104, loss: 1.31503, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.994 
training batch:   105, loss: 1.48808, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.990 
training batch:   106, loss: 1.97107, precision: 0.850 recall: 0.971 f1: 0.907 accuracy: 0.994 
training batch:   107, loss: 0.26495, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   108, loss: 0.24094, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   109, loss: 1.40129, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.995 
training batch:   110, loss: 0.82971, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.996 
training batch:   111, loss: 0.35063, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:   112, loss: 0.50308, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   113, loss: 0.20074, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   114, loss: 0.84918, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.998 
training batch:   115, loss: 1.28500, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.994 
training batch:   116, loss: 0.76910, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.996 
training batch:   117, loss: 0.67255, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:   118, loss: 1.28706, precision: 1.000 recall: 0.977 f1: 0.988 accuracy: 0.996 
training batch:   119, loss: 0.09845, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.32027, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   121, loss: 0.99702, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.996 
training batch:   122, loss: 0.17119, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   123, loss: 0.46648, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.999 
training batch:   124, loss: 0.37222, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.999 
training batch:   125, loss: 1.18611, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   126, loss: 0.17276, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   127, loss: 0.29297, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.998 
training batch:   128, loss: 1.71831, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.994 
training batch:   129, loss: 0.75742, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.996 
training batch:   130, loss: 1.76729, precision: 0.857 recall: 1.000 f1: 0.923 accuracy: 0.994 
training batch:   131, loss: 0.77859, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:   132, loss: 1.79181, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.978 
start evaluate engines...
label: Dsa, precision: 0.980 recall: 0.981 f1: 0.979 
label: Chk, precision: 0.633 recall: 0.667 f1: 0.644 
label: Ins, precision: 0.389 recall: 0.279 f1: 0.319 
label: Sur, precision: 0.964 recall: 0.956 f1: 0.960 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.919 recall: 0.922 f1: 0.919 
time consumption:1.79(min), precision: 0.943 recall: 0.928 f1: 0.935 accuracy: 0.988 
epoch:24/100
training batch:     1, loss: 0.40456, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.998 
training batch:     2, loss: 0.64017, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.998 
training batch:     3, loss: 1.22719, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.995 
training batch:     4, loss: 0.13148, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:     5, loss: 1.94295, precision: 0.978 recall: 0.957 f1: 0.967 accuracy: 0.996 
training batch:     6, loss: 0.28256, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.999 
training batch:     7, loss: 0.56467, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.999 
training batch:     8, loss: 0.12842, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:     9, loss: 0.38486, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    10, loss: 0.87712, precision: 0.960 recall: 1.000 f1: 0.980 accuracy: 0.999 
training batch:    11, loss: 0.30408, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    12, loss: 0.08247, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    13, loss: 1.88844, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.993 
training batch:    14, loss: 0.60646, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.999 
training batch:    15, loss: 0.83231, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:    16, loss: 0.71460, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:    17, loss: 1.02245, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:    18, loss: 0.04263, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    19, loss: 0.25046, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.999 
training batch:    20, loss: 2.60277, precision: 0.917 recall: 1.000 f1: 0.957 accuracy: 0.994 
training batch:    21, loss: 0.08908, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    22, loss: 0.21945, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.999 
training batch:    23, loss: 0.27321, precision: 1.000 recall: 0.975 f1: 0.987 accuracy: 0.999 
training batch:    24, loss: 0.79308, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.996 
training batch:    25, loss: 0.16135, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    26, loss: 2.26994, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.995 
training batch:    27, loss: 0.46834, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    28, loss: 0.16165, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    29, loss: 0.35197, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    30, loss: 0.46028, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    31, loss: 0.77243, precision: 0.920 recall: 1.000 f1: 0.958 accuracy: 0.998 
training batch:    32, loss: 0.23906, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    33, loss: 0.21184, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    34, loss: 0.59363, precision: 0.909 recall: 0.952 f1: 0.930 accuracy: 0.998 
training batch:    35, loss: 0.90764, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.995 
training batch:    36, loss: 0.54031, precision: 1.000 recall: 0.975 f1: 0.987 accuracy: 0.999 
training batch:    37, loss: 1.54579, precision: 0.882 recall: 0.909 f1: 0.896 accuracy: 0.989 
training batch:    38, loss: 0.84138, precision: 0.974 recall: 0.950 f1: 0.962 accuracy: 0.995 
training batch:    39, loss: 0.07152, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    40, loss: 0.45688, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.998 
training batch:    41, loss: 0.32323, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    42, loss: 0.26161, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    43, loss: 1.27411, precision: 0.882 recall: 0.968 f1: 0.923 accuracy: 0.995 
training batch:    44, loss: 0.14310, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    45, loss: 0.37468, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:    46, loss: 1.70741, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.996 
training batch:    47, loss: 1.39807, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.996 
training batch:    48, loss: 0.54597, precision: 0.936 recall: 1.000 f1: 0.967 accuracy: 0.996 
training batch:    49, loss: 0.20761, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    50, loss: 0.10318, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    51, loss: 0.27179, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:    52, loss: 0.25356, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.999 
training batch:    53, loss: 0.21654, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    54, loss: 0.61900, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    55, loss: 0.79787, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.998 
training batch:    56, loss: 0.51184, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:    57, loss: 0.37338, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:    58, loss: 0.20274, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    59, loss: 0.41533, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:    60, loss: 0.29503, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    61, loss: 0.26605, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    62, loss: 0.36868, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.998 
training batch:    63, loss: 0.32439, precision: 1.000 recall: 0.958 f1: 0.979 accuracy: 0.998 
training batch:    64, loss: 0.36328, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.999 
training batch:    65, loss: 0.38795, precision: 0.955 recall: 0.977 f1: 0.966 accuracy: 0.999 
training batch:    66, loss: 0.10768, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    67, loss: 0.22864, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    68, loss: 0.24248, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:    69, loss: 0.53287, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    70, loss: 0.13937, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:    71, loss: 1.36609, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.995 
training batch:    72, loss: 2.56157, precision: 0.900 recall: 0.973 f1: 0.935 accuracy: 0.995 
training batch:    73, loss: 0.23534, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    74, loss: 0.73032, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.998 
training batch:    75, loss: 0.15968, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:    76, loss: 0.51724, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.998 
training batch:    77, loss: 0.21655, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    78, loss: 1.04617, precision: 0.895 recall: 0.971 f1: 0.932 accuracy: 0.995 
training batch:    79, loss: 0.55205, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:    80, loss: 0.39676, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.998 
training batch:    81, loss: 1.45805, precision: 1.000 recall: 0.947 f1: 0.973 accuracy: 0.996 
training batch:    82, loss: 1.45663, precision: 0.941 recall: 0.889 f1: 0.914 accuracy: 0.994 
training batch:    83, loss: 0.15199, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    84, loss: 0.81532, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.996 
training batch:    85, loss: 1.65440, precision: 0.967 recall: 0.906 f1: 0.935 accuracy: 0.994 
training batch:    86, loss: 1.99699, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.991 
training batch:    87, loss: 0.25052, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:    88, loss: 0.40640, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:    89, loss: 0.10133, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    90, loss: 0.79840, precision: 0.921 recall: 0.972 f1: 0.946 accuracy: 0.996 
training batch:    91, loss: 0.77760, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    92, loss: 0.84198, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.996 
training batch:    93, loss: 0.30655, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    94, loss: 9.85756, precision: 0.912 recall: 0.969 f1: 0.939 accuracy: 0.989 
training batch:    95, loss: 1.89780, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.993 
training batch:    96, loss: 0.49133, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    97, loss: 1.05710, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.998 
training batch:    98, loss: 0.16420, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    99, loss: 0.41153, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   100, loss: 0.25435, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   101, loss: 2.51118, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.986 
training batch:   102, loss: 0.67203, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.999 
training batch:   103, loss: 1.66304, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.994 
training batch:   104, loss: 4.86156, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.989 
training batch:   105, loss: 2.37225, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.993 
training batch:   106, loss: 0.69025, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.998 
training batch:   107, loss: 1.48334, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.996 
training batch:   108, loss: 1.36328, precision: 0.963 recall: 0.867 f1: 0.912 accuracy: 0.995 
training batch:   109, loss: 0.76837, precision: 0.964 recall: 0.931 f1: 0.947 accuracy: 0.998 
training batch:   110, loss: 0.83525, precision: 0.955 recall: 0.933 f1: 0.944 accuracy: 0.996 
training batch:   111, loss: 0.64595, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   112, loss: 0.49237, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   113, loss: 0.59471, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   114, loss: 0.82082, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   115, loss: 1.00146, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.996 
training batch:   116, loss: 0.41078, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:   117, loss: 0.46075, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:   118, loss: 0.60747, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.995 
training batch:   119, loss: 1.65767, precision: 0.967 recall: 0.829 f1: 0.892 accuracy: 0.994 
training batch:   120, loss: 0.09406, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   121, loss: 1.97873, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.983 
training batch:   122, loss: 0.13383, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   123, loss: 0.80334, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.998 
training batch:   124, loss: 0.87932, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   125, loss: 0.94615, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:   126, loss: 0.26257, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   127, loss: 1.49802, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.995 
training batch:   128, loss: 1.06117, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.994 
training batch:   129, loss: 0.90425, precision: 0.927 recall: 0.974 f1: 0.950 accuracy: 0.998 
training batch:   130, loss: 1.44492, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.988 
training batch:   131, loss: 2.37283, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.993 
training batch:   132, loss: 1.62912, precision: 0.750 recall: 0.857 f1: 0.800 accuracy: 0.995 
start evaluate engines...
label: Dsa, precision: 0.973 recall: 0.981 f1: 0.975 
label: Chk, precision: 0.633 recall: 0.667 f1: 0.644 
label: Ins, precision: 0.273 recall: 0.212 f1: 0.234 
label: Sur, precision: 0.973 recall: 0.978 f1: 0.974 
label: Med, precision: 0.400 recall: 0.400 f1: 0.400 
label: Ana, precision: 0.919 recall: 0.923 f1: 0.919 
time consumption:1.97(min), precision: 0.936 recall: 0.926 f1: 0.931 accuracy: 0.987 
early stopped, no progress obtained within 5 epochs
overall best f1 is 0.935127345210562 at 19 epoch
total training time consumption: 48.858(min)
