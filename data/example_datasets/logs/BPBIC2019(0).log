2022-10-04 17:13:21
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY++++++++++++++++++++++++++++++++++++++++
 Status:
     mode                 : train
 ++++++++++++++++++++++++++++++++++++++++
 Datasets:
     datasets         fold: data/example_datasets/datasets
     train            file: train19.csv
     validation       file: None
     vocab             dir: data/example_datasets/vocab/2019
     delimiter            : b
     use  pretrained model: True
     pretrained      model: Bert
     finetune             : False
     use    middle   model: True
     middle          model: bilstm+idcnn
     checkpoints       dir: checkpoints/BPBIC(2019)
     log               dir: data/example_datasets/logs
 ++++++++++++++++++++++++++++++++++++++++
Labeling Scheme:
     label          scheme: BIO
     label           level: 2
     suffixes             : ['Dsa', 'Chk', 'Ins', 'Sur', 'Med', 'Ana']
     measuring     metrics: ['precision', 'recall', 'f1', 'accuracy']
 ++++++++++++++++++++++++++++++++++++++++
Model Configuration:
     embedding         dim: 100
     max  sequence  length: 100
     hidden            dim: 128
     filter           nums: 64
     idcnn            nums: 3
     CUDA  VISIBLE  DEVICE: 0
     seed                 : 23
 ++++++++++++++++++++++++++++++++++++++++
 Training Settings:
     epoch                : 100
     batch            size: 8
     dropout              : 0.3
     learning         rate: 0.001
     optimizer            : Adam
     use               gan: True
     gan            method: pgd
     checkpoint       name: model_our
     max       checkpoints: 3
     print       per_batch: 1
     is     early     stop: True
     patient              : 5
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY END++++++++++++++++++++++++++++++++++++++++
label vocab files not exist, building label vocab...
dataManager initialed...
mode: train
loading data...
validating set is not exist, built...
training set size: 1427, validating set size: 159
++++++++++++++++++++training starting++++++++++++++++++++
epoch:1/100
training batch:     1, loss: 283.46939, precision: 0.023 recall: 0.080 f1: 0.036 accuracy: 0.022 
training batch:     2, loss: 263.76990, precision: 0.006 recall: 0.051 f1: 0.011 accuracy: 0.035 
training batch:     3, loss: 255.72955, precision: 0.028 recall: 0.275 f1: 0.050 accuracy: 0.014 
training batch:     4, loss: 286.89996, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.771 
training batch:     5, loss: 194.10103, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.825 
training batch:     6, loss: 225.57709, precision: 0.014 recall: 0.167 f1: 0.026 accuracy: 0.410 
training batch:     7, loss: 228.24010, precision: 0.014 recall: 0.061 f1: 0.022 accuracy: 0.345 
training batch:     8, loss: 217.83614, precision: 0.031 recall: 0.128 f1: 0.050 accuracy: 0.459 
training batch:     9, loss: 127.87091, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.786 
training batch:    10, loss: 168.29019, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.787 
training batch:    11, loss: 180.55893, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.875 
training batch:    12, loss: 168.48199, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.864 
training batch:    13, loss: 145.92926, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.810 
training batch:    14, loss: 179.40674, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.739 
training batch:    15, loss: 120.19273, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.794 
training batch:    16, loss: 127.48219, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.674 
training batch:    17, loss: 98.37759, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.819 
training batch:    18, loss: 123.86502, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.851 
training batch:    19, loss: 139.13873, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.787 
training batch:    20, loss: 90.63300, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.835 
training batch:    21, loss: 99.18951, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.810 
training batch:    22, loss: 111.40835, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.754 
training batch:    23, loss: 120.40331, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.792 
training batch:    24, loss: 115.82395, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.792 
training batch:    25, loss: 81.72267, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.771 
training batch:    26, loss: 95.51212, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.820 
training batch:    27, loss: 104.30138, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.775 
training batch:    28, loss: 83.33638, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.802 
training batch:    29, loss: 80.70135, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.786 
training batch:    30, loss: 66.11375, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.800 
training batch:    31, loss: 83.26705, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.810 
training batch:    32, loss: 60.73596, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.859 
training batch:    33, loss: 83.31879, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.756 
training batch:    34, loss: 84.32682, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.858 
training batch:    35, loss: 84.96015, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.831 
training batch:    36, loss: 59.95658, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.870 
training batch:    37, loss: 62.63598, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.859 
training batch:    38, loss: 77.43508, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.767 
training batch:    39, loss: 69.09890, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.786 
training batch:    40, loss: 61.19027, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.824 
training batch:    41, loss: 45.58917, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.833 
training batch:    42, loss: 59.64206, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.819 
training batch:    43, loss: 49.23708, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.876 
training batch:    44, loss: 60.68127, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.834 
training batch:    45, loss: 89.18236, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.746 
training batch:    46, loss: 56.14913, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.807 
training batch:    47, loss: 57.92996, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.834 
training batch:    48, loss: 43.21439, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.910 
training batch:    49, loss: 57.69287, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.831 
training batch:    50, loss: 43.39687, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.856 
training batch:    51, loss: 45.61194, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.865 
training batch:    52, loss: 48.42992, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.854 
training batch:    53, loss: 40.63985, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.853 
training batch:    54, loss: 41.59402, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.860 
training batch:    55, loss: 62.92873, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.796 
training batch:    56, loss: 49.16193, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.854 
training batch:    57, loss: 60.19336, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.880 
training batch:    58, loss: 63.20611, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.781 
training batch:    59, loss: 83.23194, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.818 
training batch:    60, loss: 47.27730, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.838 
training batch:    61, loss: 39.76142, precision: 0.500 recall: 0.111 f1: 0.182 accuracy: 0.891 
training batch:    62, loss: 56.69656, precision: 0.500 recall: 0.079 f1: 0.136 accuracy: 0.838 
training batch:    63, loss: 50.91254, precision: 0.200 recall: 0.056 f1: 0.087 accuracy: 0.868 
training batch:    64, loss: 61.81072, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.824 
training batch:    65, loss: 48.59405, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.868 
training batch:    66, loss: 58.50539, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.829 
training batch:    67, loss: 50.82966, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.860 
training batch:    68, loss: 44.56336, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.876 
training batch:    69, loss: 37.12696, precision: 0.500 recall: 0.036 f1: 0.067 accuracy: 0.876 
training batch:    70, loss: 43.22702, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.854 
training batch:    71, loss: 32.53545, precision: 0.500 recall: 0.077 f1: 0.133 accuracy: 0.904 
training batch:    72, loss: 34.20572, precision: 0.467 recall: 0.171 f1: 0.250 accuracy: 0.901 
training batch:    73, loss: 43.09682, precision: 0.200 recall: 0.077 f1: 0.111 accuracy: 0.875 
training batch:    74, loss: 44.88103, precision: 0.200 recall: 0.062 f1: 0.095 accuracy: 0.909 
training batch:    75, loss: 40.08975, precision: 0.154 recall: 0.062 f1: 0.089 accuracy: 0.881 
training batch:    76, loss: 51.28740, precision: 0.333 recall: 0.119 f1: 0.175 accuracy: 0.843 
training batch:    77, loss: 54.35773, precision: 0.429 recall: 0.162 f1: 0.235 accuracy: 0.858 
training batch:    78, loss: 38.35900, precision: 0.425 recall: 0.415 f1: 0.420 accuracy: 0.881 
training batch:    79, loss: 33.87264, precision: 0.222 recall: 0.286 f1: 0.250 accuracy: 0.904 
training batch:    80, loss: 31.34435, precision: 0.296 recall: 0.308 f1: 0.302 accuracy: 0.912 
training batch:    81, loss: 33.74324, precision: 0.333 recall: 0.025 f1: 0.047 accuracy: 0.904 
training batch:    82, loss: 28.16740, precision: 0.500 recall: 0.118 f1: 0.190 accuracy: 0.927 
training batch:    83, loss: 33.66452, precision: 0.167 recall: 0.025 f1: 0.043 accuracy: 0.904 
training batch:    84, loss: 29.53012, precision: 0.154 recall: 0.087 f1: 0.111 accuracy: 0.909 
training batch:    85, loss: 53.33344, precision: 0.231 recall: 0.162 f1: 0.190 accuracy: 0.865 
training batch:    86, loss: 48.23289, precision: 0.343 recall: 0.333 f1: 0.338 accuracy: 0.880 
training batch:    87, loss: 35.79755, precision: 0.311 recall: 0.368 f1: 0.337 accuracy: 0.889 
training batch:    88, loss: 29.36123, precision: 0.250 recall: 0.200 f1: 0.222 accuracy: 0.926 
training batch:    89, loss: 40.75855, precision: 0.389 recall: 0.368 f1: 0.378 accuracy: 0.885 
training batch:    90, loss: 61.45836, precision: 0.381 recall: 0.178 f1: 0.242 accuracy: 0.831 
training batch:    91, loss: 32.37995, precision: 0.167 recall: 0.061 f1: 0.089 accuracy: 0.899 
training batch:    92, loss: 33.82076, precision: 0.625 recall: 0.370 f1: 0.465 accuracy: 0.896 
training batch:    93, loss: 27.46073, precision: 0.455 recall: 0.161 f1: 0.238 accuracy: 0.916 
training batch:    94, loss: 38.61376, precision: 0.250 recall: 0.048 f1: 0.080 accuracy: 0.881 
training batch:    95, loss: 23.87974, precision: 0.471 recall: 0.258 f1: 0.333 accuracy: 0.935 
training batch:    96, loss: 23.02575, precision: 0.667 recall: 0.312 f1: 0.426 accuracy: 0.939 
training batch:    97, loss: 34.40876, precision: 0.667 recall: 0.350 f1: 0.459 accuracy: 0.890 
training batch:    98, loss: 35.95696, precision: 0.316 recall: 0.194 f1: 0.240 accuracy: 0.889 
training batch:    99, loss: 39.80458, precision: 0.512 recall: 0.512 f1: 0.512 accuracy: 0.858 
training batch:   100, loss: 24.02683, precision: 0.667 recall: 0.390 f1: 0.492 accuracy: 0.925 
training batch:   101, loss: 33.38680, precision: 0.400 recall: 0.130 f1: 0.197 accuracy: 0.896 
training batch:   102, loss: 30.58743, precision: 0.381 recall: 0.195 f1: 0.258 accuracy: 0.902 
training batch:   103, loss: 55.51991, precision: 0.462 recall: 0.158 f1: 0.235 accuracy: 0.886 
training batch:   104, loss: 38.28480, precision: 0.562 recall: 0.250 f1: 0.346 accuracy: 0.912 
training batch:   105, loss: 57.07135, precision: 0.562 recall: 0.231 f1: 0.327 accuracy: 0.881 
training batch:   106, loss: 42.22703, precision: 0.311 recall: 0.452 f1: 0.368 accuracy: 0.875 
training batch:   107, loss: 34.91808, precision: 0.419 recall: 0.406 f1: 0.413 accuracy: 0.882 
training batch:   108, loss: 44.50792, precision: 0.356 recall: 0.432 f1: 0.390 accuracy: 0.884 
training batch:   109, loss: 45.12779, precision: 0.304 recall: 0.452 f1: 0.364 accuracy: 0.886 
training batch:   110, loss: 29.50226, precision: 0.355 recall: 0.306 f1: 0.328 accuracy: 0.919 
training batch:   111, loss: 24.23301, precision: 0.436 recall: 0.500 f1: 0.466 accuracy: 0.921 
training batch:   112, loss: 28.63482, precision: 0.611 recall: 0.324 f1: 0.423 accuracy: 0.929 
training batch:   113, loss: 24.77865, precision: 0.533 recall: 0.320 f1: 0.400 accuracy: 0.944 
training batch:   114, loss: 43.41617, precision: 0.571 recall: 0.205 f1: 0.302 accuracy: 0.873 
training batch:   115, loss: 43.62877, precision: 0.286 recall: 0.053 f1: 0.089 accuracy: 0.892 
training batch:   116, loss: 33.88496, precision: 0.286 recall: 0.059 f1: 0.098 accuracy: 0.907 
training batch:   117, loss: 19.39400, precision: 0.615 recall: 0.235 f1: 0.340 accuracy: 0.941 
training batch:   118, loss: 27.72312, precision: 0.360 recall: 0.265 f1: 0.305 accuracy: 0.920 
training batch:   119, loss: 27.55546, precision: 0.500 recall: 0.351 f1: 0.413 accuracy: 0.921 
training batch:   120, loss: 23.30674, precision: 0.714 recall: 0.571 f1: 0.635 accuracy: 0.931 
training batch:   121, loss: 24.56261, precision: 0.457 recall: 0.533 f1: 0.492 accuracy: 0.931 
training batch:   122, loss: 31.72600, precision: 0.650 recall: 0.542 f1: 0.591 accuracy: 0.925 
training batch:   123, loss: 41.62490, precision: 0.500 recall: 0.409 f1: 0.450 accuracy: 0.871 
training batch:   124, loss: 25.14625, precision: 0.419 recall: 0.562 f1: 0.480 accuracy: 0.921 
training batch:   125, loss: 28.86092, precision: 0.606 recall: 0.500 f1: 0.548 accuracy: 0.925 
training batch:   126, loss: 31.87502, precision: 0.467 recall: 0.269 f1: 0.341 accuracy: 0.922 
training batch:   127, loss: 23.89600, precision: 0.480 recall: 0.387 f1: 0.429 accuracy: 0.932 
training batch:   128, loss: 22.21117, precision: 0.818 recall: 0.643 f1: 0.720 accuracy: 0.951 
training batch:   129, loss: 29.38459, precision: 0.562 recall: 0.400 f1: 0.468 accuracy: 0.919 
training batch:   130, loss: 60.38881, precision: 0.806 recall: 0.595 f1: 0.685 accuracy: 0.895 
training batch:   131, loss: 28.91562, precision: 0.593 recall: 0.516 f1: 0.552 accuracy: 0.907 
training batch:   132, loss: 48.34889, precision: 0.276 recall: 0.200 f1: 0.232 accuracy: 0.840 
training batch:   133, loss: 27.23226, precision: 0.472 recall: 0.415 f1: 0.442 accuracy: 0.911 
training batch:   134, loss: 59.66708, precision: 0.458 recall: 0.355 f1: 0.400 accuracy: 0.860 
training batch:   135, loss: 23.55710, precision: 0.531 recall: 0.548 f1: 0.540 accuracy: 0.939 
training batch:   136, loss: 56.62460, precision: 0.327 recall: 0.362 f1: 0.343 accuracy: 0.830 
training batch:   137, loss: 36.60503, precision: 0.500 recall: 0.345 f1: 0.408 accuracy: 0.892 
training batch:   138, loss: 33.51080, precision: 0.593 recall: 0.500 f1: 0.542 accuracy: 0.901 
training batch:   139, loss: 35.06650, precision: 0.615 recall: 0.471 f1: 0.533 accuracy: 0.910 
training batch:   140, loss: 21.59021, precision: 0.654 recall: 0.515 f1: 0.576 accuracy: 0.938 
training batch:   141, loss: 18.07056, precision: 0.704 recall: 0.543 f1: 0.613 accuracy: 0.965 
training batch:   142, loss: 30.23243, precision: 0.600 recall: 0.308 f1: 0.407 accuracy: 0.905 
training batch:   143, loss: 37.76857, precision: 0.500 recall: 0.282 f1: 0.361 accuracy: 0.887 
training batch:   144, loss: 37.18770, precision: 0.647 recall: 0.306 f1: 0.415 accuracy: 0.899 
training batch:   145, loss: 26.12457, precision: 0.500 recall: 0.472 f1: 0.486 accuracy: 0.914 
training batch:   146, loss: 29.28872, precision: 0.480 recall: 0.364 f1: 0.414 accuracy: 0.920 
training batch:   147, loss: 24.92230, precision: 0.545 recall: 0.429 f1: 0.480 accuracy: 0.911 
training batch:   148, loss: 37.24742, precision: 0.485 recall: 0.500 f1: 0.492 accuracy: 0.882 
training batch:   149, loss: 23.74727, precision: 0.679 recall: 0.594 f1: 0.633 accuracy: 0.924 
training batch:   150, loss: 17.15514, precision: 0.654 recall: 0.515 f1: 0.576 accuracy: 0.943 
training batch:   151, loss: 27.19787, precision: 0.600 recall: 0.514 f1: 0.554 accuracy: 0.919 
training batch:   152, loss: 24.69114, precision: 0.593 recall: 0.471 f1: 0.525 accuracy: 0.941 
training batch:   153, loss: 48.52469, precision: 0.533 recall: 0.571 f1: 0.552 accuracy: 0.900 
training batch:   154, loss: 26.76116, precision: 0.667 recall: 0.513 f1: 0.580 accuracy: 0.921 
training batch:   155, loss: 43.80521, precision: 0.310 recall: 0.225 f1: 0.261 accuracy: 0.874 
training batch:   156, loss: 26.44618, precision: 0.559 recall: 0.576 f1: 0.567 accuracy: 0.892 
training batch:   157, loss: 14.87146, precision: 0.519 recall: 0.483 f1: 0.500 accuracy: 0.953 
training batch:   158, loss: 32.63578, precision: 0.389 recall: 0.368 f1: 0.378 accuracy: 0.897 
training batch:   159, loss: 17.13064, precision: 0.711 recall: 0.730 f1: 0.720 accuracy: 0.951 
training batch:   160, loss: 22.96664, precision: 0.630 recall: 0.459 f1: 0.531 accuracy: 0.924 
training batch:   161, loss: 27.95105, precision: 0.731 recall: 0.559 f1: 0.633 accuracy: 0.912 
training batch:   162, loss: 28.50009, precision: 0.571 recall: 0.457 f1: 0.508 accuracy: 0.922 
training batch:   163, loss: 31.27542, precision: 0.541 recall: 0.513 f1: 0.526 accuracy: 0.895 
training batch:   164, loss: 27.10612, precision: 0.364 recall: 0.353 f1: 0.358 accuracy: 0.924 
training batch:   165, loss: 24.73457, precision: 0.714 recall: 0.606 f1: 0.656 accuracy: 0.944 
training batch:   166, loss: 18.68515, precision: 0.852 recall: 0.622 f1: 0.719 accuracy: 0.945 
training batch:   167, loss: 37.13536, precision: 0.625 recall: 0.455 f1: 0.526 accuracy: 0.889 
training batch:   168, loss: 29.64648, precision: 0.545 recall: 0.414 f1: 0.471 accuracy: 0.921 
training batch:   169, loss: 23.03671, precision: 0.559 recall: 0.528 f1: 0.543 accuracy: 0.924 
training batch:   170, loss: 23.87551, precision: 0.542 recall: 0.433 f1: 0.481 accuracy: 0.929 
training batch:   171, loss: 45.07045, precision: 0.600 recall: 0.525 f1: 0.560 accuracy: 0.859 
training batch:   172, loss: 23.27210, precision: 0.423 recall: 0.367 f1: 0.393 accuracy: 0.925 
training batch:   173, loss: 22.17295, precision: 0.619 recall: 0.481 f1: 0.542 accuracy: 0.938 
training batch:   174, loss: 23.38711, precision: 0.536 recall: 0.536 f1: 0.536 accuracy: 0.951 
training batch:   175, loss: 42.77676, precision: 0.462 recall: 0.333 f1: 0.387 accuracy: 0.875 
training batch:   176, loss: 31.01938, precision: 0.500 recall: 0.395 f1: 0.441 accuracy: 0.904 
training batch:   177, loss: 22.48723, precision: 0.618 recall: 0.488 f1: 0.545 accuracy: 0.925 
training batch:   178, loss: 18.21344, precision: 0.400 recall: 0.444 f1: 0.421 accuracy: 0.947 
start evaluate engines...
label: Dsa, precision: 0.663 recall: 0.524 f1: 0.579 
label: Chk, precision: 0.050 recall: 0.050 f1: 0.050 
label: Ins, precision: 0.000 recall: 0.000 f1: 0.000 
label: Sur, precision: 0.787 recall: 0.795 f1: 0.785 
label: Med, precision: 0.000 recall: 0.000 f1: 0.000 
label: Ana, precision: 0.628 recall: 0.662 f1: 0.641 
time consumption:2.56(min), precision: 0.684 recall: 0.604 f1: 0.640 accuracy: 0.946 
saved the new best model with f1: 0.640
epoch:2/100
training batch:     1, loss: 14.58492, precision: 0.743 recall: 0.743 f1: 0.743 accuracy: 0.971 
training batch:     2, loss: 20.70932, precision: 0.486 recall: 0.474 f1: 0.480 accuracy: 0.953 
training batch:     3, loss: 24.10545, precision: 0.600 recall: 0.484 f1: 0.536 accuracy: 0.931 
training batch:     4, loss: 20.19740, precision: 0.708 recall: 0.486 f1: 0.576 accuracy: 0.938 
training batch:     5, loss: 46.27937, precision: 0.531 recall: 0.500 f1: 0.515 accuracy: 0.882 
training batch:     6, loss: 14.41038, precision: 0.406 recall: 0.406 f1: 0.406 accuracy: 0.954 
training batch:     7, loss: 19.04289, precision: 0.300 recall: 0.444 f1: 0.358 accuracy: 0.943 
training batch:     8, loss: 15.87100, precision: 0.417 recall: 0.556 f1: 0.476 accuracy: 0.944 
training batch:     9, loss: 20.79023, precision: 0.690 recall: 0.667 f1: 0.678 accuracy: 0.935 
training batch:    10, loss: 17.87346, precision: 0.783 recall: 0.581 f1: 0.667 accuracy: 0.943 
training batch:    11, loss: 13.57523, precision: 0.562 recall: 0.562 f1: 0.562 accuracy: 0.960 
training batch:    12, loss: 20.84571, precision: 0.625 recall: 0.500 f1: 0.556 accuracy: 0.940 
training batch:    13, loss: 34.00875, precision: 0.600 recall: 0.364 f1: 0.453 accuracy: 0.916 
training batch:    14, loss: 11.68587, precision: 0.500 recall: 0.367 f1: 0.423 accuracy: 0.948 
training batch:    15, loss: 22.10039, precision: 0.579 recall: 0.458 f1: 0.512 accuracy: 0.925 
training batch:    16, loss: 17.61386, precision: 0.550 recall: 0.344 f1: 0.423 accuracy: 0.946 
training batch:    17, loss: 13.81965, precision: 0.737 recall: 0.560 f1: 0.636 accuracy: 0.963 
training batch:    18, loss: 25.57695, precision: 0.542 recall: 0.342 f1: 0.419 accuracy: 0.927 
training batch:    19, loss: 13.53209, precision: 0.559 recall: 0.576 f1: 0.567 accuracy: 0.950 
training batch:    20, loss: 22.99290, precision: 0.593 recall: 0.552 f1: 0.571 accuracy: 0.927 
training batch:    21, loss: 16.26252, precision: 0.719 recall: 0.697 f1: 0.708 accuracy: 0.949 
training batch:    22, loss: 20.62154, precision: 0.615 recall: 0.681 f1: 0.646 accuracy: 0.936 
training batch:    23, loss: 27.58289, precision: 0.436 recall: 0.548 f1: 0.486 accuracy: 0.912 
training batch:    24, loss: 24.30068, precision: 0.297 recall: 0.367 f1: 0.328 accuracy: 0.904 
training batch:    25, loss: 19.60260, precision: 0.659 recall: 0.600 f1: 0.628 accuracy: 0.946 
training batch:    26, loss: 18.41526, precision: 0.586 recall: 0.500 f1: 0.540 accuracy: 0.943 
training batch:    27, loss: 41.53880, precision: 0.595 recall: 0.611 f1: 0.603 accuracy: 0.882 
training batch:    28, loss: 31.09547, precision: 0.606 recall: 0.500 f1: 0.548 accuracy: 0.907 
training batch:    29, loss: 16.85178, precision: 0.700 recall: 0.656 f1: 0.677 accuracy: 0.939 
training batch:    30, loss: 17.45706, precision: 0.778 recall: 0.677 f1: 0.724 accuracy: 0.950 
training batch:    31, loss: 32.95925, precision: 0.591 recall: 0.361 f1: 0.448 accuracy: 0.912 
training batch:    32, loss: 31.22532, precision: 0.593 recall: 0.485 f1: 0.533 accuracy: 0.902 
training batch:    33, loss: 33.25140, precision: 0.615 recall: 0.390 f1: 0.478 accuracy: 0.882 
training batch:    34, loss: 28.00534, precision: 0.519 recall: 0.389 f1: 0.444 accuracy: 0.925 
training batch:    35, loss: 19.40217, precision: 0.636 recall: 0.483 f1: 0.549 accuracy: 0.944 
training batch:    36, loss: 25.60228, precision: 0.667 recall: 0.581 f1: 0.621 accuracy: 0.934 
training batch:    37, loss: 29.50567, precision: 0.714 recall: 0.526 f1: 0.606 accuracy: 0.917 
training batch:    38, loss: 20.44487, precision: 0.675 recall: 0.675 f1: 0.675 accuracy: 0.922 
training batch:    39, loss: 15.98112, precision: 0.700 recall: 0.700 f1: 0.700 accuracy: 0.958 
training batch:    40, loss: 26.14297, precision: 0.767 recall: 0.639 f1: 0.697 accuracy: 0.921 
training batch:    41, loss: 21.30239, precision: 0.613 recall: 0.704 f1: 0.655 accuracy: 0.934 
training batch:    42, loss: 15.66841, precision: 0.788 recall: 0.788 f1: 0.788 accuracy: 0.966 
training batch:    43, loss: 17.83526, precision: 0.656 recall: 0.636 f1: 0.646 accuracy: 0.956 
training batch:    44, loss: 17.64559, precision: 0.677 recall: 0.538 f1: 0.600 accuracy: 0.941 
training batch:    45, loss: 21.61411, precision: 0.655 recall: 0.528 f1: 0.585 accuracy: 0.936 
training batch:    46, loss: 25.17137, precision: 0.694 recall: 0.714 f1: 0.704 accuracy: 0.936 
training batch:    47, loss: 24.52113, precision: 0.647 recall: 0.579 f1: 0.611 accuracy: 0.941 
training batch:    48, loss: 18.86676, precision: 0.562 recall: 0.529 f1: 0.545 accuracy: 0.946 
training batch:    49, loss: 19.88998, precision: 0.750 recall: 0.615 f1: 0.676 accuracy: 0.946 
training batch:    50, loss: 14.98248, precision: 0.682 recall: 0.536 f1: 0.600 accuracy: 0.955 
training batch:    51, loss: 14.48407, precision: 0.692 recall: 0.692 f1: 0.692 accuracy: 0.959 
training batch:    52, loss: 19.37380, precision: 0.605 recall: 0.639 f1: 0.622 accuracy: 0.938 
training batch:    53, loss: 11.17721, precision: 0.828 recall: 0.600 f1: 0.696 accuracy: 0.959 
training batch:    54, loss: 18.19256, precision: 0.722 recall: 0.667 f1: 0.693 accuracy: 0.940 
training batch:    55, loss: 24.43234, precision: 0.639 recall: 0.590 f1: 0.613 accuracy: 0.910 
training batch:    56, loss: 12.91053, precision: 0.548 recall: 0.486 f1: 0.515 accuracy: 0.958 
training batch:    57, loss: 16.05513, precision: 0.714 recall: 0.667 f1: 0.690 accuracy: 0.940 
training batch:    58, loss: 9.12087, precision: 0.913 recall: 0.724 f1: 0.808 accuracy: 0.973 
training batch:    59, loss: 14.19781, precision: 0.700 recall: 0.677 f1: 0.689 accuracy: 0.946 
training batch:    60, loss: 23.15647, precision: 0.674 recall: 0.674 f1: 0.674 accuracy: 0.922 
training batch:    61, loss: 12.59868, precision: 0.593 recall: 0.444 f1: 0.508 accuracy: 0.959 
training batch:    62, loss: 23.65988, precision: 0.690 recall: 0.625 f1: 0.656 accuracy: 0.943 
training batch:    63, loss: 12.99225, precision: 0.839 recall: 0.722 f1: 0.776 accuracy: 0.960 
training batch:    64, loss: 19.21120, precision: 0.758 recall: 0.658 f1: 0.704 accuracy: 0.946 
training batch:    65, loss: 12.61359, precision: 0.581 recall: 0.545 f1: 0.562 accuracy: 0.958 
training batch:    66, loss: 15.33718, precision: 0.690 recall: 0.625 f1: 0.656 accuracy: 0.948 
training batch:    67, loss: 20.83578, precision: 0.714 recall: 0.556 f1: 0.625 accuracy: 0.936 
training batch:    68, loss: 7.56639, precision: 0.704 recall: 0.655 f1: 0.679 accuracy: 0.975 
training batch:    69, loss: 19.97346, precision: 0.622 recall: 0.639 f1: 0.630 accuracy: 0.934 
training batch:    70, loss: 24.63977, precision: 0.641 recall: 0.658 f1: 0.649 accuracy: 0.921 
training batch:    71, loss: 29.41743, precision: 0.733 recall: 0.660 f1: 0.695 accuracy: 0.916 
training batch:    72, loss: 10.47502, precision: 0.667 recall: 0.769 f1: 0.714 accuracy: 0.969 
training batch:    73, loss: 18.39767, precision: 0.757 recall: 0.757 f1: 0.757 accuracy: 0.946 
training batch:    74, loss: 25.67074, precision: 0.684 recall: 0.578 f1: 0.627 accuracy: 0.927 
training batch:    75, loss: 19.01639, precision: 0.500 recall: 0.429 f1: 0.462 accuracy: 0.917 
training batch:    76, loss: 14.18700, precision: 0.625 recall: 0.625 f1: 0.625 accuracy: 0.955 
training batch:    77, loss: 16.61382, precision: 0.697 recall: 0.622 f1: 0.657 accuracy: 0.948 
training batch:    78, loss: 29.79299, precision: 0.586 recall: 0.436 f1: 0.500 accuracy: 0.891 
training batch:    79, loss: 24.72146, precision: 0.733 recall: 0.579 f1: 0.647 accuracy: 0.934 
training batch:    80, loss: 23.92064, precision: 0.700 recall: 0.512 f1: 0.592 accuracy: 0.929 
training batch:    81, loss: 25.30478, precision: 0.689 recall: 0.705 f1: 0.697 accuracy: 0.924 
training batch:    82, loss: 20.36328, precision: 0.710 recall: 0.629 f1: 0.667 accuracy: 0.930 
training batch:    83, loss: 8.68700, precision: 0.926 recall: 0.806 f1: 0.862 accuracy: 0.978 
training batch:    84, loss: 19.37662, precision: 0.641 recall: 0.625 f1: 0.633 accuracy: 0.925 
training batch:    85, loss: 18.88013, precision: 0.711 recall: 0.692 f1: 0.701 accuracy: 0.931 
training batch:    86, loss: 19.57879, precision: 0.771 recall: 0.600 f1: 0.675 accuracy: 0.936 
training batch:    87, loss: 14.01000, precision: 0.714 recall: 0.500 f1: 0.588 accuracy: 0.959 
training batch:    88, loss: 14.23909, precision: 0.778 recall: 0.700 f1: 0.737 accuracy: 0.960 
training batch:    89, loss: 21.61999, precision: 0.655 recall: 0.594 f1: 0.623 accuracy: 0.939 
training batch:    90, loss: 23.01126, precision: 0.595 recall: 0.658 f1: 0.625 accuracy: 0.934 
training batch:    91, loss: 16.64212, precision: 0.706 recall: 0.686 f1: 0.696 accuracy: 0.959 
training batch:    92, loss: 13.57219, precision: 0.719 recall: 0.676 f1: 0.697 accuracy: 0.963 
training batch:    93, loss: 12.43015, precision: 0.694 recall: 0.781 f1: 0.735 accuracy: 0.959 
training batch:    94, loss: 19.41936, precision: 0.658 recall: 0.641 f1: 0.649 accuracy: 0.931 
training batch:    95, loss: 20.60338, precision: 0.621 recall: 0.581 f1: 0.600 accuracy: 0.943 
training batch:    96, loss: 15.93920, precision: 0.792 recall: 0.543 f1: 0.644 accuracy: 0.944 
training batch:    97, loss: 16.49923, precision: 0.774 recall: 0.632 f1: 0.696 accuracy: 0.964 
training batch:    98, loss: 15.10256, precision: 0.824 recall: 0.700 f1: 0.757 accuracy: 0.945 
training batch:    99, loss: 31.30063, precision: 0.737 recall: 0.549 f1: 0.629 accuracy: 0.919 
training batch:   100, loss: 16.76295, precision: 0.812 recall: 0.703 f1: 0.754 accuracy: 0.958 
training batch:   101, loss: 15.45014, precision: 0.704 recall: 0.594 f1: 0.644 accuracy: 0.946 
training batch:   102, loss: 12.56878, precision: 0.750 recall: 0.769 f1: 0.759 accuracy: 0.965 
training batch:   103, loss: 14.93851, precision: 0.824 recall: 0.622 f1: 0.709 accuracy: 0.954 
training batch:   104, loss: 17.56555, precision: 0.649 recall: 0.667 f1: 0.658 accuracy: 0.953 
training batch:   105, loss: 23.44035, precision: 0.486 recall: 0.621 f1: 0.545 accuracy: 0.920 
training batch:   106, loss: 15.65143, precision: 0.576 recall: 0.576 f1: 0.576 accuracy: 0.949 
training batch:   107, loss: 12.39832, precision: 0.688 recall: 0.710 f1: 0.698 accuracy: 0.973 
training batch:   108, loss: 51.26150, precision: 0.706 recall: 0.649 f1: 0.676 accuracy: 0.904 
training batch:   109, loss: 20.23184, precision: 0.583 recall: 0.571 f1: 0.577 accuracy: 0.927 
training batch:   110, loss: 20.46087, precision: 0.720 recall: 0.600 f1: 0.655 accuracy: 0.941 
training batch:   111, loss: 25.11658, precision: 0.625 recall: 0.568 f1: 0.595 accuracy: 0.926 
training batch:   112, loss: 24.10865, precision: 0.686 recall: 0.585 f1: 0.632 accuracy: 0.920 
training batch:   113, loss: 28.50616, precision: 0.815 recall: 0.710 f1: 0.759 accuracy: 0.915 
training batch:   114, loss: 14.36578, precision: 0.800 recall: 0.762 f1: 0.780 accuracy: 0.956 
training batch:   115, loss: 31.26804, precision: 0.594 recall: 0.500 f1: 0.543 accuracy: 0.896 
training batch:   116, loss: 24.86789, precision: 0.562 recall: 0.581 f1: 0.571 accuracy: 0.921 
training batch:   117, loss: 16.58873, precision: 0.750 recall: 0.659 f1: 0.701 accuracy: 0.943 
training batch:   118, loss: 16.19238, precision: 0.714 recall: 0.758 f1: 0.735 accuracy: 0.949 
training batch:   119, loss: 25.78615, precision: 0.639 recall: 0.511 f1: 0.568 accuracy: 0.915 
training batch:   120, loss: 19.16553, precision: 0.655 recall: 0.543 f1: 0.594 accuracy: 0.932 
training batch:   121, loss: 12.19183, precision: 0.750 recall: 0.724 f1: 0.737 accuracy: 0.969 
training batch:   122, loss: 23.57201, precision: 0.645 recall: 0.588 f1: 0.615 accuracy: 0.921 
training batch:   123, loss: 25.84283, precision: 0.792 recall: 0.543 f1: 0.644 accuracy: 0.911 
training batch:   124, loss: 24.25334, precision: 0.581 recall: 0.543 f1: 0.562 accuracy: 0.895 
training batch:   125, loss: 11.30470, precision: 0.758 recall: 0.781 f1: 0.769 accuracy: 0.964 
training batch:   126, loss: 15.72021, precision: 0.667 recall: 0.649 f1: 0.658 accuracy: 0.950 
training batch:   127, loss: 18.04286, precision: 0.571 recall: 0.526 f1: 0.548 accuracy: 0.940 
training batch:   128, loss: 15.51528, precision: 0.618 recall: 0.636 f1: 0.627 accuracy: 0.944 
training batch:   129, loss: 9.77975, precision: 0.710 recall: 0.629 f1: 0.667 accuracy: 0.966 
training batch:   130, loss: 38.84091, precision: 0.630 recall: 0.486 f1: 0.548 accuracy: 0.917 
training batch:   131, loss: 15.51247, precision: 0.500 recall: 0.475 f1: 0.487 accuracy: 0.941 
training batch:   132, loss: 14.15311, precision: 0.710 recall: 0.611 f1: 0.657 accuracy: 0.958 
training batch:   133, loss: 18.88619, precision: 0.882 recall: 0.732 f1: 0.800 accuracy: 0.948 
training batch:   134, loss: 15.43318, precision: 0.778 recall: 0.560 f1: 0.651 accuracy: 0.945 
training batch:   135, loss: 20.05337, precision: 0.517 recall: 0.500 f1: 0.508 accuracy: 0.949 
training batch:   136, loss: 14.46647, precision: 0.742 recall: 0.622 f1: 0.676 accuracy: 0.946 
training batch:   137, loss: 20.28626, precision: 0.542 recall: 0.703 f1: 0.612 accuracy: 0.925 
training batch:   138, loss: 13.68401, precision: 0.683 recall: 0.778 f1: 0.727 accuracy: 0.969 
training batch:   139, loss: 13.46237, precision: 0.655 recall: 0.594 f1: 0.623 accuracy: 0.954 
training batch:   140, loss: 21.84100, precision: 0.743 recall: 0.788 f1: 0.765 accuracy: 0.935 
training batch:   141, loss: 28.94765, precision: 0.692 recall: 0.667 f1: 0.679 accuracy: 0.929 
training batch:   142, loss: 19.95329, precision: 0.679 recall: 0.633 f1: 0.655 accuracy: 0.939 
training batch:   143, loss: 18.95068, precision: 0.656 recall: 0.525 f1: 0.583 accuracy: 0.930 
training batch:   144, loss: 13.35931, precision: 0.833 recall: 0.571 f1: 0.678 accuracy: 0.965 
training batch:   145, loss: 21.65775, precision: 0.645 recall: 0.588 f1: 0.615 accuracy: 0.938 
training batch:   146, loss: 9.54853, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.976 
training batch:   147, loss: 11.86362, precision: 0.800 recall: 0.780 f1: 0.790 accuracy: 0.955 
training batch:   148, loss: 13.46150, precision: 0.871 recall: 0.818 f1: 0.844 accuracy: 0.953 
training batch:   149, loss: 18.34788, precision: 0.710 recall: 0.667 f1: 0.688 accuracy: 0.951 
training batch:   150, loss: 29.63858, precision: 0.655 recall: 0.543 f1: 0.594 accuracy: 0.891 
training batch:   151, loss: 13.84467, precision: 0.711 recall: 0.692 f1: 0.701 accuracy: 0.951 
training batch:   152, loss: 10.69795, precision: 0.800 recall: 0.718 f1: 0.757 accuracy: 0.965 
training batch:   153, loss: 11.19379, precision: 0.850 recall: 0.850 f1: 0.850 accuracy: 0.969 
training batch:   154, loss: 9.71318, precision: 0.667 recall: 0.741 f1: 0.702 accuracy: 0.974 
training batch:   155, loss: 13.44001, precision: 0.690 recall: 0.674 f1: 0.682 accuracy: 0.964 
training batch:   156, loss: 15.92342, precision: 0.750 recall: 0.732 f1: 0.741 accuracy: 0.960 
training batch:   157, loss: 16.66886, precision: 0.607 recall: 0.515 f1: 0.557 accuracy: 0.954 
training batch:   158, loss: 12.30488, precision: 0.711 recall: 0.750 f1: 0.730 accuracy: 0.954 
training batch:   159, loss: 17.61480, precision: 0.625 recall: 0.641 f1: 0.633 accuracy: 0.958 
training batch:   160, loss: 17.65654, precision: 0.629 recall: 0.611 f1: 0.620 accuracy: 0.941 
training batch:   161, loss: 13.55949, precision: 0.783 recall: 0.600 f1: 0.679 accuracy: 0.960 
training batch:   162, loss: 16.70336, precision: 0.667 recall: 0.692 f1: 0.679 accuracy: 0.960 
training batch:   163, loss: 15.34449, precision: 0.724 recall: 0.700 f1: 0.712 accuracy: 0.959 
training batch:   164, loss: 12.75264, precision: 0.650 recall: 0.619 f1: 0.634 accuracy: 0.959 
training batch:   165, loss: 8.08549, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.973 
training batch:   166, loss: 17.67009, precision: 0.795 recall: 0.738 f1: 0.765 accuracy: 0.951 
training batch:   167, loss: 15.30226, precision: 0.514 recall: 0.643 f1: 0.571 accuracy: 0.944 
training batch:   168, loss: 22.63046, precision: 0.731 recall: 0.594 f1: 0.655 accuracy: 0.936 
training batch:   169, loss: 34.59203, precision: 0.735 recall: 0.758 f1: 0.746 accuracy: 0.920 
training batch:   170, loss: 16.39556, precision: 0.800 recall: 0.632 f1: 0.706 accuracy: 0.959 
training batch:   171, loss: 27.61808, precision: 0.654 recall: 0.472 f1: 0.548 accuracy: 0.917 
training batch:   172, loss: 21.79397, precision: 0.586 recall: 0.405 f1: 0.479 accuracy: 0.907 
training batch:   173, loss: 23.95877, precision: 0.677 recall: 0.656 f1: 0.667 accuracy: 0.881 
training batch:   174, loss: 14.68414, precision: 0.593 recall: 0.533 f1: 0.561 accuracy: 0.951 
training batch:   175, loss: 14.40858, precision: 0.730 recall: 0.794 f1: 0.761 accuracy: 0.958 
training batch:   176, loss: 15.21447, precision: 0.724 recall: 0.636 f1: 0.677 accuracy: 0.974 
training batch:   177, loss: 26.21378, precision: 0.551 recall: 0.692 f1: 0.614 accuracy: 0.906 
training batch:   178, loss: 29.49884, precision: 0.667 recall: 0.769 f1: 0.714 accuracy: 0.927 
start evaluate engines...
label: Dsa, precision: 0.695 recall: 0.735 f1: 0.707 
label: Chk, precision: 0.470 recall: 0.537 f1: 0.485 
label: Ins, precision: 0.100 recall: 0.042 f1: 0.058 
label: Sur, precision: 0.863 recall: 0.860 f1: 0.858 
label: Med, precision: 0.370 recall: 0.395 f1: 0.378 
label: Ana, precision: 0.760 recall: 0.785 f1: 0.769 
time consumption:3.35(min), precision: 0.762 recall: 0.773 f1: 0.767 accuracy: 0.958 
saved the new best model with f1: 0.767
epoch:3/100
training batch:     1, loss: 12.70022, precision: 0.647 recall: 0.595 f1: 0.620 accuracy: 0.961 
training batch:     2, loss: 11.45560, precision: 0.667 recall: 0.571 f1: 0.615 accuracy: 0.959 
training batch:     3, loss: 19.68408, precision: 0.692 recall: 0.574 f1: 0.628 accuracy: 0.939 
training batch:     4, loss: 20.24081, precision: 0.667 recall: 0.733 f1: 0.698 accuracy: 0.929 
training batch:     5, loss: 6.97648, precision: 0.697 recall: 0.793 f1: 0.742 accuracy: 0.973 
training batch:     6, loss: 21.32312, precision: 0.700 recall: 0.737 f1: 0.718 accuracy: 0.939 
training batch:     7, loss: 18.65939, precision: 0.805 recall: 0.805 f1: 0.805 accuracy: 0.953 
training batch:     8, loss: 23.54573, precision: 0.812 recall: 0.839 f1: 0.825 accuracy: 0.922 
training batch:     9, loss: 5.90102, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.988 
training batch:    10, loss: 8.28162, precision: 0.815 recall: 0.846 f1: 0.830 accuracy: 0.975 
training batch:    11, loss: 15.70598, precision: 0.774 recall: 0.706 f1: 0.738 accuracy: 0.950 
training batch:    12, loss: 20.53722, precision: 0.788 recall: 0.667 f1: 0.722 accuracy: 0.939 
training batch:    13, loss: 13.83415, precision: 0.625 recall: 0.541 f1: 0.580 accuracy: 0.939 
training batch:    14, loss: 14.76764, precision: 0.824 recall: 0.667 f1: 0.737 accuracy: 0.958 
training batch:    15, loss: 22.31798, precision: 0.742 recall: 0.639 f1: 0.687 accuracy: 0.916 
training batch:    16, loss: 15.30296, precision: 0.828 recall: 0.774 f1: 0.800 accuracy: 0.949 
training batch:    17, loss: 13.13359, precision: 0.750 recall: 0.711 f1: 0.730 accuracy: 0.948 
training batch:    18, loss: 26.90096, precision: 0.818 recall: 0.844 f1: 0.831 accuracy: 0.944 
training batch:    19, loss: 20.20650, precision: 0.690 recall: 0.674 f1: 0.682 accuracy: 0.938 
training batch:    20, loss: 12.10234, precision: 0.760 recall: 0.576 f1: 0.655 accuracy: 0.964 
training batch:    21, loss: 6.14939, precision: 0.828 recall: 0.857 f1: 0.842 accuracy: 0.984 
training batch:    22, loss: 18.00050, precision: 0.829 recall: 0.810 f1: 0.819 accuracy: 0.939 
training batch:    23, loss: 15.80511, precision: 0.778 recall: 0.636 f1: 0.700 accuracy: 0.966 
training batch:    24, loss: 8.42784, precision: 0.833 recall: 0.833 f1: 0.833 accuracy: 0.974 
training batch:    25, loss: 15.78368, precision: 0.781 recall: 0.781 f1: 0.781 accuracy: 0.955 
training batch:    26, loss: 11.39277, precision: 0.649 recall: 0.750 f1: 0.696 accuracy: 0.951 
training batch:    27, loss: 11.13923, precision: 0.706 recall: 0.750 f1: 0.727 accuracy: 0.966 
training batch:    28, loss: 12.23020, precision: 0.686 recall: 0.774 f1: 0.727 accuracy: 0.956 
training batch:    29, loss: 6.31993, precision: 0.846 recall: 0.868 f1: 0.857 accuracy: 0.985 
training batch:    30, loss: 20.56747, precision: 0.556 recall: 0.513 f1: 0.533 accuracy: 0.921 
training batch:    31, loss: 10.99924, precision: 0.767 recall: 0.719 f1: 0.742 accuracy: 0.965 
training batch:    32, loss: 12.54832, precision: 0.667 recall: 0.667 f1: 0.667 accuracy: 0.963 
training batch:    33, loss: 10.97454, precision: 0.720 recall: 0.667 f1: 0.692 accuracy: 0.963 
training batch:    34, loss: 26.79034, precision: 0.633 recall: 0.475 f1: 0.543 accuracy: 0.920 
training batch:    35, loss: 17.39906, precision: 0.867 recall: 0.867 f1: 0.867 accuracy: 0.943 
training batch:    36, loss: 18.28627, precision: 0.686 recall: 0.649 f1: 0.667 accuracy: 0.956 
training batch:    37, loss: 16.28027, precision: 0.625 recall: 0.645 f1: 0.635 accuracy: 0.945 
training batch:    38, loss: 13.96386, precision: 0.676 recall: 0.758 f1: 0.714 accuracy: 0.966 
training batch:    39, loss: 12.81792, precision: 0.750 recall: 0.675 f1: 0.711 accuracy: 0.955 
training batch:    40, loss: 22.79199, precision: 0.806 recall: 0.806 f1: 0.806 accuracy: 0.934 
training batch:    41, loss: 8.95943, precision: 0.750 recall: 0.828 f1: 0.787 accuracy: 0.966 
training batch:    42, loss: 32.25426, precision: 0.559 recall: 0.559 f1: 0.559 accuracy: 0.877 
training batch:    43, loss: 11.27466, precision: 0.844 recall: 0.730 f1: 0.783 accuracy: 0.969 
training batch:    44, loss: 13.49343, precision: 0.750 recall: 0.724 f1: 0.737 accuracy: 0.956 
training batch:    45, loss: 13.54017, precision: 0.794 recall: 0.794 f1: 0.794 accuracy: 0.959 
training batch:    46, loss: 13.30190, precision: 0.786 recall: 0.759 f1: 0.772 accuracy: 0.953 
training batch:    47, loss: 27.08185, precision: 0.767 recall: 0.639 f1: 0.697 accuracy: 0.920 
training batch:    48, loss: 18.08378, precision: 0.750 recall: 0.500 f1: 0.600 accuracy: 0.939 
training batch:    49, loss: 8.33485, precision: 0.767 recall: 0.821 f1: 0.793 accuracy: 0.969 
training batch:    50, loss: 18.70107, precision: 0.743 recall: 0.605 f1: 0.667 accuracy: 0.946 
training batch:    51, loss: 15.77739, precision: 0.769 recall: 0.741 f1: 0.755 accuracy: 0.968 
training batch:    52, loss: 8.02990, precision: 0.719 recall: 0.719 f1: 0.719 accuracy: 0.970 
training batch:    53, loss: 17.67614, precision: 0.667 recall: 0.703 f1: 0.684 accuracy: 0.935 
training batch:    54, loss: 9.18005, precision: 0.828 recall: 0.800 f1: 0.814 accuracy: 0.978 
training batch:    55, loss: 12.76321, precision: 0.765 recall: 0.743 f1: 0.754 accuracy: 0.959 
training batch:    56, loss: 9.03076, precision: 0.838 recall: 0.912 f1: 0.873 accuracy: 0.974 
training batch:    57, loss: 16.78218, precision: 0.676 recall: 0.676 f1: 0.676 accuracy: 0.961 
training batch:    58, loss: 15.07360, precision: 0.689 recall: 0.738 f1: 0.713 accuracy: 0.946 
training batch:    59, loss: 19.85135, precision: 0.743 recall: 0.812 f1: 0.776 accuracy: 0.931 
training batch:    60, loss: 9.27795, precision: 0.758 recall: 0.758 f1: 0.758 accuracy: 0.965 
training batch:    61, loss: 16.06675, precision: 0.737 recall: 0.737 f1: 0.737 accuracy: 0.943 
training batch:    62, loss: 11.98029, precision: 0.862 recall: 0.735 f1: 0.794 accuracy: 0.953 
training batch:    63, loss: 7.22950, precision: 0.870 recall: 0.645 f1: 0.741 accuracy: 0.970 
training batch:    64, loss: 19.71234, precision: 0.722 recall: 0.703 f1: 0.712 accuracy: 0.949 
training batch:    65, loss: 8.96014, precision: 0.906 recall: 0.784 f1: 0.841 accuracy: 0.973 
training batch:    66, loss: 7.79512, precision: 0.862 recall: 0.735 f1: 0.794 accuracy: 0.976 
training batch:    67, loss: 23.04951, precision: 0.880 recall: 0.647 f1: 0.746 accuracy: 0.944 
training batch:    68, loss: 30.81348, precision: 0.654 recall: 0.395 f1: 0.493 accuracy: 0.912 
training batch:    69, loss: 13.36066, precision: 0.667 recall: 0.611 f1: 0.638 accuracy: 0.960 
training batch:    70, loss: 18.96373, precision: 0.737 recall: 0.683 f1: 0.709 accuracy: 0.940 
training batch:    71, loss: 14.14081, precision: 0.811 recall: 0.750 f1: 0.779 accuracy: 0.964 
training batch:    72, loss: 18.57419, precision: 0.615 recall: 0.744 f1: 0.674 accuracy: 0.939 
training batch:    73, loss: 18.67460, precision: 0.676 recall: 0.781 f1: 0.725 accuracy: 0.946 
training batch:    74, loss: 14.24807, precision: 0.886 recall: 0.939 f1: 0.912 accuracy: 0.956 
training batch:    75, loss: 17.01688, precision: 0.800 recall: 0.837 f1: 0.818 accuracy: 0.948 
training batch:    76, loss: 7.79805, precision: 0.700 recall: 0.778 f1: 0.737 accuracy: 0.974 
training batch:    77, loss: 13.06937, precision: 0.636 recall: 0.583 f1: 0.609 accuracy: 0.946 
training batch:    78, loss: 31.09739, precision: 0.642 recall: 0.618 f1: 0.630 accuracy: 0.896 
training batch:    79, loss: 9.08041, precision: 0.963 recall: 0.765 f1: 0.852 accuracy: 0.978 
training batch:    80, loss: 10.95307, precision: 0.793 recall: 0.742 f1: 0.767 accuracy: 0.959 
training batch:    81, loss: 9.25305, precision: 0.818 recall: 0.730 f1: 0.771 accuracy: 0.970 
training batch:    82, loss: 12.05470, precision: 0.722 recall: 0.703 f1: 0.712 accuracy: 0.951 
training batch:    83, loss: 12.76044, precision: 0.767 recall: 0.846 f1: 0.805 accuracy: 0.963 
training batch:    84, loss: 22.31728, precision: 0.879 recall: 0.690 f1: 0.773 accuracy: 0.892 
training batch:    85, loss: 11.32498, precision: 0.727 recall: 0.727 f1: 0.727 accuracy: 0.953 
training batch:    86, loss: 8.96736, precision: 0.824 recall: 0.913 f1: 0.866 accuracy: 0.970 
training batch:    87, loss: 8.83022, precision: 0.875 recall: 0.897 f1: 0.886 accuracy: 0.981 
training batch:    88, loss: 14.10360, precision: 0.744 recall: 0.763 f1: 0.753 accuracy: 0.956 
training batch:    89, loss: 7.90676, precision: 0.800 recall: 0.750 f1: 0.774 accuracy: 0.974 
training batch:    90, loss: 15.37884, precision: 0.824 recall: 0.737 f1: 0.778 accuracy: 0.955 
training batch:    91, loss: 6.48785, precision: 0.913 recall: 0.840 f1: 0.875 accuracy: 0.986 
training batch:    92, loss: 9.06911, precision: 0.880 recall: 0.846 f1: 0.863 accuracy: 0.973 
training batch:    93, loss: 7.27005, precision: 0.920 recall: 0.767 f1: 0.836 accuracy: 0.981 
training batch:    94, loss: 18.81757, precision: 0.714 recall: 0.735 f1: 0.725 accuracy: 0.953 
training batch:    95, loss: 9.58089, precision: 0.781 recall: 0.735 f1: 0.758 accuracy: 0.968 
training batch:    96, loss: 11.17838, precision: 0.763 recall: 0.806 f1: 0.784 accuracy: 0.960 
training batch:    97, loss: 33.00672, precision: 0.806 recall: 0.714 f1: 0.758 accuracy: 0.900 
training batch:    98, loss: 13.62473, precision: 0.816 recall: 0.838 f1: 0.827 accuracy: 0.944 
training batch:    99, loss: 11.84393, precision: 0.824 recall: 0.757 f1: 0.789 accuracy: 0.968 
training batch:   100, loss: 9.21401, precision: 0.778 recall: 0.903 f1: 0.836 accuracy: 0.960 
training batch:   101, loss: 13.99226, precision: 0.730 recall: 0.692 f1: 0.711 accuracy: 0.934 
training batch:   102, loss: 4.34538, precision: 0.828 recall: 0.889 f1: 0.857 accuracy: 0.988 
training batch:   103, loss: 22.28534, precision: 0.645 recall: 0.690 f1: 0.667 accuracy: 0.927 
training batch:   104, loss: 5.64323, precision: 0.806 recall: 0.906 f1: 0.853 accuracy: 0.981 
training batch:   105, loss: 20.27590, precision: 0.756 recall: 0.838 f1: 0.795 accuracy: 0.940 
training batch:   106, loss: 6.91434, precision: 0.862 recall: 0.833 f1: 0.847 accuracy: 0.971 
training batch:   107, loss: 4.49683, precision: 0.870 recall: 0.741 f1: 0.800 accuracy: 0.983 
training batch:   108, loss: 15.99533, precision: 0.759 recall: 0.647 f1: 0.698 accuracy: 0.956 
training batch:   109, loss: 14.04599, precision: 0.697 recall: 0.697 f1: 0.697 accuracy: 0.959 
training batch:   110, loss: 24.72574, precision: 0.810 recall: 0.486 f1: 0.607 accuracy: 0.916 
training batch:   111, loss: 5.69431, precision: 0.917 recall: 0.786 f1: 0.846 accuracy: 0.978 
training batch:   112, loss: 13.06250, precision: 0.800 recall: 0.718 f1: 0.757 accuracy: 0.961 
training batch:   113, loss: 17.93220, precision: 0.750 recall: 0.720 f1: 0.735 accuracy: 0.953 
training batch:   114, loss: 11.12187, precision: 0.857 recall: 0.811 f1: 0.833 accuracy: 0.960 
training batch:   115, loss: 9.55305, precision: 0.824 recall: 0.778 f1: 0.800 accuracy: 0.976 
training batch:   116, loss: 11.52684, precision: 0.800 recall: 0.821 f1: 0.810 accuracy: 0.968 
training batch:   117, loss: 16.98823, precision: 0.875 recall: 0.778 f1: 0.824 accuracy: 0.955 
training batch:   118, loss: 15.42973, precision: 0.718 recall: 0.718 f1: 0.718 accuracy: 0.953 
training batch:   119, loss: 12.25179, precision: 0.811 recall: 0.750 f1: 0.779 accuracy: 0.959 
training batch:   120, loss: 14.19756, precision: 0.778 recall: 0.724 f1: 0.750 accuracy: 0.954 
training batch:   121, loss: 12.96072, precision: 0.853 recall: 0.829 f1: 0.841 accuracy: 0.950 
training batch:   122, loss: 20.76736, precision: 0.838 recall: 0.838 f1: 0.838 accuracy: 0.943 
training batch:   123, loss: 19.56989, precision: 0.676 recall: 0.639 f1: 0.657 accuracy: 0.936 
training batch:   124, loss: 10.38225, precision: 0.838 recall: 0.795 f1: 0.816 accuracy: 0.964 
training batch:   125, loss: 16.31731, precision: 0.723 recall: 0.708 f1: 0.716 accuracy: 0.916 
training batch:   126, loss: 17.35212, precision: 0.647 recall: 0.733 f1: 0.688 accuracy: 0.936 
training batch:   127, loss: 8.48988, precision: 0.788 recall: 0.839 f1: 0.812 accuracy: 0.973 
training batch:   128, loss: 11.70159, precision: 0.816 recall: 0.689 f1: 0.747 accuracy: 0.964 
training batch:   129, loss: 9.51049, precision: 0.789 recall: 0.882 f1: 0.833 accuracy: 0.966 
training batch:   130, loss: 12.10166, precision: 0.771 recall: 0.730 f1: 0.750 accuracy: 0.969 
training batch:   131, loss: 8.93644, precision: 0.711 recall: 0.771 f1: 0.740 accuracy: 0.963 
training batch:   132, loss: 24.72504, precision: 0.605 recall: 0.535 f1: 0.568 accuracy: 0.911 
training batch:   133, loss: 7.18961, precision: 0.791 recall: 0.850 f1: 0.819 accuracy: 0.974 
training batch:   134, loss: 14.66793, precision: 0.821 recall: 0.697 f1: 0.754 accuracy: 0.949 
training batch:   135, loss: 11.93618, precision: 0.778 recall: 0.757 f1: 0.767 accuracy: 0.970 
training batch:   136, loss: 6.00631, precision: 0.893 recall: 0.833 f1: 0.862 accuracy: 0.985 
training batch:   137, loss: 15.31097, precision: 0.833 recall: 0.789 f1: 0.811 accuracy: 0.926 
training batch:   138, loss: 12.57428, precision: 0.676 recall: 0.697 f1: 0.687 accuracy: 0.948 
training batch:   139, loss: 24.71144, precision: 0.711 recall: 0.659 f1: 0.684 accuracy: 0.930 
training batch:   140, loss: 10.02448, precision: 0.722 recall: 0.765 f1: 0.743 accuracy: 0.975 
training batch:   141, loss: 11.48830, precision: 0.700 recall: 0.800 f1: 0.747 accuracy: 0.973 
training batch:   142, loss: 18.33804, precision: 0.775 recall: 0.756 f1: 0.765 accuracy: 0.939 
training batch:   143, loss: 18.51008, precision: 0.800 recall: 0.727 f1: 0.762 accuracy: 0.953 
training batch:   144, loss: 9.23595, precision: 0.800 recall: 0.889 f1: 0.842 accuracy: 0.971 
training batch:   145, loss: 11.32035, precision: 0.733 recall: 0.733 f1: 0.733 accuracy: 0.955 
training batch:   146, loss: 12.71542, precision: 0.694 recall: 0.641 f1: 0.667 accuracy: 0.958 
training batch:   147, loss: 12.38363, precision: 0.742 recall: 0.605 f1: 0.667 accuracy: 0.960 
training batch:   148, loss: 16.02343, precision: 0.586 recall: 0.515 f1: 0.548 accuracy: 0.934 
training batch:   149, loss: 6.24606, precision: 0.824 recall: 0.800 f1: 0.812 accuracy: 0.986 
training batch:   150, loss: 11.88126, precision: 0.730 recall: 0.692 f1: 0.711 accuracy: 0.964 
training batch:   151, loss: 16.72523, precision: 0.583 recall: 0.677 f1: 0.627 accuracy: 0.938 
training batch:   152, loss: 7.68912, precision: 0.840 recall: 0.913 f1: 0.875 accuracy: 0.970 
training batch:   153, loss: 16.41624, precision: 0.658 recall: 0.735 f1: 0.694 accuracy: 0.944 
training batch:   154, loss: 12.29552, precision: 0.632 recall: 0.615 f1: 0.623 accuracy: 0.950 
training batch:   155, loss: 23.07790, precision: 0.774 recall: 0.632 f1: 0.696 accuracy: 0.917 
training batch:   156, loss: 16.08176, precision: 0.757 recall: 0.778 f1: 0.767 accuracy: 0.949 
training batch:   157, loss: 11.60892, precision: 0.839 recall: 0.812 f1: 0.825 accuracy: 0.944 
training batch:   158, loss: 21.49819, precision: 0.618 recall: 0.538 f1: 0.575 accuracy: 0.938 
training batch:   159, loss: 24.65501, precision: 0.567 recall: 0.567 f1: 0.567 accuracy: 0.925 
training batch:   160, loss: 11.74676, precision: 0.633 recall: 0.576 f1: 0.603 accuracy: 0.964 
training batch:   161, loss: 20.48035, precision: 0.697 recall: 0.605 f1: 0.648 accuracy: 0.943 
training batch:   162, loss: 9.48294, precision: 0.750 recall: 0.750 f1: 0.750 accuracy: 0.966 
training batch:   163, loss: 8.26232, precision: 0.865 recall: 0.821 f1: 0.842 accuracy: 0.979 
training batch:   164, loss: 8.70048, precision: 0.743 recall: 0.788 f1: 0.765 accuracy: 0.976 
training batch:   165, loss: 7.65300, precision: 0.872 recall: 0.895 f1: 0.883 accuracy: 0.974 
training batch:   166, loss: 14.03902, precision: 0.789 recall: 0.857 f1: 0.822 accuracy: 0.963 
training batch:   167, loss: 22.25693, precision: 0.600 recall: 0.632 f1: 0.615 accuracy: 0.938 
training batch:   168, loss: 10.10416, precision: 0.771 recall: 0.844 f1: 0.806 accuracy: 0.973 
training batch:   169, loss: 13.36514, precision: 0.676 recall: 0.639 f1: 0.657 accuracy: 0.941 
training batch:   170, loss: 9.44674, precision: 0.700 recall: 0.656 f1: 0.677 accuracy: 0.969 
training batch:   171, loss: 11.62694, precision: 0.615 recall: 0.686 f1: 0.649 accuracy: 0.946 
training batch:   172, loss: 12.34817, precision: 0.811 recall: 0.882 f1: 0.845 accuracy: 0.971 
training batch:   173, loss: 14.52101, precision: 0.711 recall: 0.727 f1: 0.719 accuracy: 0.946 
training batch:   174, loss: 13.17084, precision: 0.833 recall: 0.816 f1: 0.825 accuracy: 0.959 
training batch:   175, loss: 14.19553, precision: 0.594 recall: 0.613 f1: 0.603 accuracy: 0.949 
training batch:   176, loss: 7.79908, precision: 0.800 recall: 0.727 f1: 0.762 accuracy: 0.976 
training batch:   177, loss: 7.83556, precision: 0.816 recall: 0.816 f1: 0.816 accuracy: 0.976 
training batch:   178, loss: 17.14779, precision: 0.571 recall: 0.500 f1: 0.533 accuracy: 0.957 
start evaluate engines...
label: Dsa, precision: 0.751 recall: 0.726 f1: 0.733 
label: Chk, precision: 0.725 recall: 0.730 f1: 0.702 
label: Ins, precision: 0.250 recall: 0.150 f1: 0.182 
label: Sur, precision: 0.911 recall: 0.887 f1: 0.891 
label: Med, precision: 0.415 recall: 0.440 f1: 0.423 
label: Ana, precision: 0.821 recall: 0.801 f1: 0.807 
time consumption:3.28(min), precision: 0.828 recall: 0.803 f1: 0.815 accuracy: 0.965 
saved the new best model with f1: 0.815
epoch:4/100
training batch:     1, loss: 11.49173, precision: 0.743 recall: 0.703 f1: 0.722 accuracy: 0.969 
training batch:     2, loss: 11.78553, precision: 0.788 recall: 0.743 f1: 0.765 accuracy: 0.963 
training batch:     3, loss: 16.07133, precision: 0.792 recall: 0.576 f1: 0.667 accuracy: 0.956 
training batch:     4, loss: 5.45316, precision: 0.926 recall: 0.781 f1: 0.847 accuracy: 0.984 
training batch:     5, loss: 9.90919, precision: 0.818 recall: 0.730 f1: 0.771 accuracy: 0.968 
training batch:     6, loss: 3.60786, precision: 0.842 recall: 0.941 f1: 0.889 accuracy: 0.986 
training batch:     7, loss: 7.67707, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.978 
training batch:     8, loss: 10.14952, precision: 0.641 recall: 0.714 f1: 0.676 accuracy: 0.961 
training batch:     9, loss: 18.33714, precision: 0.784 recall: 0.763 f1: 0.773 accuracy: 0.940 
training batch:    10, loss: 7.77315, precision: 0.853 recall: 0.906 f1: 0.879 accuracy: 0.980 
training batch:    11, loss: 10.66751, precision: 0.700 recall: 0.677 f1: 0.689 accuracy: 0.964 
training batch:    12, loss: 17.79335, precision: 0.628 recall: 0.675 f1: 0.651 accuracy: 0.934 
training batch:    13, loss: 25.46565, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.953 
training batch:    14, loss: 15.48436, precision: 0.833 recall: 0.761 f1: 0.795 accuracy: 0.939 
training batch:    15, loss: 15.15527, precision: 0.618 recall: 0.568 f1: 0.592 accuracy: 0.950 
training batch:    16, loss: 12.20442, precision: 0.960 recall: 0.727 f1: 0.828 accuracy: 0.959 
training batch:    17, loss: 10.34087, precision: 0.806 recall: 0.714 f1: 0.758 accuracy: 0.969 
training batch:    18, loss: 6.41454, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.991 
training batch:    19, loss: 13.29137, precision: 0.710 recall: 0.667 f1: 0.688 accuracy: 0.943 
training batch:    20, loss: 10.92719, precision: 0.784 recall: 0.763 f1: 0.773 accuracy: 0.969 
training batch:    21, loss: 12.87828, precision: 0.750 recall: 0.871 f1: 0.806 accuracy: 0.956 
training batch:    22, loss: 12.02689, precision: 0.800 recall: 0.848 f1: 0.824 accuracy: 0.956 
training batch:    23, loss: 18.30116, precision: 0.686 recall: 0.774 f1: 0.727 accuracy: 0.932 
training batch:    24, loss: 11.51120, precision: 0.767 recall: 0.767 f1: 0.767 accuracy: 0.965 
training batch:    25, loss: 8.53941, precision: 0.811 recall: 0.750 f1: 0.779 accuracy: 0.976 
training batch:    26, loss: 6.13534, precision: 0.786 recall: 0.805 f1: 0.795 accuracy: 0.981 
training batch:    27, loss: 11.37557, precision: 0.778 recall: 0.778 f1: 0.778 accuracy: 0.965 
training batch:    28, loss: 13.02325, precision: 0.763 recall: 0.630 f1: 0.690 accuracy: 0.965 
training batch:    29, loss: 6.36721, precision: 0.686 recall: 0.727 f1: 0.706 accuracy: 0.981 
training batch:    30, loss: 6.86706, precision: 0.861 recall: 0.838 f1: 0.849 accuracy: 0.974 
training batch:    31, loss: 7.20267, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.979 
training batch:    32, loss: 14.01644, precision: 0.700 recall: 0.800 f1: 0.747 accuracy: 0.939 
training batch:    33, loss: 18.35463, precision: 0.808 recall: 0.700 f1: 0.750 accuracy: 0.948 
training batch:    34, loss: 5.08138, precision: 0.833 recall: 0.758 f1: 0.794 accuracy: 0.985 
training batch:    35, loss: 8.72293, precision: 0.931 recall: 0.771 f1: 0.844 accuracy: 0.985 
training batch:    36, loss: 6.75268, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.981 
training batch:    37, loss: 4.38612, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.991 
training batch:    38, loss: 6.90258, precision: 0.844 recall: 0.871 f1: 0.857 accuracy: 0.980 
training batch:    39, loss: 11.08499, precision: 0.732 recall: 0.857 f1: 0.789 accuracy: 0.965 
training batch:    40, loss: 7.16744, precision: 0.793 recall: 0.821 f1: 0.807 accuracy: 0.978 
training batch:    41, loss: 13.37829, precision: 0.711 recall: 0.675 f1: 0.692 accuracy: 0.951 
training batch:    42, loss: 9.55553, precision: 0.811 recall: 0.857 f1: 0.833 accuracy: 0.968 
training batch:    43, loss: 9.27621, precision: 0.886 recall: 0.861 f1: 0.873 accuracy: 0.985 
training batch:    44, loss: 8.51965, precision: 0.658 recall: 0.758 f1: 0.704 accuracy: 0.968 
training batch:    45, loss: 14.44860, precision: 0.698 recall: 0.769 f1: 0.732 accuracy: 0.936 
training batch:    46, loss: 12.26453, precision: 0.721 recall: 0.775 f1: 0.747 accuracy: 0.963 
training batch:    47, loss: 11.52593, precision: 0.821 recall: 0.821 f1: 0.821 accuracy: 0.966 
training batch:    48, loss: 13.71313, precision: 0.912 recall: 0.838 f1: 0.873 accuracy: 0.956 
training batch:    49, loss: 11.30545, precision: 0.579 recall: 0.579 f1: 0.579 accuracy: 0.961 
training batch:    50, loss: 7.16353, precision: 0.853 recall: 0.763 f1: 0.806 accuracy: 0.979 
training batch:    51, loss: 11.58700, precision: 0.808 recall: 0.600 f1: 0.689 accuracy: 0.961 
training batch:    52, loss: 14.83449, precision: 0.909 recall: 0.698 f1: 0.789 accuracy: 0.945 
training batch:    53, loss: 9.40340, precision: 0.872 recall: 0.829 f1: 0.850 accuracy: 0.976 
training batch:    54, loss: 9.90247, precision: 0.743 recall: 0.650 f1: 0.693 accuracy: 0.959 
training batch:    55, loss: 11.85707, precision: 0.744 recall: 0.784 f1: 0.763 accuracy: 0.946 
training batch:    56, loss: 10.12476, precision: 0.724 recall: 0.750 f1: 0.737 accuracy: 0.950 
training batch:    57, loss: 10.53181, precision: 0.607 recall: 0.607 f1: 0.607 accuracy: 0.953 
training batch:    58, loss: 8.84842, precision: 0.848 recall: 0.757 f1: 0.800 accuracy: 0.976 
training batch:    59, loss: 14.97835, precision: 0.791 recall: 0.810 f1: 0.800 accuracy: 0.943 
training batch:    60, loss: 7.03104, precision: 0.912 recall: 0.861 f1: 0.886 accuracy: 0.980 
training batch:    61, loss: 8.90808, precision: 0.833 recall: 0.769 f1: 0.800 accuracy: 0.966 
training batch:    62, loss: 9.60599, precision: 0.900 recall: 0.871 f1: 0.885 accuracy: 0.966 
training batch:    63, loss: 8.63254, precision: 0.828 recall: 0.828 f1: 0.828 accuracy: 0.966 
training batch:    64, loss: 10.21021, precision: 0.667 recall: 0.667 f1: 0.667 accuracy: 0.966 
training batch:    65, loss: 15.94684, precision: 0.733 recall: 0.688 f1: 0.710 accuracy: 0.951 
training batch:    66, loss: 18.26669, precision: 0.636 recall: 0.737 f1: 0.683 accuracy: 0.948 
training batch:    67, loss: 12.30429, precision: 0.581 recall: 0.643 f1: 0.610 accuracy: 0.945 
training batch:    68, loss: 9.88783, precision: 0.704 recall: 0.731 f1: 0.717 accuracy: 0.960 
training batch:    69, loss: 15.42020, precision: 0.649 recall: 0.649 f1: 0.649 accuracy: 0.948 
training batch:    70, loss: 9.14927, precision: 0.850 recall: 0.850 f1: 0.850 accuracy: 0.963 
training batch:    71, loss: 19.15257, precision: 0.825 recall: 0.733 f1: 0.776 accuracy: 0.935 
training batch:    72, loss: 7.76559, precision: 0.769 recall: 0.714 f1: 0.741 accuracy: 0.971 
training batch:    73, loss: 11.50569, precision: 0.756 recall: 0.756 f1: 0.756 accuracy: 0.950 
training batch:    74, loss: 8.27720, precision: 0.950 recall: 0.864 f1: 0.905 accuracy: 0.968 
training batch:    75, loss: 12.01550, precision: 0.815 recall: 0.710 f1: 0.759 accuracy: 0.966 
training batch:    76, loss: 10.16111, precision: 0.814 recall: 0.814 f1: 0.814 accuracy: 0.964 
training batch:    77, loss: 11.31841, precision: 0.811 recall: 0.811 f1: 0.811 accuracy: 0.970 
training batch:    78, loss: 6.04584, precision: 0.946 recall: 0.897 f1: 0.921 accuracy: 0.981 
training batch:    79, loss: 18.83220, precision: 0.639 recall: 0.657 f1: 0.648 accuracy: 0.929 
training batch:    80, loss: 5.88635, precision: 0.783 recall: 0.783 f1: 0.783 accuracy: 0.984 
training batch:    81, loss: 13.18647, precision: 0.784 recall: 0.784 f1: 0.784 accuracy: 0.948 
training batch:    82, loss: 9.82033, precision: 0.889 recall: 0.865 f1: 0.877 accuracy: 0.966 
training batch:    83, loss: 7.14621, precision: 0.842 recall: 0.889 f1: 0.865 accuracy: 0.974 
training batch:    84, loss: 10.50951, precision: 0.927 recall: 0.884 f1: 0.905 accuracy: 0.978 
training batch:    85, loss: 11.80914, precision: 0.829 recall: 0.850 f1: 0.840 accuracy: 0.956 
training batch:    86, loss: 11.31548, precision: 0.750 recall: 0.727 f1: 0.738 accuracy: 0.964 
training batch:    87, loss: 15.67531, precision: 0.710 recall: 0.710 f1: 0.710 accuracy: 0.955 
training batch:    88, loss: 6.92787, precision: 0.868 recall: 0.805 f1: 0.835 accuracy: 0.976 
training batch:    89, loss: 20.92545, precision: 0.844 recall: 0.643 f1: 0.730 accuracy: 0.922 
training batch:    90, loss: 12.06612, precision: 0.792 recall: 0.731 f1: 0.760 accuracy: 0.959 
training batch:    91, loss: 9.62738, precision: 0.844 recall: 0.794 f1: 0.818 accuracy: 0.966 
training batch:    92, loss: 14.84943, precision: 0.780 recall: 0.821 f1: 0.800 accuracy: 0.956 
training batch:    93, loss: 6.61017, precision: 0.909 recall: 0.857 f1: 0.882 accuracy: 0.980 
training batch:    94, loss: 8.04156, precision: 0.718 recall: 0.778 f1: 0.747 accuracy: 0.979 
training batch:    95, loss: 7.46809, precision: 0.878 recall: 0.857 f1: 0.867 accuracy: 0.973 
training batch:    96, loss: 4.79293, precision: 0.833 recall: 0.882 f1: 0.857 accuracy: 0.980 
training batch:    97, loss: 19.65779, precision: 0.658 recall: 0.735 f1: 0.694 accuracy: 0.936 
training batch:    98, loss: 10.02811, precision: 0.725 recall: 0.853 f1: 0.784 accuracy: 0.959 
training batch:    99, loss: 12.42327, precision: 0.825 recall: 0.868 f1: 0.846 accuracy: 0.958 
training batch:   100, loss: 10.12701, precision: 0.795 recall: 0.795 f1: 0.795 accuracy: 0.971 
training batch:   101, loss: 5.14924, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.984 
training batch:   102, loss: 8.97963, precision: 0.793 recall: 0.657 f1: 0.719 accuracy: 0.961 
training batch:   103, loss: 8.96812, precision: 0.857 recall: 0.882 f1: 0.870 accuracy: 0.963 
training batch:   104, loss: 13.08898, precision: 0.750 recall: 0.636 f1: 0.689 accuracy: 0.965 
training batch:   105, loss: 10.72526, precision: 0.771 recall: 0.771 f1: 0.771 accuracy: 0.948 
training batch:   106, loss: 11.46230, precision: 0.741 recall: 0.645 f1: 0.690 accuracy: 0.948 
training batch:   107, loss: 15.78889, precision: 0.824 recall: 0.737 f1: 0.778 accuracy: 0.944 
training batch:   108, loss: 6.84906, precision: 0.886 recall: 0.861 f1: 0.873 accuracy: 0.975 
training batch:   109, loss: 7.36290, precision: 0.722 recall: 0.743 f1: 0.732 accuracy: 0.978 
training batch:   110, loss: 16.47398, precision: 0.848 recall: 0.824 f1: 0.836 accuracy: 0.944 
training batch:   111, loss: 11.61492, precision: 0.714 recall: 0.833 f1: 0.769 accuracy: 0.955 
training batch:   112, loss: 4.63832, precision: 0.833 recall: 0.882 f1: 0.857 accuracy: 0.983 
training batch:   113, loss: 9.25490, precision: 0.733 recall: 0.688 f1: 0.710 accuracy: 0.969 
training batch:   114, loss: 2.11760, precision: 0.938 recall: 0.833 f1: 0.882 accuracy: 0.991 
training batch:   115, loss: 20.47932, precision: 0.659 recall: 0.643 f1: 0.651 accuracy: 0.958 
training batch:   116, loss: 11.46799, precision: 0.812 recall: 0.722 f1: 0.765 accuracy: 0.960 
training batch:   117, loss: 9.41732, precision: 0.806 recall: 0.784 f1: 0.795 accuracy: 0.961 
training batch:   118, loss: 9.29935, precision: 0.724 recall: 0.700 f1: 0.712 accuracy: 0.968 
training batch:   119, loss: 10.31443, precision: 0.625 recall: 0.690 f1: 0.656 accuracy: 0.939 
training batch:   120, loss: 3.39871, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.989 
training batch:   121, loss: 6.25847, precision: 0.824 recall: 0.848 f1: 0.836 accuracy: 0.984 
training batch:   122, loss: 9.11755, precision: 0.816 recall: 0.861 f1: 0.838 accuracy: 0.965 
training batch:   123, loss: 9.86292, precision: 0.667 recall: 0.686 f1: 0.676 accuracy: 0.956 
training batch:   124, loss: 7.11609, precision: 0.912 recall: 0.838 f1: 0.873 accuracy: 0.976 
training batch:   125, loss: 8.50633, precision: 0.806 recall: 0.829 f1: 0.817 accuracy: 0.979 
training batch:   126, loss: 22.17389, precision: 0.767 recall: 0.719 f1: 0.742 accuracy: 0.907 
training batch:   127, loss: 8.12701, precision: 0.731 recall: 0.633 f1: 0.679 accuracy: 0.973 
training batch:   128, loss: 5.26501, precision: 0.865 recall: 0.889 f1: 0.877 accuracy: 0.979 
training batch:   129, loss: 21.13938, precision: 0.765 recall: 0.743 f1: 0.754 accuracy: 0.932 
training batch:   130, loss: 6.41013, precision: 0.865 recall: 0.842 f1: 0.853 accuracy: 0.970 
training batch:   131, loss: 8.26059, precision: 0.800 recall: 0.875 f1: 0.836 accuracy: 0.966 
training batch:   132, loss: 11.33742, precision: 0.775 recall: 0.795 f1: 0.785 accuracy: 0.964 
training batch:   133, loss: 7.73686, precision: 0.815 recall: 0.846 f1: 0.830 accuracy: 0.986 
training batch:   134, loss: 8.06763, precision: 0.794 recall: 0.818 f1: 0.806 accuracy: 0.970 
training batch:   135, loss: 7.56783, precision: 0.838 recall: 0.816 f1: 0.827 accuracy: 0.979 
training batch:   136, loss: 7.63015, precision: 0.897 recall: 0.867 f1: 0.881 accuracy: 0.978 
training batch:   137, loss: 10.77750, precision: 0.719 recall: 0.719 f1: 0.719 accuracy: 0.965 
training batch:   138, loss: 10.16233, precision: 0.852 recall: 0.742 f1: 0.793 accuracy: 0.970 
training batch:   139, loss: 6.56263, precision: 0.811 recall: 0.857 f1: 0.833 accuracy: 0.971 
training batch:   140, loss: 10.78252, precision: 0.795 recall: 0.838 f1: 0.816 accuracy: 0.954 
training batch:   141, loss: 5.68069, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.988 
training batch:   142, loss: 8.04106, precision: 0.846 recall: 0.786 f1: 0.815 accuracy: 0.979 
training batch:   143, loss: 19.17312, precision: 0.769 recall: 0.750 f1: 0.759 accuracy: 0.929 
training batch:   144, loss: 3.06079, precision: 0.952 recall: 0.833 f1: 0.889 accuracy: 0.990 
training batch:   145, loss: 4.23704, precision: 0.889 recall: 0.923 f1: 0.906 accuracy: 0.991 
training batch:   146, loss: 13.62132, precision: 0.861 recall: 0.756 f1: 0.805 accuracy: 0.975 
training batch:   147, loss: 6.62746, precision: 0.812 recall: 0.743 f1: 0.776 accuracy: 0.985 
training batch:   148, loss: 10.25832, precision: 0.793 recall: 0.767 f1: 0.780 accuracy: 0.954 
training batch:   149, loss: 9.08386, precision: 0.906 recall: 0.853 f1: 0.879 accuracy: 0.979 
training batch:   150, loss: 22.49236, precision: 0.731 recall: 0.691 f1: 0.710 accuracy: 0.948 
training batch:   151, loss: 15.82267, precision: 0.818 recall: 0.900 f1: 0.857 accuracy: 0.965 
training batch:   152, loss: 5.95257, precision: 0.861 recall: 0.886 f1: 0.873 accuracy: 0.984 
training batch:   153, loss: 13.94440, precision: 0.767 recall: 0.825 f1: 0.795 accuracy: 0.945 
training batch:   154, loss: 15.14689, precision: 0.697 recall: 0.742 f1: 0.719 accuracy: 0.945 
training batch:   155, loss: 6.65386, precision: 0.815 recall: 0.815 f1: 0.815 accuracy: 0.980 
training batch:   156, loss: 13.01928, precision: 0.816 recall: 0.861 f1: 0.838 accuracy: 0.953 
training batch:   157, loss: 13.99346, precision: 0.788 recall: 0.765 f1: 0.776 accuracy: 0.954 
training batch:   158, loss: 5.53725, precision: 0.917 recall: 0.892 f1: 0.904 accuracy: 0.978 
training batch:   159, loss: 14.48830, precision: 0.743 recall: 0.684 f1: 0.712 accuracy: 0.950 
training batch:   160, loss: 9.92957, precision: 0.765 recall: 0.684 f1: 0.722 accuracy: 0.963 
training batch:   161, loss: 9.82335, precision: 0.839 recall: 0.667 f1: 0.743 accuracy: 0.966 
training batch:   162, loss: 10.25219, precision: 0.769 recall: 0.811 f1: 0.789 accuracy: 0.959 
training batch:   163, loss: 9.59263, precision: 0.816 recall: 0.838 f1: 0.827 accuracy: 0.974 
training batch:   164, loss: 11.09801, precision: 0.857 recall: 0.811 f1: 0.833 accuracy: 0.956 
training batch:   165, loss: 6.85183, precision: 0.868 recall: 0.892 f1: 0.880 accuracy: 0.981 
training batch:   166, loss: 9.53026, precision: 0.861 recall: 0.912 f1: 0.886 accuracy: 0.974 
training batch:   167, loss: 10.19795, precision: 0.788 recall: 0.812 f1: 0.800 accuracy: 0.968 
training batch:   168, loss: 10.12856, precision: 0.844 recall: 0.900 f1: 0.871 accuracy: 0.970 
training batch:   169, loss: 11.30460, precision: 0.902 recall: 0.822 f1: 0.860 accuracy: 0.973 
training batch:   170, loss: 6.79165, precision: 0.806 recall: 0.879 f1: 0.841 accuracy: 0.966 
training batch:   171, loss: 9.96638, precision: 0.833 recall: 0.875 f1: 0.854 accuracy: 0.965 
training batch:   172, loss: 16.46761, precision: 0.806 recall: 0.641 f1: 0.714 accuracy: 0.949 
training batch:   173, loss: 11.84157, precision: 0.878 recall: 0.878 f1: 0.878 accuracy: 0.968 
training batch:   174, loss: 9.67529, precision: 0.781 recall: 0.625 f1: 0.694 accuracy: 0.955 
training batch:   175, loss: 9.47137, precision: 0.857 recall: 0.750 f1: 0.800 accuracy: 0.974 
training batch:   176, loss: 8.42940, precision: 0.786 recall: 0.943 f1: 0.857 accuracy: 0.975 
training batch:   177, loss: 6.09899, precision: 0.829 recall: 0.829 f1: 0.829 accuracy: 0.983 
training batch:   178, loss: 17.89272, precision: 0.737 recall: 0.737 f1: 0.737 accuracy: 0.927 
start evaluate engines...
label: Dsa, precision: 0.721 recall: 0.714 f1: 0.711 
label: Chk, precision: 0.713 recall: 0.680 f1: 0.682 
label: Ins, precision: 0.343 recall: 0.383 f1: 0.358 
label: Sur, precision: 0.831 recall: 0.873 f1: 0.848 
label: Med, precision: 0.383 recall: 0.415 f1: 0.395 
label: Ana, precision: 0.813 recall: 0.857 f1: 0.832 
time consumption:4.25(min), precision: 0.799 recall: 0.840 f1: 0.818 accuracy: 0.965 
saved the new best model with f1: 0.818
epoch:5/100
training batch:     1, loss: 5.38804, precision: 0.917 recall: 0.846 f1: 0.880 accuracy: 0.990 
training batch:     2, loss: 10.06250, precision: 0.811 recall: 0.857 f1: 0.833 accuracy: 0.965 
training batch:     3, loss: 4.35405, precision: 0.862 recall: 0.893 f1: 0.877 accuracy: 0.981 
training batch:     4, loss: 5.40518, precision: 0.750 recall: 0.868 f1: 0.805 accuracy: 0.974 
training batch:     5, loss: 14.27169, precision: 0.704 recall: 0.633 f1: 0.667 accuracy: 0.966 
training batch:     6, loss: 21.38866, precision: 0.800 recall: 0.800 f1: 0.800 accuracy: 0.950 
training batch:     7, loss: 7.53130, precision: 0.828 recall: 0.667 f1: 0.738 accuracy: 0.975 
training batch:     8, loss: 3.80035, precision: 0.857 recall: 0.828 f1: 0.842 accuracy: 0.983 
training batch:     9, loss: 2.95493, precision: 0.969 recall: 0.886 f1: 0.925 accuracy: 0.988 
training batch:    10, loss: 5.47952, precision: 0.872 recall: 0.919 f1: 0.895 accuracy: 0.981 
training batch:    11, loss: 9.01928, precision: 0.810 recall: 0.850 f1: 0.829 accuracy: 0.970 
training batch:    12, loss: 8.55044, precision: 0.926 recall: 0.833 f1: 0.877 accuracy: 0.975 
training batch:    13, loss: 10.36767, precision: 0.794 recall: 0.818 f1: 0.806 accuracy: 0.961 
training batch:    14, loss: 4.26727, precision: 0.921 recall: 0.897 f1: 0.909 accuracy: 0.994 
training batch:    15, loss: 5.89407, precision: 0.667 recall: 0.811 f1: 0.732 accuracy: 0.974 
training batch:    16, loss: 11.75314, precision: 0.826 recall: 0.864 f1: 0.844 accuracy: 0.963 
training batch:    17, loss: 19.44638, precision: 0.724 recall: 0.636 f1: 0.677 accuracy: 0.960 
training batch:    18, loss: 10.94146, precision: 0.821 recall: 0.821 f1: 0.821 accuracy: 0.969 
training batch:    19, loss: 6.24516, precision: 0.846 recall: 0.786 f1: 0.815 accuracy: 0.975 
training batch:    20, loss: 6.85110, precision: 0.818 recall: 0.794 f1: 0.806 accuracy: 0.973 
training batch:    21, loss: 7.72698, precision: 0.903 recall: 0.848 f1: 0.875 accuracy: 0.965 
training batch:    22, loss: 11.78333, precision: 0.742 recall: 0.742 f1: 0.742 accuracy: 0.936 
training batch:    23, loss: 7.22892, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.968 
training batch:    24, loss: 6.09926, precision: 0.861 recall: 0.861 f1: 0.861 accuracy: 0.985 
training batch:    25, loss: 9.47276, precision: 0.897 recall: 0.722 f1: 0.800 accuracy: 0.970 
training batch:    26, loss: 6.37806, precision: 0.727 recall: 0.727 f1: 0.727 accuracy: 0.975 
training batch:    27, loss: 10.34610, precision: 0.865 recall: 0.780 f1: 0.821 accuracy: 0.971 
training batch:    28, loss: 6.54576, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.974 
training batch:    29, loss: 4.87165, precision: 0.821 recall: 0.821 f1: 0.821 accuracy: 0.988 
training batch:    30, loss: 3.74288, precision: 0.867 recall: 0.929 f1: 0.897 accuracy: 0.988 
training batch:    31, loss: 6.28593, precision: 0.838 recall: 0.816 f1: 0.827 accuracy: 0.981 
training batch:    32, loss: 6.68137, precision: 0.844 recall: 0.771 f1: 0.806 accuracy: 0.980 
training batch:    33, loss: 17.20752, precision: 0.588 recall: 0.606 f1: 0.597 accuracy: 0.940 
training batch:    34, loss: 12.51920, precision: 0.750 recall: 0.767 f1: 0.759 accuracy: 0.963 
training batch:    35, loss: 9.65820, precision: 0.789 recall: 0.811 f1: 0.800 accuracy: 0.960 
training batch:    36, loss: 7.58354, precision: 0.840 recall: 0.955 f1: 0.894 accuracy: 0.983 
training batch:    37, loss: 8.91090, precision: 0.658 recall: 0.658 f1: 0.658 accuracy: 0.956 
training batch:    38, loss: 15.38464, precision: 0.884 recall: 0.950 f1: 0.916 accuracy: 0.960 
training batch:    39, loss: 3.28150, precision: 0.857 recall: 0.938 f1: 0.896 accuracy: 0.990 
training batch:    40, loss: 25.08887, precision: 0.656 recall: 0.677 f1: 0.667 accuracy: 0.936 
training batch:    41, loss: 7.20059, precision: 0.769 recall: 0.789 f1: 0.779 accuracy: 0.975 
training batch:    42, loss: 3.90780, precision: 0.862 recall: 0.833 f1: 0.847 accuracy: 0.988 
training batch:    43, loss: 17.53320, precision: 0.683 recall: 0.651 f1: 0.667 accuracy: 0.932 
training batch:    44, loss: 12.43053, precision: 0.750 recall: 0.711 f1: 0.730 accuracy: 0.944 
training batch:    45, loss: 9.76347, precision: 0.879 recall: 0.829 f1: 0.853 accuracy: 0.974 
training batch:    46, loss: 5.27973, precision: 0.889 recall: 0.857 f1: 0.873 accuracy: 0.979 
training batch:    47, loss: 3.94687, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.985 
training batch:    48, loss: 4.42226, precision: 0.800 recall: 0.828 f1: 0.814 accuracy: 0.986 
training batch:    49, loss: 7.17448, precision: 0.806 recall: 0.758 f1: 0.781 accuracy: 0.969 
training batch:    50, loss: 5.02432, precision: 0.848 recall: 0.848 f1: 0.848 accuracy: 0.985 
training batch:    51, loss: 18.86201, precision: 0.692 recall: 0.750 f1: 0.720 accuracy: 0.927 
training batch:    52, loss: 7.18911, precision: 0.758 recall: 0.781 f1: 0.769 accuracy: 0.981 
training batch:    53, loss: 4.62573, precision: 0.861 recall: 0.886 f1: 0.873 accuracy: 0.984 
training batch:    54, loss: 6.52761, precision: 0.917 recall: 0.846 f1: 0.880 accuracy: 0.980 
training batch:    55, loss: 10.26401, precision: 0.733 recall: 0.688 f1: 0.710 accuracy: 0.978 
training batch:    56, loss: 7.89167, precision: 0.694 recall: 0.758 f1: 0.725 accuracy: 0.968 
training batch:    57, loss: 11.17230, precision: 0.703 recall: 0.788 f1: 0.743 accuracy: 0.956 
training batch:    58, loss: 6.18777, precision: 0.846 recall: 0.825 f1: 0.835 accuracy: 0.981 
training batch:    59, loss: 5.59308, precision: 0.800 recall: 0.828 f1: 0.814 accuracy: 0.980 
training batch:    60, loss: 10.17206, precision: 0.808 recall: 0.700 f1: 0.750 accuracy: 0.955 
training batch:    61, loss: 7.07063, precision: 0.727 recall: 0.774 f1: 0.750 accuracy: 0.976 
training batch:    62, loss: 5.18858, precision: 0.860 recall: 0.881 f1: 0.871 accuracy: 0.988 
training batch:    63, loss: 7.99051, precision: 0.762 recall: 0.727 f1: 0.744 accuracy: 0.969 
training batch:    64, loss: 8.85441, precision: 0.921 recall: 0.854 f1: 0.886 accuracy: 0.978 
training batch:    65, loss: 20.47466, precision: 0.750 recall: 0.635 f1: 0.688 accuracy: 0.946 
training batch:    66, loss: 11.70878, precision: 0.786 recall: 0.759 f1: 0.772 accuracy: 0.973 
training batch:    67, loss: 8.41725, precision: 0.882 recall: 0.938 f1: 0.909 accuracy: 0.980 
training batch:    68, loss: 15.17128, precision: 0.698 recall: 0.789 f1: 0.741 accuracy: 0.936 
training batch:    69, loss: 7.39704, precision: 0.879 recall: 0.806 f1: 0.841 accuracy: 0.974 
training batch:    70, loss: 7.44621, precision: 0.791 recall: 0.895 f1: 0.840 accuracy: 0.965 
training batch:    71, loss: 7.83673, precision: 0.722 recall: 0.765 f1: 0.743 accuracy: 0.971 
training batch:    72, loss: 6.16045, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.975 
training batch:    73, loss: 4.93500, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.991 
training batch:    74, loss: 7.52713, precision: 0.757 recall: 0.824 f1: 0.789 accuracy: 0.971 
training batch:    75, loss: 5.61286, precision: 0.875 recall: 0.966 f1: 0.918 accuracy: 0.976 
training batch:    76, loss: 13.21420, precision: 0.893 recall: 0.833 f1: 0.862 accuracy: 0.959 
training batch:    77, loss: 3.76067, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.994 
training batch:    78, loss: 5.75660, precision: 0.868 recall: 0.786 f1: 0.825 accuracy: 0.983 
training batch:    79, loss: 7.27670, precision: 0.943 recall: 0.786 f1: 0.857 accuracy: 0.971 
training batch:    80, loss: 9.24047, precision: 0.879 recall: 0.763 f1: 0.817 accuracy: 0.968 
training batch:    81, loss: 19.55361, precision: 0.714 recall: 0.676 f1: 0.694 accuracy: 0.907 
training batch:    82, loss: 12.01334, precision: 0.833 recall: 0.750 f1: 0.789 accuracy: 0.954 
training batch:    83, loss: 9.35993, precision: 0.812 recall: 0.722 f1: 0.765 accuracy: 0.973 
training batch:    84, loss: 12.53828, precision: 0.733 recall: 0.868 f1: 0.795 accuracy: 0.931 
training batch:    85, loss: 16.88578, precision: 0.879 recall: 0.879 f1: 0.879 accuracy: 0.934 
training batch:    86, loss: 6.62374, precision: 0.697 recall: 0.742 f1: 0.719 accuracy: 0.980 
training batch:    87, loss: 12.15910, precision: 0.710 recall: 0.688 f1: 0.698 accuracy: 0.941 
training batch:    88, loss: 17.44434, precision: 0.833 recall: 0.694 f1: 0.758 accuracy: 0.920 
training batch:    89, loss: 12.67877, precision: 0.857 recall: 0.878 f1: 0.867 accuracy: 0.954 
training batch:    90, loss: 7.93644, precision: 0.805 recall: 0.825 f1: 0.815 accuracy: 0.975 
training batch:    91, loss: 7.27496, precision: 0.791 recall: 0.850 f1: 0.819 accuracy: 0.980 
training batch:    92, loss: 10.68666, precision: 0.811 recall: 0.827 f1: 0.819 accuracy: 0.974 
training batch:    93, loss: 6.84082, precision: 0.758 recall: 0.833 f1: 0.794 accuracy: 0.971 
training batch:    94, loss: 5.06087, precision: 0.788 recall: 0.867 f1: 0.825 accuracy: 0.981 
training batch:    95, loss: 8.18984, precision: 0.933 recall: 0.875 f1: 0.903 accuracy: 0.963 
training batch:    96, loss: 3.38503, precision: 0.862 recall: 0.833 f1: 0.847 accuracy: 0.990 
training batch:    97, loss: 6.44957, precision: 0.838 recall: 0.775 f1: 0.805 accuracy: 0.976 
training batch:    98, loss: 7.91936, precision: 0.784 recall: 0.744 f1: 0.763 accuracy: 0.974 
training batch:    99, loss: 12.31728, precision: 0.710 recall: 0.667 f1: 0.688 accuracy: 0.961 
training batch:   100, loss: 4.91862, precision: 0.833 recall: 0.806 f1: 0.820 accuracy: 0.986 
training batch:   101, loss: 5.24842, precision: 0.861 recall: 0.861 f1: 0.861 accuracy: 0.980 
training batch:   102, loss: 10.67899, precision: 0.879 recall: 0.906 f1: 0.892 accuracy: 0.974 
training batch:   103, loss: 18.39742, precision: 0.773 recall: 0.708 f1: 0.739 accuracy: 0.927 
training batch:   104, loss: 9.27344, precision: 0.968 recall: 0.857 f1: 0.909 accuracy: 0.968 
training batch:   105, loss: 6.58749, precision: 0.800 recall: 0.800 f1: 0.800 accuracy: 0.975 
training batch:   106, loss: 5.46727, precision: 0.893 recall: 0.862 f1: 0.877 accuracy: 0.984 
training batch:   107, loss: 4.85864, precision: 0.783 recall: 0.783 f1: 0.783 accuracy: 0.983 
training batch:   108, loss: 7.89849, precision: 0.808 recall: 0.724 f1: 0.764 accuracy: 0.969 
training batch:   109, loss: 14.10009, precision: 0.710 recall: 0.733 f1: 0.721 accuracy: 0.949 
training batch:   110, loss: 10.66554, precision: 0.806 recall: 0.781 f1: 0.794 accuracy: 0.971 
training batch:   111, loss: 5.18005, precision: 0.909 recall: 0.857 f1: 0.882 accuracy: 0.985 
training batch:   112, loss: 6.66125, precision: 0.829 recall: 0.853 f1: 0.841 accuracy: 0.976 
training batch:   113, loss: 11.89973, precision: 0.781 recall: 0.714 f1: 0.746 accuracy: 0.956 
training batch:   114, loss: 7.97541, precision: 0.889 recall: 0.800 f1: 0.842 accuracy: 0.985 
training batch:   115, loss: 9.53967, precision: 0.793 recall: 0.793 f1: 0.793 accuracy: 0.974 
training batch:   116, loss: 10.47550, precision: 0.800 recall: 0.744 f1: 0.771 accuracy: 0.964 
training batch:   117, loss: 10.04179, precision: 0.769 recall: 0.811 f1: 0.789 accuracy: 0.968 
training batch:   118, loss: 9.24976, precision: 0.750 recall: 0.844 f1: 0.794 accuracy: 0.963 
training batch:   119, loss: 5.60085, precision: 0.806 recall: 0.806 f1: 0.806 accuracy: 0.986 
training batch:   120, loss: 16.71006, precision: 0.735 recall: 0.694 f1: 0.714 accuracy: 0.939 
training batch:   121, loss: 13.15809, precision: 0.745 recall: 0.833 f1: 0.787 accuracy: 0.946 
training batch:   122, loss: 5.15054, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.986 
training batch:   123, loss: 3.30888, precision: 0.850 recall: 0.850 f1: 0.850 accuracy: 0.988 
training batch:   124, loss: 4.87162, precision: 0.912 recall: 0.816 f1: 0.861 accuracy: 0.979 
training batch:   125, loss: 9.50489, precision: 0.738 recall: 0.795 f1: 0.765 accuracy: 0.958 
training batch:   126, loss: 9.28509, precision: 0.868 recall: 0.825 f1: 0.846 accuracy: 0.964 
training batch:   127, loss: 6.26939, precision: 0.889 recall: 0.821 f1: 0.853 accuracy: 0.979 
training batch:   128, loss: 18.15797, precision: 0.643 recall: 0.692 f1: 0.667 accuracy: 0.936 
training batch:   129, loss: 18.46597, precision: 0.792 recall: 0.826 f1: 0.809 accuracy: 0.940 
training batch:   130, loss: 13.86520, precision: 0.854 recall: 0.854 f1: 0.854 accuracy: 0.936 
training batch:   131, loss: 14.55608, precision: 0.667 recall: 0.686 f1: 0.676 accuracy: 0.930 
training batch:   132, loss: 7.87716, precision: 0.861 recall: 0.886 f1: 0.873 accuracy: 0.979 
training batch:   133, loss: 8.54123, precision: 0.795 recall: 0.816 f1: 0.805 accuracy: 0.966 
training batch:   134, loss: 9.21129, precision: 0.733 recall: 0.815 f1: 0.772 accuracy: 0.966 
training batch:   135, loss: 6.70378, precision: 0.868 recall: 0.917 f1: 0.892 accuracy: 0.975 
training batch:   136, loss: 6.22656, precision: 0.812 recall: 0.788 f1: 0.800 accuracy: 0.974 
training batch:   137, loss: 5.74691, precision: 0.852 recall: 0.767 f1: 0.807 accuracy: 0.983 
training batch:   138, loss: 5.51408, precision: 0.867 recall: 0.788 f1: 0.825 accuracy: 0.980 
training batch:   139, loss: 10.66640, precision: 0.895 recall: 0.850 f1: 0.872 accuracy: 0.969 
training batch:   140, loss: 11.96414, precision: 0.839 recall: 0.722 f1: 0.776 accuracy: 0.958 
training batch:   141, loss: 5.75590, precision: 0.875 recall: 0.933 f1: 0.903 accuracy: 0.983 
training batch:   142, loss: 9.77724, precision: 0.758 recall: 0.735 f1: 0.746 accuracy: 0.964 
training batch:   143, loss: 9.09846, precision: 0.844 recall: 0.771 f1: 0.806 accuracy: 0.971 
training batch:   144, loss: 7.06161, precision: 0.821 recall: 0.889 f1: 0.853 accuracy: 0.976 
training batch:   145, loss: 7.16922, precision: 0.794 recall: 0.771 f1: 0.783 accuracy: 0.970 
training batch:   146, loss: 8.19241, precision: 0.828 recall: 0.727 f1: 0.774 accuracy: 0.971 
training batch:   147, loss: 6.61311, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.984 
training batch:   148, loss: 4.69851, precision: 0.953 recall: 0.911 f1: 0.932 accuracy: 0.988 
training batch:   149, loss: 12.48004, precision: 0.714 recall: 0.714 f1: 0.714 accuracy: 0.953 
training batch:   150, loss: 4.13737, precision: 0.806 recall: 0.935 f1: 0.866 accuracy: 0.984 
training batch:   151, loss: 7.80491, precision: 0.861 recall: 0.861 f1: 0.861 accuracy: 0.974 
training batch:   152, loss: 5.85404, precision: 0.974 recall: 0.925 f1: 0.949 accuracy: 0.986 
training batch:   153, loss: 12.09773, precision: 0.778 recall: 0.778 f1: 0.778 accuracy: 0.960 
training batch:   154, loss: 9.11246, precision: 0.784 recall: 0.829 f1: 0.806 accuracy: 0.958 
training batch:   155, loss: 6.30466, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.973 
training batch:   156, loss: 10.53515, precision: 0.935 recall: 0.906 f1: 0.921 accuracy: 0.976 
training batch:   157, loss: 4.21537, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.976 
training batch:   158, loss: 4.84700, precision: 0.935 recall: 0.806 f1: 0.866 accuracy: 0.984 
training batch:   159, loss: 10.33463, precision: 0.857 recall: 0.828 f1: 0.842 accuracy: 0.970 
training batch:   160, loss: 8.47775, precision: 0.884 recall: 0.905 f1: 0.894 accuracy: 0.975 
training batch:   161, loss: 3.58016, precision: 0.850 recall: 0.850 f1: 0.850 accuracy: 0.990 
training batch:   162, loss: 10.88907, precision: 0.741 recall: 0.645 f1: 0.690 accuracy: 0.963 
training batch:   163, loss: 9.54622, precision: 0.750 recall: 0.774 f1: 0.762 accuracy: 0.974 
training batch:   164, loss: 12.65677, precision: 0.864 recall: 0.927 f1: 0.894 accuracy: 0.959 
training batch:   165, loss: 2.95039, precision: 0.821 recall: 0.852 f1: 0.836 accuracy: 0.985 
training batch:   166, loss: 6.64650, precision: 0.775 recall: 0.838 f1: 0.805 accuracy: 0.970 
training batch:   167, loss: 9.60133, precision: 0.867 recall: 0.867 f1: 0.867 accuracy: 0.954 
training batch:   168, loss: 6.45454, precision: 0.833 recall: 0.862 f1: 0.847 accuracy: 0.980 
training batch:   169, loss: 7.13119, precision: 0.824 recall: 0.800 f1: 0.812 accuracy: 0.971 
training batch:   170, loss: 13.92625, precision: 0.867 recall: 0.839 f1: 0.852 accuracy: 0.968 
training batch:   171, loss: 7.26136, precision: 0.839 recall: 0.897 f1: 0.867 accuracy: 0.965 
training batch:   172, loss: 10.36388, precision: 0.791 recall: 0.850 f1: 0.819 accuracy: 0.966 
training batch:   173, loss: 9.65369, precision: 0.893 recall: 0.862 f1: 0.877 accuracy: 0.978 
training batch:   174, loss: 11.23450, precision: 0.857 recall: 0.769 f1: 0.811 accuracy: 0.955 
training batch:   175, loss: 11.02039, precision: 0.788 recall: 0.765 f1: 0.776 accuracy: 0.963 
training batch:   176, loss: 6.80270, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.984 
training batch:   177, loss: 5.71331, precision: 0.811 recall: 0.833 f1: 0.822 accuracy: 0.986 
training batch:   178, loss: 9.99825, precision: 0.929 recall: 0.867 f1: 0.897 accuracy: 0.967 
start evaluate engines...
label: Dsa, precision: 0.682 recall: 0.760 f1: 0.712 
label: Chk, precision: 0.483 recall: 0.403 f1: 0.419 
label: Ins, precision: 0.358 recall: 0.371 f1: 0.361 
label: Sur, precision: 0.880 recall: 0.871 f1: 0.873 
label: Med, precision: 0.380 recall: 0.405 f1: 0.388 
label: Ana, precision: 0.846 recall: 0.804 f1: 0.821 
time consumption:4.23(min), precision: 0.823 recall: 0.820 f1: 0.821 accuracy: 0.966 
saved the new best model with f1: 0.821
epoch:6/100
training batch:     1, loss: 4.33758, precision: 0.970 recall: 0.914 f1: 0.941 accuracy: 0.989 
training batch:     2, loss: 13.41145, precision: 0.750 recall: 0.686 f1: 0.716 accuracy: 0.963 
training batch:     3, loss: 14.89848, precision: 0.767 recall: 0.719 f1: 0.742 accuracy: 0.943 
training batch:     4, loss: 12.38226, precision: 0.854 recall: 0.854 f1: 0.854 accuracy: 0.964 
training batch:     5, loss: 11.17841, precision: 0.879 recall: 0.829 f1: 0.853 accuracy: 0.964 
training batch:     6, loss: 8.28192, precision: 0.897 recall: 0.812 f1: 0.852 accuracy: 0.979 
training batch:     7, loss: 11.59377, precision: 0.833 recall: 0.857 f1: 0.845 accuracy: 0.950 
training batch:     8, loss: 6.11139, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.989 
training batch:     9, loss: 8.58114, precision: 0.864 recall: 0.809 f1: 0.835 accuracy: 0.976 
training batch:    10, loss: 8.61485, precision: 0.811 recall: 0.857 f1: 0.833 accuracy: 0.979 
training batch:    11, loss: 15.41015, precision: 0.816 recall: 0.795 f1: 0.805 accuracy: 0.946 
training batch:    12, loss: 1.78083, precision: 0.935 recall: 1.000 f1: 0.967 accuracy: 0.998 
training batch:    13, loss: 2.29731, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.994 
training batch:    14, loss: 5.58709, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.986 
training batch:    15, loss: 4.89442, precision: 0.821 recall: 0.852 f1: 0.836 accuracy: 0.984 
training batch:    16, loss: 6.63976, precision: 0.839 recall: 0.839 f1: 0.839 accuracy: 0.966 
training batch:    17, loss: 5.94856, precision: 0.875 recall: 0.824 f1: 0.848 accuracy: 0.973 
training batch:    18, loss: 7.59272, precision: 0.848 recall: 0.875 f1: 0.862 accuracy: 0.974 
training batch:    19, loss: 7.41338, precision: 0.806 recall: 0.806 f1: 0.806 accuracy: 0.971 
training batch:    20, loss: 3.91790, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.995 
training batch:    21, loss: 7.03775, precision: 0.800 recall: 0.824 f1: 0.812 accuracy: 0.981 
training batch:    22, loss: 13.09222, precision: 0.697 recall: 0.622 f1: 0.657 accuracy: 0.958 
training batch:    23, loss: 10.37549, precision: 0.805 recall: 0.750 f1: 0.776 accuracy: 0.973 
training batch:    24, loss: 3.77632, precision: 0.880 recall: 0.880 f1: 0.880 accuracy: 0.990 
training batch:    25, loss: 5.68858, precision: 0.861 recall: 0.886 f1: 0.873 accuracy: 0.976 
training batch:    26, loss: 5.72282, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.974 
training batch:    27, loss: 5.10116, precision: 0.821 recall: 0.800 f1: 0.810 accuracy: 0.980 
training batch:    28, loss: 4.68025, precision: 0.889 recall: 0.865 f1: 0.877 accuracy: 0.979 
training batch:    29, loss: 5.35526, precision: 0.842 recall: 0.744 f1: 0.790 accuracy: 0.978 
training batch:    30, loss: 10.74085, precision: 0.833 recall: 0.732 f1: 0.779 accuracy: 0.960 
training batch:    31, loss: 6.29758, precision: 0.775 recall: 0.861 f1: 0.816 accuracy: 0.960 
training batch:    32, loss: 4.97479, precision: 0.861 recall: 0.775 f1: 0.816 accuracy: 0.976 
training batch:    33, loss: 4.90821, precision: 0.857 recall: 0.833 f1: 0.845 accuracy: 0.976 
training batch:    34, loss: 4.77758, precision: 0.860 recall: 0.925 f1: 0.892 accuracy: 0.980 
training batch:    35, loss: 2.96866, precision: 1.000 recall: 0.926 f1: 0.962 accuracy: 0.995 
training batch:    36, loss: 10.76048, precision: 0.917 recall: 0.892 f1: 0.904 accuracy: 0.966 
training batch:    37, loss: 3.19455, precision: 0.857 recall: 0.938 f1: 0.896 accuracy: 0.985 
training batch:    38, loss: 4.67500, precision: 0.872 recall: 0.944 f1: 0.907 accuracy: 0.984 
training batch:    39, loss: 9.85577, precision: 0.829 recall: 0.895 f1: 0.861 accuracy: 0.964 
training batch:    40, loss: 5.63359, precision: 0.808 recall: 0.875 f1: 0.840 accuracy: 0.984 
training batch:    41, loss: 12.37211, precision: 0.812 recall: 0.765 f1: 0.788 accuracy: 0.973 
training batch:    42, loss: 16.18149, precision: 0.784 recall: 0.784 f1: 0.784 accuracy: 0.949 
training batch:    43, loss: 6.05928, precision: 0.833 recall: 0.857 f1: 0.845 accuracy: 0.980 
training batch:    44, loss: 16.46418, precision: 0.639 recall: 0.561 f1: 0.597 accuracy: 0.925 
training batch:    45, loss: 4.29870, precision: 0.938 recall: 0.833 f1: 0.882 accuracy: 0.985 
training batch:    46, loss: 6.55418, precision: 0.844 recall: 0.905 f1: 0.874 accuracy: 0.981 
training batch:    47, loss: 5.82104, precision: 0.881 recall: 0.860 f1: 0.871 accuracy: 0.985 
training batch:    48, loss: 5.82659, precision: 0.864 recall: 0.760 f1: 0.809 accuracy: 0.969 
training batch:    49, loss: 8.55269, precision: 0.763 recall: 0.806 f1: 0.784 accuracy: 0.976 
training batch:    50, loss: 4.83442, precision: 0.889 recall: 0.774 f1: 0.828 accuracy: 0.980 
training batch:    51, loss: 5.14832, precision: 0.829 recall: 0.829 f1: 0.829 accuracy: 0.986 
training batch:    52, loss: 6.50059, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.980 
training batch:    53, loss: 6.04335, precision: 0.704 recall: 0.704 f1: 0.704 accuracy: 0.971 
training batch:    54, loss: 14.24005, precision: 0.771 recall: 0.844 f1: 0.806 accuracy: 0.945 
training batch:    55, loss: 9.30714, precision: 0.767 recall: 0.805 f1: 0.786 accuracy: 0.965 
training batch:    56, loss: 5.86848, precision: 0.794 recall: 0.844 f1: 0.818 accuracy: 0.983 
training batch:    57, loss: 5.13636, precision: 0.800 recall: 0.903 f1: 0.848 accuracy: 0.976 
training batch:    58, loss: 8.51538, precision: 0.810 recall: 0.791 f1: 0.800 accuracy: 0.968 
training batch:    59, loss: 9.47364, precision: 0.758 recall: 0.714 f1: 0.735 accuracy: 0.966 
training batch:    60, loss: 5.20780, precision: 0.853 recall: 0.906 f1: 0.879 accuracy: 0.981 
training batch:    61, loss: 6.40742, precision: 0.902 recall: 0.939 f1: 0.920 accuracy: 0.980 
training batch:    62, loss: 4.21427, precision: 0.865 recall: 0.865 f1: 0.865 accuracy: 0.985 
training batch:    63, loss: 6.48921, precision: 0.878 recall: 0.857 f1: 0.867 accuracy: 0.981 
training batch:    64, loss: 4.01144, precision: 0.889 recall: 0.842 f1: 0.865 accuracy: 0.990 
training batch:    65, loss: 5.70626, precision: 0.857 recall: 0.909 f1: 0.882 accuracy: 0.974 
training batch:    66, loss: 3.63923, precision: 0.839 recall: 0.812 f1: 0.825 accuracy: 0.988 
training batch:    67, loss: 4.28970, precision: 0.900 recall: 0.871 f1: 0.885 accuracy: 0.980 
training batch:    68, loss: 5.21749, precision: 0.897 recall: 0.867 f1: 0.881 accuracy: 0.985 
training batch:    69, loss: 5.86614, precision: 0.925 recall: 0.925 f1: 0.925 accuracy: 0.989 
training batch:    70, loss: 4.20998, precision: 0.886 recall: 0.861 f1: 0.873 accuracy: 0.988 
training batch:    71, loss: 7.61210, precision: 0.833 recall: 0.833 f1: 0.833 accuracy: 0.968 
training batch:    72, loss: 7.79060, precision: 0.903 recall: 0.933 f1: 0.918 accuracy: 0.979 
training batch:    73, loss: 9.05378, precision: 0.889 recall: 0.960 f1: 0.923 accuracy: 0.970 
training batch:    74, loss: 5.29028, precision: 0.886 recall: 0.886 f1: 0.886 accuracy: 0.988 
training batch:    75, loss: 2.43072, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    76, loss: 4.58459, precision: 0.750 recall: 0.750 f1: 0.750 accuracy: 0.986 
training batch:    77, loss: 3.15248, precision: 0.909 recall: 0.968 f1: 0.937 accuracy: 0.993 
training batch:    78, loss: 3.40424, precision: 0.885 recall: 0.852 f1: 0.868 accuracy: 0.985 
training batch:    79, loss: 5.35014, precision: 0.800 recall: 0.933 f1: 0.862 accuracy: 0.986 
training batch:    80, loss: 15.86955, precision: 0.821 recall: 0.676 f1: 0.742 accuracy: 0.948 
training batch:    81, loss: 2.97967, precision: 0.939 recall: 0.861 f1: 0.899 accuracy: 0.991 
training batch:    82, loss: 5.98605, precision: 0.872 recall: 0.895 f1: 0.883 accuracy: 0.984 
training batch:    83, loss: 5.39233, precision: 0.919 recall: 0.872 f1: 0.895 accuracy: 0.989 
training batch:    84, loss: 11.21218, precision: 0.935 recall: 0.906 f1: 0.921 accuracy: 0.975 
training batch:    85, loss: 6.90563, precision: 0.857 recall: 0.769 f1: 0.811 accuracy: 0.971 
training batch:    86, loss: 5.84900, precision: 0.838 recall: 0.795 f1: 0.816 accuracy: 0.981 
training batch:    87, loss: 7.73303, precision: 0.821 recall: 0.697 f1: 0.754 accuracy: 0.973 
training batch:    88, loss: 7.66744, precision: 0.900 recall: 0.964 f1: 0.931 accuracy: 0.985 
training batch:    89, loss: 2.32751, precision: 0.900 recall: 0.964 f1: 0.931 accuracy: 0.990 
training batch:    90, loss: 7.50974, precision: 0.704 recall: 0.655 f1: 0.679 accuracy: 0.960 
training batch:    91, loss: 5.04231, precision: 0.758 recall: 0.806 f1: 0.781 accuracy: 0.979 
training batch:    92, loss: 9.23542, precision: 0.773 recall: 0.850 f1: 0.810 accuracy: 0.965 
training batch:    93, loss: 3.54950, precision: 0.886 recall: 0.939 f1: 0.912 accuracy: 0.989 
training batch:    94, loss: 7.63704, precision: 0.824 recall: 0.824 f1: 0.824 accuracy: 0.970 
training batch:    95, loss: 5.43291, precision: 0.795 recall: 0.939 f1: 0.861 accuracy: 0.984 
training batch:    96, loss: 1.61205, precision: 1.000 recall: 0.889 f1: 0.941 accuracy: 0.996 
training batch:    97, loss: 4.87815, precision: 0.829 recall: 0.872 f1: 0.850 accuracy: 0.985 
training batch:    98, loss: 7.85746, precision: 0.821 recall: 0.941 f1: 0.877 accuracy: 0.969 
training batch:    99, loss: 1.69092, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.996 
training batch:   100, loss: 6.10262, precision: 0.886 recall: 0.861 f1: 0.873 accuracy: 0.978 
training batch:   101, loss: 13.46619, precision: 0.778 recall: 0.757 f1: 0.767 accuracy: 0.960 
training batch:   102, loss: 6.52798, precision: 0.727 recall: 0.640 f1: 0.681 accuracy: 0.984 
training batch:   103, loss: 6.33044, precision: 0.933 recall: 0.800 f1: 0.862 accuracy: 0.973 
training batch:   104, loss: 7.07381, precision: 0.789 recall: 0.789 f1: 0.789 accuracy: 0.974 
training batch:   105, loss: 14.20823, precision: 0.781 recall: 0.694 f1: 0.735 accuracy: 0.924 
training batch:   106, loss: 16.47492, precision: 0.769 recall: 0.667 f1: 0.714 accuracy: 0.950 
training batch:   107, loss: 2.68570, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.983 
training batch:   108, loss: 7.22015, precision: 0.730 recall: 0.844 f1: 0.783 accuracy: 0.978 
training batch:   109, loss: 3.79053, precision: 0.889 recall: 0.923 f1: 0.906 accuracy: 0.991 
training batch:   110, loss: 3.49210, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.991 
training batch:   111, loss: 5.39508, precision: 0.837 recall: 0.900 f1: 0.867 accuracy: 0.978 
training batch:   112, loss: 4.39746, precision: 0.829 recall: 0.906 f1: 0.866 accuracy: 0.976 
training batch:   113, loss: 3.34809, precision: 0.850 recall: 0.850 f1: 0.850 accuracy: 0.990 
training batch:   114, loss: 13.66154, precision: 0.643 recall: 0.711 f1: 0.675 accuracy: 0.950 
training batch:   115, loss: 10.47386, precision: 0.786 recall: 0.892 f1: 0.835 accuracy: 0.950 
training batch:   116, loss: 6.71230, precision: 0.765 recall: 0.839 f1: 0.800 accuracy: 0.980 
training batch:   117, loss: 7.89919, precision: 0.871 recall: 0.900 f1: 0.885 accuracy: 0.976 
training batch:   118, loss: 13.05674, precision: 0.812 recall: 0.839 f1: 0.825 accuracy: 0.955 
training batch:   119, loss: 3.17248, precision: 0.935 recall: 0.906 f1: 0.921 accuracy: 0.984 
training batch:   120, loss: 8.05886, precision: 0.773 recall: 0.708 f1: 0.739 accuracy: 0.968 
training batch:   121, loss: 7.10216, precision: 0.865 recall: 0.914 f1: 0.889 accuracy: 0.975 
training batch:   122, loss: 6.68847, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.969 
training batch:   123, loss: 7.56006, precision: 0.846 recall: 0.825 f1: 0.835 accuracy: 0.975 
training batch:   124, loss: 6.64738, precision: 0.780 recall: 0.780 f1: 0.780 accuracy: 0.976 
training batch:   125, loss: 10.60944, precision: 0.879 recall: 0.707 f1: 0.784 accuracy: 0.935 
training batch:   126, loss: 12.41754, precision: 0.824 recall: 0.757 f1: 0.789 accuracy: 0.954 
training batch:   127, loss: 6.40542, precision: 0.892 recall: 0.805 f1: 0.846 accuracy: 0.970 
training batch:   128, loss: 6.56284, precision: 0.833 recall: 0.926 f1: 0.877 accuracy: 0.976 
training batch:   129, loss: 4.37768, precision: 0.886 recall: 0.912 f1: 0.899 accuracy: 0.988 
training batch:   130, loss: 6.45125, precision: 0.892 recall: 0.917 f1: 0.904 accuracy: 0.970 
training batch:   131, loss: 6.82349, precision: 0.810 recall: 0.850 f1: 0.829 accuracy: 0.984 
training batch:   132, loss: 8.46559, precision: 0.773 recall: 0.810 f1: 0.791 accuracy: 0.964 
training batch:   133, loss: 8.26097, precision: 0.923 recall: 0.973 f1: 0.947 accuracy: 0.970 
training batch:   134, loss: 3.01862, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.988 
training batch:   135, loss: 10.28960, precision: 0.841 recall: 0.841 f1: 0.841 accuracy: 0.961 
training batch:   136, loss: 13.93635, precision: 0.854 recall: 0.875 f1: 0.864 accuracy: 0.948 
training batch:   137, loss: 13.32645, precision: 0.714 recall: 0.714 f1: 0.714 accuracy: 0.958 
training batch:   138, loss: 20.88165, precision: 0.781 recall: 0.758 f1: 0.769 accuracy: 0.959 
training batch:   139, loss: 8.61488, precision: 0.735 recall: 0.714 f1: 0.725 accuracy: 0.963 
training batch:   140, loss: 5.31792, precision: 0.821 recall: 0.793 f1: 0.807 accuracy: 0.969 
training batch:   141, loss: 6.99332, precision: 0.821 recall: 0.865 f1: 0.842 accuracy: 0.975 
training batch:   142, loss: 5.52635, precision: 0.862 recall: 0.862 f1: 0.862 accuracy: 0.985 
training batch:   143, loss: 7.49558, precision: 0.868 recall: 0.846 f1: 0.857 accuracy: 0.971 
training batch:   144, loss: 9.86079, precision: 0.825 recall: 0.825 f1: 0.825 accuracy: 0.979 
training batch:   145, loss: 8.04013, precision: 0.763 recall: 0.906 f1: 0.829 accuracy: 0.974 
training batch:   146, loss: 12.06026, precision: 0.806 recall: 0.676 f1: 0.735 accuracy: 0.965 
training batch:   147, loss: 8.32934, precision: 0.811 recall: 0.769 f1: 0.789 accuracy: 0.961 
training batch:   148, loss: 4.55462, precision: 0.892 recall: 0.892 f1: 0.892 accuracy: 0.986 
training batch:   149, loss: 8.12514, precision: 0.925 recall: 0.860 f1: 0.892 accuracy: 0.970 
training batch:   150, loss: 7.53741, precision: 0.853 recall: 0.829 f1: 0.841 accuracy: 0.963 
training batch:   151, loss: 4.39927, precision: 0.895 recall: 0.872 f1: 0.883 accuracy: 0.985 
training batch:   152, loss: 3.57536, precision: 0.833 recall: 0.909 f1: 0.870 accuracy: 0.985 
training batch:   153, loss: 8.17759, precision: 0.800 recall: 0.824 f1: 0.812 accuracy: 0.974 
training batch:   154, loss: 5.84292, precision: 0.794 recall: 0.818 f1: 0.806 accuracy: 0.976 
training batch:   155, loss: 8.21684, precision: 0.730 recall: 0.692 f1: 0.711 accuracy: 0.963 
training batch:   156, loss: 6.06086, precision: 0.868 recall: 0.892 f1: 0.880 accuracy: 0.981 
training batch:   157, loss: 5.26984, precision: 0.841 recall: 0.841 f1: 0.841 accuracy: 0.985 
training batch:   158, loss: 15.77758, precision: 0.789 recall: 0.882 f1: 0.833 accuracy: 0.951 
training batch:   159, loss: 7.07206, precision: 0.732 recall: 0.714 f1: 0.723 accuracy: 0.975 
training batch:   160, loss: 2.95052, precision: 0.882 recall: 0.938 f1: 0.909 accuracy: 0.989 
training batch:   161, loss: 5.38702, precision: 0.875 recall: 0.833 f1: 0.854 accuracy: 0.984 
training batch:   162, loss: 11.07293, precision: 0.763 recall: 0.806 f1: 0.784 accuracy: 0.961 
training batch:   163, loss: 4.01146, precision: 0.929 recall: 0.839 f1: 0.881 accuracy: 0.985 
training batch:   164, loss: 7.99407, precision: 0.828 recall: 0.828 f1: 0.828 accuracy: 0.976 
training batch:   165, loss: 9.87002, precision: 0.821 recall: 0.800 f1: 0.810 accuracy: 0.955 
training batch:   166, loss: 15.53245, precision: 0.824 recall: 0.737 f1: 0.778 accuracy: 0.938 
training batch:   167, loss: 5.48727, precision: 0.867 recall: 0.722 f1: 0.788 accuracy: 0.975 
training batch:   168, loss: 7.46960, precision: 0.882 recall: 0.811 f1: 0.845 accuracy: 0.971 
training batch:   169, loss: 7.59441, precision: 0.763 recall: 0.784 f1: 0.773 accuracy: 0.971 
training batch:   170, loss: 10.78543, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.956 
training batch:   171, loss: 4.01741, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.989 
training batch:   172, loss: 7.67609, precision: 0.861 recall: 0.816 f1: 0.838 accuracy: 0.974 
training batch:   173, loss: 2.41499, precision: 0.912 recall: 0.969 f1: 0.939 accuracy: 0.995 
training batch:   174, loss: 8.32999, precision: 0.722 recall: 0.722 f1: 0.722 accuracy: 0.963 
training batch:   175, loss: 6.24630, precision: 0.765 recall: 0.765 f1: 0.765 accuracy: 0.981 
training batch:   176, loss: 10.94785, precision: 0.707 recall: 0.763 f1: 0.734 accuracy: 0.965 
training batch:   177, loss: 10.53752, precision: 0.676 recall: 0.719 f1: 0.697 accuracy: 0.955 
training batch:   178, loss: 8.67273, precision: 0.647 recall: 0.846 f1: 0.733 accuracy: 0.973 
start evaluate engines...
label: Dsa, precision: 0.735 recall: 0.758 f1: 0.740 
label: Chk, precision: 0.700 recall: 0.680 f1: 0.669 
label: Ins, precision: 0.346 recall: 0.371 f1: 0.354 
label: Sur, precision: 0.857 recall: 0.931 f1: 0.887 
label: Med, precision: 0.390 recall: 0.415 f1: 0.398 
label: Ana, precision: 0.839 recall: 0.816 f1: 0.824 
time consumption:4.28(min), precision: 0.824 recall: 0.835 f1: 0.829 accuracy: 0.966 
saved the new best model with f1: 0.829
epoch:7/100
training batch:     1, loss: 7.10046, precision: 0.833 recall: 0.714 f1: 0.769 accuracy: 0.973 
training batch:     2, loss: 5.67191, precision: 0.935 recall: 0.906 f1: 0.921 accuracy: 0.986 
training batch:     3, loss: 6.60561, precision: 0.966 recall: 0.778 f1: 0.862 accuracy: 0.984 
training batch:     4, loss: 5.43905, precision: 0.885 recall: 0.676 f1: 0.767 accuracy: 0.971 
training batch:     5, loss: 8.99125, precision: 0.800 recall: 0.750 f1: 0.774 accuracy: 0.950 
training batch:     6, loss: 5.05679, precision: 0.969 recall: 0.795 f1: 0.873 accuracy: 0.988 
training batch:     7, loss: 5.94320, precision: 0.857 recall: 0.833 f1: 0.845 accuracy: 0.974 
training batch:     8, loss: 5.48632, precision: 0.905 recall: 0.884 f1: 0.894 accuracy: 0.985 
training batch:     9, loss: 8.18311, precision: 0.850 recall: 0.829 f1: 0.840 accuracy: 0.973 
training batch:    10, loss: 7.73495, precision: 0.750 recall: 0.900 f1: 0.818 accuracy: 0.970 
training batch:    11, loss: 2.42802, precision: 0.788 recall: 0.867 f1: 0.825 accuracy: 0.990 
training batch:    12, loss: 7.93828, precision: 0.660 recall: 0.750 f1: 0.702 accuracy: 0.963 
training batch:    13, loss: 5.45787, precision: 0.794 recall: 0.871 f1: 0.831 accuracy: 0.976 
training batch:    14, loss: 4.54635, precision: 0.895 recall: 0.919 f1: 0.907 accuracy: 0.986 
training batch:    15, loss: 4.78030, precision: 0.868 recall: 0.892 f1: 0.880 accuracy: 0.988 
training batch:    16, loss: 7.27476, precision: 0.706 recall: 0.667 f1: 0.686 accuracy: 0.976 
training batch:    17, loss: 2.57414, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.990 
training batch:    18, loss: 10.48388, precision: 0.771 recall: 0.871 f1: 0.818 accuracy: 0.963 
training batch:    19, loss: 8.23198, precision: 0.800 recall: 0.960 f1: 0.873 accuracy: 0.973 
training batch:    20, loss: 8.76122, precision: 0.792 recall: 0.731 f1: 0.760 accuracy: 0.973 
training batch:    21, loss: 3.83141, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.989 
training batch:    22, loss: 7.31587, precision: 0.912 recall: 0.838 f1: 0.873 accuracy: 0.971 
training batch:    23, loss: 5.03009, precision: 0.839 recall: 0.812 f1: 0.825 accuracy: 0.981 
training batch:    24, loss: 4.69957, precision: 0.939 recall: 0.838 f1: 0.886 accuracy: 0.984 
training batch:    25, loss: 3.72632, precision: 0.966 recall: 0.875 f1: 0.918 accuracy: 0.985 
training batch:    26, loss: 3.39258, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.990 
training batch:    27, loss: 4.94592, precision: 0.838 recall: 0.861 f1: 0.849 accuracy: 0.976 
training batch:    28, loss: 4.07210, precision: 0.771 recall: 0.818 f1: 0.794 accuracy: 0.980 
training batch:    29, loss: 3.09111, precision: 0.951 recall: 0.929 f1: 0.940 accuracy: 0.991 
training batch:    30, loss: 13.90383, precision: 0.917 recall: 0.971 f1: 0.943 accuracy: 0.968 
training batch:    31, loss: 4.15752, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.988 
training batch:    32, loss: 5.82211, precision: 0.912 recall: 0.886 f1: 0.899 accuracy: 0.983 
training batch:    33, loss: 2.58528, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.994 
training batch:    34, loss: 5.29960, precision: 0.750 recall: 0.700 f1: 0.724 accuracy: 0.983 
training batch:    35, loss: 5.40162, precision: 0.912 recall: 0.861 f1: 0.886 accuracy: 0.969 
training batch:    36, loss: 11.98321, precision: 0.872 recall: 0.829 f1: 0.850 accuracy: 0.968 
training batch:    37, loss: 2.65811, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.991 
training batch:    38, loss: 1.73704, precision: 0.889 recall: 0.923 f1: 0.906 accuracy: 0.995 
training batch:    39, loss: 3.84286, precision: 0.879 recall: 0.906 f1: 0.892 accuracy: 0.980 
training batch:    40, loss: 5.34229, precision: 0.871 recall: 0.818 f1: 0.844 accuracy: 0.989 
training batch:    41, loss: 7.77348, precision: 0.886 recall: 0.861 f1: 0.873 accuracy: 0.973 
training batch:    42, loss: 9.43855, precision: 0.800 recall: 0.909 f1: 0.851 accuracy: 0.970 
training batch:    43, loss: 10.03712, precision: 0.645 recall: 0.541 f1: 0.588 accuracy: 0.964 
training batch:    44, loss: 4.91851, precision: 0.842 recall: 0.821 f1: 0.831 accuracy: 0.988 
training batch:    45, loss: 3.55530, precision: 0.852 recall: 0.920 f1: 0.885 accuracy: 0.989 
training batch:    46, loss: 3.32229, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.986 
training batch:    47, loss: 7.24018, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.979 
training batch:    48, loss: 5.91167, precision: 0.810 recall: 0.773 f1: 0.791 accuracy: 0.973 
training batch:    49, loss: 3.48210, precision: 0.828 recall: 0.889 f1: 0.857 accuracy: 0.983 
training batch:    50, loss: 3.97796, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.989 
training batch:    51, loss: 11.55820, precision: 0.696 recall: 0.727 f1: 0.711 accuracy: 0.961 
training batch:    52, loss: 9.76917, precision: 0.812 recall: 0.867 f1: 0.839 accuracy: 0.971 
training batch:    53, loss: 4.67042, precision: 0.949 recall: 0.925 f1: 0.937 accuracy: 0.990 
training batch:    54, loss: 5.36001, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.980 
training batch:    55, loss: 7.18207, precision: 0.854 recall: 0.875 f1: 0.864 accuracy: 0.971 
training batch:    56, loss: 11.14579, precision: 0.794 recall: 0.900 f1: 0.844 accuracy: 0.970 
training batch:    57, loss: 7.99075, precision: 0.839 recall: 0.765 f1: 0.800 accuracy: 0.964 
training batch:    58, loss: 7.22732, precision: 0.811 recall: 0.811 f1: 0.811 accuracy: 0.971 
training batch:    59, loss: 7.20213, precision: 0.842 recall: 0.842 f1: 0.842 accuracy: 0.974 
training batch:    60, loss: 2.52479, precision: 0.946 recall: 0.897 f1: 0.921 accuracy: 0.994 
training batch:    61, loss: 4.38146, precision: 0.974 recall: 0.902 f1: 0.937 accuracy: 0.991 
training batch:    62, loss: 3.97006, precision: 0.871 recall: 0.794 f1: 0.831 accuracy: 0.984 
training batch:    63, loss: 5.84241, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.984 
training batch:    64, loss: 4.64169, precision: 0.875 recall: 0.848 f1: 0.862 accuracy: 0.985 
training batch:    65, loss: 4.28400, precision: 0.943 recall: 0.892 f1: 0.917 accuracy: 0.984 
training batch:    66, loss: 2.86521, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.995 
training batch:    67, loss: 6.39989, precision: 0.833 recall: 0.811 f1: 0.822 accuracy: 0.973 
training batch:    68, loss: 6.80019, precision: 0.775 recall: 0.861 f1: 0.816 accuracy: 0.975 
training batch:    69, loss: 6.48692, precision: 0.827 recall: 0.878 f1: 0.851 accuracy: 0.976 
training batch:    70, loss: 3.11946, precision: 0.824 recall: 0.875 f1: 0.848 accuracy: 0.979 
training batch:    71, loss: 3.77858, precision: 0.880 recall: 0.898 f1: 0.889 accuracy: 0.988 
training batch:    72, loss: 11.34885, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.970 
training batch:    73, loss: 4.11400, precision: 0.818 recall: 0.844 f1: 0.831 accuracy: 0.988 
training batch:    74, loss: 4.20336, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.983 
training batch:    75, loss: 5.91572, precision: 0.829 recall: 0.879 f1: 0.853 accuracy: 0.978 
training batch:    76, loss: 5.22781, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.983 
training batch:    77, loss: 12.32983, precision: 0.758 recall: 0.862 f1: 0.806 accuracy: 0.941 
training batch:    78, loss: 5.00063, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.981 
training batch:    79, loss: 6.01609, precision: 0.868 recall: 0.917 f1: 0.892 accuracy: 0.968 
training batch:    80, loss: 7.35815, precision: 0.848 recall: 0.903 f1: 0.875 accuracy: 0.979 
training batch:    81, loss: 4.28734, precision: 0.812 recall: 0.812 f1: 0.812 accuracy: 0.981 
training batch:    82, loss: 4.57829, precision: 0.885 recall: 0.821 f1: 0.852 accuracy: 0.990 
training batch:    83, loss: 9.01666, precision: 0.771 recall: 0.844 f1: 0.806 accuracy: 0.964 
training batch:    84, loss: 5.48657, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.980 
training batch:    85, loss: 5.23441, precision: 0.829 recall: 0.784 f1: 0.806 accuracy: 0.978 
training batch:    86, loss: 5.38954, precision: 0.896 recall: 0.878 f1: 0.887 accuracy: 0.976 
training batch:    87, loss: 6.00060, precision: 0.914 recall: 0.842 f1: 0.877 accuracy: 0.975 
training batch:    88, loss: 3.25568, precision: 0.907 recall: 0.975 f1: 0.940 accuracy: 0.991 
training batch:    89, loss: 6.31336, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.976 
training batch:    90, loss: 8.50935, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.973 
training batch:    91, loss: 3.94799, precision: 0.824 recall: 0.875 f1: 0.848 accuracy: 0.981 
training batch:    92, loss: 9.52621, precision: 0.960 recall: 0.923 f1: 0.941 accuracy: 0.963 
training batch:    93, loss: 11.11993, precision: 0.697 recall: 0.622 f1: 0.657 accuracy: 0.965 
training batch:    94, loss: 5.91399, precision: 0.862 recall: 0.781 f1: 0.820 accuracy: 0.974 
training batch:    95, loss: 9.81577, precision: 0.833 recall: 0.811 f1: 0.822 accuracy: 0.948 
training batch:    96, loss: 8.21150, precision: 0.842 recall: 0.780 f1: 0.810 accuracy: 0.976 
training batch:    97, loss: 2.99416, precision: 0.862 recall: 0.893 f1: 0.877 accuracy: 0.984 
training batch:    98, loss: 5.15552, precision: 0.850 recall: 0.872 f1: 0.861 accuracy: 0.984 
training batch:    99, loss: 7.37756, precision: 0.926 recall: 0.806 f1: 0.862 accuracy: 0.965 
training batch:   100, loss: 5.41670, precision: 0.844 recall: 0.794 f1: 0.818 accuracy: 0.975 
training batch:   101, loss: 6.76357, precision: 0.875 recall: 0.840 f1: 0.857 accuracy: 0.976 
training batch:   102, loss: 7.91811, precision: 0.739 recall: 0.829 f1: 0.782 accuracy: 0.969 
training batch:   103, loss: 6.05539, precision: 0.897 recall: 0.875 f1: 0.886 accuracy: 0.979 
training batch:   104, loss: 10.65409, precision: 0.725 recall: 0.806 f1: 0.763 accuracy: 0.968 
training batch:   105, loss: 9.22609, precision: 0.865 recall: 0.914 f1: 0.889 accuracy: 0.954 
training batch:   106, loss: 6.61077, precision: 0.884 recall: 0.905 f1: 0.894 accuracy: 0.975 
training batch:   107, loss: 5.81869, precision: 0.724 recall: 0.778 f1: 0.750 accuracy: 0.983 
training batch:   108, loss: 6.42974, precision: 0.818 recall: 0.871 f1: 0.844 accuracy: 0.975 
training batch:   109, loss: 6.23728, precision: 0.848 recall: 0.848 f1: 0.848 accuracy: 0.971 
training batch:   110, loss: 4.27415, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.989 
training batch:   111, loss: 4.09023, precision: 0.900 recall: 0.918 f1: 0.909 accuracy: 0.986 
training batch:   112, loss: 4.19952, precision: 0.915 recall: 0.935 f1: 0.925 accuracy: 0.980 
training batch:   113, loss: 3.51248, precision: 0.923 recall: 0.774 f1: 0.842 accuracy: 0.983 
training batch:   114, loss: 6.36794, precision: 0.829 recall: 0.879 f1: 0.853 accuracy: 0.979 
training batch:   115, loss: 7.01690, precision: 0.816 recall: 0.775 f1: 0.795 accuracy: 0.980 
training batch:   116, loss: 10.99484, precision: 0.857 recall: 0.800 f1: 0.828 accuracy: 0.950 
training batch:   117, loss: 2.45274, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.993 
training batch:   118, loss: 4.18802, precision: 0.865 recall: 0.889 f1: 0.877 accuracy: 0.986 
training batch:   119, loss: 5.60069, precision: 0.857 recall: 0.732 f1: 0.789 accuracy: 0.971 
training batch:   120, loss: 9.23608, precision: 0.875 recall: 0.750 f1: 0.808 accuracy: 0.974 
training batch:   121, loss: 1.82521, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.998 
training batch:   122, loss: 10.26268, precision: 0.837 recall: 0.788 f1: 0.812 accuracy: 0.955 
training batch:   123, loss: 3.89446, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.988 
training batch:   124, loss: 7.49683, precision: 0.837 recall: 0.923 f1: 0.878 accuracy: 0.969 
training batch:   125, loss: 9.56875, precision: 0.784 recall: 0.763 f1: 0.773 accuracy: 0.966 
training batch:   126, loss: 16.45331, precision: 0.812 recall: 0.788 f1: 0.800 accuracy: 0.936 
training batch:   127, loss: 8.10293, precision: 0.860 recall: 0.878 f1: 0.869 accuracy: 0.978 
training batch:   128, loss: 4.96183, precision: 0.844 recall: 0.818 f1: 0.831 accuracy: 0.985 
training batch:   129, loss: 6.79959, precision: 0.879 recall: 0.829 f1: 0.853 accuracy: 0.981 
training batch:   130, loss: 6.35578, precision: 0.853 recall: 0.763 f1: 0.806 accuracy: 0.976 
training batch:   131, loss: 3.14375, precision: 0.880 recall: 0.846 f1: 0.863 accuracy: 0.991 
training batch:   132, loss: 6.52139, precision: 0.774 recall: 0.828 f1: 0.800 accuracy: 0.971 
training batch:   133, loss: 6.62480, precision: 0.900 recall: 0.844 f1: 0.871 accuracy: 0.979 
training batch:   134, loss: 5.33799, precision: 0.833 recall: 0.882 f1: 0.857 accuracy: 0.983 
training batch:   135, loss: 10.80897, precision: 0.714 recall: 0.857 f1: 0.779 accuracy: 0.948 
training batch:   136, loss: 6.00308, precision: 0.864 recall: 0.864 f1: 0.864 accuracy: 0.973 
training batch:   137, loss: 7.78599, precision: 0.714 recall: 0.811 f1: 0.759 accuracy: 0.964 
training batch:   138, loss: 9.26501, precision: 0.871 recall: 0.844 f1: 0.857 accuracy: 0.984 
training batch:   139, loss: 3.71324, precision: 0.867 recall: 1.000 f1: 0.929 accuracy: 0.981 
training batch:   140, loss: 4.11037, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.993 
training batch:   141, loss: 7.08472, precision: 0.919 recall: 0.850 f1: 0.883 accuracy: 0.961 
training batch:   142, loss: 5.62095, precision: 0.900 recall: 0.837 f1: 0.867 accuracy: 0.979 
training batch:   143, loss: 7.34792, precision: 0.903 recall: 0.933 f1: 0.918 accuracy: 0.961 
training batch:   144, loss: 6.34669, precision: 0.875 recall: 0.757 f1: 0.812 accuracy: 0.981 
training batch:   145, loss: 7.76767, precision: 0.854 recall: 0.833 f1: 0.843 accuracy: 0.966 
training batch:   146, loss: 11.57362, precision: 0.818 recall: 0.771 f1: 0.794 accuracy: 0.965 
training batch:   147, loss: 9.18830, precision: 0.700 recall: 0.677 f1: 0.689 accuracy: 0.955 
training batch:   148, loss: 5.74658, precision: 0.879 recall: 0.906 f1: 0.892 accuracy: 0.984 
training batch:   149, loss: 4.73409, precision: 0.805 recall: 0.892 f1: 0.846 accuracy: 0.979 
training batch:   150, loss: 4.83698, precision: 0.844 recall: 0.818 f1: 0.831 accuracy: 0.990 
training batch:   151, loss: 7.24085, precision: 0.950 recall: 0.905 f1: 0.927 accuracy: 0.980 
training batch:   152, loss: 5.47933, precision: 0.865 recall: 0.842 f1: 0.853 accuracy: 0.984 
training batch:   153, loss: 2.90742, precision: 0.769 recall: 0.909 f1: 0.833 accuracy: 0.991 
training batch:   154, loss: 8.52383, precision: 0.778 recall: 0.724 f1: 0.750 accuracy: 0.961 
training batch:   155, loss: 6.58739, precision: 0.838 recall: 0.838 f1: 0.838 accuracy: 0.961 
training batch:   156, loss: 8.78233, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.976 
training batch:   157, loss: 5.58297, precision: 0.787 recall: 0.925 f1: 0.851 accuracy: 0.983 
training batch:   158, loss: 8.79588, precision: 0.933 recall: 0.848 f1: 0.889 accuracy: 0.973 
training batch:   159, loss: 9.38447, precision: 0.868 recall: 0.846 f1: 0.857 accuracy: 0.985 
training batch:   160, loss: 10.98615, precision: 0.867 recall: 0.788 f1: 0.825 accuracy: 0.946 
training batch:   161, loss: 5.64793, precision: 0.839 recall: 0.867 f1: 0.852 accuracy: 0.986 
training batch:   162, loss: 6.91888, precision: 0.852 recall: 0.719 f1: 0.780 accuracy: 0.985 
training batch:   163, loss: 5.66590, precision: 0.848 recall: 0.848 f1: 0.848 accuracy: 0.976 
training batch:   164, loss: 7.94176, precision: 0.886 recall: 0.812 f1: 0.848 accuracy: 0.968 
training batch:   165, loss: 10.01418, precision: 0.853 recall: 0.935 f1: 0.892 accuracy: 0.964 
training batch:   166, loss: 5.12186, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.985 
training batch:   167, loss: 2.94128, precision: 0.967 recall: 0.853 f1: 0.906 accuracy: 0.990 
training batch:   168, loss: 10.39287, precision: 0.784 recall: 0.763 f1: 0.773 accuracy: 0.949 
training batch:   169, loss: 6.18705, precision: 0.861 recall: 0.838 f1: 0.849 accuracy: 0.983 
training batch:   170, loss: 4.56084, precision: 0.914 recall: 0.842 f1: 0.877 accuracy: 0.978 
training batch:   171, loss: 5.86746, precision: 0.886 recall: 0.838 f1: 0.861 accuracy: 0.980 
training batch:   172, loss: 4.70530, precision: 0.839 recall: 0.867 f1: 0.852 accuracy: 0.976 
training batch:   173, loss: 3.50546, precision: 0.946 recall: 0.875 f1: 0.909 accuracy: 0.986 
training batch:   174, loss: 5.02530, precision: 0.907 recall: 0.886 f1: 0.897 accuracy: 0.984 
training batch:   175, loss: 9.19888, precision: 0.781 recall: 0.758 f1: 0.769 accuracy: 0.960 
training batch:   176, loss: 5.51627, precision: 0.923 recall: 0.889 f1: 0.906 accuracy: 0.986 
training batch:   177, loss: 4.92413, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.983 
training batch:   178, loss: 1.98694, precision: 0.875 recall: 1.000 f1: 0.933 accuracy: 0.993 
start evaluate engines...
label: Dsa, precision: 0.770 recall: 0.785 f1: 0.772 
label: Chk, precision: 0.675 recall: 0.640 f1: 0.643 
label: Ins, precision: 0.292 recall: 0.275 f1: 0.277 
label: Sur, precision: 0.859 recall: 0.893 f1: 0.870 
label: Med, precision: 0.345 recall: 0.395 f1: 0.362 
label: Ana, precision: 0.799 recall: 0.866 f1: 0.829 
time consumption:4.29(min), precision: 0.816 recall: 0.856 f1: 0.835 accuracy: 0.968 
saved the new best model with f1: 0.835
epoch:8/100
training batch:     1, loss: 4.22821, precision: 0.794 recall: 0.931 f1: 0.857 accuracy: 0.986 
training batch:     2, loss: 3.30025, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.986 
training batch:     3, loss: 0.93198, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:     4, loss: 4.49435, precision: 0.750 recall: 0.909 f1: 0.822 accuracy: 0.981 
training batch:     5, loss: 7.43919, precision: 0.848 recall: 0.778 f1: 0.812 accuracy: 0.975 
training batch:     6, loss: 6.79597, precision: 0.767 recall: 0.719 f1: 0.742 accuracy: 0.974 
training batch:     7, loss: 4.73402, precision: 0.902 recall: 0.902 f1: 0.902 accuracy: 0.985 
training batch:     8, loss: 13.94382, precision: 0.731 recall: 0.704 f1: 0.717 accuracy: 0.959 
training batch:     9, loss: 2.26846, precision: 0.947 recall: 0.923 f1: 0.935 accuracy: 0.994 
training batch:    10, loss: 6.28378, precision: 0.892 recall: 0.868 f1: 0.880 accuracy: 0.980 
training batch:    11, loss: 6.80937, precision: 0.848 recall: 0.778 f1: 0.812 accuracy: 0.975 
training batch:    12, loss: 5.23570, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.985 
training batch:    13, loss: 8.35879, precision: 0.765 recall: 0.722 f1: 0.743 accuracy: 0.965 
training batch:    14, loss: 2.34834, precision: 0.935 recall: 0.879 f1: 0.906 accuracy: 0.994 
training batch:    15, loss: 2.77118, precision: 0.892 recall: 0.917 f1: 0.904 accuracy: 0.988 
training batch:    16, loss: 8.01675, precision: 0.825 recall: 0.750 f1: 0.786 accuracy: 0.969 
training batch:    17, loss: 4.67802, precision: 0.900 recall: 0.871 f1: 0.885 accuracy: 0.974 
training batch:    18, loss: 6.59582, precision: 0.818 recall: 0.771 f1: 0.794 accuracy: 0.964 
training batch:    19, loss: 4.44958, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.986 
training batch:    20, loss: 3.24522, precision: 0.917 recall: 0.846 f1: 0.880 accuracy: 0.989 
training batch:    21, loss: 2.00535, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.995 
training batch:    22, loss: 3.64890, precision: 0.811 recall: 0.811 f1: 0.811 accuracy: 0.983 
training batch:    23, loss: 4.97551, precision: 0.872 recall: 0.810 f1: 0.840 accuracy: 0.988 
training batch:    24, loss: 6.28484, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.978 
training batch:    25, loss: 3.81499, precision: 0.853 recall: 0.935 f1: 0.892 accuracy: 0.986 
training batch:    26, loss: 2.34308, precision: 0.853 recall: 1.000 f1: 0.921 accuracy: 0.991 
training batch:    27, loss: 7.93819, precision: 0.828 recall: 0.828 f1: 0.828 accuracy: 0.979 
training batch:    28, loss: 8.29786, precision: 0.711 recall: 0.794 f1: 0.750 accuracy: 0.973 
training batch:    29, loss: 5.47031, precision: 0.788 recall: 0.765 f1: 0.776 accuracy: 0.975 
training batch:    30, loss: 5.90170, precision: 0.818 recall: 0.964 f1: 0.885 accuracy: 0.986 
training batch:    31, loss: 5.12943, precision: 0.814 recall: 0.833 f1: 0.824 accuracy: 0.979 
training batch:    32, loss: 6.27426, precision: 0.775 recall: 0.861 f1: 0.816 accuracy: 0.983 
training batch:    33, loss: 5.18962, precision: 0.812 recall: 0.897 f1: 0.852 accuracy: 0.980 
training batch:    34, loss: 2.38737, precision: 0.914 recall: 0.970 f1: 0.941 accuracy: 0.993 
training batch:    35, loss: 5.94495, precision: 0.865 recall: 0.821 f1: 0.842 accuracy: 0.974 
training batch:    36, loss: 5.57545, precision: 0.905 recall: 0.826 f1: 0.864 accuracy: 0.970 
training batch:    37, loss: 6.59116, precision: 0.784 recall: 0.784 f1: 0.784 accuracy: 0.968 
training batch:    38, loss: 9.30170, precision: 0.941 recall: 0.865 f1: 0.901 accuracy: 0.969 
training batch:    39, loss: 7.22744, precision: 0.860 recall: 0.860 f1: 0.860 accuracy: 0.966 
training batch:    40, loss: 7.82769, precision: 0.897 recall: 0.854 f1: 0.875 accuracy: 0.969 
training batch:    41, loss: 3.97954, precision: 0.933 recall: 0.875 f1: 0.903 accuracy: 0.986 
training batch:    42, loss: 9.96594, precision: 0.906 recall: 0.967 f1: 0.935 accuracy: 0.964 
training batch:    43, loss: 4.55539, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.991 
training batch:    44, loss: 3.65780, precision: 0.875 recall: 0.800 f1: 0.836 accuracy: 0.989 
training batch:    45, loss: 7.26631, precision: 0.795 recall: 0.861 f1: 0.827 accuracy: 0.954 
training batch:    46, loss: 4.53745, precision: 0.884 recall: 0.844 f1: 0.864 accuracy: 0.981 
training batch:    47, loss: 8.73168, precision: 0.880 recall: 0.846 f1: 0.863 accuracy: 0.941 
training batch:    48, loss: 3.15315, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.993 
training batch:    49, loss: 3.45549, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.989 
training batch:    50, loss: 3.63574, precision: 0.921 recall: 0.854 f1: 0.886 accuracy: 0.990 
training batch:    51, loss: 3.19475, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.988 
training batch:    52, loss: 3.76083, precision: 0.759 recall: 0.917 f1: 0.830 accuracy: 0.986 
training batch:    53, loss: 6.75673, precision: 0.870 recall: 0.952 f1: 0.909 accuracy: 0.975 
training batch:    54, loss: 6.01593, precision: 0.811 recall: 0.833 f1: 0.822 accuracy: 0.975 
training batch:    55, loss: 2.39409, precision: 0.875 recall: 0.966 f1: 0.918 accuracy: 0.988 
training batch:    56, loss: 3.12358, precision: 0.865 recall: 0.914 f1: 0.889 accuracy: 0.990 
training batch:    57, loss: 4.65556, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.985 
training batch:    58, loss: 3.41382, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.990 
training batch:    59, loss: 2.02301, precision: 0.900 recall: 0.947 f1: 0.923 accuracy: 0.993 
training batch:    60, loss: 5.53686, precision: 0.885 recall: 0.852 f1: 0.868 accuracy: 0.981 
training batch:    61, loss: 3.17798, precision: 0.903 recall: 0.848 f1: 0.875 accuracy: 0.984 
training batch:    62, loss: 3.34192, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.989 
training batch:    63, loss: 5.12343, precision: 0.964 recall: 0.844 f1: 0.900 accuracy: 0.976 
training batch:    64, loss: 6.86357, precision: 0.892 recall: 0.846 f1: 0.868 accuracy: 0.976 
training batch:    65, loss: 5.75923, precision: 0.946 recall: 0.897 f1: 0.921 accuracy: 0.976 
training batch:    66, loss: 2.57145, precision: 0.909 recall: 0.882 f1: 0.896 accuracy: 0.993 
training batch:    67, loss: 6.76920, precision: 0.839 recall: 0.812 f1: 0.825 accuracy: 0.976 
training batch:    68, loss: 8.54389, precision: 0.750 recall: 0.857 f1: 0.800 accuracy: 0.974 
training batch:    69, loss: 7.10847, precision: 0.776 recall: 0.760 f1: 0.768 accuracy: 0.971 
training batch:    70, loss: 7.72599, precision: 0.830 recall: 0.848 f1: 0.839 accuracy: 0.963 
training batch:    71, loss: 7.41871, precision: 0.781 recall: 0.806 f1: 0.794 accuracy: 0.969 
training batch:    72, loss: 6.91978, precision: 0.829 recall: 0.895 f1: 0.861 accuracy: 0.978 
training batch:    73, loss: 5.28020, precision: 0.897 recall: 0.921 f1: 0.909 accuracy: 0.983 
training batch:    74, loss: 9.54987, precision: 0.816 recall: 0.784 f1: 0.800 accuracy: 0.968 
training batch:    75, loss: 9.07348, precision: 0.781 recall: 0.676 f1: 0.725 accuracy: 0.965 
training batch:    76, loss: 6.69407, precision: 0.926 recall: 0.833 f1: 0.877 accuracy: 0.986 
training batch:    77, loss: 7.11489, precision: 0.881 recall: 0.949 f1: 0.914 accuracy: 0.980 
training batch:    78, loss: 4.07443, precision: 0.938 recall: 0.882 f1: 0.909 accuracy: 0.983 
training batch:    79, loss: 2.82013, precision: 0.844 recall: 0.844 f1: 0.844 accuracy: 0.993 
training batch:    80, loss: 7.23259, precision: 0.927 recall: 0.884 f1: 0.905 accuracy: 0.961 
training batch:    81, loss: 5.67186, precision: 0.895 recall: 0.919 f1: 0.907 accuracy: 0.975 
training batch:    82, loss: 4.36749, precision: 0.892 recall: 0.943 f1: 0.917 accuracy: 0.978 
training batch:    83, loss: 3.67690, precision: 0.824 recall: 0.933 f1: 0.875 accuracy: 0.986 
training batch:    84, loss: 5.24660, precision: 0.938 recall: 0.811 f1: 0.870 accuracy: 0.975 
training batch:    85, loss: 9.19885, precision: 0.704 recall: 0.543 f1: 0.613 accuracy: 0.964 
training batch:    86, loss: 6.21475, precision: 0.786 recall: 0.786 f1: 0.786 accuracy: 0.966 
training batch:    87, loss: 4.05119, precision: 0.784 recall: 0.829 f1: 0.806 accuracy: 0.989 
training batch:    88, loss: 5.12243, precision: 0.941 recall: 0.889 f1: 0.914 accuracy: 0.983 
training batch:    89, loss: 4.55630, precision: 0.897 recall: 0.946 f1: 0.921 accuracy: 0.988 
training batch:    90, loss: 6.30994, precision: 0.872 recall: 0.895 f1: 0.883 accuracy: 0.970 
training batch:    91, loss: 4.12093, precision: 0.870 recall: 0.870 f1: 0.870 accuracy: 0.984 
training batch:    92, loss: 4.55865, precision: 0.857 recall: 0.889 f1: 0.873 accuracy: 0.983 
training batch:    93, loss: 6.63730, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.964 
training batch:    94, loss: 2.38530, precision: 0.951 recall: 0.907 f1: 0.929 accuracy: 0.991 
training batch:    95, loss: 4.24786, precision: 0.897 recall: 0.875 f1: 0.886 accuracy: 0.980 
training batch:    96, loss: 2.77876, precision: 0.853 recall: 0.906 f1: 0.879 accuracy: 0.989 
training batch:    97, loss: 4.66428, precision: 0.848 recall: 0.886 f1: 0.867 accuracy: 0.983 
training batch:    98, loss: 11.19588, precision: 0.793 recall: 0.821 f1: 0.807 accuracy: 0.973 
training batch:    99, loss: 10.29021, precision: 0.788 recall: 0.788 f1: 0.788 accuracy: 0.961 
training batch:   100, loss: 7.40502, precision: 0.800 recall: 0.778 f1: 0.789 accuracy: 0.969 
training batch:   101, loss: 3.74250, precision: 0.919 recall: 0.850 f1: 0.883 accuracy: 0.990 
training batch:   102, loss: 3.27031, precision: 0.906 recall: 0.853 f1: 0.879 accuracy: 0.989 
training batch:   103, loss: 9.84674, precision: 0.824 recall: 0.800 f1: 0.812 accuracy: 0.966 
training batch:   104, loss: 10.15929, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.976 
training batch:   105, loss: 5.78548, precision: 0.952 recall: 0.930 f1: 0.941 accuracy: 0.976 
training batch:   106, loss: 2.30675, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.990 
training batch:   107, loss: 3.39396, precision: 0.829 recall: 0.784 f1: 0.806 accuracy: 0.989 
training batch:   108, loss: 3.13138, precision: 0.892 recall: 0.971 f1: 0.930 accuracy: 0.990 
training batch:   109, loss: 3.47559, precision: 0.902 recall: 0.902 f1: 0.902 accuracy: 0.983 
training batch:   110, loss: 3.94835, precision: 0.767 recall: 0.885 f1: 0.821 accuracy: 0.988 
training batch:   111, loss: 5.08558, precision: 0.839 recall: 0.839 f1: 0.839 accuracy: 0.983 
training batch:   112, loss: 5.94466, precision: 0.795 recall: 0.854 f1: 0.824 accuracy: 0.976 
training batch:   113, loss: 7.99136, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.975 
training batch:   114, loss: 2.43376, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.996 
training batch:   115, loss: 8.48185, precision: 0.763 recall: 0.806 f1: 0.784 accuracy: 0.953 
training batch:   116, loss: 1.65292, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.993 
training batch:   117, loss: 2.46684, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.990 
training batch:   118, loss: 3.69917, precision: 0.927 recall: 0.927 f1: 0.927 accuracy: 0.988 
training batch:   119, loss: 4.32169, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.991 
training batch:   120, loss: 3.68288, precision: 0.885 recall: 0.821 f1: 0.852 accuracy: 0.985 
training batch:   121, loss: 4.37431, precision: 0.853 recall: 0.853 f1: 0.853 accuracy: 0.984 
training batch:   122, loss: 3.19608, precision: 0.886 recall: 0.912 f1: 0.899 accuracy: 0.989 
training batch:   123, loss: 3.67912, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.984 
training batch:   124, loss: 9.24069, precision: 0.865 recall: 0.821 f1: 0.842 accuracy: 0.973 
training batch:   125, loss: 11.60673, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.978 
training batch:   126, loss: 3.61190, precision: 0.900 recall: 0.844 f1: 0.871 accuracy: 0.985 
training batch:   127, loss: 5.36867, precision: 0.872 recall: 0.944 f1: 0.907 accuracy: 0.979 
training batch:   128, loss: 4.85806, precision: 0.871 recall: 0.871 f1: 0.871 accuracy: 0.981 
training batch:   129, loss: 7.95399, precision: 0.838 recall: 0.838 f1: 0.838 accuracy: 0.959 
training batch:   130, loss: 6.64513, precision: 0.900 recall: 0.844 f1: 0.871 accuracy: 0.984 
training batch:   131, loss: 6.82734, precision: 0.811 recall: 0.789 f1: 0.800 accuracy: 0.976 
training batch:   132, loss: 6.28511, precision: 0.824 recall: 0.875 f1: 0.848 accuracy: 0.980 
training batch:   133, loss: 5.69003, precision: 0.927 recall: 0.884 f1: 0.905 accuracy: 0.980 
training batch:   134, loss: 4.37334, precision: 0.879 recall: 0.935 f1: 0.906 accuracy: 0.988 
training batch:   135, loss: 4.15847, precision: 0.867 recall: 0.848 f1: 0.857 accuracy: 0.988 
training batch:   136, loss: 5.55956, precision: 0.833 recall: 0.893 f1: 0.862 accuracy: 0.980 
training batch:   137, loss: 4.78561, precision: 0.886 recall: 0.838 f1: 0.861 accuracy: 0.981 
training batch:   138, loss: 7.20708, precision: 0.759 recall: 0.846 f1: 0.800 accuracy: 0.974 
training batch:   139, loss: 2.15968, precision: 0.919 recall: 0.895 f1: 0.907 accuracy: 0.995 
training batch:   140, loss: 4.55785, precision: 0.840 recall: 0.913 f1: 0.875 accuracy: 0.989 
training batch:   141, loss: 6.64202, precision: 0.794 recall: 0.794 f1: 0.794 accuracy: 0.971 
training batch:   142, loss: 6.73180, precision: 0.889 recall: 0.828 f1: 0.857 accuracy: 0.983 
training batch:   143, loss: 7.92365, precision: 0.947 recall: 0.923 f1: 0.935 accuracy: 0.980 
training batch:   144, loss: 7.32108, precision: 0.811 recall: 0.882 f1: 0.845 accuracy: 0.966 
training batch:   145, loss: 6.54191, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.975 
training batch:   146, loss: 2.92894, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.989 
training batch:   147, loss: 10.33187, precision: 0.824 recall: 0.718 f1: 0.767 accuracy: 0.956 
training batch:   148, loss: 8.09640, precision: 0.841 recall: 0.841 f1: 0.841 accuracy: 0.955 
training batch:   149, loss: 3.94830, precision: 0.889 recall: 0.970 f1: 0.928 accuracy: 0.991 
training batch:   150, loss: 7.17520, precision: 0.879 recall: 0.906 f1: 0.892 accuracy: 0.985 
training batch:   151, loss: 7.57462, precision: 0.759 recall: 0.815 f1: 0.786 accuracy: 0.978 
training batch:   152, loss: 3.30088, precision: 0.829 recall: 0.853 f1: 0.841 accuracy: 0.989 
training batch:   153, loss: 8.11040, precision: 0.767 recall: 0.793 f1: 0.780 accuracy: 0.970 
training batch:   154, loss: 6.96540, precision: 0.947 recall: 0.878 f1: 0.911 accuracy: 0.970 
training batch:   155, loss: 5.17651, precision: 0.868 recall: 0.868 f1: 0.868 accuracy: 0.978 
training batch:   156, loss: 3.34710, precision: 0.879 recall: 0.906 f1: 0.892 accuracy: 0.990 
training batch:   157, loss: 2.85702, precision: 0.879 recall: 0.784 f1: 0.829 accuracy: 0.985 
training batch:   158, loss: 6.88208, precision: 0.821 recall: 0.780 f1: 0.800 accuracy: 0.975 
training batch:   159, loss: 2.87756, precision: 0.932 recall: 0.953 f1: 0.943 accuracy: 0.991 
training batch:   160, loss: 3.45770, precision: 0.862 recall: 0.806 f1: 0.833 accuracy: 0.985 
training batch:   161, loss: 7.53855, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.981 
training batch:   162, loss: 2.76196, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.988 
training batch:   163, loss: 5.02692, precision: 0.875 recall: 0.854 f1: 0.864 accuracy: 0.979 
training batch:   164, loss: 2.71985, precision: 0.921 recall: 0.897 f1: 0.909 accuracy: 0.991 
training batch:   165, loss: 4.11858, precision: 0.793 recall: 0.920 f1: 0.852 accuracy: 0.976 
training batch:   166, loss: 11.48265, precision: 0.757 recall: 0.737 f1: 0.747 accuracy: 0.955 
training batch:   167, loss: 5.39813, precision: 0.808 recall: 0.840 f1: 0.824 accuracy: 0.986 
training batch:   168, loss: 2.58757, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.988 
training batch:   169, loss: 4.57118, precision: 0.833 recall: 0.938 f1: 0.882 accuracy: 0.984 
training batch:   170, loss: 3.50040, precision: 0.895 recall: 0.895 f1: 0.895 accuracy: 0.991 
training batch:   171, loss: 2.49001, precision: 0.833 recall: 0.962 f1: 0.893 accuracy: 0.990 
training batch:   172, loss: 3.96982, precision: 0.867 recall: 0.951 f1: 0.907 accuracy: 0.986 
training batch:   173, loss: 5.15849, precision: 0.829 recall: 0.879 f1: 0.853 accuracy: 0.980 
training batch:   174, loss: 6.50609, precision: 0.767 recall: 0.657 f1: 0.708 accuracy: 0.975 
training batch:   175, loss: 1.90810, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.996 
training batch:   176, loss: 4.27146, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.990 
training batch:   177, loss: 3.55855, precision: 0.852 recall: 0.920 f1: 0.885 accuracy: 0.984 
training batch:   178, loss: 5.19181, precision: 0.786 recall: 0.846 f1: 0.815 accuracy: 0.987 
start evaluate engines...
label: Dsa, precision: 0.739 recall: 0.777 f1: 0.752 
label: Chk, precision: 0.692 recall: 0.700 f1: 0.673 
label: Ins, precision: 0.354 recall: 0.371 f1: 0.361 
label: Sur, precision: 0.884 recall: 0.892 f1: 0.882 
label: Med, precision: 0.355 recall: 0.380 f1: 0.363 
label: Ana, precision: 0.861 recall: 0.809 f1: 0.829 
time consumption:4.31(min), precision: 0.845 recall: 0.837 f1: 0.840 accuracy: 0.968 
saved the new best model with f1: 0.840
epoch:9/100
training batch:     1, loss: 7.18762, precision: 1.000 recall: 0.658 f1: 0.794 accuracy: 0.979 
training batch:     2, loss: 6.69260, precision: 0.844 recall: 0.900 f1: 0.871 accuracy: 0.971 
training batch:     3, loss: 1.69760, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.995 
training batch:     4, loss: 3.81873, precision: 0.939 recall: 0.886 f1: 0.912 accuracy: 0.980 
training batch:     5, loss: 1.79029, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.996 
training batch:     6, loss: 5.16798, precision: 0.875 recall: 0.946 f1: 0.909 accuracy: 0.978 
training batch:     7, loss: 2.62994, precision: 0.909 recall: 0.857 f1: 0.882 accuracy: 0.990 
training batch:     8, loss: 3.04124, precision: 0.824 recall: 0.848 f1: 0.836 accuracy: 0.985 
training batch:     9, loss: 3.57815, precision: 0.892 recall: 0.892 f1: 0.892 accuracy: 0.984 
training batch:    10, loss: 4.04265, precision: 0.935 recall: 0.879 f1: 0.906 accuracy: 0.985 
training batch:    11, loss: 2.91112, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.985 
training batch:    12, loss: 2.78639, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.993 
training batch:    13, loss: 2.08318, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.996 
training batch:    14, loss: 1.95980, precision: 0.857 recall: 0.947 f1: 0.900 accuracy: 0.993 
training batch:    15, loss: 7.07747, precision: 0.818 recall: 0.878 f1: 0.847 accuracy: 0.970 
training batch:    16, loss: 8.65434, precision: 0.767 recall: 0.885 f1: 0.821 accuracy: 0.968 
training batch:    17, loss: 3.17136, precision: 0.878 recall: 0.923 f1: 0.900 accuracy: 0.988 
training batch:    18, loss: 3.46638, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.988 
training batch:    19, loss: 4.07154, precision: 0.886 recall: 0.816 f1: 0.849 accuracy: 0.980 
training batch:    20, loss: 7.61803, precision: 0.794 recall: 0.771 f1: 0.783 accuracy: 0.975 
training batch:    21, loss: 2.81117, precision: 0.861 recall: 0.838 f1: 0.849 accuracy: 0.988 
training batch:    22, loss: 2.44228, precision: 0.857 recall: 0.889 f1: 0.873 accuracy: 0.991 
training batch:    23, loss: 4.79314, precision: 0.853 recall: 0.879 f1: 0.866 accuracy: 0.981 
training batch:    24, loss: 3.00331, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.991 
training batch:    25, loss: 2.67041, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.988 
training batch:    26, loss: 5.92181, precision: 0.939 recall: 0.886 f1: 0.912 accuracy: 0.986 
training batch:    27, loss: 3.76968, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.985 
training batch:    28, loss: 5.01363, precision: 0.895 recall: 0.872 f1: 0.883 accuracy: 0.978 
training batch:    29, loss: 10.31911, precision: 0.812 recall: 0.812 f1: 0.812 accuracy: 0.963 
training batch:    30, loss: 1.92917, precision: 0.957 recall: 0.880 f1: 0.917 accuracy: 0.993 
training batch:    31, loss: 2.20338, precision: 0.968 recall: 0.857 f1: 0.909 accuracy: 0.994 
training batch:    32, loss: 1.50423, precision: 0.850 recall: 0.944 f1: 0.895 accuracy: 0.994 
training batch:    33, loss: 6.38817, precision: 0.854 recall: 0.891 f1: 0.872 accuracy: 0.981 
training batch:    34, loss: 3.99751, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.988 
training batch:    35, loss: 2.91961, precision: 0.930 recall: 0.930 f1: 0.930 accuracy: 0.988 
training batch:    36, loss: 2.47139, precision: 0.962 recall: 0.926 f1: 0.943 accuracy: 0.994 
training batch:    37, loss: 1.65028, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.995 
training batch:    38, loss: 1.81195, precision: 0.976 recall: 0.930 f1: 0.952 accuracy: 0.996 
training batch:    39, loss: 8.47110, precision: 0.857 recall: 0.789 f1: 0.822 accuracy: 0.963 
training batch:    40, loss: 1.67642, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.994 
training batch:    41, loss: 6.86288, precision: 0.850 recall: 0.895 f1: 0.872 accuracy: 0.984 
training batch:    42, loss: 3.85516, precision: 0.943 recall: 0.892 f1: 0.917 accuracy: 0.978 
training batch:    43, loss: 3.66289, precision: 0.793 recall: 0.920 f1: 0.852 accuracy: 0.983 
training batch:    44, loss: 3.95051, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.990 
training batch:    45, loss: 5.52010, precision: 0.846 recall: 1.000 f1: 0.917 accuracy: 0.979 
training batch:    46, loss: 2.98348, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.995 
training batch:    47, loss: 7.15576, precision: 0.829 recall: 0.879 f1: 0.853 accuracy: 0.974 
training batch:    48, loss: 1.64920, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.995 
training batch:    49, loss: 5.75896, precision: 0.829 recall: 0.744 f1: 0.784 accuracy: 0.979 
training batch:    50, loss: 4.97364, precision: 0.850 recall: 0.919 f1: 0.883 accuracy: 0.979 
training batch:    51, loss: 6.02573, precision: 0.886 recall: 0.886 f1: 0.886 accuracy: 0.983 
training batch:    52, loss: 3.86127, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.979 
training batch:    53, loss: 2.63072, precision: 0.912 recall: 0.886 f1: 0.899 accuracy: 0.990 
training batch:    54, loss: 2.94278, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.989 
training batch:    55, loss: 3.68152, precision: 0.882 recall: 0.909 f1: 0.896 accuracy: 0.986 
training batch:    56, loss: 5.82697, precision: 0.840 recall: 0.808 f1: 0.824 accuracy: 0.980 
training batch:    57, loss: 2.95316, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.989 
training batch:    58, loss: 1.92068, precision: 0.906 recall: 0.967 f1: 0.935 accuracy: 0.994 
training batch:    59, loss: 2.45650, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.988 
training batch:    60, loss: 3.42434, precision: 0.848 recall: 0.875 f1: 0.862 accuracy: 0.986 
training batch:    61, loss: 3.55571, precision: 0.860 recall: 0.881 f1: 0.871 accuracy: 0.991 
training batch:    62, loss: 4.30360, precision: 0.854 recall: 0.854 f1: 0.854 accuracy: 0.979 
training batch:    63, loss: 7.81994, precision: 0.821 recall: 0.800 f1: 0.810 accuracy: 0.973 
training batch:    64, loss: 2.34372, precision: 0.936 recall: 0.917 f1: 0.926 accuracy: 0.994 
training batch:    65, loss: 1.69628, precision: 0.909 recall: 0.968 f1: 0.937 accuracy: 0.995 
training batch:    66, loss: 2.14942, precision: 0.848 recall: 0.933 f1: 0.889 accuracy: 0.993 
training batch:    67, loss: 3.05687, precision: 0.882 recall: 0.938 f1: 0.909 accuracy: 0.979 
training batch:    68, loss: 4.38184, precision: 0.865 recall: 0.842 f1: 0.853 accuracy: 0.988 
training batch:    69, loss: 10.70459, precision: 0.880 recall: 0.815 f1: 0.846 accuracy: 0.970 
training batch:    70, loss: 1.64426, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.993 
training batch:    71, loss: 6.35727, precision: 0.848 recall: 0.737 f1: 0.789 accuracy: 0.976 
training batch:    72, loss: 5.54001, precision: 0.848 recall: 0.907 f1: 0.876 accuracy: 0.981 
training batch:    73, loss: 5.08109, precision: 0.867 recall: 0.867 f1: 0.867 accuracy: 0.985 
training batch:    74, loss: 5.09818, precision: 0.818 recall: 0.818 f1: 0.818 accuracy: 0.975 
training batch:    75, loss: 4.45913, precision: 0.929 recall: 0.867 f1: 0.897 accuracy: 0.988 
training batch:    76, loss: 3.82793, precision: 0.886 recall: 0.861 f1: 0.873 accuracy: 0.990 
training batch:    77, loss: 3.44454, precision: 0.938 recall: 0.882 f1: 0.909 accuracy: 0.994 
training batch:    78, loss: 5.05033, precision: 0.780 recall: 0.800 f1: 0.790 accuracy: 0.981 
training batch:    79, loss: 3.50903, precision: 0.846 recall: 0.971 f1: 0.904 accuracy: 0.988 
training batch:    80, loss: 10.06979, precision: 0.829 recall: 0.810 f1: 0.819 accuracy: 0.959 
training batch:    81, loss: 3.01561, precision: 0.882 recall: 0.857 f1: 0.870 accuracy: 0.993 
training batch:    82, loss: 5.19753, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.980 
training batch:    83, loss: 3.77760, precision: 0.878 recall: 0.900 f1: 0.889 accuracy: 0.991 
training batch:    84, loss: 2.86401, precision: 0.761 recall: 0.833 f1: 0.795 accuracy: 0.989 
training batch:    85, loss: 1.95120, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.993 
training batch:    86, loss: 4.09901, precision: 0.953 recall: 0.932 f1: 0.943 accuracy: 0.988 
training batch:    87, loss: 1.33965, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.996 
training batch:    88, loss: 3.56530, precision: 0.824 recall: 0.875 f1: 0.848 accuracy: 0.985 
training batch:    89, loss: 2.24596, precision: 0.939 recall: 0.886 f1: 0.912 accuracy: 0.994 
training batch:    90, loss: 1.87504, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.995 
training batch:    91, loss: 2.46225, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.989 
training batch:    92, loss: 4.93871, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.984 
training batch:    93, loss: 2.09528, precision: 0.854 recall: 0.897 f1: 0.875 accuracy: 0.990 
training batch:    94, loss: 4.24919, precision: 0.919 recall: 0.895 f1: 0.907 accuracy: 0.983 
training batch:    95, loss: 10.63207, precision: 0.852 recall: 0.885 f1: 0.868 accuracy: 0.949 
training batch:    96, loss: 3.34537, precision: 0.846 recall: 0.917 f1: 0.880 accuracy: 0.984 
training batch:    97, loss: 4.08314, precision: 0.964 recall: 0.844 f1: 0.900 accuracy: 0.990 
training batch:    98, loss: 9.26456, precision: 0.793 recall: 0.793 f1: 0.793 accuracy: 0.971 
training batch:    99, loss: 2.86729, precision: 0.818 recall: 0.931 f1: 0.871 accuracy: 0.990 
training batch:   100, loss: 1.84167, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:   101, loss: 7.89632, precision: 0.902 recall: 0.804 f1: 0.851 accuracy: 0.975 
training batch:   102, loss: 1.28391, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.996 
training batch:   103, loss: 2.75002, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.985 
training batch:   104, loss: 5.44843, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.961 
training batch:   105, loss: 2.19714, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.995 
training batch:   106, loss: 2.54941, precision: 0.857 recall: 0.923 f1: 0.889 accuracy: 0.991 
training batch:   107, loss: 3.33113, precision: 0.848 recall: 0.903 f1: 0.875 accuracy: 0.990 
training batch:   108, loss: 3.77451, precision: 0.816 recall: 0.838 f1: 0.827 accuracy: 0.981 
training batch:   109, loss: 5.30816, precision: 0.917 recall: 0.846 f1: 0.880 accuracy: 0.978 
training batch:   110, loss: 3.80647, precision: 0.889 recall: 0.842 f1: 0.865 accuracy: 0.985 
training batch:   111, loss: 3.71156, precision: 0.793 recall: 0.920 f1: 0.852 accuracy: 0.986 
training batch:   112, loss: 7.43797, precision: 0.842 recall: 0.889 f1: 0.865 accuracy: 0.975 
training batch:   113, loss: 3.24387, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.996 
training batch:   114, loss: 5.85164, precision: 0.758 recall: 0.806 f1: 0.781 accuracy: 0.978 
training batch:   115, loss: 6.35847, precision: 0.947 recall: 0.923 f1: 0.935 accuracy: 0.985 
training batch:   116, loss: 5.28823, precision: 0.921 recall: 0.897 f1: 0.909 accuracy: 0.983 
training batch:   117, loss: 1.88332, precision: 0.929 recall: 0.897 f1: 0.912 accuracy: 0.995 
training batch:   118, loss: 3.43205, precision: 0.868 recall: 0.943 f1: 0.904 accuracy: 0.993 
training batch:   119, loss: 1.08913, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.998 
training batch:   120, loss: 4.94598, precision: 0.811 recall: 0.857 f1: 0.833 accuracy: 0.979 
training batch:   121, loss: 6.03651, precision: 0.844 recall: 0.818 f1: 0.831 accuracy: 0.983 
training batch:   122, loss: 4.93170, precision: 0.913 recall: 0.857 f1: 0.884 accuracy: 0.979 
training batch:   123, loss: 4.11127, precision: 0.958 recall: 0.958 f1: 0.958 accuracy: 0.989 
training batch:   124, loss: 2.52771, precision: 0.783 recall: 0.783 f1: 0.783 accuracy: 0.990 
training batch:   125, loss: 11.06955, precision: 0.900 recall: 0.964 f1: 0.931 accuracy: 0.964 
training batch:   126, loss: 3.77682, precision: 0.846 recall: 0.917 f1: 0.880 accuracy: 0.981 
training batch:   127, loss: 3.68930, precision: 0.897 recall: 0.812 f1: 0.852 accuracy: 0.978 
training batch:   128, loss: 4.52666, precision: 0.897 recall: 0.833 f1: 0.864 accuracy: 0.986 
training batch:   129, loss: 3.62291, precision: 0.914 recall: 0.941 f1: 0.928 accuracy: 0.991 
training batch:   130, loss: 7.77921, precision: 0.848 recall: 0.800 f1: 0.824 accuracy: 0.969 
training batch:   131, loss: 5.68614, precision: 0.854 recall: 0.875 f1: 0.864 accuracy: 0.966 
training batch:   132, loss: 5.76060, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.989 
training batch:   133, loss: 5.09592, precision: 0.771 recall: 0.818 f1: 0.794 accuracy: 0.980 
training batch:   134, loss: 5.91235, precision: 0.833 recall: 0.909 f1: 0.870 accuracy: 0.974 
training batch:   135, loss: 4.48741, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.985 
training batch:   136, loss: 4.27999, precision: 0.872 recall: 0.891 f1: 0.882 accuracy: 0.989 
training batch:   137, loss: 6.81527, precision: 0.848 recall: 0.848 f1: 0.848 accuracy: 0.980 
training batch:   138, loss: 6.75932, precision: 0.829 recall: 0.829 f1: 0.829 accuracy: 0.955 
training batch:   139, loss: 14.71712, precision: 0.816 recall: 0.738 f1: 0.775 accuracy: 0.944 
training batch:   140, loss: 4.31397, precision: 0.897 recall: 0.833 f1: 0.864 accuracy: 0.984 
training batch:   141, loss: 6.44714, precision: 0.824 recall: 0.875 f1: 0.848 accuracy: 0.979 
training batch:   142, loss: 3.01882, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.988 
training batch:   143, loss: 5.34502, precision: 1.000 recall: 0.978 f1: 0.989 accuracy: 0.983 
training batch:   144, loss: 3.30769, precision: 0.884 recall: 0.884 f1: 0.884 accuracy: 0.989 
training batch:   145, loss: 4.77464, precision: 0.875 recall: 0.854 f1: 0.864 accuracy: 0.988 
training batch:   146, loss: 4.87647, precision: 0.854 recall: 0.778 f1: 0.814 accuracy: 0.983 
training batch:   147, loss: 4.71009, precision: 0.944 recall: 0.895 f1: 0.919 accuracy: 0.989 
training batch:   148, loss: 2.41290, precision: 0.875 recall: 0.808 f1: 0.840 accuracy: 0.989 
training batch:   149, loss: 3.50512, precision: 0.824 recall: 0.875 f1: 0.848 accuracy: 0.984 
training batch:   150, loss: 5.89835, precision: 0.919 recall: 0.829 f1: 0.872 accuracy: 0.978 
training batch:   151, loss: 6.12883, precision: 0.853 recall: 0.829 f1: 0.841 accuracy: 0.981 
training batch:   152, loss: 8.51888, precision: 0.930 recall: 0.909 f1: 0.920 accuracy: 0.979 
training batch:   153, loss: 2.82348, precision: 0.844 recall: 0.871 f1: 0.857 accuracy: 0.990 
training batch:   154, loss: 5.95189, precision: 0.750 recall: 0.828 f1: 0.787 accuracy: 0.980 
training batch:   155, loss: 4.98034, precision: 0.848 recall: 0.757 f1: 0.800 accuracy: 0.975 
training batch:   156, loss: 3.35498, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.994 
training batch:   157, loss: 5.03323, precision: 0.933 recall: 0.848 f1: 0.889 accuracy: 0.980 
training batch:   158, loss: 11.50343, precision: 0.889 recall: 0.865 f1: 0.877 accuracy: 0.963 
training batch:   159, loss: 3.96992, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.988 
training batch:   160, loss: 1.56329, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.993 
training batch:   161, loss: 3.90286, precision: 0.833 recall: 0.968 f1: 0.896 accuracy: 0.981 
training batch:   162, loss: 1.64304, precision: 1.000 recall: 0.938 f1: 0.968 accuracy: 0.995 
training batch:   163, loss: 4.70454, precision: 0.881 recall: 0.841 f1: 0.860 accuracy: 0.971 
training batch:   164, loss: 5.47308, precision: 0.914 recall: 0.889 f1: 0.901 accuracy: 0.979 
training batch:   165, loss: 5.94402, precision: 0.920 recall: 0.885 f1: 0.902 accuracy: 0.970 
training batch:   166, loss: 7.70569, precision: 0.902 recall: 0.949 f1: 0.925 accuracy: 0.964 
training batch:   167, loss: 4.15078, precision: 0.879 recall: 0.879 f1: 0.879 accuracy: 0.981 
training batch:   168, loss: 4.35284, precision: 0.914 recall: 0.970 f1: 0.941 accuracy: 0.985 
training batch:   169, loss: 2.90984, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.988 
training batch:   170, loss: 3.08231, precision: 0.838 recall: 0.886 f1: 0.861 accuracy: 0.984 
training batch:   171, loss: 6.00940, precision: 0.885 recall: 0.885 f1: 0.885 accuracy: 0.971 
training batch:   172, loss: 5.47352, precision: 0.816 recall: 0.800 f1: 0.808 accuracy: 0.974 
training batch:   173, loss: 3.54349, precision: 0.909 recall: 0.952 f1: 0.930 accuracy: 0.991 
training batch:   174, loss: 5.15357, precision: 0.789 recall: 0.857 f1: 0.822 accuracy: 0.974 
training batch:   175, loss: 5.92818, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.964 
training batch:   176, loss: 2.63422, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.993 
training batch:   177, loss: 2.38948, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.993 
training batch:   178, loss: 4.54333, precision: 1.000 recall: 0.923 f1: 0.960 accuracy: 0.973 
start evaluate engines...
label: Dsa, precision: 0.776 recall: 0.717 f1: 0.739 
label: Chk, precision: 0.708 recall: 0.750 f1: 0.698 
label: Ins, precision: 0.300 recall: 0.275 f1: 0.271 
label: Sur, precision: 0.894 recall: 0.908 f1: 0.898 
label: Med, precision: 0.425 recall: 0.425 f1: 0.417 
label: Ana, precision: 0.789 recall: 0.863 f1: 0.823 
time consumption:4.30(min), precision: 0.826 recall: 0.851 f1: 0.838 accuracy: 0.967 
epoch:10/100
training batch:     1, loss: 3.19223, precision: 0.923 recall: 0.960 f1: 0.941 accuracy: 0.994 
training batch:     2, loss: 7.69191, precision: 0.854 recall: 0.854 f1: 0.854 accuracy: 0.963 
training batch:     3, loss: 4.23908, precision: 0.914 recall: 0.970 f1: 0.941 accuracy: 0.990 
training batch:     4, loss: 2.32384, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.994 
training batch:     5, loss: 1.91450, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.991 
training batch:     6, loss: 4.11119, precision: 0.929 recall: 1.000 f1: 0.963 accuracy: 0.986 
training batch:     7, loss: 5.33573, precision: 0.783 recall: 0.818 f1: 0.800 accuracy: 0.979 
training batch:     8, loss: 4.96036, precision: 0.871 recall: 0.900 f1: 0.885 accuracy: 0.976 
training batch:     9, loss: 1.98134, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.991 
training batch:    10, loss: 6.80753, precision: 0.882 recall: 0.857 f1: 0.870 accuracy: 0.974 
training batch:    11, loss: 5.62071, precision: 0.882 recall: 0.789 f1: 0.833 accuracy: 0.984 
training batch:    12, loss: 1.37392, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.996 
training batch:    13, loss: 2.52025, precision: 0.921 recall: 0.875 f1: 0.897 accuracy: 0.990 
training batch:    14, loss: 4.02583, precision: 0.861 recall: 0.912 f1: 0.886 accuracy: 0.979 
training batch:    15, loss: 3.09491, precision: 0.926 recall: 0.962 f1: 0.943 accuracy: 0.991 
training batch:    16, loss: 3.86809, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.988 
training batch:    17, loss: 4.29370, precision: 0.838 recall: 0.969 f1: 0.899 accuracy: 0.989 
training batch:    18, loss: 4.54571, precision: 0.818 recall: 0.692 f1: 0.750 accuracy: 0.984 
training batch:    19, loss: 3.00474, precision: 0.897 recall: 0.921 f1: 0.909 accuracy: 0.989 
training batch:    20, loss: 1.89349, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.993 
training batch:    21, loss: 5.93900, precision: 0.914 recall: 0.842 f1: 0.877 accuracy: 0.980 
training batch:    22, loss: 1.11456, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.995 
training batch:    23, loss: 2.07172, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.994 
training batch:    24, loss: 3.44875, precision: 0.886 recall: 0.912 f1: 0.899 accuracy: 0.989 
training batch:    25, loss: 1.90989, precision: 0.879 recall: 0.906 f1: 0.892 accuracy: 0.993 
training batch:    26, loss: 1.88702, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.995 
training batch:    27, loss: 3.05172, precision: 0.865 recall: 0.889 f1: 0.877 accuracy: 0.985 
training batch:    28, loss: 3.81987, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.989 
training batch:    29, loss: 1.65163, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.996 
training batch:    30, loss: 3.06196, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.989 
training batch:    31, loss: 2.17654, precision: 0.929 recall: 0.907 f1: 0.918 accuracy: 0.994 
training batch:    32, loss: 4.46318, precision: 0.795 recall: 0.861 f1: 0.827 accuracy: 0.975 
training batch:    33, loss: 2.62772, precision: 0.911 recall: 0.953 f1: 0.932 accuracy: 0.990 
training batch:    34, loss: 4.82816, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.980 
training batch:    35, loss: 4.27647, precision: 1.000 recall: 0.955 f1: 0.977 accuracy: 0.993 
training batch:    36, loss: 3.31714, precision: 0.970 recall: 0.914 f1: 0.941 accuracy: 0.994 
training batch:    37, loss: 2.42303, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.993 
training batch:    38, loss: 1.57674, precision: 0.871 recall: 0.931 f1: 0.900 accuracy: 0.990 
training batch:    39, loss: 3.79109, precision: 0.895 recall: 0.895 f1: 0.895 accuracy: 0.979 
training batch:    40, loss: 4.43555, precision: 0.875 recall: 0.921 f1: 0.897 accuracy: 0.986 
training batch:    41, loss: 2.45392, precision: 0.848 recall: 0.875 f1: 0.862 accuracy: 0.986 
training batch:    42, loss: 4.69862, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.978 
training batch:    43, loss: 3.17923, precision: 0.907 recall: 0.951 f1: 0.929 accuracy: 0.991 
training batch:    44, loss: 4.86160, precision: 0.860 recall: 0.860 f1: 0.860 accuracy: 0.974 
training batch:    45, loss: 2.97392, precision: 0.839 recall: 0.897 f1: 0.867 accuracy: 0.986 
training batch:    46, loss: 11.47189, precision: 0.786 recall: 0.786 f1: 0.786 accuracy: 0.958 
training batch:    47, loss: 1.38853, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.998 
training batch:    48, loss: 4.52061, precision: 0.893 recall: 0.926 f1: 0.909 accuracy: 0.974 
training batch:    49, loss: 4.15125, precision: 0.971 recall: 0.917 f1: 0.943 accuracy: 0.968 
training batch:    50, loss: 4.35042, precision: 0.881 recall: 0.902 f1: 0.892 accuracy: 0.974 
training batch:    51, loss: 6.37903, precision: 0.882 recall: 0.811 f1: 0.845 accuracy: 0.981 
training batch:    52, loss: 16.95271, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.945 
training batch:    53, loss: 3.25273, precision: 0.882 recall: 0.857 f1: 0.870 accuracy: 0.989 
training batch:    54, loss: 4.15778, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.989 
training batch:    55, loss: 5.39272, precision: 0.875 recall: 0.903 f1: 0.889 accuracy: 0.986 
training batch:    56, loss: 2.82697, precision: 0.951 recall: 0.867 f1: 0.907 accuracy: 0.993 
training batch:    57, loss: 2.21255, precision: 0.895 recall: 0.895 f1: 0.895 accuracy: 0.991 
training batch:    58, loss: 3.78021, precision: 0.907 recall: 0.867 f1: 0.886 accuracy: 0.986 
training batch:    59, loss: 3.54182, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.983 
training batch:    60, loss: 13.11709, precision: 0.850 recall: 0.872 f1: 0.861 accuracy: 0.963 
training batch:    61, loss: 2.69719, precision: 0.919 recall: 0.971 f1: 0.944 accuracy: 0.986 
training batch:    62, loss: 5.94675, precision: 0.872 recall: 0.911 f1: 0.891 accuracy: 0.971 
training batch:    63, loss: 4.92380, precision: 0.762 recall: 0.914 f1: 0.831 accuracy: 0.979 
training batch:    64, loss: 3.98961, precision: 0.842 recall: 0.914 f1: 0.877 accuracy: 0.985 
training batch:    65, loss: 3.24046, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.989 
training batch:    66, loss: 3.85867, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.986 
training batch:    67, loss: 7.44586, precision: 0.871 recall: 0.818 f1: 0.844 accuracy: 0.983 
training batch:    68, loss: 5.56143, precision: 0.861 recall: 0.886 f1: 0.873 accuracy: 0.991 
training batch:    69, loss: 3.15358, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.991 
training batch:    70, loss: 6.57245, precision: 0.846 recall: 0.825 f1: 0.835 accuracy: 0.974 
training batch:    71, loss: 2.60449, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.986 
training batch:    72, loss: 1.50916, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.996 
training batch:    73, loss: 2.77991, precision: 0.950 recall: 1.000 f1: 0.974 accuracy: 0.991 
training batch:    74, loss: 8.74454, precision: 0.878 recall: 0.827 f1: 0.851 accuracy: 0.969 
training batch:    75, loss: 8.79140, precision: 0.844 recall: 0.927 f1: 0.884 accuracy: 0.968 
training batch:    76, loss: 5.10298, precision: 0.833 recall: 0.882 f1: 0.857 accuracy: 0.975 
training batch:    77, loss: 5.02592, precision: 0.824 recall: 0.903 f1: 0.862 accuracy: 0.984 
training batch:    78, loss: 2.97520, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.993 
training batch:    79, loss: 2.94485, precision: 0.914 recall: 0.889 f1: 0.901 accuracy: 0.989 
training batch:    80, loss: 2.62288, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.998 
training batch:    81, loss: 7.81158, precision: 0.839 recall: 0.839 f1: 0.839 accuracy: 0.975 
training batch:    82, loss: 4.34654, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.986 
training batch:    83, loss: 7.14020, precision: 0.789 recall: 0.769 f1: 0.779 accuracy: 0.966 
training batch:    84, loss: 5.14517, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.985 
training batch:    85, loss: 2.74844, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.990 
training batch:    86, loss: 3.85784, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.991 
training batch:    87, loss: 3.08546, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.986 
training batch:    88, loss: 3.22993, precision: 0.897 recall: 0.946 f1: 0.921 accuracy: 0.989 
training batch:    89, loss: 3.67564, precision: 0.824 recall: 0.903 f1: 0.862 accuracy: 0.985 
training batch:    90, loss: 2.89215, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.989 
training batch:    91, loss: 5.60495, precision: 0.733 recall: 0.733 f1: 0.733 accuracy: 0.968 
training batch:    92, loss: 7.79843, precision: 0.818 recall: 0.766 f1: 0.791 accuracy: 0.983 
training batch:    93, loss: 1.48526, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.996 
training batch:    94, loss: 3.56531, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.986 
training batch:    95, loss: 5.25800, precision: 0.871 recall: 0.711 f1: 0.783 accuracy: 0.979 
training batch:    96, loss: 3.92178, precision: 0.829 recall: 0.935 f1: 0.879 accuracy: 0.981 
training batch:    97, loss: 5.24579, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.981 
training batch:    98, loss: 2.46390, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:    99, loss: 6.76343, precision: 0.919 recall: 0.895 f1: 0.907 accuracy: 0.979 
training batch:   100, loss: 3.68857, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.989 
training batch:   101, loss: 3.85104, precision: 0.882 recall: 0.938 f1: 0.909 accuracy: 0.988 
training batch:   102, loss: 4.77390, precision: 0.829 recall: 0.906 f1: 0.866 accuracy: 0.985 
training batch:   103, loss: 8.70424, precision: 0.839 recall: 0.788 f1: 0.812 accuracy: 0.975 
training batch:   104, loss: 6.98560, precision: 0.867 recall: 0.886 f1: 0.876 accuracy: 0.971 
training batch:   105, loss: 2.16121, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.989 
training batch:   106, loss: 2.75983, precision: 0.789 recall: 0.833 f1: 0.811 accuracy: 0.988 
training batch:   107, loss: 4.93135, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.973 
training batch:   108, loss: 4.40201, precision: 0.842 recall: 0.865 f1: 0.853 accuracy: 0.984 
training batch:   109, loss: 4.32458, precision: 0.862 recall: 0.862 f1: 0.862 accuracy: 0.980 
training batch:   110, loss: 3.81859, precision: 0.862 recall: 0.893 f1: 0.877 accuracy: 0.986 
training batch:   111, loss: 6.31009, precision: 0.806 recall: 0.833 f1: 0.820 accuracy: 0.979 
training batch:   112, loss: 3.82059, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.993 
training batch:   113, loss: 7.52425, precision: 0.846 recall: 0.767 f1: 0.805 accuracy: 0.971 
training batch:   114, loss: 3.07061, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.985 
training batch:   115, loss: 4.40385, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.985 
training batch:   116, loss: 5.80286, precision: 0.821 recall: 0.842 f1: 0.831 accuracy: 0.980 
training batch:   117, loss: 1.28789, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   118, loss: 3.83952, precision: 0.906 recall: 0.853 f1: 0.879 accuracy: 0.983 
training batch:   119, loss: 6.22096, precision: 0.811 recall: 0.909 f1: 0.857 accuracy: 0.969 
training batch:   120, loss: 2.92467, precision: 0.829 recall: 0.895 f1: 0.861 accuracy: 0.985 
training batch:   121, loss: 4.31593, precision: 0.825 recall: 0.767 f1: 0.795 accuracy: 0.979 
training batch:   122, loss: 5.47759, precision: 0.865 recall: 0.821 f1: 0.842 accuracy: 0.979 
training batch:   123, loss: 2.87778, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.990 
training batch:   124, loss: 10.80804, precision: 0.735 recall: 0.781 f1: 0.758 accuracy: 0.965 
training batch:   125, loss: 6.67875, precision: 0.882 recall: 0.833 f1: 0.857 accuracy: 0.961 
training batch:   126, loss: 2.38980, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.991 
training batch:   127, loss: 1.67338, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.996 
training batch:   128, loss: 6.38134, precision: 0.815 recall: 0.880 f1: 0.846 accuracy: 0.978 
training batch:   129, loss: 5.24565, precision: 0.733 recall: 0.917 f1: 0.815 accuracy: 0.979 
training batch:   130, loss: 4.07846, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.984 
training batch:   131, loss: 3.47363, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.994 
training batch:   132, loss: 3.03891, precision: 0.909 recall: 0.870 f1: 0.889 accuracy: 0.986 
training batch:   133, loss: 2.56603, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.996 
training batch:   134, loss: 5.44584, precision: 0.857 recall: 0.811 f1: 0.833 accuracy: 0.974 
training batch:   135, loss: 3.27382, precision: 0.815 recall: 0.917 f1: 0.863 accuracy: 0.986 
training batch:   136, loss: 2.37872, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.991 
training batch:   137, loss: 3.00473, precision: 0.882 recall: 0.909 f1: 0.896 accuracy: 0.985 
training batch:   138, loss: 6.31544, precision: 0.850 recall: 0.919 f1: 0.883 accuracy: 0.979 
training batch:   139, loss: 3.72139, precision: 0.972 recall: 0.921 f1: 0.946 accuracy: 0.993 
training batch:   140, loss: 6.78943, precision: 0.821 recall: 0.762 f1: 0.790 accuracy: 0.969 
training batch:   141, loss: 2.53865, precision: 0.944 recall: 0.919 f1: 0.932 accuracy: 0.986 
training batch:   142, loss: 3.38246, precision: 0.893 recall: 0.862 f1: 0.877 accuracy: 0.983 
training batch:   143, loss: 6.03616, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.981 
training batch:   144, loss: 4.45853, precision: 0.872 recall: 0.829 f1: 0.850 accuracy: 0.976 
training batch:   145, loss: 3.30014, precision: 0.960 recall: 0.923 f1: 0.941 accuracy: 0.989 
training batch:   146, loss: 2.74086, precision: 1.000 recall: 0.871 f1: 0.931 accuracy: 0.989 
training batch:   147, loss: 3.23440, precision: 0.788 recall: 0.897 f1: 0.839 accuracy: 0.986 
training batch:   148, loss: 2.30121, precision: 0.846 recall: 0.868 f1: 0.857 accuracy: 0.991 
training batch:   149, loss: 5.30788, precision: 0.838 recall: 0.838 f1: 0.838 accuracy: 0.983 
training batch:   150, loss: 1.82228, precision: 0.889 recall: 0.970 f1: 0.928 accuracy: 0.994 
training batch:   151, loss: 2.46363, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.988 
training batch:   152, loss: 2.24437, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.991 
training batch:   153, loss: 3.74840, precision: 0.906 recall: 0.853 f1: 0.879 accuracy: 0.991 
training batch:   154, loss: 2.84523, precision: 0.889 recall: 0.909 f1: 0.899 accuracy: 0.984 
training batch:   155, loss: 2.30284, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.990 
training batch:   156, loss: 2.72539, precision: 0.857 recall: 0.882 f1: 0.870 accuracy: 0.988 
training batch:   157, loss: 1.60156, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.996 
training batch:   158, loss: 6.13943, precision: 0.829 recall: 0.763 f1: 0.795 accuracy: 0.976 
training batch:   159, loss: 5.57550, precision: 0.879 recall: 0.829 f1: 0.853 accuracy: 0.981 
training batch:   160, loss: 3.14920, precision: 0.914 recall: 0.889 f1: 0.901 accuracy: 0.989 
training batch:   161, loss: 3.03252, precision: 0.833 recall: 0.926 f1: 0.877 accuracy: 0.979 
training batch:   162, loss: 5.49538, precision: 0.898 recall: 0.957 f1: 0.926 accuracy: 0.988 
training batch:   163, loss: 3.91190, precision: 0.936 recall: 0.957 f1: 0.946 accuracy: 0.985 
training batch:   164, loss: 5.85425, precision: 0.829 recall: 0.829 f1: 0.829 accuracy: 0.983 
training batch:   165, loss: 4.30954, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.988 
training batch:   166, loss: 2.63020, precision: 0.808 recall: 0.840 f1: 0.824 accuracy: 0.991 
training batch:   167, loss: 3.10730, precision: 0.909 recall: 1.000 f1: 0.952 accuracy: 0.989 
training batch:   168, loss: 3.47023, precision: 0.875 recall: 0.848 f1: 0.862 accuracy: 0.988 
training batch:   169, loss: 5.07052, precision: 0.781 recall: 0.862 f1: 0.820 accuracy: 0.983 
training batch:   170, loss: 5.62328, precision: 0.818 recall: 0.818 f1: 0.818 accuracy: 0.978 
training batch:   171, loss: 1.84956, precision: 0.972 recall: 0.921 f1: 0.946 accuracy: 0.994 
training batch:   172, loss: 2.41690, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.993 
training batch:   173, loss: 1.57326, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.996 
training batch:   174, loss: 8.86161, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.981 
training batch:   175, loss: 3.24658, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.980 
training batch:   176, loss: 4.93810, precision: 0.853 recall: 0.879 f1: 0.866 accuracy: 0.975 
training batch:   177, loss: 3.11171, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.984 
training batch:   178, loss: 1.66968, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.997 
start evaluate engines...
label: Dsa, precision: 0.781 recall: 0.696 f1: 0.729 
label: Chk, precision: 0.658 recall: 0.630 f1: 0.626 
label: Ins, precision: 0.267 recall: 0.250 f1: 0.248 
label: Sur, precision: 0.909 recall: 0.883 f1: 0.893 
label: Med, precision: 0.315 recall: 0.340 f1: 0.323 
label: Ana, precision: 0.813 recall: 0.842 f1: 0.825 
time consumption:4.36(min), precision: 0.837 recall: 0.810 f1: 0.822 accuracy: 0.964 
epoch:11/100
training batch:     1, loss: 1.44019, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:     2, loss: 1.67747, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.995 
training batch:     3, loss: 4.22897, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.990 
training batch:     4, loss: 5.73564, precision: 0.784 recall: 0.784 f1: 0.784 accuracy: 0.964 
training batch:     5, loss: 2.50674, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.991 
training batch:     6, loss: 4.31432, precision: 0.806 recall: 0.879 f1: 0.841 accuracy: 0.983 
training batch:     7, loss: 4.42901, precision: 0.927 recall: 0.844 f1: 0.884 accuracy: 0.985 
training batch:     8, loss: 2.68439, precision: 0.895 recall: 0.895 f1: 0.895 accuracy: 0.990 
training batch:     9, loss: 2.75331, precision: 0.864 recall: 0.950 f1: 0.905 accuracy: 0.989 
training batch:    10, loss: 2.57654, precision: 0.917 recall: 0.846 f1: 0.880 accuracy: 0.986 
training batch:    11, loss: 1.99205, precision: 0.935 recall: 0.906 f1: 0.921 accuracy: 0.995 
training batch:    12, loss: 3.89765, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.983 
training batch:    13, loss: 2.07852, precision: 0.895 recall: 0.919 f1: 0.907 accuracy: 0.990 
training batch:    14, loss: 6.87965, precision: 0.872 recall: 0.919 f1: 0.895 accuracy: 0.973 
training batch:    15, loss: 2.29950, precision: 0.854 recall: 0.875 f1: 0.864 accuracy: 0.986 
training batch:    16, loss: 1.66084, precision: 0.921 recall: 0.875 f1: 0.897 accuracy: 0.991 
training batch:    17, loss: 1.07806, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    18, loss: 1.89415, precision: 0.897 recall: 0.921 f1: 0.909 accuracy: 0.995 
training batch:    19, loss: 2.41592, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.993 
training batch:    20, loss: 2.28378, precision: 0.864 recall: 0.927 f1: 0.894 accuracy: 0.993 
training batch:    21, loss: 5.24985, precision: 0.925 recall: 0.881 f1: 0.902 accuracy: 0.983 
training batch:    22, loss: 3.71017, precision: 0.864 recall: 0.905 f1: 0.884 accuracy: 0.988 
training batch:    23, loss: 2.14392, precision: 0.906 recall: 0.967 f1: 0.935 accuracy: 0.991 
training batch:    24, loss: 6.15873, precision: 0.880 recall: 1.000 f1: 0.936 accuracy: 0.973 
training batch:    25, loss: 3.09673, precision: 0.842 recall: 0.914 f1: 0.877 accuracy: 0.984 
training batch:    26, loss: 4.37148, precision: 0.886 recall: 0.886 f1: 0.886 accuracy: 0.980 
training batch:    27, loss: 1.28639, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.996 
training batch:    28, loss: 1.84383, precision: 0.964 recall: 0.900 f1: 0.931 accuracy: 0.989 
training batch:    29, loss: 3.79901, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.983 
training batch:    30, loss: 5.78943, precision: 0.875 recall: 0.737 f1: 0.800 accuracy: 0.974 
training batch:    31, loss: 3.95236, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.980 
training batch:    32, loss: 6.26590, precision: 0.878 recall: 0.923 f1: 0.900 accuracy: 0.981 
training batch:    33, loss: 2.13266, precision: 0.939 recall: 0.886 f1: 0.912 accuracy: 0.990 
training batch:    34, loss: 3.78923, precision: 0.875 recall: 0.921 f1: 0.897 accuracy: 0.986 
training batch:    35, loss: 6.22461, precision: 0.933 recall: 0.824 f1: 0.875 accuracy: 0.973 
training batch:    36, loss: 1.53065, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.996 
training batch:    37, loss: 4.19990, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.979 
training batch:    38, loss: 1.66086, precision: 0.902 recall: 0.925 f1: 0.914 accuracy: 0.995 
training batch:    39, loss: 3.40659, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.991 
training batch:    40, loss: 8.90785, precision: 0.821 recall: 0.842 f1: 0.831 accuracy: 0.951 
training batch:    41, loss: 6.09732, precision: 0.886 recall: 0.861 f1: 0.873 accuracy: 0.974 
training batch:    42, loss: 3.25262, precision: 0.870 recall: 0.889 f1: 0.879 accuracy: 0.983 
training batch:    43, loss: 3.24043, precision: 0.838 recall: 0.861 f1: 0.849 accuracy: 0.990 
training batch:    44, loss: 4.40793, precision: 0.842 recall: 0.865 f1: 0.853 accuracy: 0.984 
training batch:    45, loss: 1.61920, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:    46, loss: 5.56488, precision: 0.884 recall: 0.884 f1: 0.884 accuracy: 0.975 
training batch:    47, loss: 8.38904, precision: 0.778 recall: 0.848 f1: 0.812 accuracy: 0.971 
training batch:    48, loss: 2.56927, precision: 0.868 recall: 0.892 f1: 0.880 accuracy: 0.990 
training batch:    49, loss: 4.07851, precision: 0.867 recall: 0.929 f1: 0.897 accuracy: 0.985 
training batch:    50, loss: 2.13519, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.995 
training batch:    51, loss: 4.69938, precision: 0.884 recall: 0.927 f1: 0.905 accuracy: 0.981 
training batch:    52, loss: 3.16721, precision: 0.911 recall: 0.891 f1: 0.901 accuracy: 0.981 
training batch:    53, loss: 9.43481, precision: 0.861 recall: 0.861 f1: 0.861 accuracy: 0.963 
training batch:    54, loss: 3.23269, precision: 0.909 recall: 0.889 f1: 0.899 accuracy: 0.981 
training batch:    55, loss: 4.01497, precision: 0.816 recall: 0.795 f1: 0.805 accuracy: 0.976 
training batch:    56, loss: 2.12926, precision: 0.971 recall: 0.895 f1: 0.932 accuracy: 0.993 
training batch:    57, loss: 6.85641, precision: 0.949 recall: 0.902 f1: 0.925 accuracy: 0.975 
training batch:    58, loss: 2.71045, precision: 1.000 recall: 0.933 f1: 0.966 accuracy: 0.995 
training batch:    59, loss: 4.57054, precision: 0.871 recall: 0.844 f1: 0.857 accuracy: 0.985 
training batch:    60, loss: 1.87633, precision: 0.938 recall: 0.957 f1: 0.947 accuracy: 0.994 
training batch:    61, loss: 3.30070, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.979 
training batch:    62, loss: 5.58018, precision: 0.775 recall: 0.861 f1: 0.816 accuracy: 0.974 
training batch:    63, loss: 2.99998, precision: 0.925 recall: 0.974 f1: 0.949 accuracy: 0.993 
training batch:    64, loss: 2.90794, precision: 0.932 recall: 0.976 f1: 0.953 accuracy: 0.991 
training batch:    65, loss: 3.85358, precision: 0.923 recall: 0.878 f1: 0.900 accuracy: 0.989 
training batch:    66, loss: 1.97243, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.995 
training batch:    67, loss: 7.37000, precision: 0.821 recall: 0.793 f1: 0.807 accuracy: 0.980 
training batch:    68, loss: 5.61140, precision: 0.903 recall: 0.848 f1: 0.875 accuracy: 0.980 
training batch:    69, loss: 3.38175, precision: 0.769 recall: 0.870 f1: 0.816 accuracy: 0.984 
training batch:    70, loss: 6.24181, precision: 0.853 recall: 0.935 f1: 0.892 accuracy: 0.970 
training batch:    71, loss: 3.45419, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.988 
training batch:    72, loss: 6.50335, precision: 0.900 recall: 0.923 f1: 0.911 accuracy: 0.971 
training batch:    73, loss: 1.98640, precision: 0.871 recall: 0.818 f1: 0.844 accuracy: 0.991 
training batch:    74, loss: 2.71313, precision: 0.974 recall: 0.881 f1: 0.925 accuracy: 0.990 
training batch:    75, loss: 5.66039, precision: 0.853 recall: 1.000 f1: 0.921 accuracy: 0.975 
training batch:    76, loss: 3.63499, precision: 0.826 recall: 0.760 f1: 0.792 accuracy: 0.979 
training batch:    77, loss: 3.25604, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.990 
training batch:    78, loss: 6.65522, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.978 
training batch:    79, loss: 4.48317, precision: 0.868 recall: 0.825 f1: 0.846 accuracy: 0.988 
training batch:    80, loss: 3.70378, precision: 0.838 recall: 0.816 f1: 0.827 accuracy: 0.989 
training batch:    81, loss: 3.14343, precision: 0.829 recall: 0.879 f1: 0.853 accuracy: 0.989 
training batch:    82, loss: 3.05670, precision: 0.806 recall: 0.853 f1: 0.829 accuracy: 0.988 
training batch:    83, loss: 3.04933, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.993 
training batch:    84, loss: 2.80508, precision: 0.840 recall: 0.875 f1: 0.857 accuracy: 0.988 
training batch:    85, loss: 8.90891, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.958 
training batch:    86, loss: 4.11210, precision: 0.886 recall: 0.939 f1: 0.912 accuracy: 0.989 
training batch:    87, loss: 3.88753, precision: 0.926 recall: 0.893 f1: 0.909 accuracy: 0.988 
training batch:    88, loss: 3.96432, precision: 0.861 recall: 0.838 f1: 0.849 accuracy: 0.985 
training batch:    89, loss: 4.22064, precision: 0.812 recall: 0.839 f1: 0.825 accuracy: 0.980 
training batch:    90, loss: 4.95448, precision: 0.842 recall: 0.762 f1: 0.800 accuracy: 0.965 
training batch:    91, loss: 5.84718, precision: 0.868 recall: 0.892 f1: 0.880 accuracy: 0.961 
training batch:    92, loss: 4.24600, precision: 0.892 recall: 0.892 f1: 0.892 accuracy: 0.991 
training batch:    93, loss: 3.77045, precision: 0.771 recall: 0.818 f1: 0.794 accuracy: 0.973 
training batch:    94, loss: 2.75253, precision: 0.848 recall: 0.903 f1: 0.875 accuracy: 0.981 
training batch:    95, loss: 2.13836, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.989 
training batch:    96, loss: 4.02567, precision: 0.800 recall: 0.828 f1: 0.814 accuracy: 0.985 
training batch:    97, loss: 4.96211, precision: 0.844 recall: 0.844 f1: 0.844 accuracy: 0.985 
training batch:    98, loss: 2.92928, precision: 0.818 recall: 0.818 f1: 0.818 accuracy: 0.986 
training batch:    99, loss: 2.97411, precision: 0.963 recall: 0.929 f1: 0.945 accuracy: 0.983 
training batch:   100, loss: 5.34632, precision: 0.794 recall: 0.794 f1: 0.794 accuracy: 0.978 
training batch:   101, loss: 2.81754, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.986 
training batch:   102, loss: 6.89799, precision: 0.925 recall: 0.881 f1: 0.902 accuracy: 0.985 
training batch:   103, loss: 3.92290, precision: 0.897 recall: 0.875 f1: 0.886 accuracy: 0.988 
training batch:   104, loss: 2.30062, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.994 
training batch:   105, loss: 1.70201, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:   106, loss: 1.29248, precision: 0.900 recall: 0.818 f1: 0.857 accuracy: 0.995 
training batch:   107, loss: 3.06862, precision: 0.939 recall: 0.838 f1: 0.886 accuracy: 0.986 
training batch:   108, loss: 4.47978, precision: 0.897 recall: 0.839 f1: 0.867 accuracy: 0.983 
training batch:   109, loss: 3.72560, precision: 0.867 recall: 0.929 f1: 0.897 accuracy: 0.978 
training batch:   110, loss: 3.93237, precision: 0.925 recall: 0.881 f1: 0.902 accuracy: 0.991 
training batch:   111, loss: 6.44344, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.981 
training batch:   112, loss: 3.20488, precision: 0.864 recall: 0.826 f1: 0.844 accuracy: 0.984 
training batch:   113, loss: 3.30203, precision: 0.833 recall: 0.862 f1: 0.847 accuracy: 0.981 
training batch:   114, loss: 2.34207, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.993 
training batch:   115, loss: 2.39483, precision: 0.902 recall: 0.925 f1: 0.914 accuracy: 0.991 
training batch:   116, loss: 6.69516, precision: 0.875 recall: 0.848 f1: 0.862 accuracy: 0.974 
training batch:   117, loss: 7.64810, precision: 0.788 recall: 0.743 f1: 0.765 accuracy: 0.956 
training batch:   118, loss: 1.72427, precision: 0.880 recall: 0.917 f1: 0.898 accuracy: 0.994 
training batch:   119, loss: 4.34604, precision: 0.811 recall: 0.909 f1: 0.857 accuracy: 0.983 
training batch:   120, loss: 3.10597, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.990 
training batch:   121, loss: 5.92203, precision: 0.909 recall: 0.952 f1: 0.930 accuracy: 0.986 
training batch:   122, loss: 4.56374, precision: 0.881 recall: 0.881 f1: 0.881 accuracy: 0.986 
training batch:   123, loss: 3.77840, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.990 
training batch:   124, loss: 2.06926, precision: 0.886 recall: 0.939 f1: 0.912 accuracy: 0.994 
training batch:   125, loss: 3.78331, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.988 
training batch:   126, loss: 3.32979, precision: 0.933 recall: 0.955 f1: 0.944 accuracy: 0.990 
training batch:   127, loss: 1.03696, precision: 0.913 recall: 0.955 f1: 0.933 accuracy: 0.998 
training batch:   128, loss: 2.93155, precision: 0.842 recall: 0.970 f1: 0.901 accuracy: 0.991 
training batch:   129, loss: 3.74670, precision: 0.925 recall: 0.902 f1: 0.914 accuracy: 0.983 
training batch:   130, loss: 3.73895, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.983 
training batch:   131, loss: 5.15720, precision: 0.800 recall: 0.903 f1: 0.848 accuracy: 0.986 
training batch:   132, loss: 6.10153, precision: 0.974 recall: 0.884 f1: 0.927 accuracy: 0.976 
training batch:   133, loss: 2.41394, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.989 
training batch:   134, loss: 2.49826, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:   135, loss: 4.22273, precision: 0.900 recall: 0.923 f1: 0.911 accuracy: 0.976 
training batch:   136, loss: 4.15273, precision: 0.837 recall: 0.878 f1: 0.857 accuracy: 0.986 
training batch:   137, loss: 7.15723, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.979 
training batch:   138, loss: 2.87289, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.984 
training batch:   139, loss: 2.36018, precision: 0.907 recall: 0.975 f1: 0.940 accuracy: 0.991 
training batch:   140, loss: 2.56281, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.990 
training batch:   141, loss: 2.02506, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:   142, loss: 2.95836, precision: 0.974 recall: 0.950 f1: 0.962 accuracy: 0.994 
training batch:   143, loss: 1.52058, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.998 
training batch:   144, loss: 2.53839, precision: 0.857 recall: 0.960 f1: 0.906 accuracy: 0.989 
training batch:   145, loss: 4.28889, precision: 0.838 recall: 0.816 f1: 0.827 accuracy: 0.978 
training batch:   146, loss: 4.85017, precision: 0.846 recall: 0.880 f1: 0.863 accuracy: 0.975 
training batch:   147, loss: 3.06236, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.989 
training batch:   148, loss: 5.12044, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.970 
training batch:   149, loss: 2.83313, precision: 0.895 recall: 0.919 f1: 0.907 accuracy: 0.994 
training batch:   150, loss: 6.47356, precision: 0.821 recall: 0.800 f1: 0.810 accuracy: 0.975 
training batch:   151, loss: 5.69347, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.980 
training batch:   152, loss: 3.12122, precision: 0.882 recall: 0.789 f1: 0.833 accuracy: 0.989 
training batch:   153, loss: 1.76842, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.994 
training batch:   154, loss: 5.41094, precision: 0.889 recall: 0.952 f1: 0.920 accuracy: 0.980 
training batch:   155, loss: 1.87811, precision: 0.917 recall: 0.971 f1: 0.943 accuracy: 0.991 
training batch:   156, loss: 4.98578, precision: 0.968 recall: 0.909 f1: 0.937 accuracy: 0.973 
training batch:   157, loss: 1.67107, precision: 0.952 recall: 0.976 f1: 0.964 accuracy: 0.994 
training batch:   158, loss: 3.89959, precision: 0.840 recall: 0.808 f1: 0.824 accuracy: 0.984 
training batch:   159, loss: 4.06776, precision: 0.833 recall: 0.938 f1: 0.882 accuracy: 0.986 
training batch:   160, loss: 1.74466, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.994 
training batch:   161, loss: 3.05920, precision: 0.936 recall: 0.936 f1: 0.936 accuracy: 0.990 
training batch:   162, loss: 1.58093, precision: 0.955 recall: 0.913 f1: 0.933 accuracy: 0.995 
training batch:   163, loss: 2.55238, precision: 0.950 recall: 0.927 f1: 0.938 accuracy: 0.988 
training batch:   164, loss: 6.54279, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.969 
training batch:   165, loss: 3.42097, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.993 
training batch:   166, loss: 3.80406, precision: 0.909 recall: 1.000 f1: 0.952 accuracy: 0.979 
training batch:   167, loss: 0.97194, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   168, loss: 1.93853, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.996 
training batch:   169, loss: 3.64619, precision: 0.917 recall: 0.868 f1: 0.892 accuracy: 0.989 
training batch:   170, loss: 4.46448, precision: 0.889 recall: 0.857 f1: 0.873 accuracy: 0.986 
training batch:   171, loss: 4.48944, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.989 
training batch:   172, loss: 5.26883, precision: 0.815 recall: 0.846 f1: 0.830 accuracy: 0.981 
training batch:   173, loss: 2.32601, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.991 
training batch:   174, loss: 4.61100, precision: 0.839 recall: 0.788 f1: 0.812 accuracy: 0.966 
training batch:   175, loss: 5.64729, precision: 0.829 recall: 0.791 f1: 0.810 accuracy: 0.971 
training batch:   176, loss: 2.46523, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.994 
training batch:   177, loss: 3.51714, precision: 0.806 recall: 0.853 f1: 0.829 accuracy: 0.989 
training batch:   178, loss: 7.81702, precision: 0.900 recall: 0.818 f1: 0.857 accuracy: 0.973 
start evaluate engines...
label: Dsa, precision: 0.776 recall: 0.761 f1: 0.764 
label: Chk, precision: 0.725 recall: 0.700 f1: 0.698 
label: Ins, precision: 0.358 recall: 0.308 f1: 0.318 
label: Sur, precision: 0.847 recall: 0.887 f1: 0.863 
label: Med, precision: 0.415 recall: 0.415 f1: 0.407 
label: Ana, precision: 0.845 recall: 0.835 f1: 0.836 
time consumption:3.79(min), precision: 0.842 recall: 0.838 f1: 0.839 accuracy: 0.967 
epoch:12/100
training batch:     1, loss: 1.09297, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.995 
training batch:     2, loss: 0.89856, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.995 
training batch:     3, loss: 4.76688, precision: 0.892 recall: 0.917 f1: 0.904 accuracy: 0.981 
training batch:     4, loss: 2.84122, precision: 0.891 recall: 0.891 f1: 0.891 accuracy: 0.991 
training batch:     5, loss: 1.59074, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.990 
training batch:     6, loss: 2.67635, precision: 0.821 recall: 0.842 f1: 0.831 accuracy: 0.983 
training batch:     7, loss: 3.72040, precision: 0.957 recall: 0.936 f1: 0.946 accuracy: 0.990 
training batch:     8, loss: 5.05253, precision: 0.848 recall: 0.867 f1: 0.857 accuracy: 0.965 
training batch:     9, loss: 1.86592, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.984 
training batch:    10, loss: 4.96010, precision: 0.933 recall: 0.913 f1: 0.923 accuracy: 0.990 
training batch:    11, loss: 2.24283, precision: 0.917 recall: 0.971 f1: 0.943 accuracy: 0.991 
training batch:    12, loss: 3.39661, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.993 
training batch:    13, loss: 2.06767, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.996 
training batch:    14, loss: 2.58992, precision: 0.935 recall: 0.906 f1: 0.921 accuracy: 0.988 
training batch:    15, loss: 2.07628, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.998 
training batch:    16, loss: 0.89470, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    17, loss: 2.31755, precision: 0.925 recall: 1.000 f1: 0.961 accuracy: 0.989 
training batch:    18, loss: 2.16415, precision: 0.938 recall: 0.857 f1: 0.896 accuracy: 0.993 
training batch:    19, loss: 1.47023, precision: 0.944 recall: 0.919 f1: 0.932 accuracy: 0.995 
training batch:    20, loss: 1.99968, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.999 
training batch:    21, loss: 5.50162, precision: 0.825 recall: 0.892 f1: 0.857 accuracy: 0.986 
training batch:    22, loss: 5.85010, precision: 0.868 recall: 0.868 f1: 0.868 accuracy: 0.976 
training batch:    23, loss: 4.18335, precision: 0.828 recall: 0.857 f1: 0.842 accuracy: 0.984 
training batch:    24, loss: 1.53723, precision: 0.970 recall: 0.889 f1: 0.928 accuracy: 0.994 
training batch:    25, loss: 5.47623, precision: 0.882 recall: 0.938 f1: 0.909 accuracy: 0.986 
training batch:    26, loss: 3.67499, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.993 
training batch:    27, loss: 5.01016, precision: 0.690 recall: 0.769 f1: 0.727 accuracy: 0.979 
training batch:    28, loss: 4.17746, precision: 0.878 recall: 0.818 f1: 0.847 accuracy: 0.981 
training batch:    29, loss: 4.25150, precision: 0.809 recall: 0.809 f1: 0.809 accuracy: 0.975 
training batch:    30, loss: 1.09949, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.996 
training batch:    31, loss: 1.99808, precision: 0.879 recall: 0.935 f1: 0.906 accuracy: 0.993 
training batch:    32, loss: 3.72432, precision: 0.909 recall: 0.811 f1: 0.857 accuracy: 0.988 
training batch:    33, loss: 2.17645, precision: 0.939 recall: 0.885 f1: 0.911 accuracy: 0.991 
training batch:    34, loss: 4.64426, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.980 
training batch:    35, loss: 2.17299, precision: 0.900 recall: 0.931 f1: 0.915 accuracy: 0.991 
training batch:    36, loss: 2.85809, precision: 0.914 recall: 0.970 f1: 0.941 accuracy: 0.989 
training batch:    37, loss: 3.02158, precision: 0.871 recall: 0.794 f1: 0.831 accuracy: 0.983 
training batch:    38, loss: 2.82790, precision: 0.892 recall: 0.943 f1: 0.917 accuracy: 0.991 
training batch:    39, loss: 5.79684, precision: 0.914 recall: 0.889 f1: 0.901 accuracy: 0.981 
training batch:    40, loss: 3.63392, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.980 
training batch:    41, loss: 3.39355, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.988 
training batch:    42, loss: 2.76785, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.990 
training batch:    43, loss: 2.53822, precision: 0.884 recall: 0.950 f1: 0.916 accuracy: 0.994 
training batch:    44, loss: 1.01857, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.998 
training batch:    45, loss: 2.56559, precision: 0.914 recall: 0.889 f1: 0.901 accuracy: 0.989 
training batch:    46, loss: 2.52625, precision: 0.929 recall: 0.867 f1: 0.897 accuracy: 0.995 
training batch:    47, loss: 3.37914, precision: 0.775 recall: 0.886 f1: 0.827 accuracy: 0.985 
training batch:    48, loss: 4.19883, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.991 
training batch:    49, loss: 2.60546, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.993 
training batch:    50, loss: 2.22138, precision: 0.927 recall: 0.905 f1: 0.916 accuracy: 0.990 
training batch:    51, loss: 4.40646, precision: 0.943 recall: 0.805 f1: 0.868 accuracy: 0.990 
training batch:    52, loss: 2.81404, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.989 
training batch:    53, loss: 3.68452, precision: 0.868 recall: 0.892 f1: 0.880 accuracy: 0.989 
training batch:    54, loss: 2.41107, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.989 
training batch:    55, loss: 2.48241, precision: 0.867 recall: 0.897 f1: 0.881 accuracy: 0.980 
training batch:    56, loss: 2.42691, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.991 
training batch:    57, loss: 2.30682, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.988 
training batch:    58, loss: 1.47688, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.988 
training batch:    59, loss: 4.76624, precision: 0.889 recall: 0.865 f1: 0.877 accuracy: 0.985 
training batch:    60, loss: 4.36125, precision: 0.758 recall: 0.833 f1: 0.794 accuracy: 0.976 
training batch:    61, loss: 1.82460, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.996 
training batch:    62, loss: 1.57274, precision: 0.930 recall: 0.976 f1: 0.952 accuracy: 0.994 
training batch:    63, loss: 2.09122, precision: 0.861 recall: 0.912 f1: 0.886 accuracy: 0.989 
training batch:    64, loss: 2.89441, precision: 0.841 recall: 0.881 f1: 0.860 accuracy: 0.990 
training batch:    65, loss: 4.43182, precision: 0.902 recall: 0.881 f1: 0.892 accuracy: 0.990 
training batch:    66, loss: 3.88795, precision: 0.925 recall: 0.902 f1: 0.914 accuracy: 0.990 
training batch:    67, loss: 2.21587, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.995 
training batch:    68, loss: 2.37306, precision: 0.848 recall: 0.848 f1: 0.848 accuracy: 0.991 
training batch:    69, loss: 1.18011, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.998 
training batch:    70, loss: 0.87984, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.998 
training batch:    71, loss: 4.12672, precision: 0.875 recall: 0.848 f1: 0.862 accuracy: 0.975 
training batch:    72, loss: 8.53370, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.968 
training batch:    73, loss: 2.29304, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.990 
training batch:    74, loss: 7.34591, precision: 0.806 recall: 0.781 f1: 0.794 accuracy: 0.973 
training batch:    75, loss: 4.91886, precision: 0.806 recall: 0.833 f1: 0.820 accuracy: 0.984 
training batch:    76, loss: 1.55119, precision: 0.912 recall: 1.000 f1: 0.954 accuracy: 0.996 
training batch:    77, loss: 3.31111, precision: 0.824 recall: 0.848 f1: 0.836 accuracy: 0.981 
training batch:    78, loss: 6.83264, precision: 0.921 recall: 0.897 f1: 0.909 accuracy: 0.980 
training batch:    79, loss: 5.61151, precision: 0.812 recall: 0.897 f1: 0.852 accuracy: 0.983 
training batch:    80, loss: 1.16507, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.996 
training batch:    81, loss: 3.33693, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.980 
training batch:    82, loss: 1.69279, precision: 0.875 recall: 0.840 f1: 0.857 accuracy: 0.994 
training batch:    83, loss: 1.02969, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.996 
training batch:    84, loss: 2.05141, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.994 
training batch:    85, loss: 4.46777, precision: 0.860 recall: 0.902 f1: 0.881 accuracy: 0.986 
training batch:    86, loss: 4.66193, precision: 0.949 recall: 0.925 f1: 0.937 accuracy: 0.986 
training batch:    87, loss: 3.35152, precision: 0.853 recall: 0.935 f1: 0.892 accuracy: 0.988 
training batch:    88, loss: 1.80434, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.996 
training batch:    89, loss: 2.83847, precision: 0.947 recall: 0.878 f1: 0.911 accuracy: 0.993 
training batch:    90, loss: 3.77936, precision: 0.824 recall: 0.778 f1: 0.800 accuracy: 0.983 
training batch:    91, loss: 3.57117, precision: 0.944 recall: 0.895 f1: 0.919 accuracy: 0.989 
training batch:    92, loss: 1.74043, precision: 0.893 recall: 0.926 f1: 0.909 accuracy: 0.994 
training batch:    93, loss: 2.70401, precision: 0.868 recall: 0.846 f1: 0.857 accuracy: 0.989 
training batch:    94, loss: 3.18231, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.983 
training batch:    95, loss: 1.47031, precision: 0.875 recall: 0.903 f1: 0.889 accuracy: 0.996 
training batch:    96, loss: 2.61220, precision: 0.932 recall: 1.000 f1: 0.965 accuracy: 0.991 
training batch:    97, loss: 5.06281, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.989 
training batch:    98, loss: 4.23083, precision: 0.857 recall: 0.909 f1: 0.882 accuracy: 0.975 
training batch:    99, loss: 5.38129, precision: 0.889 recall: 0.952 f1: 0.920 accuracy: 0.981 
training batch:   100, loss: 0.65546, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.999 
training batch:   101, loss: 1.46469, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.994 
training batch:   102, loss: 5.46677, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.986 
training batch:   103, loss: 4.73563, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.983 
training batch:   104, loss: 8.00031, precision: 0.905 recall: 0.950 f1: 0.927 accuracy: 0.979 
training batch:   105, loss: 1.47592, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.993 
training batch:   106, loss: 1.89098, precision: 0.921 recall: 0.972 f1: 0.946 accuracy: 0.985 
training batch:   107, loss: 2.04024, precision: 0.829 recall: 0.853 f1: 0.841 accuracy: 0.990 
training batch:   108, loss: 3.19980, precision: 0.917 recall: 0.971 f1: 0.943 accuracy: 0.984 
training batch:   109, loss: 3.78913, precision: 0.886 recall: 0.951 f1: 0.918 accuracy: 0.986 
training batch:   110, loss: 2.05769, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.995 
training batch:   111, loss: 1.93314, precision: 1.000 recall: 0.926 f1: 0.962 accuracy: 0.995 
training batch:   112, loss: 4.62552, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.981 
training batch:   113, loss: 1.65747, precision: 0.936 recall: 0.936 f1: 0.936 accuracy: 0.995 
training batch:   114, loss: 1.64874, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.996 
training batch:   115, loss: 0.60066, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.999 
training batch:   116, loss: 1.35596, precision: 0.903 recall: 0.875 f1: 0.889 accuracy: 0.993 
training batch:   117, loss: 1.12585, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.995 
training batch:   118, loss: 2.04121, precision: 0.970 recall: 0.914 f1: 0.941 accuracy: 0.993 
training batch:   119, loss: 2.93054, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.994 
training batch:   120, loss: 2.05757, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.993 
training batch:   121, loss: 1.21596, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.995 
training batch:   122, loss: 5.29555, precision: 0.919 recall: 0.895 f1: 0.907 accuracy: 0.974 
training batch:   123, loss: 0.50772, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   124, loss: 1.99229, precision: 0.932 recall: 0.953 f1: 0.943 accuracy: 0.990 
training batch:   125, loss: 4.29179, precision: 0.857 recall: 0.774 f1: 0.814 accuracy: 0.981 
training batch:   126, loss: 4.72977, precision: 0.829 recall: 0.944 f1: 0.883 accuracy: 0.984 
training batch:   127, loss: 1.44572, precision: 0.930 recall: 0.976 f1: 0.952 accuracy: 0.993 
training batch:   128, loss: 2.82684, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.986 
training batch:   129, loss: 3.72579, precision: 0.917 recall: 0.868 f1: 0.892 accuracy: 0.986 
training batch:   130, loss: 1.27316, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.996 
training batch:   131, loss: 2.38759, precision: 1.000 recall: 0.929 f1: 0.963 accuracy: 0.996 
training batch:   132, loss: 1.41557, precision: 0.960 recall: 1.000 f1: 0.980 accuracy: 0.994 
training batch:   133, loss: 2.27223, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.995 
training batch:   134, loss: 4.79597, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.981 
training batch:   135, loss: 1.69044, precision: 0.966 recall: 0.903 f1: 0.933 accuracy: 0.991 
training batch:   136, loss: 4.60767, precision: 0.892 recall: 0.917 f1: 0.904 accuracy: 0.976 
training batch:   137, loss: 2.15152, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.995 
training batch:   138, loss: 2.83621, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.993 
training batch:   139, loss: 2.27371, precision: 0.893 recall: 0.926 f1: 0.909 accuracy: 0.995 
training batch:   140, loss: 2.13258, precision: 0.903 recall: 1.000 f1: 0.949 accuracy: 0.991 
training batch:   141, loss: 2.08932, precision: 0.947 recall: 0.878 f1: 0.911 accuracy: 0.991 
training batch:   142, loss: 1.51796, precision: 0.974 recall: 0.950 f1: 0.962 accuracy: 0.995 
training batch:   143, loss: 3.51817, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.986 
training batch:   144, loss: 3.96465, precision: 0.919 recall: 0.895 f1: 0.907 accuracy: 0.989 
training batch:   145, loss: 1.50513, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.995 
training batch:   146, loss: 1.26602, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.996 
training batch:   147, loss: 7.27919, precision: 0.725 recall: 0.806 f1: 0.763 accuracy: 0.959 
training batch:   148, loss: 1.94196, precision: 0.950 recall: 0.905 f1: 0.927 accuracy: 0.993 
training batch:   149, loss: 5.92297, precision: 0.921 recall: 1.000 f1: 0.959 accuracy: 0.976 
training batch:   150, loss: 1.25723, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.996 
training batch:   151, loss: 4.07112, precision: 0.923 recall: 0.878 f1: 0.900 accuracy: 0.978 
training batch:   152, loss: 3.82925, precision: 0.895 recall: 0.829 f1: 0.861 accuracy: 0.991 
training batch:   153, loss: 2.14343, precision: 0.900 recall: 0.844 f1: 0.871 accuracy: 0.991 
training batch:   154, loss: 2.77435, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.994 
training batch:   155, loss: 3.36387, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.986 
training batch:   156, loss: 0.27695, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   157, loss: 2.08429, precision: 0.848 recall: 0.903 f1: 0.875 accuracy: 0.993 
training batch:   158, loss: 2.99791, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.989 
training batch:   159, loss: 4.41725, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.964 
training batch:   160, loss: 2.57848, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.991 
training batch:   161, loss: 5.29755, precision: 0.872 recall: 0.829 f1: 0.850 accuracy: 0.980 
training batch:   162, loss: 7.68479, precision: 0.886 recall: 0.912 f1: 0.899 accuracy: 0.970 
training batch:   163, loss: 2.60833, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.989 
training batch:   164, loss: 1.81717, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.994 
training batch:   165, loss: 4.29335, precision: 0.850 recall: 0.829 f1: 0.840 accuracy: 0.983 
training batch:   166, loss: 2.96706, precision: 0.938 recall: 0.882 f1: 0.909 accuracy: 0.995 
training batch:   167, loss: 2.96242, precision: 0.919 recall: 0.971 f1: 0.944 accuracy: 0.989 
training batch:   168, loss: 3.25600, precision: 0.897 recall: 0.921 f1: 0.909 accuracy: 0.985 
training batch:   169, loss: 2.49464, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.991 
training batch:   170, loss: 3.25011, precision: 0.872 recall: 0.829 f1: 0.850 accuracy: 0.986 
training batch:   171, loss: 4.81323, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.985 
training batch:   172, loss: 1.07361, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.996 
training batch:   173, loss: 2.87434, precision: 1.000 recall: 0.926 f1: 0.962 accuracy: 0.986 
training batch:   174, loss: 2.36732, precision: 0.947 recall: 0.900 f1: 0.923 accuracy: 0.988 
training batch:   175, loss: 2.07725, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.993 
training batch:   176, loss: 2.34390, precision: 0.930 recall: 0.976 f1: 0.952 accuracy: 0.988 
training batch:   177, loss: 5.31132, precision: 0.794 recall: 0.900 f1: 0.844 accuracy: 0.973 
training batch:   178, loss: 3.20662, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.987 
start evaluate engines...
label: Dsa, precision: 0.783 recall: 0.767 f1: 0.771 
label: Chk, precision: 0.775 recall: 0.767 f1: 0.763 
label: Ins, precision: 0.380 recall: 0.421 f1: 0.378 
label: Sur, precision: 0.833 recall: 0.906 f1: 0.863 
label: Med, precision: 0.440 recall: 0.465 f1: 0.448 
label: Ana, precision: 0.819 recall: 0.823 f1: 0.818 
time consumption:3.35(min), precision: 0.833 recall: 0.853 f1: 0.842 accuracy: 0.966 
saved the new best model with f1: 0.842
epoch:13/100
training batch:     1, loss: 1.27600, precision: 0.926 recall: 0.962 f1: 0.943 accuracy: 0.990 
training batch:     2, loss: 2.31279, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.991 
training batch:     3, loss: 1.28648, precision: 1.000 recall: 0.933 f1: 0.966 accuracy: 0.994 
training batch:     4, loss: 0.84583, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:     5, loss: 3.07677, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.990 
training batch:     6, loss: 1.63408, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.993 
training batch:     7, loss: 0.66017, precision: 0.958 recall: 1.000 f1: 0.979 accuracy: 0.998 
training batch:     8, loss: 2.65517, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.993 
training batch:     9, loss: 4.86787, precision: 0.913 recall: 0.913 f1: 0.913 accuracy: 0.979 
training batch:    10, loss: 2.14255, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.993 
training batch:    11, loss: 2.83473, precision: 0.895 recall: 0.895 f1: 0.895 accuracy: 0.991 
training batch:    12, loss: 2.49554, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.990 
training batch:    13, loss: 2.89761, precision: 0.912 recall: 0.886 f1: 0.899 accuracy: 0.986 
training batch:    14, loss: 3.00452, precision: 0.889 recall: 0.970 f1: 0.928 accuracy: 0.986 
training batch:    15, loss: 3.02539, precision: 0.905 recall: 0.927 f1: 0.916 accuracy: 0.991 
training batch:    16, loss: 3.55344, precision: 0.880 recall: 0.880 f1: 0.880 accuracy: 0.986 
training batch:    17, loss: 2.99510, precision: 0.875 recall: 0.848 f1: 0.862 accuracy: 0.989 
training batch:    18, loss: 2.16397, precision: 0.897 recall: 0.788 f1: 0.839 accuracy: 0.991 
training batch:    19, loss: 2.55244, precision: 0.769 recall: 0.938 f1: 0.845 accuracy: 0.989 
training batch:    20, loss: 1.65158, precision: 0.906 recall: 0.853 f1: 0.879 accuracy: 0.991 
training batch:    21, loss: 3.12202, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.988 
training batch:    22, loss: 2.08220, precision: 0.939 recall: 0.861 f1: 0.899 accuracy: 0.991 
training batch:    23, loss: 3.88821, precision: 0.840 recall: 0.955 f1: 0.894 accuracy: 0.986 
training batch:    24, loss: 1.21094, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.996 
training batch:    25, loss: 2.56816, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.991 
training batch:    26, loss: 3.33432, precision: 0.800 recall: 0.903 f1: 0.848 accuracy: 0.985 
training batch:    27, loss: 1.65756, precision: 0.935 recall: 0.879 f1: 0.906 accuracy: 0.993 
training batch:    28, loss: 4.81879, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.983 
training batch:    29, loss: 1.34496, precision: 0.882 recall: 0.909 f1: 0.896 accuracy: 0.994 
training batch:    30, loss: 3.09424, precision: 0.914 recall: 0.941 f1: 0.928 accuracy: 0.991 
training batch:    31, loss: 2.15681, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.990 
training batch:    32, loss: 2.51062, precision: 0.848 recall: 0.875 f1: 0.862 accuracy: 0.990 
training batch:    33, loss: 2.68312, precision: 0.889 recall: 0.952 f1: 0.920 accuracy: 0.991 
training batch:    34, loss: 1.26901, precision: 0.900 recall: 0.871 f1: 0.885 accuracy: 0.994 
training batch:    35, loss: 1.29387, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.993 
training batch:    36, loss: 4.37479, precision: 0.941 recall: 0.865 f1: 0.901 accuracy: 0.985 
training batch:    37, loss: 2.97922, precision: 0.886 recall: 0.912 f1: 0.899 accuracy: 0.993 
training batch:    38, loss: 5.33207, precision: 0.968 recall: 0.882 f1: 0.923 accuracy: 0.984 
training batch:    39, loss: 2.66701, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.988 
training batch:    40, loss: 2.56221, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.990 
training batch:    41, loss: 3.64207, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.983 
training batch:    42, loss: 2.48949, precision: 0.889 recall: 0.970 f1: 0.928 accuracy: 0.993 
training batch:    43, loss: 1.68993, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.996 
training batch:    44, loss: 1.68774, precision: 0.946 recall: 0.921 f1: 0.933 accuracy: 0.991 
training batch:    45, loss: 6.98190, precision: 0.917 recall: 0.846 f1: 0.880 accuracy: 0.979 
training batch:    46, loss: 4.09021, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.984 
training batch:    47, loss: 0.82259, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.998 
training batch:    48, loss: 2.16548, precision: 1.000 recall: 0.958 f1: 0.979 accuracy: 0.989 
training batch:    49, loss: 5.48050, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.976 
training batch:    50, loss: 3.49656, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.984 
training batch:    51, loss: 4.54392, precision: 0.829 recall: 0.935 f1: 0.879 accuracy: 0.976 
training batch:    52, loss: 3.98175, precision: 0.842 recall: 0.914 f1: 0.877 accuracy: 0.979 
training batch:    53, loss: 4.92606, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.983 
training batch:    54, loss: 0.99939, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.998 
training batch:    55, loss: 2.63432, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.989 
training batch:    56, loss: 4.17528, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.983 
training batch:    57, loss: 2.22959, precision: 0.968 recall: 0.857 f1: 0.909 accuracy: 0.991 
training batch:    58, loss: 3.63848, precision: 0.947 recall: 0.837 f1: 0.889 accuracy: 0.985 
training batch:    59, loss: 1.87225, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.989 
training batch:    60, loss: 0.79358, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    61, loss: 1.76018, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.994 
training batch:    62, loss: 1.79736, precision: 1.000 recall: 0.951 f1: 0.975 accuracy: 0.994 
training batch:    63, loss: 2.42885, precision: 0.955 recall: 0.933 f1: 0.944 accuracy: 0.988 
training batch:    64, loss: 2.00285, precision: 0.867 recall: 0.839 f1: 0.852 accuracy: 0.990 
training batch:    65, loss: 2.69495, precision: 0.879 recall: 0.935 f1: 0.906 accuracy: 0.991 
training batch:    66, loss: 3.41198, precision: 0.872 recall: 0.895 f1: 0.883 accuracy: 0.986 
training batch:    67, loss: 2.42596, precision: 0.927 recall: 0.950 f1: 0.938 accuracy: 0.990 
training batch:    68, loss: 2.49349, precision: 0.900 recall: 0.923 f1: 0.911 accuracy: 0.989 
training batch:    69, loss: 4.26945, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.980 
training batch:    70, loss: 1.26659, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:    71, loss: 3.27478, precision: 0.833 recall: 0.833 f1: 0.833 accuracy: 0.989 
training batch:    72, loss: 2.41355, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.994 
training batch:    73, loss: 1.53589, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.995 
training batch:    74, loss: 1.45448, precision: 0.946 recall: 1.000 f1: 0.972 accuracy: 0.998 
training batch:    75, loss: 1.93793, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.993 
training batch:    76, loss: 3.35605, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.993 
training batch:    77, loss: 4.21033, precision: 0.828 recall: 0.923 f1: 0.873 accuracy: 0.985 
training batch:    78, loss: 3.54276, precision: 0.941 recall: 0.865 f1: 0.901 accuracy: 0.980 
training batch:    79, loss: 2.04660, precision: 0.944 recall: 0.919 f1: 0.932 accuracy: 0.995 
training batch:    80, loss: 2.39894, precision: 0.857 recall: 0.828 f1: 0.842 accuracy: 0.994 
training batch:    81, loss: 1.19612, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.998 
training batch:    82, loss: 1.74593, precision: 0.902 recall: 0.860 f1: 0.881 accuracy: 0.994 
training batch:    83, loss: 1.71751, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.996 
training batch:    84, loss: 2.07275, precision: 0.846 recall: 0.750 f1: 0.795 accuracy: 0.990 
training batch:    85, loss: 2.17328, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.993 
training batch:    86, loss: 2.61282, precision: 0.944 recall: 0.919 f1: 0.932 accuracy: 0.991 
training batch:    87, loss: 0.90767, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    88, loss: 2.39903, precision: 0.939 recall: 0.886 f1: 0.912 accuracy: 0.993 
training batch:    89, loss: 2.30740, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.991 
training batch:    90, loss: 2.29221, precision: 0.806 recall: 0.829 f1: 0.817 accuracy: 0.990 
training batch:    91, loss: 1.13742, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.995 
training batch:    92, loss: 5.24948, precision: 0.917 recall: 0.892 f1: 0.904 accuracy: 0.978 
training batch:    93, loss: 6.45158, precision: 0.895 recall: 0.895 f1: 0.895 accuracy: 0.965 
training batch:    94, loss: 2.34480, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.983 
training batch:    95, loss: 3.18024, precision: 0.771 recall: 0.818 f1: 0.794 accuracy: 0.986 
training batch:    96, loss: 1.43845, precision: 0.848 recall: 0.903 f1: 0.875 accuracy: 0.994 
training batch:    97, loss: 3.17963, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.984 
training batch:    98, loss: 2.77534, precision: 0.892 recall: 0.917 f1: 0.904 accuracy: 0.988 
training batch:    99, loss: 1.76965, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.988 
training batch:   100, loss: 1.19406, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:   101, loss: 5.89998, precision: 0.848 recall: 0.875 f1: 0.862 accuracy: 0.974 
training batch:   102, loss: 3.36816, precision: 0.925 recall: 0.902 f1: 0.914 accuracy: 0.991 
training batch:   103, loss: 1.32869, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.998 
training batch:   104, loss: 1.88359, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.996 
training batch:   105, loss: 1.42012, precision: 0.977 recall: 1.000 f1: 0.989 accuracy: 0.998 
training batch:   106, loss: 1.79698, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.990 
training batch:   107, loss: 1.26939, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.995 
training batch:   108, loss: 2.04918, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.993 
training batch:   109, loss: 3.40869, precision: 0.923 recall: 0.857 f1: 0.889 accuracy: 0.984 
training batch:   110, loss: 2.07433, precision: 0.871 recall: 0.931 f1: 0.900 accuracy: 0.995 
training batch:   111, loss: 3.84410, precision: 0.912 recall: 0.861 f1: 0.886 accuracy: 0.984 
training batch:   112, loss: 1.98518, precision: 0.848 recall: 0.875 f1: 0.862 accuracy: 0.985 
training batch:   113, loss: 1.25365, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.995 
training batch:   114, loss: 5.01430, precision: 0.774 recall: 0.923 f1: 0.842 accuracy: 0.983 
training batch:   115, loss: 3.25654, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.990 
training batch:   116, loss: 2.89742, precision: 0.833 recall: 0.800 f1: 0.816 accuracy: 0.988 
training batch:   117, loss: 6.41655, precision: 0.833 recall: 0.857 f1: 0.845 accuracy: 0.981 
training batch:   118, loss: 4.40193, precision: 0.973 recall: 0.837 f1: 0.900 accuracy: 0.983 
training batch:   119, loss: 3.54517, precision: 0.931 recall: 0.871 f1: 0.900 accuracy: 0.990 
training batch:   120, loss: 1.09888, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:   121, loss: 1.58630, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.994 
training batch:   122, loss: 2.33820, precision: 1.000 recall: 0.955 f1: 0.977 accuracy: 0.994 
training batch:   123, loss: 2.55060, precision: 0.895 recall: 0.895 f1: 0.895 accuracy: 0.984 
training batch:   124, loss: 6.09915, precision: 0.795 recall: 0.861 f1: 0.827 accuracy: 0.969 
training batch:   125, loss: 2.62471, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.985 
training batch:   126, loss: 5.10785, precision: 0.829 recall: 0.879 f1: 0.853 accuracy: 0.975 
training batch:   127, loss: 1.77187, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.993 
training batch:   128, loss: 4.32571, precision: 0.837 recall: 0.878 f1: 0.857 accuracy: 0.985 
training batch:   129, loss: 2.46167, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.985 
training batch:   130, loss: 2.70908, precision: 0.886 recall: 0.939 f1: 0.912 accuracy: 0.989 
training batch:   131, loss: 3.76509, precision: 0.867 recall: 0.886 f1: 0.876 accuracy: 0.990 
training batch:   132, loss: 3.60619, precision: 0.882 recall: 0.900 f1: 0.891 accuracy: 0.988 
training batch:   133, loss: 0.82680, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:   134, loss: 1.44362, precision: 1.000 recall: 0.929 f1: 0.963 accuracy: 0.994 
training batch:   135, loss: 0.87727, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.999 
training batch:   136, loss: 5.84430, precision: 0.917 recall: 0.825 f1: 0.868 accuracy: 0.975 
training batch:   137, loss: 2.24892, precision: 0.872 recall: 0.919 f1: 0.895 accuracy: 0.991 
training batch:   138, loss: 1.30579, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.996 
training batch:   139, loss: 3.18351, precision: 0.900 recall: 0.923 f1: 0.911 accuracy: 0.984 
training batch:   140, loss: 4.32473, precision: 0.897 recall: 0.946 f1: 0.921 accuracy: 0.983 
training batch:   141, loss: 1.45872, precision: 0.900 recall: 0.947 f1: 0.923 accuracy: 0.989 
training batch:   142, loss: 1.25293, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.996 
training batch:   143, loss: 0.89537, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   144, loss: 1.52182, precision: 0.951 recall: 1.000 f1: 0.975 accuracy: 0.996 
training batch:   145, loss: 0.64984, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.996 
training batch:   146, loss: 0.65398, precision: 1.000 recall: 0.958 f1: 0.979 accuracy: 0.999 
training batch:   147, loss: 5.90181, precision: 0.872 recall: 0.919 f1: 0.895 accuracy: 0.981 
training batch:   148, loss: 1.37694, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.995 
training batch:   149, loss: 1.10765, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.998 
training batch:   150, loss: 2.57352, precision: 0.895 recall: 0.919 f1: 0.907 accuracy: 0.990 
training batch:   151, loss: 0.97256, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   152, loss: 0.92915, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   153, loss: 0.52554, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   154, loss: 4.15264, precision: 0.857 recall: 0.938 f1: 0.896 accuracy: 0.976 
training batch:   155, loss: 1.62810, precision: 0.938 recall: 0.882 f1: 0.909 accuracy: 0.994 
training batch:   156, loss: 4.14212, precision: 0.829 recall: 0.725 f1: 0.773 accuracy: 0.983 
training batch:   157, loss: 2.58056, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.988 
training batch:   158, loss: 2.83339, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.994 
training batch:   159, loss: 2.10292, precision: 0.914 recall: 0.889 f1: 0.901 accuracy: 0.994 
training batch:   160, loss: 4.07393, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.978 
training batch:   161, loss: 0.91125, precision: 0.952 recall: 0.976 f1: 0.964 accuracy: 0.996 
training batch:   162, loss: 2.03986, precision: 0.833 recall: 0.893 f1: 0.862 accuracy: 0.989 
training batch:   163, loss: 3.47037, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.984 
training batch:   164, loss: 5.75385, precision: 0.902 recall: 0.841 f1: 0.871 accuracy: 0.981 
training batch:   165, loss: 7.56169, precision: 0.853 recall: 0.829 f1: 0.841 accuracy: 0.964 
training batch:   166, loss: 3.82166, precision: 0.927 recall: 0.927 f1: 0.927 accuracy: 0.976 
training batch:   167, loss: 4.47138, precision: 0.812 recall: 0.830 f1: 0.821 accuracy: 0.981 
training batch:   168, loss: 1.63258, precision: 0.932 recall: 0.953 f1: 0.943 accuracy: 0.995 
training batch:   169, loss: 1.55655, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.998 
training batch:   170, loss: 3.34772, precision: 0.865 recall: 0.914 f1: 0.889 accuracy: 0.983 
training batch:   171, loss: 3.59387, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.983 
training batch:   172, loss: 2.42088, precision: 0.898 recall: 0.936 f1: 0.917 accuracy: 0.993 
training batch:   173, loss: 1.71828, precision: 0.933 recall: 1.000 f1: 0.966 accuracy: 0.986 
training batch:   174, loss: 5.17393, precision: 0.923 recall: 0.889 f1: 0.906 accuracy: 0.968 
training batch:   175, loss: 2.11081, precision: 0.867 recall: 0.907 f1: 0.886 accuracy: 0.993 
training batch:   176, loss: 2.68019, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.993 
training batch:   177, loss: 3.05919, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.991 
training batch:   178, loss: 1.47701, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.997 
start evaluate engines...
label: Dsa, precision: 0.723 recall: 0.727 f1: 0.720 
label: Chk, precision: 0.725 recall: 0.700 f1: 0.698 
label: Ins, precision: 0.317 recall: 0.300 f1: 0.298 
label: Sur, precision: 0.894 recall: 0.918 f1: 0.903 
label: Med, precision: 0.440 recall: 0.465 f1: 0.448 
label: Ana, precision: 0.827 recall: 0.843 f1: 0.832 
time consumption:3.78(min), precision: 0.831 recall: 0.841 f1: 0.835 accuracy: 0.965 
epoch:14/100
training batch:     1, loss: 1.97981, precision: 0.889 recall: 0.914 f1: 0.901 accuracy: 0.995 
training batch:     2, loss: 1.50880, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.993 
training batch:     3, loss: 1.22319, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:     4, loss: 2.50768, precision: 0.902 recall: 0.860 f1: 0.881 accuracy: 0.988 
training batch:     5, loss: 2.31763, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.990 
training batch:     6, loss: 0.55435, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:     7, loss: 7.15396, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.980 
training batch:     8, loss: 3.12662, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.981 
training batch:     9, loss: 1.40873, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.995 
training batch:    10, loss: 2.41541, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.990 
training batch:    11, loss: 2.34790, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.988 
training batch:    12, loss: 3.40729, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.996 
training batch:    13, loss: 4.92581, precision: 0.868 recall: 0.971 f1: 0.917 accuracy: 0.965 
training batch:    14, loss: 4.00804, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.990 
training batch:    15, loss: 0.90242, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.996 
training batch:    16, loss: 2.32132, precision: 0.907 recall: 0.951 f1: 0.929 accuracy: 0.986 
training batch:    17, loss: 2.03954, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.993 
training batch:    18, loss: 1.45839, precision: 1.000 recall: 0.964 f1: 0.982 accuracy: 0.998 
training batch:    19, loss: 0.81712, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:    20, loss: 1.75069, precision: 1.000 recall: 0.978 f1: 0.989 accuracy: 0.998 
training batch:    21, loss: 2.01616, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.990 
training batch:    22, loss: 0.54755, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    23, loss: 1.09677, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.995 
training batch:    24, loss: 1.75713, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.998 
training batch:    25, loss: 2.17081, precision: 0.882 recall: 0.938 f1: 0.909 accuracy: 0.993 
training batch:    26, loss: 1.55923, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.994 
training batch:    27, loss: 1.83826, precision: 0.978 recall: 1.000 f1: 0.989 accuracy: 0.998 
training batch:    28, loss: 0.87608, precision: 0.882 recall: 0.968 f1: 0.923 accuracy: 0.995 
training batch:    29, loss: 5.24623, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.961 
training batch:    30, loss: 4.20282, precision: 0.971 recall: 0.917 f1: 0.943 accuracy: 0.990 
training batch:    31, loss: 2.05269, precision: 0.923 recall: 0.889 f1: 0.906 accuracy: 0.995 
training batch:    32, loss: 0.96866, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.996 
training batch:    33, loss: 2.33719, precision: 0.973 recall: 0.923 f1: 0.947 accuracy: 0.993 
training batch:    34, loss: 2.80634, precision: 0.949 recall: 0.925 f1: 0.937 accuracy: 0.986 
training batch:    35, loss: 2.56937, precision: 0.844 recall: 0.871 f1: 0.857 accuracy: 0.990 
training batch:    36, loss: 3.08687, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.989 
training batch:    37, loss: 1.01372, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.996 
training batch:    38, loss: 3.43141, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.991 
training batch:    39, loss: 1.47159, precision: 0.875 recall: 0.897 f1: 0.886 accuracy: 0.993 
training batch:    40, loss: 1.34984, precision: 0.935 recall: 0.956 f1: 0.945 accuracy: 0.996 
training batch:    41, loss: 1.67871, precision: 0.897 recall: 0.946 f1: 0.921 accuracy: 0.989 
training batch:    42, loss: 5.56058, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.979 
training batch:    43, loss: 4.58546, precision: 0.935 recall: 0.906 f1: 0.921 accuracy: 0.981 
training batch:    44, loss: 1.45369, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.994 
training batch:    45, loss: 3.26973, precision: 0.821 recall: 0.914 f1: 0.865 accuracy: 0.984 
training batch:    46, loss: 2.67389, precision: 0.976 recall: 0.953 f1: 0.965 accuracy: 0.991 
training batch:    47, loss: 3.32764, precision: 0.763 recall: 0.763 f1: 0.763 accuracy: 0.988 
training batch:    48, loss: 2.18303, precision: 0.895 recall: 0.919 f1: 0.907 accuracy: 0.993 
training batch:    49, loss: 1.08499, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.999 
training batch:    50, loss: 1.24648, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.998 
training batch:    51, loss: 2.55350, precision: 0.895 recall: 0.829 f1: 0.861 accuracy: 0.988 
training batch:    52, loss: 1.06870, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.995 
training batch:    53, loss: 4.65971, precision: 0.897 recall: 0.814 f1: 0.854 accuracy: 0.984 
training batch:    54, loss: 1.51463, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.996 
training batch:    55, loss: 2.86147, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.980 
training batch:    56, loss: 2.07452, precision: 0.919 recall: 0.872 f1: 0.895 accuracy: 0.990 
training batch:    57, loss: 7.03032, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.965 
training batch:    58, loss: 2.23390, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.991 
training batch:    59, loss: 1.95917, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.994 
training batch:    60, loss: 1.16142, precision: 0.865 recall: 0.914 f1: 0.889 accuracy: 0.995 
training batch:    61, loss: 1.81503, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.985 
training batch:    62, loss: 2.23993, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.998 
training batch:    63, loss: 3.28638, precision: 0.886 recall: 0.886 f1: 0.886 accuracy: 0.986 
training batch:    64, loss: 2.21503, precision: 0.929 recall: 0.975 f1: 0.951 accuracy: 0.990 
training batch:    65, loss: 3.17169, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.980 
training batch:    66, loss: 2.91327, precision: 0.865 recall: 0.914 f1: 0.889 accuracy: 0.988 
training batch:    67, loss: 1.93617, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.991 
training batch:    68, loss: 5.70686, precision: 0.930 recall: 0.889 f1: 0.909 accuracy: 0.973 
training batch:    69, loss: 1.79587, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.994 
training batch:    70, loss: 1.76039, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.995 
training batch:    71, loss: 1.69341, precision: 0.897 recall: 0.921 f1: 0.909 accuracy: 0.994 
training batch:    72, loss: 0.91096, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    73, loss: 3.86015, precision: 0.833 recall: 0.735 f1: 0.781 accuracy: 0.986 
training batch:    74, loss: 3.77228, precision: 0.857 recall: 0.938 f1: 0.896 accuracy: 0.991 
training batch:    75, loss: 2.34573, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.995 
training batch:    76, loss: 2.93802, precision: 0.895 recall: 0.919 f1: 0.907 accuracy: 0.988 
training batch:    77, loss: 1.61691, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.993 
training batch:    78, loss: 3.21835, precision: 0.909 recall: 0.857 f1: 0.882 accuracy: 0.986 
training batch:    79, loss: 3.45488, precision: 0.821 recall: 0.852 f1: 0.836 accuracy: 0.980 
training batch:    80, loss: 1.97542, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.995 
training batch:    81, loss: 2.23653, precision: 0.889 recall: 0.842 f1: 0.865 accuracy: 0.991 
training batch:    82, loss: 1.00276, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.998 
training batch:    83, loss: 3.63756, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.989 
training batch:    84, loss: 4.69962, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.985 
training batch:    85, loss: 2.57338, precision: 0.875 recall: 0.840 f1: 0.857 accuracy: 0.988 
training batch:    86, loss: 0.97150, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.996 
training batch:    87, loss: 3.63629, precision: 0.900 recall: 0.878 f1: 0.889 accuracy: 0.986 
training batch:    88, loss: 4.41199, precision: 0.773 recall: 0.850 f1: 0.810 accuracy: 0.984 
training batch:    89, loss: 0.46800, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    90, loss: 1.01581, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.993 
training batch:    91, loss: 1.63371, precision: 0.920 recall: 0.920 f1: 0.920 accuracy: 0.989 
training batch:    92, loss: 0.99127, precision: 0.875 recall: 0.903 f1: 0.889 accuracy: 0.995 
training batch:    93, loss: 3.38768, precision: 0.925 recall: 0.925 f1: 0.925 accuracy: 0.991 
training batch:    94, loss: 1.44955, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.994 
training batch:    95, loss: 3.21811, precision: 0.944 recall: 0.919 f1: 0.932 accuracy: 0.986 
training batch:    96, loss: 4.51318, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.985 
training batch:    97, loss: 4.51205, precision: 0.946 recall: 0.921 f1: 0.933 accuracy: 0.986 
training batch:    98, loss: 1.89149, precision: 0.951 recall: 0.929 f1: 0.940 accuracy: 0.990 
training batch:    99, loss: 2.52835, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.993 
training batch:   100, loss: 3.30260, precision: 0.976 recall: 0.952 f1: 0.964 accuracy: 0.991 
training batch:   101, loss: 1.09846, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.998 
training batch:   102, loss: 1.29794, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.998 
training batch:   103, loss: 4.91083, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.988 
training batch:   104, loss: 2.66730, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.989 
training batch:   105, loss: 2.04216, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.990 
training batch:   106, loss: 7.08368, precision: 0.943 recall: 0.892 f1: 0.917 accuracy: 0.971 
training batch:   107, loss: 6.08348, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.970 
training batch:   108, loss: 1.70024, precision: 1.000 recall: 0.958 f1: 0.979 accuracy: 0.990 
training batch:   109, loss: 1.90227, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.994 
training batch:   110, loss: 2.76764, precision: 0.923 recall: 0.900 f1: 0.911 accuracy: 0.990 
training batch:   111, loss: 1.37888, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.995 
training batch:   112, loss: 3.19678, precision: 0.854 recall: 0.946 f1: 0.897 accuracy: 0.991 
training batch:   113, loss: 3.39967, precision: 0.811 recall: 0.833 f1: 0.822 accuracy: 0.988 
training batch:   114, loss: 0.83612, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.999 
training batch:   115, loss: 2.99565, precision: 0.892 recall: 0.943 f1: 0.917 accuracy: 0.984 
training batch:   116, loss: 0.69908, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:   117, loss: 4.14729, precision: 0.960 recall: 0.889 f1: 0.923 accuracy: 0.990 
training batch:   118, loss: 6.52700, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.980 
training batch:   119, loss: 2.65523, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.993 
training batch:   120, loss: 2.13561, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.994 
training batch:   121, loss: 1.88019, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.996 
training batch:   122, loss: 1.36577, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.998 
training batch:   123, loss: 2.71940, precision: 0.968 recall: 0.882 f1: 0.923 accuracy: 0.993 
training batch:   124, loss: 2.04037, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.993 
training batch:   125, loss: 2.97604, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.984 
training batch:   126, loss: 1.33186, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   127, loss: 1.69539, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.996 
training batch:   128, loss: 1.80249, precision: 0.919 recall: 0.971 f1: 0.944 accuracy: 0.995 
training batch:   129, loss: 3.45706, precision: 0.895 recall: 1.000 f1: 0.944 accuracy: 0.983 
training batch:   130, loss: 0.71912, precision: 0.960 recall: 1.000 f1: 0.980 accuracy: 0.999 
training batch:   131, loss: 0.93201, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.995 
training batch:   132, loss: 3.83772, precision: 0.786 recall: 0.846 f1: 0.815 accuracy: 0.993 
training batch:   133, loss: 1.31363, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.996 
training batch:   134, loss: 1.99208, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.990 
training batch:   135, loss: 5.81004, precision: 0.853 recall: 0.829 f1: 0.841 accuracy: 0.971 
training batch:   136, loss: 1.90927, precision: 0.961 recall: 0.925 f1: 0.942 accuracy: 0.995 
training batch:   137, loss: 2.76680, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.989 
training batch:   138, loss: 0.42842, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   139, loss: 1.92597, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.988 
training batch:   140, loss: 2.85396, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.990 
training batch:   141, loss: 7.43474, precision: 0.889 recall: 0.800 f1: 0.842 accuracy: 0.976 
training batch:   142, loss: 3.21047, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.985 
training batch:   143, loss: 1.26010, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.989 
training batch:   144, loss: 2.75924, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.995 
training batch:   145, loss: 2.19450, precision: 0.871 recall: 0.900 f1: 0.885 accuracy: 0.991 
training batch:   146, loss: 1.41737, precision: 0.933 recall: 0.955 f1: 0.944 accuracy: 0.995 
training batch:   147, loss: 1.68179, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.998 
training batch:   148, loss: 1.70952, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.995 
training batch:   149, loss: 4.04979, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.986 
training batch:   150, loss: 3.18703, precision: 0.917 recall: 0.892 f1: 0.904 accuracy: 0.981 
training batch:   151, loss: 3.27540, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.990 
training batch:   152, loss: 2.03851, precision: 0.921 recall: 0.897 f1: 0.909 accuracy: 0.981 
training batch:   153, loss: 2.65474, precision: 0.917 recall: 0.846 f1: 0.880 accuracy: 0.983 
training batch:   154, loss: 2.60318, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.993 
training batch:   155, loss: 2.46105, precision: 0.857 recall: 0.837 f1: 0.847 accuracy: 0.984 
training batch:   156, loss: 3.98692, precision: 0.889 recall: 0.909 f1: 0.899 accuracy: 0.983 
training batch:   157, loss: 0.92928, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:   158, loss: 4.06180, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.973 
training batch:   159, loss: 1.55347, precision: 0.878 recall: 0.923 f1: 0.900 accuracy: 0.989 
training batch:   160, loss: 3.59314, precision: 0.844 recall: 0.844 f1: 0.844 accuracy: 0.985 
training batch:   161, loss: 2.79007, precision: 0.892 recall: 0.868 f1: 0.880 accuracy: 0.990 
training batch:   162, loss: 2.61823, precision: 0.875 recall: 0.894 f1: 0.884 accuracy: 0.985 
training batch:   163, loss: 2.18958, precision: 0.897 recall: 0.839 f1: 0.867 accuracy: 0.994 
training batch:   164, loss: 1.49025, precision: 0.964 recall: 0.931 f1: 0.947 accuracy: 0.993 
training batch:   165, loss: 2.76768, precision: 0.897 recall: 0.921 f1: 0.909 accuracy: 0.995 
training batch:   166, loss: 15.17853, precision: 0.795 recall: 0.854 f1: 0.824 accuracy: 0.969 
training batch:   167, loss: 1.91145, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.995 
training batch:   168, loss: 1.27667, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.998 
training batch:   169, loss: 2.29346, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.993 
training batch:   170, loss: 1.49413, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.996 
training batch:   171, loss: 3.25278, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.990 
training batch:   172, loss: 4.25703, precision: 0.902 recall: 0.881 f1: 0.892 accuracy: 0.980 
training batch:   173, loss: 2.19472, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.994 
training batch:   174, loss: 2.29396, precision: 0.882 recall: 0.857 f1: 0.870 accuracy: 0.988 
training batch:   175, loss: 1.13791, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.995 
training batch:   176, loss: 2.21544, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.995 
training batch:   177, loss: 4.04750, precision: 0.967 recall: 0.879 f1: 0.921 accuracy: 0.985 
training batch:   178, loss: 1.79508, precision: 0.923 recall: 0.857 f1: 0.889 accuracy: 0.993 
start evaluate engines...
label: Dsa, precision: 0.785 recall: 0.758 f1: 0.766 
label: Chk, precision: 0.533 recall: 0.478 f1: 0.480 
label: Ins, precision: 0.308 recall: 0.317 f1: 0.309 
label: Sur, precision: 0.824 recall: 0.900 f1: 0.855 
label: Med, precision: 0.355 recall: 0.380 f1: 0.363 
label: Ana, precision: 0.792 recall: 0.792 f1: 0.789 
time consumption:3.79(min), precision: 0.813 recall: 0.805 f1: 0.808 accuracy: 0.965 
epoch:15/100
training batch:     1, loss: 4.90805, precision: 0.838 recall: 0.816 f1: 0.827 accuracy: 0.984 
training batch:     2, loss: 5.57253, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.985 
training batch:     3, loss: 4.18974, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.990 
training batch:     4, loss: 6.20691, precision: 0.932 recall: 0.911 f1: 0.921 accuracy: 0.980 
training batch:     5, loss: 1.64062, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.996 
training batch:     6, loss: 3.36132, precision: 0.857 recall: 0.933 f1: 0.894 accuracy: 0.990 
training batch:     7, loss: 2.20390, precision: 0.946 recall: 0.921 f1: 0.933 accuracy: 0.991 
training batch:     8, loss: 2.60976, precision: 0.848 recall: 0.848 f1: 0.848 accuracy: 0.990 
training batch:     9, loss: 4.16293, precision: 0.882 recall: 0.938 f1: 0.909 accuracy: 0.983 
training batch:    10, loss: 1.41759, precision: 0.931 recall: 1.000 f1: 0.964 accuracy: 0.993 
training batch:    11, loss: 1.69437, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.994 
training batch:    12, loss: 2.97291, precision: 0.927 recall: 0.927 f1: 0.927 accuracy: 0.990 
training batch:    13, loss: 2.85911, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.986 
training batch:    14, loss: 1.18231, precision: 1.000 recall: 0.958 f1: 0.979 accuracy: 0.994 
training batch:    15, loss: 1.92036, precision: 0.919 recall: 0.895 f1: 0.907 accuracy: 0.994 
training batch:    16, loss: 3.99005, precision: 0.968 recall: 0.882 f1: 0.923 accuracy: 0.986 
training batch:    17, loss: 4.56082, precision: 0.930 recall: 0.952 f1: 0.941 accuracy: 0.984 
training batch:    18, loss: 2.59167, precision: 0.889 recall: 0.857 f1: 0.873 accuracy: 0.983 
training batch:    19, loss: 0.96756, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:    20, loss: 2.60681, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.988 
training batch:    21, loss: 0.90057, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:    22, loss: 1.63688, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.996 
training batch:    23, loss: 2.48637, precision: 1.000 recall: 0.889 f1: 0.941 accuracy: 0.988 
training batch:    24, loss: 1.55286, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.994 
training batch:    25, loss: 2.13670, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.994 
training batch:    26, loss: 0.92348, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.994 
training batch:    27, loss: 2.94643, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.990 
training batch:    28, loss: 1.30556, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.994 
training batch:    29, loss: 3.65329, precision: 0.842 recall: 0.821 f1: 0.831 accuracy: 0.985 
training batch:    30, loss: 4.42778, precision: 0.953 recall: 0.932 f1: 0.943 accuracy: 0.986 
training batch:    31, loss: 1.53203, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:    32, loss: 3.98217, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.978 
training batch:    33, loss: 1.31149, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:    34, loss: 1.41747, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.995 
training batch:    35, loss: 1.02003, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.996 
training batch:    36, loss: 2.48381, precision: 0.892 recall: 0.943 f1: 0.917 accuracy: 0.991 
training batch:    37, loss: 2.45731, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.995 
training batch:    38, loss: 3.52207, precision: 0.854 recall: 0.897 f1: 0.875 accuracy: 0.985 
training batch:    39, loss: 0.60788, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    40, loss: 2.26448, precision: 0.861 recall: 0.838 f1: 0.849 accuracy: 0.991 
training batch:    41, loss: 3.43599, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.994 
training batch:    42, loss: 1.89304, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.993 
training batch:    43, loss: 1.41932, precision: 0.964 recall: 0.900 f1: 0.931 accuracy: 0.996 
training batch:    44, loss: 2.04776, precision: 0.844 recall: 0.905 f1: 0.874 accuracy: 0.989 
training batch:    45, loss: 1.22275, precision: 0.949 recall: 0.925 f1: 0.937 accuracy: 0.996 
training batch:    46, loss: 2.24045, precision: 0.900 recall: 0.964 f1: 0.931 accuracy: 0.993 
training batch:    47, loss: 3.38789, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.989 
training batch:    48, loss: 1.15633, precision: 1.000 recall: 0.960 f1: 0.980 accuracy: 0.991 
training batch:    49, loss: 3.50348, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.993 
training batch:    50, loss: 2.49924, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:    51, loss: 2.20667, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.991 
training batch:    52, loss: 1.02559, precision: 0.967 recall: 0.906 f1: 0.935 accuracy: 0.996 
training batch:    53, loss: 0.70847, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.996 
training batch:    54, loss: 3.02072, precision: 0.880 recall: 1.000 f1: 0.936 accuracy: 0.993 
training batch:    55, loss: 2.27017, precision: 0.946 recall: 0.897 f1: 0.921 accuracy: 0.991 
training batch:    56, loss: 1.41751, precision: 0.914 recall: 0.889 f1: 0.901 accuracy: 0.994 
training batch:    57, loss: 1.79180, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.995 
training batch:    58, loss: 1.99477, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.988 
training batch:    59, loss: 2.13647, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.993 
training batch:    60, loss: 3.31018, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.989 
training batch:    61, loss: 0.78224, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:    62, loss: 3.54568, precision: 0.933 recall: 0.875 f1: 0.903 accuracy: 0.993 
training batch:    63, loss: 1.72719, precision: 0.964 recall: 0.931 f1: 0.947 accuracy: 0.994 
training batch:    64, loss: 2.34297, precision: 0.857 recall: 0.947 f1: 0.900 accuracy: 0.993 
training batch:    65, loss: 2.44296, precision: 0.930 recall: 0.930 f1: 0.930 accuracy: 0.991 
training batch:    66, loss: 1.88182, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.989 
training batch:    67, loss: 0.93603, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    68, loss: 3.75778, precision: 0.891 recall: 0.891 f1: 0.891 accuracy: 0.990 
training batch:    69, loss: 1.55267, precision: 0.972 recall: 0.897 f1: 0.933 accuracy: 0.993 
training batch:    70, loss: 1.27749, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:    71, loss: 1.86447, precision: 0.952 recall: 0.976 f1: 0.964 accuracy: 0.989 
training batch:    72, loss: 1.78159, precision: 0.921 recall: 0.972 f1: 0.946 accuracy: 0.993 
training batch:    73, loss: 2.92125, precision: 0.824 recall: 0.966 f1: 0.889 accuracy: 0.988 
training batch:    74, loss: 1.63658, precision: 0.895 recall: 0.919 f1: 0.907 accuracy: 0.995 
training batch:    75, loss: 0.41389, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    76, loss: 4.29398, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.984 
training batch:    77, loss: 1.78926, precision: 0.833 recall: 0.800 f1: 0.816 accuracy: 0.994 
training batch:    78, loss: 1.77821, precision: 0.895 recall: 0.895 f1: 0.895 accuracy: 0.990 
training batch:    79, loss: 0.87386, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.998 
training batch:    80, loss: 1.85052, precision: 0.900 recall: 0.923 f1: 0.911 accuracy: 0.988 
training batch:    81, loss: 0.75461, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.996 
training batch:    82, loss: 1.35696, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:    83, loss: 0.88164, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.998 
training batch:    84, loss: 1.58540, precision: 0.923 recall: 0.900 f1: 0.911 accuracy: 0.991 
training batch:    85, loss: 1.69524, precision: 0.929 recall: 0.867 f1: 0.897 accuracy: 0.995 
training batch:    86, loss: 2.76985, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.989 
training batch:    87, loss: 1.88226, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.989 
training batch:    88, loss: 1.83020, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.994 
training batch:    89, loss: 1.60579, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.995 
training batch:    90, loss: 0.28514, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    91, loss: 1.30205, precision: 0.978 recall: 0.936 f1: 0.957 accuracy: 0.998 
training batch:    92, loss: 1.54256, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.989 
training batch:    93, loss: 1.73044, precision: 0.978 recall: 0.957 f1: 0.967 accuracy: 0.998 
training batch:    94, loss: 1.19075, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.996 
training batch:    95, loss: 1.85411, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.993 
training batch:    96, loss: 0.93468, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.999 
training batch:    97, loss: 5.60562, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.980 
training batch:    98, loss: 2.25266, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.991 
training batch:    99, loss: 1.51367, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.994 
training batch:   100, loss: 2.22047, precision: 0.925 recall: 0.881 f1: 0.902 accuracy: 0.994 
training batch:   101, loss: 2.85010, precision: 0.881 recall: 0.925 f1: 0.902 accuracy: 0.986 
training batch:   102, loss: 1.08165, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.996 
training batch:   103, loss: 1.97305, precision: 0.893 recall: 0.862 f1: 0.877 accuracy: 0.989 
training batch:   104, loss: 1.22696, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.994 
training batch:   105, loss: 1.90868, precision: 0.950 recall: 0.927 f1: 0.938 accuracy: 0.989 
training batch:   106, loss: 0.57043, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:   107, loss: 5.44296, precision: 0.844 recall: 0.794 f1: 0.818 accuracy: 0.974 
training batch:   108, loss: 2.00951, precision: 0.923 recall: 0.973 f1: 0.947 accuracy: 0.995 
training batch:   109, loss: 2.84300, precision: 0.867 recall: 0.867 f1: 0.867 accuracy: 0.984 
training batch:   110, loss: 3.81613, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.994 
training batch:   111, loss: 2.88972, precision: 0.893 recall: 0.833 f1: 0.862 accuracy: 0.990 
training batch:   112, loss: 1.09053, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.996 
training batch:   113, loss: 1.02707, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.998 
training batch:   114, loss: 1.66963, precision: 0.906 recall: 1.000 f1: 0.951 accuracy: 0.988 
training batch:   115, loss: 0.53296, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.999 
training batch:   116, loss: 2.95178, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.988 
training batch:   117, loss: 1.53957, precision: 0.905 recall: 0.884 f1: 0.894 accuracy: 0.995 
training batch:   118, loss: 1.55208, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.996 
training batch:   119, loss: 1.14832, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.994 
training batch:   120, loss: 4.30365, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.986 
training batch:   121, loss: 4.44495, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.976 
training batch:   122, loss: 3.74240, precision: 0.913 recall: 0.913 f1: 0.913 accuracy: 0.984 
training batch:   123, loss: 1.38374, precision: 1.000 recall: 0.943 f1: 0.971 accuracy: 0.994 
training batch:   124, loss: 3.47968, precision: 0.917 recall: 0.971 f1: 0.943 accuracy: 0.991 
training batch:   125, loss: 2.44214, precision: 0.913 recall: 0.840 f1: 0.875 accuracy: 0.985 
training batch:   126, loss: 6.64940, precision: 0.919 recall: 0.829 f1: 0.872 accuracy: 0.970 
training batch:   127, loss: 3.18715, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.994 
training batch:   128, loss: 1.65196, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.994 
training batch:   129, loss: 0.78943, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.996 
training batch:   130, loss: 3.92183, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   131, loss: 1.54615, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.991 
training batch:   132, loss: 5.46970, precision: 0.879 recall: 0.935 f1: 0.906 accuracy: 0.973 
training batch:   133, loss: 2.28383, precision: 0.946 recall: 1.000 f1: 0.972 accuracy: 0.991 
training batch:   134, loss: 1.54575, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.993 
training batch:   135, loss: 2.06548, precision: 0.902 recall: 1.000 f1: 0.949 accuracy: 0.991 
training batch:   136, loss: 1.27321, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.996 
training batch:   137, loss: 0.84142, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:   138, loss: 1.34619, precision: 0.919 recall: 0.895 f1: 0.907 accuracy: 0.995 
training batch:   139, loss: 1.61833, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.991 
training batch:   140, loss: 2.41413, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.988 
training batch:   141, loss: 3.24831, precision: 0.933 recall: 0.913 f1: 0.923 accuracy: 0.990 
training batch:   142, loss: 7.33530, precision: 0.750 recall: 1.000 f1: 0.857 accuracy: 0.966 
training batch:   143, loss: 2.32385, precision: 0.950 recall: 0.905 f1: 0.927 accuracy: 0.994 
training batch:   144, loss: 3.20740, precision: 0.917 recall: 0.868 f1: 0.892 accuracy: 0.991 
training batch:   145, loss: 1.40649, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.993 
training batch:   146, loss: 0.75563, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   147, loss: 1.60353, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.988 
training batch:   148, loss: 2.63513, precision: 0.833 recall: 0.938 f1: 0.882 accuracy: 0.989 
training batch:   149, loss: 3.88840, precision: 0.971 recall: 0.872 f1: 0.919 accuracy: 0.991 
training batch:   150, loss: 2.39142, precision: 0.862 recall: 1.000 f1: 0.926 accuracy: 0.989 
training batch:   151, loss: 2.01255, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.994 
training batch:   152, loss: 0.98999, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   153, loss: 3.13914, precision: 0.946 recall: 0.897 f1: 0.921 accuracy: 0.991 
training batch:   154, loss: 2.24307, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.990 
training batch:   155, loss: 1.93225, precision: 0.923 recall: 0.889 f1: 0.906 accuracy: 0.996 
training batch:   156, loss: 2.86850, precision: 1.000 recall: 0.868 f1: 0.930 accuracy: 0.989 
training batch:   157, loss: 1.95089, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.996 
training batch:   158, loss: 2.73300, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.988 
training batch:   159, loss: 1.25604, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   160, loss: 2.81081, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.988 
training batch:   161, loss: 2.09456, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.990 
training batch:   162, loss: 4.06544, precision: 0.773 recall: 0.919 f1: 0.840 accuracy: 0.984 
training batch:   163, loss: 2.42397, precision: 0.909 recall: 0.882 f1: 0.896 accuracy: 0.989 
training batch:   164, loss: 0.83305, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.998 
training batch:   165, loss: 1.81630, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:   166, loss: 0.82471, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:   167, loss: 0.87926, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:   168, loss: 1.46765, precision: 0.875 recall: 0.903 f1: 0.889 accuracy: 0.991 
training batch:   169, loss: 3.66212, precision: 0.821 recall: 0.821 f1: 0.821 accuracy: 0.985 
training batch:   170, loss: 4.30769, precision: 0.897 recall: 0.921 f1: 0.909 accuracy: 0.983 
training batch:   171, loss: 1.67972, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.995 
training batch:   172, loss: 6.02939, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.984 
training batch:   173, loss: 1.79079, precision: 0.833 recall: 0.926 f1: 0.877 accuracy: 0.986 
training batch:   174, loss: 5.57126, precision: 0.903 recall: 0.800 f1: 0.848 accuracy: 0.990 
training batch:   175, loss: 2.71863, precision: 0.884 recall: 0.950 f1: 0.916 accuracy: 0.984 
training batch:   176, loss: 1.82249, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.991 
training batch:   177, loss: 1.75949, precision: 0.926 recall: 0.893 f1: 0.909 accuracy: 0.995 
training batch:   178, loss: 3.30103, precision: 0.950 recall: 0.864 f1: 0.905 accuracy: 0.987 
start evaluate engines...
label: Dsa, precision: 0.751 recall: 0.781 f1: 0.757 
label: Chk, precision: 0.608 recall: 0.600 f1: 0.588 
label: Ins, precision: 0.354 recall: 0.329 f1: 0.334 
label: Sur, precision: 0.823 recall: 0.853 f1: 0.831 
label: Med, precision: 0.400 recall: 0.425 f1: 0.408 
label: Ana, precision: 0.839 recall: 0.810 f1: 0.821 
time consumption:3.82(min), precision: 0.834 recall: 0.831 f1: 0.832 accuracy: 0.966 
epoch:16/100
training batch:     1, loss: 3.61642, precision: 0.915 recall: 0.956 f1: 0.935 accuracy: 0.990 
training batch:     2, loss: 0.47392, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:     3, loss: 2.35680, precision: 0.973 recall: 0.923 f1: 0.947 accuracy: 0.995 
training batch:     4, loss: 1.85550, precision: 0.963 recall: 0.929 f1: 0.945 accuracy: 0.993 
training batch:     5, loss: 1.02843, precision: 0.912 recall: 1.000 f1: 0.954 accuracy: 0.996 
training batch:     6, loss: 1.71350, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.994 
training batch:     7, loss: 1.01296, precision: 0.962 recall: 0.926 f1: 0.943 accuracy: 0.990 
training batch:     8, loss: 1.74733, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.996 
training batch:     9, loss: 1.70334, precision: 0.897 recall: 0.946 f1: 0.921 accuracy: 0.995 
training batch:    10, loss: 2.24835, precision: 0.927 recall: 1.000 f1: 0.962 accuracy: 0.995 
training batch:    11, loss: 1.29834, precision: 0.920 recall: 0.958 f1: 0.939 accuracy: 0.995 
training batch:    12, loss: 1.38844, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:    13, loss: 2.46401, precision: 0.956 recall: 0.977 f1: 0.966 accuracy: 0.994 
training batch:    14, loss: 2.45352, precision: 0.897 recall: 1.000 f1: 0.946 accuracy: 0.990 
training batch:    15, loss: 0.53764, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    16, loss: 1.53304, precision: 0.931 recall: 0.900 f1: 0.915 accuracy: 0.995 
training batch:    17, loss: 3.02227, precision: 0.930 recall: 0.833 f1: 0.879 accuracy: 0.985 
training batch:    18, loss: 1.91931, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.994 
training batch:    19, loss: 4.14281, precision: 0.895 recall: 0.810 f1: 0.850 accuracy: 0.978 
training batch:    20, loss: 1.69519, precision: 1.000 recall: 0.939 f1: 0.969 accuracy: 0.990 
training batch:    21, loss: 1.06898, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    22, loss: 1.30643, precision: 0.980 recall: 0.961 f1: 0.970 accuracy: 0.995 
training batch:    23, loss: 1.82643, precision: 0.977 recall: 1.000 f1: 0.988 accuracy: 0.995 
training batch:    24, loss: 2.58110, precision: 0.909 recall: 0.968 f1: 0.937 accuracy: 0.993 
training batch:    25, loss: 0.58449, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.998 
training batch:    26, loss: 2.31607, precision: 0.903 recall: 0.933 f1: 0.918 accuracy: 0.994 
training batch:    27, loss: 1.43207, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.990 
training batch:    28, loss: 2.68703, precision: 0.912 recall: 0.969 f1: 0.939 accuracy: 0.988 
training batch:    29, loss: 2.24413, precision: 1.000 recall: 0.946 f1: 0.972 accuracy: 0.988 
training batch:    30, loss: 1.29359, precision: 0.921 recall: 0.972 f1: 0.946 accuracy: 0.996 
training batch:    31, loss: 1.91472, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.988 
training batch:    32, loss: 1.91281, precision: 1.000 recall: 0.919 f1: 0.958 accuracy: 0.995 
training batch:    33, loss: 2.90181, precision: 0.947 recall: 0.900 f1: 0.923 accuracy: 0.988 
training batch:    34, loss: 1.33076, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.996 
training batch:    35, loss: 1.10759, precision: 0.932 recall: 0.953 f1: 0.943 accuracy: 0.996 
training batch:    36, loss: 1.81042, precision: 0.950 recall: 0.927 f1: 0.938 accuracy: 0.996 
training batch:    37, loss: 2.03093, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.993 
training batch:    38, loss: 3.17419, precision: 0.918 recall: 0.957 f1: 0.938 accuracy: 0.976 
training batch:    39, loss: 1.43280, precision: 0.840 recall: 0.875 f1: 0.857 accuracy: 0.995 
training batch:    40, loss: 0.51227, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    41, loss: 3.78902, precision: 0.921 recall: 0.972 f1: 0.946 accuracy: 0.983 
training batch:    42, loss: 0.97270, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:    43, loss: 0.87128, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:    44, loss: 0.65198, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:    45, loss: 3.84079, precision: 0.848 recall: 0.848 f1: 0.848 accuracy: 0.988 
training batch:    46, loss: 0.24205, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    47, loss: 3.61266, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.976 
training batch:    48, loss: 1.24016, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.991 
training batch:    49, loss: 0.94231, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:    50, loss: 5.96469, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.960 
training batch:    51, loss: 1.08704, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.995 
training batch:    52, loss: 0.66110, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:    53, loss: 1.00217, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.995 
training batch:    54, loss: 4.60432, precision: 0.816 recall: 0.939 f1: 0.873 accuracy: 0.990 
training batch:    55, loss: 2.62084, precision: 0.946 recall: 0.921 f1: 0.933 accuracy: 0.996 
training batch:    56, loss: 2.52098, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.996 
training batch:    57, loss: 0.93904, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.996 
training batch:    58, loss: 1.44633, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.998 
training batch:    59, loss: 1.48959, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.996 
training batch:    60, loss: 1.46466, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.995 
training batch:    61, loss: 2.55463, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.989 
training batch:    62, loss: 1.83406, precision: 0.931 recall: 0.844 f1: 0.885 accuracy: 0.994 
training batch:    63, loss: 1.59944, precision: 0.947 recall: 0.900 f1: 0.923 accuracy: 0.994 
training batch:    64, loss: 1.72577, precision: 0.906 recall: 0.967 f1: 0.935 accuracy: 0.994 
training batch:    65, loss: 1.12051, precision: 1.000 recall: 0.950 f1: 0.974 accuracy: 0.998 
training batch:    66, loss: 1.36896, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.994 
training batch:    67, loss: 1.28586, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.996 
training batch:    68, loss: 2.54704, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.990 
training batch:    69, loss: 1.59183, precision: 0.867 recall: 0.897 f1: 0.881 accuracy: 0.993 
training batch:    70, loss: 1.59547, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:    71, loss: 1.39268, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.996 
training batch:    72, loss: 0.73030, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:    73, loss: 0.39937, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    74, loss: 0.86182, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.996 
training batch:    75, loss: 1.42769, precision: 0.871 recall: 0.900 f1: 0.885 accuracy: 0.991 
training batch:    76, loss: 1.31044, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.996 
training batch:    77, loss: 0.87654, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.996 
training batch:    78, loss: 0.99707, precision: 0.947 recall: 1.000 f1: 0.973 accuracy: 0.998 
training batch:    79, loss: 2.71992, precision: 0.895 recall: 0.919 f1: 0.907 accuracy: 0.990 
training batch:    80, loss: 0.68991, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:    81, loss: 0.89410, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.996 
training batch:    82, loss: 1.20192, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.994 
training batch:    83, loss: 1.77684, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.994 
training batch:    84, loss: 2.34924, precision: 0.949 recall: 0.925 f1: 0.937 accuracy: 0.995 
training batch:    85, loss: 0.87093, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.994 
training batch:    86, loss: 0.57939, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:    87, loss: 0.99924, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.995 
training batch:    88, loss: 1.08775, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.998 
training batch:    89, loss: 1.29355, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.990 
training batch:    90, loss: 0.71336, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    91, loss: 0.65625, precision: 0.935 recall: 1.000 f1: 0.967 accuracy: 0.996 
training batch:    92, loss: 1.67035, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.993 
training batch:    93, loss: 0.99414, precision: 0.926 recall: 1.000 f1: 0.962 accuracy: 0.995 
training batch:    94, loss: 3.42307, precision: 0.938 recall: 0.882 f1: 0.909 accuracy: 0.974 
training batch:    95, loss: 1.06209, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.996 
training batch:    96, loss: 2.00598, precision: 0.881 recall: 0.925 f1: 0.902 accuracy: 0.993 
training batch:    97, loss: 2.60736, precision: 0.879 recall: 0.879 f1: 0.879 accuracy: 0.990 
training batch:    98, loss: 1.06624, precision: 0.971 recall: 0.892 f1: 0.930 accuracy: 0.996 
training batch:    99, loss: 1.47914, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.998 
training batch:   100, loss: 4.25740, precision: 0.912 recall: 0.861 f1: 0.886 accuracy: 0.990 
training batch:   101, loss: 0.29037, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   102, loss: 1.35913, precision: 0.871 recall: 0.900 f1: 0.885 accuracy: 0.993 
training batch:   103, loss: 1.14618, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.996 
training batch:   104, loss: 1.06555, precision: 0.861 recall: 0.969 f1: 0.912 accuracy: 0.995 
training batch:   105, loss: 1.83783, precision: 0.946 recall: 1.000 f1: 0.972 accuracy: 0.990 
training batch:   106, loss: 0.80482, precision: 0.917 recall: 0.957 f1: 0.936 accuracy: 0.998 
training batch:   107, loss: 1.09077, precision: 0.929 recall: 0.975 f1: 0.951 accuracy: 0.996 
training batch:   108, loss: 0.33186, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   109, loss: 11.07350, precision: 0.895 recall: 0.872 f1: 0.883 accuracy: 0.968 
training batch:   110, loss: 3.75166, precision: 0.912 recall: 0.969 f1: 0.939 accuracy: 0.985 
training batch:   111, loss: 0.94835, precision: 0.974 recall: 0.927 f1: 0.950 accuracy: 0.996 
training batch:   112, loss: 2.79742, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.990 
training batch:   113, loss: 2.40187, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.994 
training batch:   114, loss: 4.52130, precision: 0.944 recall: 0.895 f1: 0.919 accuracy: 0.980 
training batch:   115, loss: 1.15556, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.995 
training batch:   116, loss: 0.49921, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:   117, loss: 2.06490, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.985 
training batch:   118, loss: 3.11800, precision: 0.909 recall: 0.882 f1: 0.896 accuracy: 0.981 
training batch:   119, loss: 2.15358, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.994 
training batch:   120, loss: 1.52345, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.990 
training batch:   121, loss: 1.24684, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.994 
training batch:   122, loss: 3.42033, precision: 1.000 recall: 0.944 f1: 0.971 accuracy: 0.991 
training batch:   123, loss: 2.08743, precision: 0.893 recall: 0.893 f1: 0.893 accuracy: 0.974 
training batch:   124, loss: 1.70067, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.995 
training batch:   125, loss: 2.71809, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.984 
training batch:   126, loss: 1.78653, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.991 
training batch:   127, loss: 1.51672, precision: 0.920 recall: 0.885 f1: 0.902 accuracy: 0.990 
training batch:   128, loss: 2.93109, precision: 0.929 recall: 1.000 f1: 0.963 accuracy: 0.991 
training batch:   129, loss: 2.83366, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.993 
training batch:   130, loss: 1.08232, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.996 
training batch:   131, loss: 1.47501, precision: 0.861 recall: 0.939 f1: 0.899 accuracy: 0.993 
training batch:   132, loss: 1.55713, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.985 
training batch:   133, loss: 0.55234, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   134, loss: 0.77759, precision: 0.972 recall: 0.921 f1: 0.946 accuracy: 0.998 
training batch:   135, loss: 2.89714, precision: 0.912 recall: 0.838 f1: 0.873 accuracy: 0.993 
training batch:   136, loss: 1.19679, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:   137, loss: 0.80307, precision: 0.929 recall: 0.897 f1: 0.912 accuracy: 0.996 
training batch:   138, loss: 1.42596, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.996 
training batch:   139, loss: 1.25169, precision: 0.923 recall: 0.973 f1: 0.947 accuracy: 0.996 
training batch:   140, loss: 4.06387, precision: 0.657 recall: 0.742 f1: 0.697 accuracy: 0.984 
training batch:   141, loss: 2.59991, precision: 0.892 recall: 0.846 f1: 0.868 accuracy: 0.988 
training batch:   142, loss: 1.38748, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.996 
training batch:   143, loss: 2.26279, precision: 0.907 recall: 0.951 f1: 0.929 accuracy: 0.993 
training batch:   144, loss: 3.53957, precision: 0.967 recall: 0.906 f1: 0.935 accuracy: 0.991 
training batch:   145, loss: 1.87369, precision: 0.919 recall: 0.971 f1: 0.944 accuracy: 0.990 
training batch:   146, loss: 3.69250, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.989 
training batch:   147, loss: 2.18590, precision: 0.925 recall: 0.925 f1: 0.925 accuracy: 0.990 
training batch:   148, loss: 5.08453, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.974 
training batch:   149, loss: 0.73125, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.996 
training batch:   150, loss: 0.67606, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.998 
training batch:   151, loss: 1.78488, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.994 
training batch:   152, loss: 2.29434, precision: 0.871 recall: 0.900 f1: 0.885 accuracy: 0.991 
training batch:   153, loss: 4.34276, precision: 0.897 recall: 0.814 f1: 0.854 accuracy: 0.985 
training batch:   154, loss: 2.87126, precision: 0.911 recall: 0.932 f1: 0.921 accuracy: 0.994 
training batch:   155, loss: 2.76235, precision: 0.930 recall: 0.889 f1: 0.909 accuracy: 0.985 
training batch:   156, loss: 2.41460, precision: 0.853 recall: 0.879 f1: 0.866 accuracy: 0.991 
training batch:   157, loss: 3.23747, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.991 
training batch:   158, loss: 2.25357, precision: 0.833 recall: 0.962 f1: 0.893 accuracy: 0.994 
training batch:   159, loss: 0.68909, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.996 
training batch:   160, loss: 2.22713, precision: 0.920 recall: 0.885 f1: 0.902 accuracy: 0.993 
training batch:   161, loss: 0.98662, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   162, loss: 1.95248, precision: 0.911 recall: 1.000 f1: 0.953 accuracy: 0.988 
training batch:   163, loss: 1.72772, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.994 
training batch:   164, loss: 2.84367, precision: 0.977 recall: 0.935 f1: 0.956 accuracy: 0.988 
training batch:   165, loss: 4.86539, precision: 0.861 recall: 0.861 f1: 0.861 accuracy: 0.984 
training batch:   166, loss: 4.96034, precision: 0.733 recall: 0.917 f1: 0.815 accuracy: 0.984 
training batch:   167, loss: 2.40175, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.975 
training batch:   168, loss: 3.57240, precision: 0.956 recall: 0.935 f1: 0.945 accuracy: 0.988 
training batch:   169, loss: 1.00954, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.995 
training batch:   170, loss: 2.05920, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.993 
training batch:   171, loss: 2.72536, precision: 0.906 recall: 0.967 f1: 0.935 accuracy: 0.983 
training batch:   172, loss: 1.01483, precision: 0.914 recall: 0.941 f1: 0.928 accuracy: 0.995 
training batch:   173, loss: 1.67799, precision: 0.962 recall: 0.893 f1: 0.926 accuracy: 0.983 
training batch:   174, loss: 0.84616, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.996 
training batch:   175, loss: 2.38353, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.990 
training batch:   176, loss: 1.99765, precision: 1.000 recall: 0.879 f1: 0.935 accuracy: 0.991 
training batch:   177, loss: 7.24818, precision: 0.821 recall: 0.800 f1: 0.810 accuracy: 0.973 
training batch:   178, loss: 2.41597, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.993 
start evaluate engines...
label: Dsa, precision: 0.749 recall: 0.754 f1: 0.744 
label: Chk, precision: 0.750 recall: 0.740 f1: 0.726 
label: Ins, precision: 0.396 recall: 0.388 f1: 0.379 
label: Sur, precision: 0.891 recall: 0.908 f1: 0.896 
label: Med, precision: 0.450 recall: 0.475 f1: 0.458 
label: Ana, precision: 0.807 recall: 0.843 f1: 0.822 
time consumption:3.90(min), precision: 0.827 recall: 0.854 f1: 0.839 accuracy: 0.968 
epoch:17/100
training batch:     1, loss: 0.76431, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.998 
training batch:     2, loss: 1.65213, precision: 0.886 recall: 0.969 f1: 0.925 accuracy: 0.994 
training batch:     3, loss: 0.66374, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.999 
training batch:     4, loss: 1.45350, precision: 0.952 recall: 0.976 f1: 0.964 accuracy: 0.996 
training batch:     5, loss: 1.25935, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:     6, loss: 3.04518, precision: 0.870 recall: 0.930 f1: 0.899 accuracy: 0.984 
training batch:     7, loss: 1.62413, precision: 0.885 recall: 0.920 f1: 0.902 accuracy: 0.995 
training batch:     8, loss: 1.32971, precision: 0.951 recall: 1.000 f1: 0.975 accuracy: 0.994 
training batch:     9, loss: 1.55939, precision: 0.950 recall: 1.000 f1: 0.974 accuracy: 0.995 
training batch:    10, loss: 1.70087, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.995 
training batch:    11, loss: 1.58781, precision: 0.893 recall: 0.893 f1: 0.893 accuracy: 0.996 
training batch:    12, loss: 1.36842, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.995 
training batch:    13, loss: 1.34456, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.996 
training batch:    14, loss: 1.56607, precision: 0.931 recall: 0.900 f1: 0.915 accuracy: 0.993 
training batch:    15, loss: 1.67950, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.995 
training batch:    16, loss: 0.56863, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.998 
training batch:    17, loss: 4.65236, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.980 
training batch:    18, loss: 2.24658, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.996 
training batch:    19, loss: 1.18465, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.998 
training batch:    20, loss: 2.27036, precision: 0.955 recall: 0.977 f1: 0.966 accuracy: 0.983 
training batch:    21, loss: 1.34036, precision: 0.941 recall: 0.960 f1: 0.950 accuracy: 0.995 
training batch:    22, loss: 2.26424, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.990 
training batch:    23, loss: 1.47200, precision: 0.955 recall: 0.933 f1: 0.944 accuracy: 0.995 
training batch:    24, loss: 1.92900, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.994 
training batch:    25, loss: 1.20276, precision: 0.927 recall: 0.950 f1: 0.938 accuracy: 0.995 
training batch:    26, loss: 2.46355, precision: 0.943 recall: 0.892 f1: 0.917 accuracy: 0.993 
training batch:    27, loss: 1.17570, precision: 0.951 recall: 0.929 f1: 0.940 accuracy: 0.996 
training batch:    28, loss: 1.11403, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.996 
training batch:    29, loss: 2.58830, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.988 
training batch:    30, loss: 2.01819, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.993 
training batch:    31, loss: 1.39616, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.996 
training batch:    32, loss: 1.62044, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.988 
training batch:    33, loss: 2.81047, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.995 
training batch:    34, loss: 0.45438, precision: 0.957 recall: 1.000 f1: 0.978 accuracy: 0.999 
training batch:    35, loss: 2.58289, precision: 0.816 recall: 0.886 f1: 0.849 accuracy: 0.989 
training batch:    36, loss: 2.04250, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.993 
training batch:    37, loss: 0.33098, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    38, loss: 1.25731, precision: 0.946 recall: 1.000 f1: 0.972 accuracy: 0.995 
training batch:    39, loss: 1.60100, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.995 
training batch:    40, loss: 1.30116, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.995 
training batch:    41, loss: 0.77408, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.998 
training batch:    42, loss: 1.66431, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.995 
training batch:    43, loss: 1.15575, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:    44, loss: 0.76053, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.998 
training batch:    45, loss: 1.41560, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.994 
training batch:    46, loss: 1.49567, precision: 0.952 recall: 0.909 f1: 0.930 accuracy: 0.991 
training batch:    47, loss: 1.10144, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.993 
training batch:    48, loss: 1.25418, precision: 0.862 recall: 0.926 f1: 0.893 accuracy: 0.993 
training batch:    49, loss: 1.04793, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.994 
training batch:    50, loss: 1.73822, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.996 
training batch:    51, loss: 1.39412, precision: 0.862 recall: 0.926 f1: 0.893 accuracy: 0.995 
training batch:    52, loss: 1.05437, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.996 
training batch:    53, loss: 0.48694, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:    54, loss: 2.42667, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.994 
training batch:    55, loss: 3.10760, precision: 0.906 recall: 0.829 f1: 0.866 accuracy: 0.984 
training batch:    56, loss: 3.17775, precision: 0.897 recall: 0.839 f1: 0.867 accuracy: 0.991 
training batch:    57, loss: 1.67326, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.995 
training batch:    58, loss: 2.24751, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.990 
training batch:    59, loss: 0.41135, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:    60, loss: 3.13109, precision: 0.927 recall: 0.974 f1: 0.950 accuracy: 0.994 
training batch:    61, loss: 0.99303, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.998 
training batch:    62, loss: 0.56721, precision: 1.000 recall: 0.980 f1: 0.990 accuracy: 0.998 
training batch:    63, loss: 3.43431, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.988 
training batch:    64, loss: 1.02551, precision: 0.979 recall: 1.000 f1: 0.989 accuracy: 0.998 
training batch:    65, loss: 0.47951, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    66, loss: 1.11212, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.998 
training batch:    67, loss: 1.30917, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.998 
training batch:    68, loss: 0.59752, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.996 
training batch:    69, loss: 1.17499, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.995 
training batch:    70, loss: 3.23558, precision: 0.951 recall: 0.907 f1: 0.929 accuracy: 0.988 
training batch:    71, loss: 1.62624, precision: 0.974 recall: 0.925 f1: 0.949 accuracy: 0.996 
training batch:    72, loss: 2.46758, precision: 0.865 recall: 0.914 f1: 0.889 accuracy: 0.991 
training batch:    73, loss: 2.08174, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.993 
training batch:    74, loss: 1.63617, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.990 
training batch:    75, loss: 2.36157, precision: 0.967 recall: 0.829 f1: 0.892 accuracy: 0.994 
training batch:    76, loss: 1.21191, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.995 
training batch:    77, loss: 3.49893, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.988 
training batch:    78, loss: 6.50266, precision: 0.886 recall: 0.939 f1: 0.912 accuracy: 0.979 
training batch:    79, loss: 1.32474, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.995 
training batch:    80, loss: 1.99535, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.988 
training batch:    81, loss: 1.28114, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.995 
training batch:    82, loss: 2.54398, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.989 
training batch:    83, loss: 0.87654, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.995 
training batch:    84, loss: 0.85518, precision: 0.960 recall: 1.000 f1: 0.980 accuracy: 0.999 
training batch:    85, loss: 1.87502, precision: 0.818 recall: 0.900 f1: 0.857 accuracy: 0.986 
training batch:    86, loss: 2.88181, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.990 
training batch:    87, loss: 2.80225, precision: 0.857 recall: 0.923 f1: 0.889 accuracy: 0.968 
training batch:    88, loss: 2.56017, precision: 0.971 recall: 0.919 f1: 0.944 accuracy: 0.993 
training batch:    89, loss: 1.08458, precision: 0.923 recall: 0.900 f1: 0.911 accuracy: 0.993 
training batch:    90, loss: 2.22293, precision: 0.929 recall: 0.975 f1: 0.951 accuracy: 0.993 
training batch:    91, loss: 3.49255, precision: 0.921 recall: 0.897 f1: 0.909 accuracy: 0.986 
training batch:    92, loss: 3.35114, precision: 0.886 recall: 0.838 f1: 0.861 accuracy: 0.981 
training batch:    93, loss: 1.32402, precision: 0.931 recall: 1.000 f1: 0.964 accuracy: 0.998 
training batch:    94, loss: 1.75654, precision: 0.927 recall: 0.950 f1: 0.938 accuracy: 0.993 
training batch:    95, loss: 0.59354, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:    96, loss: 2.38174, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.996 
training batch:    97, loss: 1.73930, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.991 
training batch:    98, loss: 0.98587, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    99, loss: 1.04877, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.996 
training batch:   100, loss: 0.82597, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   101, loss: 5.14999, precision: 0.875 recall: 0.933 f1: 0.903 accuracy: 0.988 
training batch:   102, loss: 1.83891, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.994 
training batch:   103, loss: 2.86225, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.984 
training batch:   104, loss: 0.70480, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   105, loss: 3.68155, precision: 0.882 recall: 0.938 f1: 0.909 accuracy: 0.990 
training batch:   106, loss: 1.65192, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.996 
training batch:   107, loss: 1.65320, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.990 
training batch:   108, loss: 0.78462, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.998 
training batch:   109, loss: 1.99028, precision: 1.000 recall: 0.935 f1: 0.966 accuracy: 0.995 
training batch:   110, loss: 3.32004, precision: 0.941 recall: 0.889 f1: 0.914 accuracy: 0.991 
training batch:   111, loss: 2.30942, precision: 0.867 recall: 0.812 f1: 0.839 accuracy: 0.988 
training batch:   112, loss: 3.17471, precision: 0.960 recall: 0.923 f1: 0.941 accuracy: 0.989 
training batch:   113, loss: 2.60475, precision: 0.844 recall: 0.794 f1: 0.818 accuracy: 0.984 
training batch:   114, loss: 2.13620, precision: 1.000 recall: 0.931 f1: 0.964 accuracy: 0.993 
training batch:   115, loss: 0.88579, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:   116, loss: 3.66893, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.988 
training batch:   117, loss: 1.36046, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.994 
training batch:   118, loss: 1.20854, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.998 
training batch:   119, loss: 1.70050, precision: 0.903 recall: 0.966 f1: 0.933 accuracy: 0.991 
training batch:   120, loss: 0.73590, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   121, loss: 0.75386, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   122, loss: 1.26454, precision: 0.957 recall: 1.000 f1: 0.978 accuracy: 0.995 
training batch:   123, loss: 2.62146, precision: 0.900 recall: 0.947 f1: 0.923 accuracy: 0.994 
training batch:   124, loss: 2.79005, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.988 
training batch:   125, loss: 2.27132, precision: 0.923 recall: 0.973 f1: 0.947 accuracy: 0.988 
training batch:   126, loss: 1.74321, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.994 
training batch:   127, loss: 1.53609, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.994 
training batch:   128, loss: 1.75232, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.994 
training batch:   129, loss: 1.47971, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   130, loss: 2.52980, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.995 
training batch:   131, loss: 2.32843, precision: 0.857 recall: 0.878 f1: 0.867 accuracy: 0.990 
training batch:   132, loss: 1.95326, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.990 
training batch:   133, loss: 1.24490, precision: 1.000 recall: 0.977 f1: 0.989 accuracy: 0.999 
training batch:   134, loss: 3.27866, precision: 0.966 recall: 0.903 f1: 0.933 accuracy: 0.989 
training batch:   135, loss: 2.24394, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.990 
training batch:   136, loss: 1.56652, precision: 0.951 recall: 0.907 f1: 0.929 accuracy: 0.991 
training batch:   137, loss: 0.85565, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.996 
training batch:   138, loss: 0.62613, precision: 1.000 recall: 0.962 f1: 0.980 accuracy: 0.998 
training batch:   139, loss: 1.86687, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.990 
training batch:   140, loss: 0.94255, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.998 
training batch:   141, loss: 4.32024, precision: 0.953 recall: 0.932 f1: 0.943 accuracy: 0.980 
training batch:   142, loss: 1.07445, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.995 
training batch:   143, loss: 1.78740, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.994 
training batch:   144, loss: 2.41135, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.994 
training batch:   145, loss: 0.29785, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   146, loss: 3.19200, precision: 0.815 recall: 0.786 f1: 0.800 accuracy: 0.990 
training batch:   147, loss: 2.84408, precision: 0.882 recall: 0.882 f1: 0.882 accuracy: 0.990 
training batch:   148, loss: 2.70815, precision: 0.914 recall: 0.941 f1: 0.928 accuracy: 0.990 
training batch:   149, loss: 1.09906, precision: 0.897 recall: 1.000 f1: 0.945 accuracy: 0.994 
training batch:   150, loss: 1.25443, precision: 0.929 recall: 0.951 f1: 0.940 accuracy: 0.994 
training batch:   151, loss: 2.55240, precision: 0.889 recall: 0.842 f1: 0.865 accuracy: 0.986 
training batch:   152, loss: 1.63940, precision: 0.839 recall: 0.897 f1: 0.867 accuracy: 0.990 
training batch:   153, loss: 1.97263, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.996 
training batch:   154, loss: 0.73805, precision: 0.958 recall: 0.979 f1: 0.968 accuracy: 0.996 
training batch:   155, loss: 1.46140, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:   156, loss: 3.56166, precision: 0.905 recall: 0.927 f1: 0.916 accuracy: 0.988 
training batch:   157, loss: 1.37950, precision: 0.913 recall: 0.913 f1: 0.913 accuracy: 0.989 
training batch:   158, loss: 1.47084, precision: 0.970 recall: 0.914 f1: 0.941 accuracy: 0.995 
training batch:   159, loss: 0.84265, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:   160, loss: 1.20016, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.991 
training batch:   161, loss: 1.58882, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.995 
training batch:   162, loss: 2.51669, precision: 0.966 recall: 1.000 f1: 0.982 accuracy: 0.996 
training batch:   163, loss: 1.11464, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.998 
training batch:   164, loss: 1.51360, precision: 0.907 recall: 0.951 f1: 0.929 accuracy: 0.995 
training batch:   165, loss: 0.57597, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   166, loss: 2.10301, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.980 
training batch:   167, loss: 3.94391, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.983 
training batch:   168, loss: 2.25035, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.985 
training batch:   169, loss: 1.55518, precision: 0.914 recall: 0.941 f1: 0.928 accuracy: 0.995 
training batch:   170, loss: 1.63809, precision: 0.978 recall: 0.957 f1: 0.967 accuracy: 0.994 
training batch:   171, loss: 0.77716, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   172, loss: 1.24632, precision: 1.000 recall: 0.944 f1: 0.971 accuracy: 0.996 
training batch:   173, loss: 1.89902, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.994 
training batch:   174, loss: 3.00490, precision: 0.923 recall: 0.878 f1: 0.900 accuracy: 0.983 
training batch:   175, loss: 2.18224, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.994 
training batch:   176, loss: 6.84917, precision: 0.848 recall: 0.903 f1: 0.875 accuracy: 0.980 
training batch:   177, loss: 2.74048, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.989 
training batch:   178, loss: 0.25382, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: Dsa, precision: 0.838 recall: 0.804 f1: 0.814 
label: Chk, precision: 0.733 recall: 0.767 f1: 0.740 
label: Ins, precision: 0.358 recall: 0.300 f1: 0.310 
label: Sur, precision: 0.884 recall: 0.908 f1: 0.892 
label: Med, precision: 0.450 recall: 0.475 f1: 0.458 
label: Ana, precision: 0.834 recall: 0.878 f1: 0.854 
time consumption:3.91(min), precision: 0.853 recall: 0.874 f1: 0.863 accuracy: 0.970 
saved the new best model with f1: 0.863
epoch:18/100
training batch:     1, loss: 1.04628, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.993 
training batch:     2, loss: 1.00388, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.996 
training batch:     3, loss: 1.49405, precision: 0.930 recall: 0.930 f1: 0.930 accuracy: 0.994 
training batch:     4, loss: 1.74525, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.994 
training batch:     5, loss: 1.58473, precision: 0.895 recall: 1.000 f1: 0.944 accuracy: 0.994 
training batch:     6, loss: 4.43266, precision: 0.844 recall: 0.871 f1: 0.857 accuracy: 0.979 
training batch:     7, loss: 1.44957, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.996 
training batch:     8, loss: 1.51158, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.993 
training batch:     9, loss: 1.00247, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    10, loss: 0.64426, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    11, loss: 0.69293, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:    12, loss: 1.94240, precision: 1.000 recall: 0.931 f1: 0.964 accuracy: 0.995 
training batch:    13, loss: 0.91248, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.998 
training batch:    14, loss: 1.45656, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.996 
training batch:    15, loss: 2.38474, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.991 
training batch:    16, loss: 0.57199, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:    17, loss: 2.11839, precision: 0.906 recall: 0.906 f1: 0.906 accuracy: 0.995 
training batch:    18, loss: 0.38240, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.999 
training batch:    19, loss: 4.37582, precision: 0.882 recall: 0.789 f1: 0.833 accuracy: 0.980 
training batch:    20, loss: 1.00175, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.995 
training batch:    21, loss: 0.91977, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    22, loss: 1.24306, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.994 
training batch:    23, loss: 1.34746, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.996 
training batch:    24, loss: 1.37914, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.996 
training batch:    25, loss: 2.54686, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.991 
training batch:    26, loss: 3.41205, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.991 
training batch:    27, loss: 0.23811, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    28, loss: 1.00093, precision: 0.962 recall: 1.000 f1: 0.980 accuracy: 0.998 
training batch:    29, loss: 2.19994, precision: 0.912 recall: 0.969 f1: 0.939 accuracy: 0.991 
training batch:    30, loss: 1.39868, precision: 0.882 recall: 0.968 f1: 0.923 accuracy: 0.993 
training batch:    31, loss: 2.00871, precision: 0.902 recall: 0.902 f1: 0.902 accuracy: 0.994 
training batch:    32, loss: 1.61040, precision: 0.864 recall: 0.927 f1: 0.894 accuracy: 0.989 
training batch:    33, loss: 2.03761, precision: 0.806 recall: 0.862 f1: 0.833 accuracy: 0.991 
training batch:    34, loss: 2.02281, precision: 0.902 recall: 0.902 f1: 0.902 accuracy: 0.988 
training batch:    35, loss: 0.69136, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.995 
training batch:    36, loss: 1.36118, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.991 
training batch:    37, loss: 1.58670, precision: 1.000 recall: 0.935 f1: 0.967 accuracy: 0.993 
training batch:    38, loss: 2.58634, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.993 
training batch:    39, loss: 1.70918, precision: 0.862 recall: 0.926 f1: 0.893 accuracy: 0.984 
training batch:    40, loss: 3.21294, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.978 
training batch:    41, loss: 1.80383, precision: 0.971 recall: 0.919 f1: 0.944 accuracy: 0.996 
training batch:    42, loss: 1.14362, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:    43, loss: 0.67761, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.996 
training batch:    44, loss: 1.07828, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    45, loss: 0.25562, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    46, loss: 1.18568, precision: 0.917 recall: 1.000 f1: 0.957 accuracy: 0.995 
training batch:    47, loss: 4.20871, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.979 
training batch:    48, loss: 2.86342, precision: 0.882 recall: 0.938 f1: 0.909 accuracy: 0.989 
training batch:    49, loss: 0.30103, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    50, loss: 1.38431, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.991 
training batch:    51, loss: 0.65405, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.999 
training batch:    52, loss: 2.76848, precision: 0.892 recall: 0.846 f1: 0.868 accuracy: 0.994 
training batch:    53, loss: 1.39847, precision: 0.900 recall: 0.931 f1: 0.915 accuracy: 0.993 
training batch:    54, loss: 2.28050, precision: 0.881 recall: 0.902 f1: 0.892 accuracy: 0.988 
training batch:    55, loss: 1.18166, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.996 
training batch:    56, loss: 0.88829, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    57, loss: 1.71902, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.996 
training batch:    58, loss: 3.26605, precision: 0.952 recall: 0.889 f1: 0.920 accuracy: 0.991 
training batch:    59, loss: 1.69029, precision: 0.882 recall: 0.909 f1: 0.896 accuracy: 0.990 
training batch:    60, loss: 0.69186, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.998 
training batch:    61, loss: 4.62195, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.983 
training batch:    62, loss: 1.13612, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.993 
training batch:    63, loss: 1.22510, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:    64, loss: 5.65307, precision: 0.788 recall: 0.897 f1: 0.839 accuracy: 0.971 
training batch:    65, loss: 2.95193, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.986 
training batch:    66, loss: 1.80026, precision: 0.882 recall: 0.909 f1: 0.896 accuracy: 0.990 
training batch:    67, loss: 0.89185, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.995 
training batch:    68, loss: 0.79988, precision: 0.897 recall: 0.963 f1: 0.929 accuracy: 0.996 
training batch:    69, loss: 0.44841, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    70, loss: 0.89777, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.996 
training batch:    71, loss: 2.51433, precision: 0.871 recall: 0.900 f1: 0.885 accuracy: 0.991 
training batch:    72, loss: 2.00891, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.988 
training batch:    73, loss: 5.44456, precision: 0.900 recall: 0.857 f1: 0.878 accuracy: 0.971 
training batch:    74, loss: 0.72853, precision: 1.000 recall: 0.933 f1: 0.966 accuracy: 0.995 
training batch:    75, loss: 1.95654, precision: 0.969 recall: 0.912 f1: 0.939 accuracy: 0.994 
training batch:    76, loss: 3.18546, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.994 
training batch:    77, loss: 2.68974, precision: 0.976 recall: 0.930 f1: 0.952 accuracy: 0.986 
training batch:    78, loss: 1.55283, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.998 
training batch:    79, loss: 3.41725, precision: 0.771 recall: 0.871 f1: 0.818 accuracy: 0.986 
training batch:    80, loss: 1.08145, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.998 
training batch:    81, loss: 4.53960, precision: 0.806 recall: 0.862 f1: 0.833 accuracy: 0.970 
training batch:    82, loss: 2.30998, precision: 0.841 recall: 0.974 f1: 0.902 accuracy: 0.991 
training batch:    83, loss: 2.16960, precision: 0.914 recall: 1.000 f1: 0.955 accuracy: 0.994 
training batch:    84, loss: 0.44913, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    85, loss: 0.42628, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    86, loss: 3.40901, precision: 0.841 recall: 0.860 f1: 0.851 accuracy: 0.976 
training batch:    87, loss: 2.31236, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.994 
training batch:    88, loss: 3.96732, precision: 0.893 recall: 0.893 f1: 0.893 accuracy: 0.993 
training batch:    89, loss: 3.67193, precision: 0.889 recall: 0.865 f1: 0.877 accuracy: 0.983 
training batch:    90, loss: 4.98872, precision: 0.881 recall: 0.902 f1: 0.892 accuracy: 0.983 
training batch:    91, loss: 3.20883, precision: 0.871 recall: 0.931 f1: 0.900 accuracy: 0.989 
training batch:    92, loss: 0.60443, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    93, loss: 0.93365, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.998 
training batch:    94, loss: 2.49451, precision: 0.906 recall: 0.806 f1: 0.853 accuracy: 0.988 
training batch:    95, loss: 1.77779, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.995 
training batch:    96, loss: 2.26111, precision: 0.871 recall: 0.900 f1: 0.885 accuracy: 0.988 
training batch:    97, loss: 1.18590, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.999 
training batch:    98, loss: 1.43518, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:    99, loss: 2.25549, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.994 
training batch:   100, loss: 0.95479, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.995 
training batch:   101, loss: 0.78308, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.996 
training batch:   102, loss: 0.81548, precision: 1.000 recall: 0.975 f1: 0.987 accuracy: 0.999 
training batch:   103, loss: 1.11086, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.995 
training batch:   104, loss: 3.60944, precision: 0.839 recall: 1.000 f1: 0.912 accuracy: 0.979 
training batch:   105, loss: 1.12433, precision: 0.892 recall: 0.892 f1: 0.892 accuracy: 0.995 
training batch:   106, loss: 0.84442, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.998 
training batch:   107, loss: 3.57120, precision: 0.932 recall: 0.976 f1: 0.953 accuracy: 0.991 
training batch:   108, loss: 3.30594, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.988 
training batch:   109, loss: 0.65788, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.996 
training batch:   110, loss: 1.90154, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.994 
training batch:   111, loss: 1.51881, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.998 
training batch:   112, loss: 0.74802, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:   113, loss: 1.14325, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.999 
training batch:   114, loss: 2.95464, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.989 
training batch:   115, loss: 4.25961, precision: 0.927 recall: 0.950 f1: 0.938 accuracy: 0.971 
training batch:   116, loss: 0.71083, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   117, loss: 2.62878, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.991 
training batch:   118, loss: 2.54570, precision: 0.941 recall: 0.889 f1: 0.914 accuracy: 0.991 
training batch:   119, loss: 2.06821, precision: 0.923 recall: 0.900 f1: 0.911 accuracy: 0.991 
training batch:   120, loss: 1.72366, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.988 
training batch:   121, loss: 1.73582, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.991 
training batch:   122, loss: 2.89030, precision: 0.976 recall: 0.953 f1: 0.965 accuracy: 0.974 
training batch:   123, loss: 2.40805, precision: 0.931 recall: 0.900 f1: 0.915 accuracy: 0.993 
training batch:   124, loss: 0.58031, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   125, loss: 0.91176, precision: 1.000 recall: 0.949 f1: 0.974 accuracy: 0.993 
training batch:   126, loss: 7.52803, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.930 
training batch:   127, loss: 1.42743, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   128, loss: 1.34808, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.995 
training batch:   129, loss: 2.61531, precision: 0.867 recall: 0.963 f1: 0.912 accuracy: 0.986 
training batch:   130, loss: 1.20645, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.998 
training batch:   131, loss: 1.15176, precision: 0.976 recall: 0.953 f1: 0.965 accuracy: 0.996 
training batch:   132, loss: 1.04912, precision: 0.941 recall: 0.970 f1: 0.955 accuracy: 0.998 
training batch:   133, loss: 3.62329, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.986 
training batch:   134, loss: 4.86989, precision: 0.953 recall: 0.911 f1: 0.932 accuracy: 0.991 
training batch:   135, loss: 4.81781, precision: 0.969 recall: 0.886 f1: 0.925 accuracy: 0.979 
training batch:   136, loss: 8.48148, precision: 1.000 recall: 0.929 f1: 0.963 accuracy: 0.973 
training batch:   137, loss: 2.10730, precision: 0.840 recall: 0.840 f1: 0.840 accuracy: 0.988 
training batch:   138, loss: 0.92552, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.996 
training batch:   139, loss: 2.89696, precision: 0.906 recall: 0.967 f1: 0.935 accuracy: 0.984 
training batch:   140, loss: 3.33426, precision: 0.946 recall: 0.921 f1: 0.933 accuracy: 0.974 
training batch:   141, loss: 2.48578, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.990 
training batch:   142, loss: 7.35002, precision: 1.000 recall: 0.975 f1: 0.987 accuracy: 0.983 
training batch:   143, loss: 2.28470, precision: 0.868 recall: 0.943 f1: 0.904 accuracy: 0.994 
training batch:   144, loss: 3.23177, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.983 
training batch:   145, loss: 1.64140, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.994 
training batch:   146, loss: 2.05990, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.994 
training batch:   147, loss: 1.12534, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   148, loss: 4.86443, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.979 
training batch:   149, loss: 1.57816, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.991 
training batch:   150, loss: 0.90776, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.996 
training batch:   151, loss: 4.43706, precision: 0.897 recall: 0.839 f1: 0.867 accuracy: 0.976 
training batch:   152, loss: 4.89335, precision: 0.915 recall: 0.896 f1: 0.905 accuracy: 0.986 
training batch:   153, loss: 2.32408, precision: 0.932 recall: 0.976 f1: 0.953 accuracy: 0.993 
training batch:   154, loss: 1.22165, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.993 
training batch:   155, loss: 0.53137, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   156, loss: 3.37126, precision: 0.966 recall: 0.824 f1: 0.889 accuracy: 0.994 
training batch:   157, loss: 3.30433, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.986 
training batch:   158, loss: 1.82403, precision: 0.952 recall: 1.000 f1: 0.976 accuracy: 0.991 
training batch:   159, loss: 2.02316, precision: 0.935 recall: 0.956 f1: 0.945 accuracy: 0.988 
training batch:   160, loss: 1.97897, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.989 
training batch:   161, loss: 3.40347, precision: 0.915 recall: 0.896 f1: 0.905 accuracy: 0.984 
training batch:   162, loss: 1.41161, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.994 
training batch:   163, loss: 0.99638, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.998 
training batch:   164, loss: 1.45367, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.996 
training batch:   165, loss: 1.50209, precision: 1.000 recall: 0.955 f1: 0.977 accuracy: 0.996 
training batch:   166, loss: 1.21548, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.994 
training batch:   167, loss: 4.23096, precision: 0.892 recall: 0.868 f1: 0.880 accuracy: 0.983 
training batch:   168, loss: 1.39284, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.998 
training batch:   169, loss: 4.62759, precision: 0.897 recall: 0.875 f1: 0.886 accuracy: 0.983 
training batch:   170, loss: 3.04933, precision: 0.879 recall: 0.853 f1: 0.866 accuracy: 0.990 
training batch:   171, loss: 2.37192, precision: 0.923 recall: 0.900 f1: 0.911 accuracy: 0.991 
training batch:   172, loss: 0.94453, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:   173, loss: 4.03461, precision: 0.921 recall: 0.833 f1: 0.875 accuracy: 0.981 
training batch:   174, loss: 2.82657, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.985 
training batch:   175, loss: 2.81815, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.984 
training batch:   176, loss: 1.31303, precision: 0.900 recall: 0.923 f1: 0.911 accuracy: 0.991 
training batch:   177, loss: 1.47627, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   178, loss: 1.34306, precision: 0.941 recall: 0.889 f1: 0.914 accuracy: 0.993 
start evaluate engines...
label: Dsa, precision: 0.757 recall: 0.772 f1: 0.759 
label: Chk, precision: 0.700 recall: 0.717 f1: 0.695 
label: Ins, precision: 0.358 recall: 0.321 f1: 0.328 
label: Sur, precision: 0.879 recall: 0.918 f1: 0.895 
label: Med, precision: 0.415 recall: 0.415 f1: 0.407 
label: Ana, precision: 0.819 recall: 0.848 f1: 0.831 
time consumption:3.89(min), precision: 0.824 recall: 0.850 f1: 0.836 accuracy: 0.967 
epoch:19/100
training batch:     1, loss: 2.04492, precision: 0.902 recall: 0.925 f1: 0.914 accuracy: 0.993 
training batch:     2, loss: 1.91751, precision: 0.977 recall: 0.956 f1: 0.966 accuracy: 0.984 
training batch:     3, loss: 0.85146, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:     4, loss: 0.96182, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:     5, loss: 2.39972, precision: 0.900 recall: 0.947 f1: 0.923 accuracy: 0.988 
training batch:     6, loss: 4.03146, precision: 0.955 recall: 1.000 f1: 0.977 accuracy: 0.978 
training batch:     7, loss: 3.67343, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.988 
training batch:     8, loss: 1.56152, precision: 0.875 recall: 0.903 f1: 0.889 accuracy: 0.991 
training batch:     9, loss: 1.60185, precision: 0.886 recall: 0.886 f1: 0.886 accuracy: 0.993 
training batch:    10, loss: 2.72092, precision: 0.892 recall: 0.943 f1: 0.917 accuracy: 0.990 
training batch:    11, loss: 0.62227, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    12, loss: 1.69833, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.994 
training batch:    13, loss: 0.99857, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.995 
training batch:    14, loss: 2.08365, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.994 
training batch:    15, loss: 1.97913, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.991 
training batch:    16, loss: 0.57680, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    17, loss: 0.72385, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    18, loss: 0.43442, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:    19, loss: 1.64667, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.995 
training batch:    20, loss: 0.65584, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.995 
training batch:    21, loss: 0.83678, precision: 0.977 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:    22, loss: 2.01511, precision: 0.875 recall: 0.833 f1: 0.854 accuracy: 0.986 
training batch:    23, loss: 2.67451, precision: 0.914 recall: 1.000 f1: 0.955 accuracy: 0.991 
training batch:    24, loss: 3.63928, precision: 0.897 recall: 0.875 f1: 0.886 accuracy: 0.986 
training batch:    25, loss: 2.83226, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.985 
training batch:    26, loss: 0.75500, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    27, loss: 1.40396, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.996 
training batch:    28, loss: 2.24997, precision: 0.912 recall: 0.886 f1: 0.899 accuracy: 0.990 
training batch:    29, loss: 2.68924, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.991 
training batch:    30, loss: 0.73633, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:    31, loss: 0.98178, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:    32, loss: 0.35658, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    33, loss: 2.14412, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.993 
training batch:    34, loss: 1.37900, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.993 
training batch:    35, loss: 2.28578, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.983 
training batch:    36, loss: 1.35172, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.996 
training batch:    37, loss: 5.26340, precision: 0.891 recall: 0.911 f1: 0.901 accuracy: 0.980 
training batch:    38, loss: 0.56548, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:    39, loss: 0.86806, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.995 
training batch:    40, loss: 0.52672, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.999 
training batch:    41, loss: 4.77414, precision: 0.878 recall: 0.857 f1: 0.867 accuracy: 0.986 
training batch:    42, loss: 2.66171, precision: 0.875 recall: 0.854 f1: 0.864 accuracy: 0.989 
training batch:    43, loss: 0.50914, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    44, loss: 5.97096, precision: 0.806 recall: 0.879 f1: 0.841 accuracy: 0.978 
training batch:    45, loss: 1.84346, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.994 
training batch:    46, loss: 1.60162, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.991 
training batch:    47, loss: 4.13971, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.974 
training batch:    48, loss: 3.07121, precision: 0.800 recall: 0.875 f1: 0.836 accuracy: 0.979 
training batch:    49, loss: 2.17262, precision: 0.952 recall: 0.930 f1: 0.941 accuracy: 0.990 
training batch:    50, loss: 2.90839, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.993 
training batch:    51, loss: 2.03754, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.974 
training batch:    52, loss: 0.31552, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    53, loss: 2.07166, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.996 
training batch:    54, loss: 3.17155, precision: 0.972 recall: 0.921 f1: 0.946 accuracy: 0.994 
training batch:    55, loss: 1.37869, precision: 0.926 recall: 0.962 f1: 0.943 accuracy: 0.994 
training batch:    56, loss: 2.59441, precision: 0.919 recall: 0.895 f1: 0.907 accuracy: 0.991 
training batch:    57, loss: 3.84032, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.989 
training batch:    58, loss: 1.20361, precision: 0.920 recall: 0.958 f1: 0.939 accuracy: 0.994 
training batch:    59, loss: 2.16730, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.989 
training batch:    60, loss: 0.71701, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    61, loss: 2.99850, precision: 0.921 recall: 0.875 f1: 0.897 accuracy: 0.983 
training batch:    62, loss: 3.46848, precision: 0.919 recall: 0.895 f1: 0.907 accuracy: 0.983 
training batch:    63, loss: 1.43391, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.998 
training batch:    64, loss: 0.65384, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.996 
training batch:    65, loss: 2.67836, precision: 0.917 recall: 0.971 f1: 0.943 accuracy: 0.991 
training batch:    66, loss: 1.62836, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.991 
training batch:    67, loss: 2.81787, precision: 0.781 recall: 0.862 f1: 0.820 accuracy: 0.984 
training batch:    68, loss: 1.35167, precision: 0.971 recall: 0.919 f1: 0.944 accuracy: 0.994 
training batch:    69, loss: 4.41071, precision: 0.878 recall: 0.923 f1: 0.900 accuracy: 0.973 
training batch:    70, loss: 0.60896, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.998 
training batch:    71, loss: 0.80849, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.995 
training batch:    72, loss: 2.63084, precision: 0.892 recall: 0.971 f1: 0.930 accuracy: 0.991 
training batch:    73, loss: 1.46510, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.995 
training batch:    74, loss: 2.66695, precision: 0.974 recall: 0.925 f1: 0.949 accuracy: 0.986 
training batch:    75, loss: 0.55214, precision: 1.000 recall: 0.975 f1: 0.987 accuracy: 0.999 
training batch:    76, loss: 0.91876, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:    77, loss: 1.46616, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.996 
training batch:    78, loss: 1.25327, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.998 
training batch:    79, loss: 2.10141, precision: 1.000 recall: 0.929 f1: 0.963 accuracy: 0.993 
training batch:    80, loss: 1.25404, precision: 0.919 recall: 1.000 f1: 0.958 accuracy: 0.995 
training batch:    81, loss: 1.80276, precision: 0.950 recall: 0.905 f1: 0.927 accuracy: 0.990 
training batch:    82, loss: 1.17796, precision: 0.959 recall: 0.959 f1: 0.959 accuracy: 0.998 
training batch:    83, loss: 4.23158, precision: 0.857 recall: 0.909 f1: 0.882 accuracy: 0.978 
training batch:    84, loss: 1.11992, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.994 
training batch:    85, loss: 2.98763, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.989 
training batch:    86, loss: 1.53555, precision: 0.956 recall: 0.956 f1: 0.956 accuracy: 0.991 
training batch:    87, loss: 2.50517, precision: 0.929 recall: 0.951 f1: 0.940 accuracy: 0.993 
training batch:    88, loss: 1.14688, precision: 0.977 recall: 0.933 f1: 0.955 accuracy: 0.991 
training batch:    89, loss: 3.43428, precision: 0.881 recall: 0.881 f1: 0.881 accuracy: 0.983 
training batch:    90, loss: 1.36386, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.993 
training batch:    91, loss: 3.57518, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.988 
training batch:    92, loss: 2.90575, precision: 0.935 recall: 0.906 f1: 0.921 accuracy: 0.988 
training batch:    93, loss: 1.90663, precision: 0.867 recall: 0.929 f1: 0.897 accuracy: 0.995 
training batch:    94, loss: 2.23684, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.993 
training batch:    95, loss: 1.11392, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.995 
training batch:    96, loss: 0.32921, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    97, loss: 1.78656, precision: 0.956 recall: 0.956 f1: 0.956 accuracy: 0.996 
training batch:    98, loss: 4.67319, precision: 0.892 recall: 0.917 f1: 0.904 accuracy: 0.979 
training batch:    99, loss: 2.72861, precision: 0.875 recall: 0.921 f1: 0.897 accuracy: 0.979 
training batch:   100, loss: 1.94827, precision: 0.964 recall: 0.931 f1: 0.947 accuracy: 0.996 
training batch:   101, loss: 1.63884, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.993 
training batch:   102, loss: 0.41345, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   103, loss: 1.25598, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.995 
training batch:   104, loss: 2.00243, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.993 
training batch:   105, loss: 3.40269, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.986 
training batch:   106, loss: 1.08067, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   107, loss: 1.04958, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:   108, loss: 1.38417, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.995 
training batch:   109, loss: 2.59749, precision: 0.882 recall: 0.938 f1: 0.909 accuracy: 0.989 
training batch:   110, loss: 2.20944, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.988 
training batch:   111, loss: 1.37531, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.993 
training batch:   112, loss: 0.40578, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.999 
training batch:   113, loss: 1.31393, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.994 
training batch:   114, loss: 1.94208, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.994 
training batch:   115, loss: 2.57841, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.989 
training batch:   116, loss: 0.69223, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   117, loss: 0.79289, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   118, loss: 2.33238, precision: 0.931 recall: 1.000 f1: 0.964 accuracy: 0.993 
training batch:   119, loss: 0.50020, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.998 
training batch:   120, loss: 1.96275, precision: 0.927 recall: 0.905 f1: 0.916 accuracy: 0.988 
training batch:   121, loss: 1.09392, precision: 0.977 recall: 0.955 f1: 0.966 accuracy: 0.998 
training batch:   122, loss: 2.94554, precision: 0.824 recall: 0.778 f1: 0.800 accuracy: 0.985 
training batch:   123, loss: 1.49280, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.996 
training batch:   124, loss: 2.29936, precision: 0.949 recall: 0.902 f1: 0.925 accuracy: 0.994 
training batch:   125, loss: 5.61308, precision: 0.944 recall: 0.919 f1: 0.932 accuracy: 0.981 
training batch:   126, loss: 1.95058, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.991 
training batch:   127, loss: 0.69978, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   128, loss: 1.54466, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.994 
training batch:   129, loss: 1.93057, precision: 0.932 recall: 0.911 f1: 0.921 accuracy: 0.995 
training batch:   130, loss: 1.75427, precision: 0.861 recall: 0.861 f1: 0.861 accuracy: 0.991 
training batch:   131, loss: 0.34186, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   132, loss: 2.38362, precision: 0.882 recall: 1.000 f1: 0.938 accuracy: 0.991 
training batch:   133, loss: 0.62325, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.994 
training batch:   134, loss: 0.57333, precision: 0.955 recall: 0.955 f1: 0.955 accuracy: 0.995 
training batch:   135, loss: 0.83206, precision: 0.906 recall: 0.967 f1: 0.935 accuracy: 0.996 
training batch:   136, loss: 4.21654, precision: 0.938 recall: 0.882 f1: 0.909 accuracy: 0.985 
training batch:   137, loss: 1.06201, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:   138, loss: 0.71989, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:   139, loss: 1.33176, precision: 0.966 recall: 0.903 f1: 0.933 accuracy: 0.989 
training batch:   140, loss: 0.83809, precision: 0.978 recall: 0.978 f1: 0.978 accuracy: 0.999 
training batch:   141, loss: 1.53197, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.995 
training batch:   142, loss: 0.89159, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.995 
training batch:   143, loss: 0.88818, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.995 
training batch:   144, loss: 1.70126, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.989 
training batch:   145, loss: 2.02397, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.989 
training batch:   146, loss: 1.02621, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   147, loss: 1.38780, precision: 0.927 recall: 0.974 f1: 0.950 accuracy: 0.993 
training batch:   148, loss: 2.81717, precision: 0.811 recall: 0.882 f1: 0.845 accuracy: 0.985 
training batch:   149, loss: 0.38254, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   150, loss: 0.93111, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.996 
training batch:   151, loss: 3.70096, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.985 
training batch:   152, loss: 1.66103, precision: 0.955 recall: 0.913 f1: 0.933 accuracy: 0.996 
training batch:   153, loss: 0.74890, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.998 
training batch:   154, loss: 0.81134, precision: 0.978 recall: 0.978 f1: 0.978 accuracy: 0.996 
training batch:   155, loss: 0.64268, precision: 1.000 recall: 0.962 f1: 0.980 accuracy: 0.998 
training batch:   156, loss: 1.82036, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.993 
training batch:   157, loss: 1.75258, precision: 0.947 recall: 0.923 f1: 0.935 accuracy: 0.988 
training batch:   158, loss: 2.57214, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.984 
training batch:   159, loss: 1.22791, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.995 
training batch:   160, loss: 0.87555, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.998 
training batch:   161, loss: 1.11633, precision: 0.974 recall: 0.925 f1: 0.949 accuracy: 0.996 
training batch:   162, loss: 2.69760, precision: 0.892 recall: 0.971 f1: 0.930 accuracy: 0.993 
training batch:   163, loss: 1.07458, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.999 
training batch:   164, loss: 0.66945, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   165, loss: 1.43098, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.995 
training batch:   166, loss: 1.04718, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.996 
training batch:   167, loss: 1.24609, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.994 
training batch:   168, loss: 1.54584, precision: 0.957 recall: 0.938 f1: 0.947 accuracy: 0.996 
training batch:   169, loss: 1.60660, precision: 0.964 recall: 0.931 f1: 0.947 accuracy: 0.985 
training batch:   170, loss: 2.53172, precision: 0.906 recall: 0.935 f1: 0.921 accuracy: 0.995 
training batch:   171, loss: 1.68262, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.995 
training batch:   172, loss: 1.56898, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.996 
training batch:   173, loss: 2.91461, precision: 0.929 recall: 0.951 f1: 0.940 accuracy: 0.990 
training batch:   174, loss: 1.00987, precision: 0.889 recall: 0.923 f1: 0.906 accuracy: 0.995 
training batch:   175, loss: 0.86974, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.998 
training batch:   176, loss: 1.59700, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.994 
training batch:   177, loss: 2.75030, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.981 
training batch:   178, loss: 2.53678, precision: 0.750 recall: 0.692 f1: 0.720 accuracy: 0.983 
start evaluate engines...
label: Dsa, precision: 0.768 recall: 0.779 f1: 0.768 
label: Chk, precision: 0.733 recall: 0.767 f1: 0.737 
label: Ins, precision: 0.317 recall: 0.287 f1: 0.282 
label: Sur, precision: 0.874 recall: 0.908 f1: 0.886 
label: Med, precision: 0.400 recall: 0.425 f1: 0.408 
label: Ana, precision: 0.835 recall: 0.834 f1: 0.832 
time consumption:2.79(min), precision: 0.840 recall: 0.845 f1: 0.842 accuracy: 0.966 
epoch:20/100
training batch:     1, loss: 1.13527, precision: 0.932 recall: 0.953 f1: 0.943 accuracy: 0.998 
training batch:     2, loss: 1.02489, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.995 
training batch:     3, loss: 2.99619, precision: 0.784 recall: 0.935 f1: 0.853 accuracy: 0.989 
training batch:     4, loss: 1.32840, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.994 
training batch:     5, loss: 0.36891, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:     6, loss: 0.89334, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.998 
training batch:     7, loss: 1.05467, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.995 
training batch:     8, loss: 0.71341, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.998 
training batch:     9, loss: 1.42336, precision: 0.974 recall: 0.950 f1: 0.962 accuracy: 0.995 
training batch:    10, loss: 1.81517, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.986 
training batch:    11, loss: 0.81311, precision: 0.974 recall: 0.950 f1: 0.962 accuracy: 0.996 
training batch:    12, loss: 1.20273, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.998 
training batch:    13, loss: 1.40286, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.996 
training batch:    14, loss: 0.82463, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:    15, loss: 3.19902, precision: 0.941 recall: 0.800 f1: 0.865 accuracy: 0.993 
training batch:    16, loss: 0.61385, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.995 
training batch:    17, loss: 2.05130, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.989 
training batch:    18, loss: 3.49698, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.995 
training batch:    19, loss: 1.75369, precision: 0.930 recall: 0.952 f1: 0.941 accuracy: 0.990 
training batch:    20, loss: 0.66905, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    21, loss: 1.44649, precision: 0.958 recall: 0.979 f1: 0.968 accuracy: 0.996 
training batch:    22, loss: 1.59312, precision: 0.950 recall: 1.000 f1: 0.974 accuracy: 0.996 
training batch:    23, loss: 4.65694, precision: 0.865 recall: 0.914 f1: 0.889 accuracy: 0.981 
training batch:    24, loss: 1.36243, precision: 0.953 recall: 0.976 f1: 0.965 accuracy: 0.993 
training batch:    25, loss: 1.01274, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.996 
training batch:    26, loss: 1.63626, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.996 
training batch:    27, loss: 1.94182, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.996 
training batch:    28, loss: 1.14552, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    29, loss: 2.23077, precision: 0.897 recall: 0.833 f1: 0.864 accuracy: 0.989 
training batch:    30, loss: 2.89848, precision: 0.929 recall: 0.975 f1: 0.951 accuracy: 0.991 
training batch:    31, loss: 1.79614, precision: 0.903 recall: 0.903 f1: 0.903 accuracy: 0.990 
training batch:    32, loss: 0.31776, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    33, loss: 0.76909, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.995 
training batch:    34, loss: 0.35953, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    35, loss: 0.51669, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    36, loss: 0.85623, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.998 
training batch:    37, loss: 1.04459, precision: 0.905 recall: 0.927 f1: 0.916 accuracy: 0.994 
training batch:    38, loss: 1.42154, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.994 
training batch:    39, loss: 1.07851, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.993 
training batch:    40, loss: 0.92163, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.998 
training batch:    41, loss: 0.99307, precision: 0.951 recall: 0.929 f1: 0.940 accuracy: 0.996 
training batch:    42, loss: 0.39764, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:    43, loss: 1.45569, precision: 0.871 recall: 1.000 f1: 0.931 accuracy: 0.991 
training batch:    44, loss: 2.33438, precision: 0.914 recall: 0.941 f1: 0.928 accuracy: 0.993 
training batch:    45, loss: 0.68173, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.993 
training batch:    46, loss: 3.98399, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.979 
training batch:    47, loss: 1.00058, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.996 
training batch:    48, loss: 0.17047, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    49, loss: 0.96591, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.998 
training batch:    50, loss: 3.40289, precision: 1.000 recall: 0.889 f1: 0.941 accuracy: 0.994 
training batch:    51, loss: 0.39458, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    52, loss: 1.12659, precision: 0.925 recall: 0.902 f1: 0.914 accuracy: 0.994 
training batch:    53, loss: 2.05064, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.994 
training batch:    54, loss: 0.36981, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    55, loss: 1.82050, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.994 
training batch:    56, loss: 1.04115, precision: 0.914 recall: 0.941 f1: 0.928 accuracy: 0.996 
training batch:    57, loss: 2.29591, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.995 
training batch:    58, loss: 1.87233, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.991 
training batch:    59, loss: 0.32039, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:    60, loss: 1.35229, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.996 
training batch:    61, loss: 1.86641, precision: 0.929 recall: 1.000 f1: 0.963 accuracy: 0.993 
training batch:    62, loss: 0.87495, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:    63, loss: 1.44742, precision: 1.000 recall: 0.964 f1: 0.982 accuracy: 0.990 
training batch:    64, loss: 0.28285, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    65, loss: 0.81439, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    66, loss: 1.82384, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.996 
training batch:    67, loss: 2.38397, precision: 0.905 recall: 0.950 f1: 0.927 accuracy: 0.991 
training batch:    68, loss: 0.21170, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    69, loss: 0.77731, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:    70, loss: 6.49280, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.974 
training batch:    71, loss: 1.61066, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.995 
training batch:    72, loss: 1.22110, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.993 
training batch:    73, loss: 2.09006, precision: 1.000 recall: 0.978 f1: 0.989 accuracy: 0.996 
training batch:    74, loss: 0.72014, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.991 
training batch:    75, loss: 2.20604, precision: 0.925 recall: 0.841 f1: 0.881 accuracy: 0.988 
training batch:    76, loss: 1.84375, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.989 
training batch:    77, loss: 1.47783, precision: 0.977 recall: 0.956 f1: 0.966 accuracy: 0.998 
training batch:    78, loss: 0.81059, precision: 0.957 recall: 0.938 f1: 0.947 accuracy: 0.996 
training batch:    79, loss: 2.33294, precision: 0.961 recall: 0.961 f1: 0.961 accuracy: 0.990 
training batch:    80, loss: 1.70735, precision: 0.879 recall: 0.906 f1: 0.892 accuracy: 0.995 
training batch:    81, loss: 0.34145, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    82, loss: 1.60396, precision: 0.889 recall: 0.970 f1: 0.928 accuracy: 0.994 
training batch:    83, loss: 2.72809, precision: 0.936 recall: 0.978 f1: 0.957 accuracy: 0.989 
training batch:    84, loss: 4.85281, precision: 0.939 recall: 0.861 f1: 0.899 accuracy: 0.976 
training batch:    85, loss: 1.07367, precision: 0.930 recall: 0.952 f1: 0.941 accuracy: 0.998 
training batch:    86, loss: 1.11586, precision: 0.902 recall: 0.881 f1: 0.892 accuracy: 0.994 
training batch:    87, loss: 0.28529, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    88, loss: 1.67006, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.990 
training batch:    89, loss: 0.46800, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    90, loss: 0.67197, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    91, loss: 1.08696, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.996 
training batch:    92, loss: 1.03430, precision: 0.935 recall: 0.879 f1: 0.906 accuracy: 0.994 
training batch:    93, loss: 1.10214, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.989 
training batch:    94, loss: 2.65086, precision: 0.902 recall: 0.949 f1: 0.925 accuracy: 0.991 
training batch:    95, loss: 2.47792, precision: 0.909 recall: 0.968 f1: 0.937 accuracy: 0.993 
training batch:    96, loss: 0.90739, precision: 0.914 recall: 0.941 f1: 0.928 accuracy: 0.996 
training batch:    97, loss: 2.75786, precision: 0.917 recall: 0.943 f1: 0.930 accuracy: 0.993 
training batch:    98, loss: 0.75729, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.998 
training batch:    99, loss: 1.02400, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.999 
training batch:   100, loss: 1.25665, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.991 
training batch:   101, loss: 0.98251, precision: 0.879 recall: 0.935 f1: 0.906 accuracy: 0.996 
training batch:   102, loss: 2.95520, precision: 0.862 recall: 0.833 f1: 0.847 accuracy: 0.994 
training batch:   103, loss: 1.54805, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.998 
training batch:   104, loss: 0.68152, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:   105, loss: 2.49440, precision: 0.897 recall: 0.875 f1: 0.886 accuracy: 0.986 
training batch:   106, loss: 3.10367, precision: 0.844 recall: 0.900 f1: 0.871 accuracy: 0.991 
training batch:   107, loss: 0.41342, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   108, loss: 2.40973, precision: 1.000 recall: 0.917 f1: 0.957 accuracy: 0.993 
training batch:   109, loss: 1.00105, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.994 
training batch:   110, loss: 1.47737, precision: 0.958 recall: 0.939 f1: 0.948 accuracy: 0.994 
training batch:   111, loss: 0.49319, precision: 0.962 recall: 1.000 f1: 0.980 accuracy: 0.998 
training batch:   112, loss: 1.05780, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:   113, loss: 0.72696, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.998 
training batch:   114, loss: 0.62775, precision: 0.944 recall: 0.919 f1: 0.932 accuracy: 0.996 
training batch:   115, loss: 3.15726, precision: 0.950 recall: 0.927 f1: 0.938 accuracy: 0.988 
training batch:   116, loss: 0.26996, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   117, loss: 0.98486, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.998 
training batch:   118, loss: 1.13226, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.994 
training batch:   119, loss: 0.99890, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.996 
training batch:   120, loss: 1.50903, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.998 
training batch:   121, loss: 1.68744, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.998 
training batch:   122, loss: 2.16791, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.980 
training batch:   123, loss: 1.86143, precision: 0.886 recall: 0.939 f1: 0.912 accuracy: 0.991 
training batch:   124, loss: 2.60191, precision: 0.964 recall: 0.931 f1: 0.947 accuracy: 0.998 
training batch:   125, loss: 0.83173, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:   126, loss: 1.25230, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.998 
training batch:   127, loss: 3.29881, precision: 0.886 recall: 0.969 f1: 0.925 accuracy: 0.989 
training batch:   128, loss: 1.63123, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.989 
training batch:   129, loss: 2.10744, precision: 0.886 recall: 0.912 f1: 0.899 accuracy: 0.989 
training batch:   130, loss: 1.35858, precision: 0.893 recall: 0.962 f1: 0.926 accuracy: 0.996 
training batch:   131, loss: 0.92480, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   132, loss: 0.51125, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.999 
training batch:   133, loss: 0.87308, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.999 
training batch:   134, loss: 0.83968, precision: 0.962 recall: 0.893 f1: 0.926 accuracy: 0.996 
training batch:   135, loss: 3.78262, precision: 0.882 recall: 0.909 f1: 0.896 accuracy: 0.976 
training batch:   136, loss: 1.31871, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.996 
training batch:   137, loss: 0.81371, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.998 
training batch:   138, loss: 2.25241, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.989 
training batch:   139, loss: 1.80939, precision: 0.895 recall: 1.000 f1: 0.944 accuracy: 0.990 
training batch:   140, loss: 0.55524, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:   141, loss: 1.80186, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.995 
training batch:   142, loss: 0.61130, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.998 
training batch:   143, loss: 1.02470, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.998 
training batch:   144, loss: 0.72359, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   145, loss: 1.58130, precision: 0.875 recall: 0.933 f1: 0.903 accuracy: 0.993 
training batch:   146, loss: 1.02817, precision: 0.903 recall: 0.875 f1: 0.889 accuracy: 0.995 
training batch:   147, loss: 2.40504, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.995 
training batch:   148, loss: 2.78780, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.988 
training batch:   149, loss: 1.52046, precision: 0.931 recall: 0.931 f1: 0.931 accuracy: 0.993 
training batch:   150, loss: 0.17015, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   151, loss: 3.90160, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.991 
training batch:   152, loss: 1.45671, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.995 
training batch:   153, loss: 2.80981, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.983 
training batch:   154, loss: 0.43713, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.998 
training batch:   155, loss: 1.85136, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.993 
training batch:   156, loss: 0.57014, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   157, loss: 1.66808, precision: 0.977 recall: 0.955 f1: 0.966 accuracy: 0.996 
training batch:   158, loss: 2.91895, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.985 
training batch:   159, loss: 2.45660, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.993 
training batch:   160, loss: 2.85104, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.993 
training batch:   161, loss: 2.70668, precision: 0.921 recall: 1.000 f1: 0.959 accuracy: 0.986 
training batch:   162, loss: 1.90617, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.993 
training batch:   163, loss: 2.75348, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.990 
training batch:   164, loss: 0.36205, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:   165, loss: 3.62871, precision: 0.880 recall: 0.846 f1: 0.863 accuracy: 0.980 
training batch:   166, loss: 2.88560, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.981 
training batch:   167, loss: 2.39473, precision: 0.870 recall: 0.870 f1: 0.870 accuracy: 0.990 
training batch:   168, loss: 0.59555, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:   169, loss: 0.85847, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.996 
training batch:   170, loss: 4.97569, precision: 0.875 recall: 0.921 f1: 0.897 accuracy: 0.980 
training batch:   171, loss: 0.73770, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.996 
training batch:   172, loss: 1.71056, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.998 
training batch:   173, loss: 1.07533, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.995 
training batch:   174, loss: 0.37335, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:   175, loss: 2.07765, precision: 0.905 recall: 0.974 f1: 0.938 accuracy: 0.993 
training batch:   176, loss: 2.29201, precision: 0.868 recall: 0.846 f1: 0.857 accuracy: 0.990 
training batch:   177, loss: 2.87070, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.981 
training batch:   178, loss: 1.51208, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.993 
start evaluate engines...
label: Dsa, precision: 0.754 recall: 0.772 f1: 0.758 
label: Chk, precision: 0.750 recall: 0.767 f1: 0.747 
label: Ins, precision: 0.383 recall: 0.408 f1: 0.385 
label: Sur, precision: 0.793 recall: 0.871 f1: 0.825 
label: Med, precision: 0.362 recall: 0.355 f1: 0.350 
label: Ana, precision: 0.838 recall: 0.839 f1: 0.836 
time consumption:2.69(min), precision: 0.823 recall: 0.842 f1: 0.831 accuracy: 0.965 
epoch:21/100
training batch:     1, loss: 0.50449, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:     2, loss: 1.25793, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.996 
training batch:     3, loss: 2.89464, precision: 0.972 recall: 0.921 f1: 0.946 accuracy: 0.990 
training batch:     4, loss: 1.54152, precision: 0.886 recall: 0.912 f1: 0.899 accuracy: 0.995 
training batch:     5, loss: 0.40866, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:     6, loss: 2.36418, precision: 0.976 recall: 0.953 f1: 0.965 accuracy: 0.983 
training batch:     7, loss: 0.51013, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:     8, loss: 1.47035, precision: 0.880 recall: 1.000 f1: 0.936 accuracy: 0.990 
training batch:     9, loss: 1.20317, precision: 0.951 recall: 1.000 f1: 0.975 accuracy: 0.995 
training batch:    10, loss: 3.41577, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.983 
training batch:    11, loss: 2.40573, precision: 0.933 recall: 0.955 f1: 0.944 accuracy: 0.989 
training batch:    12, loss: 2.65326, precision: 0.976 recall: 0.932 f1: 0.953 accuracy: 0.994 
training batch:    13, loss: 2.50894, precision: 0.933 recall: 0.903 f1: 0.918 accuracy: 0.985 
training batch:    14, loss: 1.09393, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.996 
training batch:    15, loss: 1.55032, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.994 
training batch:    16, loss: 1.82755, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.978 
training batch:    17, loss: 0.65230, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.999 
training batch:    18, loss: 1.16545, precision: 0.951 recall: 0.929 f1: 0.940 accuracy: 0.995 
training batch:    19, loss: 1.37881, precision: 0.875 recall: 0.913 f1: 0.894 accuracy: 0.995 
training batch:    20, loss: 1.16733, precision: 0.969 recall: 0.912 f1: 0.939 accuracy: 0.995 
training batch:    21, loss: 1.16577, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.990 
training batch:    22, loss: 1.01099, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.996 
training batch:    23, loss: 0.78227, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.999 
training batch:    24, loss: 1.59616, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.994 
training batch:    25, loss: 1.28525, precision: 0.850 recall: 0.919 f1: 0.883 accuracy: 0.995 
training batch:    26, loss: 0.39670, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.999 
training batch:    27, loss: 1.80389, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.995 
training batch:    28, loss: 1.30762, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.998 
training batch:    29, loss: 2.28801, precision: 0.969 recall: 0.838 f1: 0.899 accuracy: 0.994 
training batch:    30, loss: 1.90279, precision: 0.935 recall: 0.906 f1: 0.921 accuracy: 0.991 
training batch:    31, loss: 0.35281, precision: 0.977 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:    32, loss: 1.07559, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.996 
training batch:    33, loss: 2.25945, precision: 0.938 recall: 0.882 f1: 0.909 accuracy: 0.990 
training batch:    34, loss: 0.89001, precision: 0.955 recall: 1.000 f1: 0.977 accuracy: 0.998 
training batch:    35, loss: 0.64917, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    36, loss: 0.60918, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:    37, loss: 0.54588, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    38, loss: 1.68573, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.993 
training batch:    39, loss: 0.98482, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.998 
training batch:    40, loss: 0.70451, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.998 
training batch:    41, loss: 1.78152, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:    42, loss: 1.72343, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.996 
training batch:    43, loss: 0.81494, precision: 0.932 recall: 0.976 f1: 0.953 accuracy: 0.996 
training batch:    44, loss: 1.21742, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.995 
training batch:    45, loss: 2.04230, precision: 0.933 recall: 0.894 f1: 0.913 accuracy: 0.993 
training batch:    46, loss: 2.16499, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.980 
training batch:    47, loss: 0.30269, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    48, loss: 0.85104, precision: 1.000 recall: 0.941 f1: 0.970 accuracy: 0.996 
training batch:    49, loss: 1.18890, precision: 0.969 recall: 0.912 f1: 0.939 accuracy: 0.996 
training batch:    50, loss: 0.56670, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.996 
training batch:    51, loss: 0.51706, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    52, loss: 0.35818, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    53, loss: 3.03915, precision: 0.825 recall: 0.846 f1: 0.835 accuracy: 0.981 
training batch:    54, loss: 1.62335, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.996 
training batch:    55, loss: 0.72206, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.999 
training batch:    56, loss: 2.26753, precision: 0.865 recall: 0.941 f1: 0.901 accuracy: 0.994 
training batch:    57, loss: 1.51259, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.996 
training batch:    58, loss: 0.81029, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.998 
training batch:    59, loss: 0.34708, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:    60, loss: 1.09145, precision: 0.926 recall: 1.000 f1: 0.962 accuracy: 0.998 
training batch:    61, loss: 3.75168, precision: 0.933 recall: 0.966 f1: 0.949 accuracy: 0.990 
training batch:    62, loss: 0.37621, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.998 
training batch:    63, loss: 1.14388, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.994 
training batch:    64, loss: 1.74118, precision: 0.930 recall: 0.930 f1: 0.930 accuracy: 0.986 
training batch:    65, loss: 1.71976, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.996 
training batch:    66, loss: 1.35831, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.989 
training batch:    67, loss: 1.58661, precision: 0.969 recall: 0.886 f1: 0.925 accuracy: 0.995 
training batch:    68, loss: 1.04161, precision: 1.000 recall: 0.941 f1: 0.970 accuracy: 0.998 
training batch:    69, loss: 2.62155, precision: 0.852 recall: 0.852 f1: 0.852 accuracy: 0.988 
training batch:    70, loss: 3.63681, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.973 
training batch:    71, loss: 1.34264, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.994 
training batch:    72, loss: 1.40759, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.998 
training batch:    73, loss: 0.48672, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    74, loss: 1.04491, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.996 
training batch:    75, loss: 0.98720, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.998 
training batch:    76, loss: 0.79108, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    77, loss: 1.43304, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.994 
training batch:    78, loss: 1.12062, precision: 0.915 recall: 0.935 f1: 0.925 accuracy: 0.994 
training batch:    79, loss: 0.44096, precision: 0.977 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:    80, loss: 1.33272, precision: 0.925 recall: 1.000 f1: 0.961 accuracy: 0.994 
training batch:    81, loss: 0.17519, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    82, loss: 0.35818, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    83, loss: 1.05373, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.996 
training batch:    84, loss: 0.57669, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:    85, loss: 0.68269, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:    86, loss: 1.13791, precision: 0.947 recall: 0.973 f1: 0.960 accuracy: 0.998 
training batch:    87, loss: 1.08043, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.995 
training batch:    88, loss: 1.54401, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:    89, loss: 0.66542, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.996 
training batch:    90, loss: 1.02754, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.996 
training batch:    91, loss: 0.83772, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.999 
training batch:    92, loss: 1.58440, precision: 1.000 recall: 0.903 f1: 0.949 accuracy: 0.994 
training batch:    93, loss: 0.67076, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.999 
training batch:    94, loss: 1.37285, precision: 0.938 recall: 0.857 f1: 0.896 accuracy: 0.995 
training batch:    95, loss: 0.28902, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    96, loss: 0.16380, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    97, loss: 0.96431, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.996 
training batch:    98, loss: 1.10196, precision: 0.943 recall: 0.892 f1: 0.917 accuracy: 0.995 
training batch:    99, loss: 1.42218, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.996 
training batch:   100, loss: 1.81795, precision: 0.940 recall: 0.959 f1: 0.949 accuracy: 0.993 
training batch:   101, loss: 0.66620, precision: 0.977 recall: 1.000 f1: 0.989 accuracy: 0.998 
training batch:   102, loss: 1.92232, precision: 0.927 recall: 0.974 f1: 0.950 accuracy: 0.996 
training batch:   103, loss: 4.62097, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.985 
training batch:   104, loss: 0.71780, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.998 
training batch:   105, loss: 0.24371, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   106, loss: 1.64751, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.998 
training batch:   107, loss: 0.45462, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.999 
training batch:   108, loss: 1.58119, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.995 
training batch:   109, loss: 2.99207, precision: 0.912 recall: 0.912 f1: 0.912 accuracy: 0.983 
training batch:   110, loss: 0.28604, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   111, loss: 0.93971, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.999 
training batch:   112, loss: 0.25035, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.999 
training batch:   113, loss: 2.12889, precision: 0.853 recall: 0.906 f1: 0.879 accuracy: 0.991 
training batch:   114, loss: 1.35741, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.989 
training batch:   115, loss: 0.35284, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   116, loss: 2.03560, precision: 1.000 recall: 0.929 f1: 0.963 accuracy: 0.998 
training batch:   117, loss: 0.24022, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   118, loss: 1.58467, precision: 0.905 recall: 0.826 f1: 0.864 accuracy: 0.991 
training batch:   119, loss: 1.61504, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.973 
training batch:   120, loss: 2.16345, precision: 0.889 recall: 0.865 f1: 0.877 accuracy: 0.990 
training batch:   121, loss: 1.16348, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.998 
training batch:   122, loss: 1.40460, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.993 
training batch:   123, loss: 3.65126, precision: 0.920 recall: 0.852 f1: 0.885 accuracy: 0.979 
training batch:   124, loss: 1.43095, precision: 0.871 recall: 0.931 f1: 0.900 accuracy: 0.994 
training batch:   125, loss: 0.98590, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.996 
training batch:   126, loss: 1.30145, precision: 0.941 recall: 0.980 f1: 0.960 accuracy: 0.995 
training batch:   127, loss: 1.26117, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.995 
training batch:   128, loss: 1.06467, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.996 
training batch:   129, loss: 1.04456, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.996 
training batch:   130, loss: 1.47699, precision: 0.957 recall: 1.000 f1: 0.978 accuracy: 0.995 
training batch:   131, loss: 0.34515, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   132, loss: 1.75102, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.995 
training batch:   133, loss: 1.76523, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.990 
training batch:   134, loss: 1.50894, precision: 0.967 recall: 0.906 f1: 0.935 accuracy: 0.994 
training batch:   135, loss: 2.82156, precision: 0.824 recall: 0.933 f1: 0.875 accuracy: 0.993 
training batch:   136, loss: 2.15497, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.991 
training batch:   137, loss: 2.44989, precision: 0.900 recall: 0.964 f1: 0.931 accuracy: 0.990 
training batch:   138, loss: 1.73340, precision: 0.971 recall: 0.917 f1: 0.943 accuracy: 0.994 
training batch:   139, loss: 2.23071, precision: 0.973 recall: 1.000 f1: 0.986 accuracy: 0.993 
training batch:   140, loss: 0.51595, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.999 
training batch:   141, loss: 1.01627, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.999 
training batch:   142, loss: 1.31799, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.995 
training batch:   143, loss: 0.38272, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.999 
training batch:   144, loss: 0.94879, precision: 0.951 recall: 0.929 f1: 0.940 accuracy: 0.993 
training batch:   145, loss: 1.13191, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.995 
training batch:   146, loss: 3.52539, precision: 0.857 recall: 0.837 f1: 0.847 accuracy: 0.976 
training batch:   147, loss: 0.56830, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.999 
training batch:   148, loss: 3.62291, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.991 
training batch:   149, loss: 1.78610, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.994 
training batch:   150, loss: 1.52716, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.996 
training batch:   151, loss: 1.51801, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.990 
training batch:   152, loss: 1.33821, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.996 
training batch:   153, loss: 0.21741, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   154, loss: 0.78406, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.995 
training batch:   155, loss: 0.26791, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   156, loss: 1.54262, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.995 
training batch:   157, loss: 1.91718, precision: 0.925 recall: 0.974 f1: 0.949 accuracy: 0.996 
training batch:   158, loss: 0.66389, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.998 
training batch:   159, loss: 0.49791, precision: 0.935 recall: 0.967 f1: 0.951 accuracy: 0.998 
training batch:   160, loss: 0.71619, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.993 
training batch:   161, loss: 1.25571, precision: 1.000 recall: 0.941 f1: 0.970 accuracy: 0.995 
training batch:   162, loss: 3.18640, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.988 
training batch:   163, loss: 0.44070, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   164, loss: 1.05305, precision: 0.963 recall: 0.963 f1: 0.963 accuracy: 0.998 
training batch:   165, loss: 0.70222, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.998 
training batch:   166, loss: 1.08408, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.996 
training batch:   167, loss: 0.74826, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:   168, loss: 0.58368, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.996 
training batch:   169, loss: 3.02359, precision: 0.921 recall: 0.946 f1: 0.933 accuracy: 0.991 
training batch:   170, loss: 4.19751, precision: 0.818 recall: 0.871 f1: 0.844 accuracy: 0.976 
training batch:   171, loss: 4.10027, precision: 0.828 recall: 0.857 f1: 0.842 accuracy: 0.969 
training batch:   172, loss: 0.71307, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.998 
training batch:   173, loss: 1.94727, precision: 0.955 recall: 1.000 f1: 0.977 accuracy: 0.994 
training batch:   174, loss: 1.95493, precision: 0.848 recall: 0.848 f1: 0.848 accuracy: 0.991 
training batch:   175, loss: 1.46829, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   176, loss: 1.19917, precision: 0.929 recall: 0.897 f1: 0.912 accuracy: 0.995 
training batch:   177, loss: 1.17250, precision: 1.000 recall: 0.923 f1: 0.960 accuracy: 0.994 
training batch:   178, loss: 0.63867, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.997 
start evaluate engines...
label: Dsa, precision: 0.808 recall: 0.792 f1: 0.794 
label: Chk, precision: 0.758 recall: 0.750 f1: 0.738 
label: Ins, precision: 0.341 recall: 0.325 f1: 0.316 
label: Sur, precision: 0.884 recall: 0.908 f1: 0.892 
label: Med, precision: 0.355 recall: 0.380 f1: 0.363 
label: Ana, precision: 0.813 recall: 0.823 f1: 0.815 
time consumption:2.69(min), precision: 0.837 recall: 0.844 f1: 0.839 accuracy: 0.967 
epoch:22/100
training batch:     1, loss: 2.27158, precision: 0.843 recall: 0.827 f1: 0.835 accuracy: 0.989 
training batch:     2, loss: 0.96074, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.998 
training batch:     3, loss: 0.52988, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:     4, loss: 0.88680, precision: 0.978 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:     5, loss: 0.45247, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.999 
training batch:     6, loss: 0.62825, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.996 
training batch:     7, loss: 1.00015, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.995 
training batch:     8, loss: 0.77182, precision: 0.938 recall: 1.000 f1: 0.968 accuracy: 0.998 
training batch:     9, loss: 1.61266, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.989 
training batch:    10, loss: 1.52092, precision: 0.923 recall: 0.973 f1: 0.947 accuracy: 0.995 
training batch:    11, loss: 0.85780, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    12, loss: 0.68156, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    13, loss: 0.48851, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    14, loss: 0.39539, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    15, loss: 1.79318, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.994 
training batch:    16, loss: 2.60635, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.996 
training batch:    17, loss: 0.68604, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:    18, loss: 0.71162, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:    19, loss: 2.98140, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.985 
training batch:    20, loss: 0.97255, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.998 
training batch:    21, loss: 2.08182, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.991 
training batch:    22, loss: 0.28572, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    23, loss: 0.88075, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.996 
training batch:    24, loss: 0.99080, precision: 0.970 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:    25, loss: 0.94223, precision: 0.938 recall: 0.968 f1: 0.952 accuracy: 0.998 
training batch:    26, loss: 0.88022, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.998 
training batch:    27, loss: 1.67772, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.993 
training batch:    28, loss: 3.34578, precision: 0.922 recall: 0.922 f1: 0.922 accuracy: 0.989 
training batch:    29, loss: 1.33258, precision: 0.912 recall: 0.838 f1: 0.873 accuracy: 0.994 
training batch:    30, loss: 2.62032, precision: 0.906 recall: 0.967 f1: 0.935 accuracy: 0.994 
training batch:    31, loss: 0.60042, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.996 
training batch:    32, loss: 0.15150, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    33, loss: 0.97050, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.998 
training batch:    34, loss: 0.45964, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    35, loss: 0.66206, precision: 1.000 recall: 0.939 f1: 0.969 accuracy: 0.996 
training batch:    36, loss: 1.81224, precision: 1.000 recall: 0.933 f1: 0.966 accuracy: 0.993 
training batch:    37, loss: 1.70467, precision: 1.000 recall: 0.953 f1: 0.976 accuracy: 0.990 
training batch:    38, loss: 2.03214, precision: 1.000 recall: 0.938 f1: 0.968 accuracy: 0.988 
training batch:    39, loss: 1.79364, precision: 0.920 recall: 0.958 f1: 0.939 accuracy: 0.995 
training batch:    40, loss: 0.29787, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    41, loss: 1.80170, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.990 
training batch:    42, loss: 1.66850, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    43, loss: 1.18555, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.998 
training batch:    44, loss: 0.55006, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    45, loss: 0.66608, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.999 
training batch:    46, loss: 0.37793, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    47, loss: 1.63063, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.998 
training batch:    48, loss: 1.25927, precision: 0.935 recall: 1.000 f1: 0.967 accuracy: 0.990 
training batch:    49, loss: 0.51349, precision: 1.000 recall: 0.970 f1: 0.985 accuracy: 0.995 
training batch:    50, loss: 1.54137, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.993 
training batch:    51, loss: 1.27119, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.996 
training batch:    52, loss: 0.43365, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.999 
training batch:    53, loss: 0.58838, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    54, loss: 1.44371, precision: 0.932 recall: 1.000 f1: 0.965 accuracy: 0.994 
training batch:    55, loss: 3.15744, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.988 
training batch:    56, loss: 0.25337, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    57, loss: 1.06372, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.995 
training batch:    58, loss: 0.50096, precision: 0.968 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:    59, loss: 0.61061, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.999 
training batch:    60, loss: 3.15720, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.986 
training batch:    61, loss: 2.37456, precision: 0.897 recall: 0.897 f1: 0.897 accuracy: 0.985 
training batch:    62, loss: 0.55630, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.998 
training batch:    63, loss: 0.48233, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:    64, loss: 1.28505, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.996 
training batch:    65, loss: 0.54597, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.996 
training batch:    66, loss: 0.51692, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.998 
training batch:    67, loss: 0.50935, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.999 
training batch:    68, loss: 1.69873, precision: 0.968 recall: 0.938 f1: 0.952 accuracy: 0.998 
training batch:    69, loss: 1.56520, precision: 0.978 recall: 0.936 f1: 0.957 accuracy: 0.996 
training batch:    70, loss: 0.16109, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    71, loss: 2.64320, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.984 
training batch:    72, loss: 0.98643, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.995 
training batch:    73, loss: 2.09073, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    74, loss: 0.63406, precision: 0.963 recall: 0.929 f1: 0.945 accuracy: 0.996 
training batch:    75, loss: 8.89424, precision: 0.895 recall: 0.944 f1: 0.919 accuracy: 0.981 
training batch:    76, loss: 2.77968, precision: 0.923 recall: 1.000 f1: 0.960 accuracy: 0.996 
training batch:    77, loss: 0.57040, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:    78, loss: 2.20818, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.989 
training batch:    79, loss: 0.64104, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.999 
training batch:    80, loss: 0.86943, precision: 0.958 recall: 0.979 f1: 0.968 accuracy: 0.993 
training batch:    81, loss: 0.30681, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    82, loss: 1.21930, precision: 0.952 recall: 0.976 f1: 0.964 accuracy: 0.996 
training batch:    83, loss: 1.03528, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.995 
training batch:    84, loss: 0.45512, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.998 
training batch:    85, loss: 0.59190, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    86, loss: 0.72408, precision: 1.000 recall: 0.964 f1: 0.982 accuracy: 0.996 
training batch:    87, loss: 0.72823, precision: 1.000 recall: 0.969 f1: 0.984 accuracy: 0.999 
training batch:    88, loss: 0.36470, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    89, loss: 0.74294, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.998 
training batch:    90, loss: 0.67346, precision: 0.974 recall: 0.949 f1: 0.961 accuracy: 0.996 
training batch:    91, loss: 0.27148, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    92, loss: 1.08417, precision: 0.950 recall: 1.000 f1: 0.974 accuracy: 0.995 
training batch:    93, loss: 1.50996, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.996 
training batch:    94, loss: 3.57455, precision: 0.927 recall: 0.905 f1: 0.916 accuracy: 0.979 
training batch:    95, loss: 2.33766, precision: 0.903 recall: 0.933 f1: 0.918 accuracy: 0.991 
training batch:    96, loss: 0.32568, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    97, loss: 1.82149, precision: 0.927 recall: 0.905 f1: 0.916 accuracy: 0.990 
training batch:    98, loss: 0.79501, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.995 
training batch:    99, loss: 1.56772, precision: 0.929 recall: 0.897 f1: 0.912 accuracy: 0.996 
training batch:   100, loss: 1.22728, precision: 0.979 recall: 0.940 f1: 0.959 accuracy: 0.995 
training batch:   101, loss: 1.38701, precision: 0.879 recall: 0.906 f1: 0.892 accuracy: 0.995 
training batch:   102, loss: 1.88255, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:   103, loss: 1.61005, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.994 
training batch:   104, loss: 0.33971, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   105, loss: 0.63817, precision: 0.976 recall: 0.953 f1: 0.965 accuracy: 0.998 
training batch:   106, loss: 1.36185, precision: 0.956 recall: 0.935 f1: 0.945 accuracy: 0.993 
training batch:   107, loss: 1.79378, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.993 
training batch:   108, loss: 1.10019, precision: 0.879 recall: 0.967 f1: 0.921 accuracy: 0.995 
training batch:   109, loss: 1.08548, precision: 0.972 recall: 1.000 f1: 0.986 accuracy: 0.999 
training batch:   110, loss: 1.49541, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.991 
training batch:   111, loss: 1.35909, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.996 
training batch:   112, loss: 1.37814, precision: 0.953 recall: 0.976 f1: 0.965 accuracy: 0.994 
training batch:   113, loss: 0.72694, precision: 0.947 recall: 1.000 f1: 0.973 accuracy: 0.996 
training batch:   114, loss: 1.36497, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.980 
training batch:   115, loss: 1.46515, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.989 
training batch:   116, loss: 2.20512, precision: 0.930 recall: 0.930 f1: 0.930 accuracy: 0.990 
training batch:   117, loss: 1.07886, precision: 0.923 recall: 1.000 f1: 0.960 accuracy: 0.995 
training batch:   118, loss: 1.19295, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.989 
training batch:   119, loss: 1.66676, precision: 0.920 recall: 0.885 f1: 0.902 accuracy: 0.993 
training batch:   120, loss: 0.87563, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.993 
training batch:   121, loss: 2.49057, precision: 0.917 recall: 0.868 f1: 0.892 accuracy: 0.986 
training batch:   122, loss: 0.78284, precision: 0.963 recall: 0.929 f1: 0.945 accuracy: 0.994 
training batch:   123, loss: 2.30643, precision: 0.905 recall: 0.905 f1: 0.905 accuracy: 0.990 
training batch:   124, loss: 0.52971, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.996 
training batch:   125, loss: 0.33720, precision: 1.000 recall: 0.964 f1: 0.982 accuracy: 0.999 
training batch:   126, loss: 2.82692, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.974 
training batch:   127, loss: 1.33891, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.995 
training batch:   128, loss: 1.94494, precision: 0.976 recall: 0.952 f1: 0.964 accuracy: 0.981 
training batch:   129, loss: 1.32306, precision: 0.951 recall: 1.000 f1: 0.975 accuracy: 0.996 
training batch:   130, loss: 2.06331, precision: 0.882 recall: 0.909 f1: 0.896 accuracy: 0.993 
training batch:   131, loss: 2.59163, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.998 
training batch:   132, loss: 0.66692, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:   133, loss: 0.66277, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   134, loss: 0.38219, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   135, loss: 0.13649, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   136, loss: 1.37363, precision: 0.972 recall: 0.921 f1: 0.946 accuracy: 0.998 
training batch:   137, loss: 0.66150, precision: 0.963 recall: 0.929 f1: 0.945 accuracy: 0.996 
training batch:   138, loss: 0.80762, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.998 
training batch:   139, loss: 0.93576, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.998 
training batch:   140, loss: 1.18405, precision: 0.957 recall: 0.978 f1: 0.967 accuracy: 0.999 
training batch:   141, loss: 0.50995, precision: 0.941 recall: 1.000 f1: 0.970 accuracy: 0.998 
training batch:   142, loss: 0.55281, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.998 
training batch:   143, loss: 2.06523, precision: 0.892 recall: 0.917 f1: 0.904 accuracy: 0.978 
training batch:   144, loss: 1.30373, precision: 0.938 recall: 0.957 f1: 0.947 accuracy: 0.989 
training batch:   145, loss: 0.96632, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.998 
training batch:   146, loss: 2.66905, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.981 
training batch:   147, loss: 0.80554, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.999 
training batch:   148, loss: 1.47040, precision: 0.917 recall: 0.936 f1: 0.926 accuracy: 0.989 
training batch:   149, loss: 2.63370, precision: 0.822 recall: 0.974 f1: 0.892 accuracy: 0.989 
training batch:   150, loss: 0.74918, precision: 0.955 recall: 0.977 f1: 0.966 accuracy: 0.996 
training batch:   151, loss: 0.57408, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.999 
training batch:   152, loss: 1.04941, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.998 
training batch:   153, loss: 1.04860, precision: 0.900 recall: 0.900 f1: 0.900 accuracy: 0.994 
training batch:   154, loss: 0.52304, precision: 0.962 recall: 1.000 f1: 0.980 accuracy: 0.999 
training batch:   155, loss: 0.55469, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.998 
training batch:   156, loss: 1.42896, precision: 0.903 recall: 0.848 f1: 0.875 accuracy: 0.994 
training batch:   157, loss: 3.87726, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.975 
training batch:   158, loss: 0.25449, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   159, loss: 0.60632, precision: 1.000 recall: 0.925 f1: 0.961 accuracy: 0.996 
training batch:   160, loss: 1.75293, precision: 0.970 recall: 0.914 f1: 0.941 accuracy: 0.996 
training batch:   161, loss: 0.84631, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.998 
training batch:   162, loss: 0.22800, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   163, loss: 1.05368, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.998 
training batch:   164, loss: 0.88638, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.999 
training batch:   165, loss: 0.45560, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   166, loss: 0.79800, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   167, loss: 1.39467, precision: 0.857 recall: 0.923 f1: 0.889 accuracy: 0.991 
training batch:   168, loss: 1.36278, precision: 0.939 recall: 1.000 f1: 0.969 accuracy: 0.995 
training batch:   169, loss: 4.22273, precision: 0.795 recall: 0.939 f1: 0.861 accuracy: 0.980 
training batch:   170, loss: 0.19975, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   171, loss: 2.28978, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.991 
training batch:   172, loss: 0.71255, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   173, loss: 0.22168, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   174, loss: 1.39606, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.999 
training batch:   175, loss: 1.93794, precision: 1.000 recall: 0.972 f1: 0.986 accuracy: 0.991 
training batch:   176, loss: 1.28575, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.998 
training batch:   177, loss: 1.32413, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.991 
training batch:   178, loss: 2.72380, precision: 0.909 recall: 0.833 f1: 0.870 accuracy: 0.990 
start evaluate engines...
label: Dsa, precision: 0.803 recall: 0.739 f1: 0.764 
label: Chk, precision: 0.700 recall: 0.690 f1: 0.676 
label: Ins, precision: 0.383 recall: 0.287 f1: 0.308 
label: Sur, precision: 0.868 recall: 0.883 f1: 0.873 
label: Med, precision: 0.400 recall: 0.425 f1: 0.408 
label: Ana, precision: 0.839 recall: 0.846 f1: 0.840 
time consumption:2.71(min), precision: 0.848 recall: 0.833 f1: 0.840 accuracy: 0.968 
early stopped, no progress obtained within 5 epochs
overall best f1 is 0.8625247064859748 at 17 epoch
total training time consumption: 80.323(min)
